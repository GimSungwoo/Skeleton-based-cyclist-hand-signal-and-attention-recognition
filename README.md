# Spatial Temporal Graph Convolutional Networks (ST-GCN)

## main files
	'work_dir' - includes the trained model
	'convert-openpose' - includes the Python scripts which can generate the skeleton dataset using the output of Openpose
	'config' - includes the configuration files of the test or training.

## Prerequisites
- PyTorch
- NumPy
- Other Python libraries can be installed by `pip install -r requirements.txt`

## Data Preparation
Download the skeleton datasets which are generated by Openpose:
1. Cyclist skeleton dataset: 
		https://pan.baidu.com/s/1htbqWI0srX5A38xQu_xh5A
2. Kinetics skeleton dataset: 
		https://s3-us-west-1.amazonaws.com/yysijie-data/public/kinetics-skeleton/kinetics-skeleton.zip
or download the original video dataset and then generate the skeletons by Openpose
0. Openpose:
		https://github.com/CMU-Perceptual-Computing-Lab/openpose
1. Cyclist video dataset: 
		https://pan.baidu.com/s/1MylaSe7qgcPFEP775UIkxw
2. Kinetics video dataset: 
		https://deepmind.com/research/open-source/open-source-datasets/kinetics/

##  Testing Pretrained Models
		python main.py --config config/st_gcn/<dataset>/test.yaml
1. To evaluate ST-GCN model pretrained on **cyclist**, run
		python main.py --config config/st_gcn/cyclist/test.yaml
2. To evaluate ST-GCN model pretrained on **Kinetcis-skeleton**, run
		python main.py --config config/st_gcn/kinetics-skeleton/test.yaml
3. Similary, the configuration file for testing baseline models can be found under the 
		`./config/baseline`.
4. To speed up evaluation by multi-gpu inference or modify batch size for reducing the memory cost, set ```--test-batch-size``` and ```--device``` like:
		python main.py --config <config file> --test-batch-size <batch size> --device <gpu0> <gpu1> ...

## Training
To train a new ST-GCN model, run 
		python main.py --config config/st_gcn/<dataset>/train.yaml [--work-dir <work folder>]

## Citation
@inproceedings{stgcn2018aaai,
  title     = {Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition},
  author    = {Sijie Yan and Yuanjun Xiong and Dahua Lin},
  booktitle = {AAAI},
  year      = {2018},
}

