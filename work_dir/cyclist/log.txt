[ Wed Apr 25 09:14:18 2018 ] Parameters:
{'work_dir': 'work_dir/cyclist', 'config': 'config/st_gcn/cyclist/train.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 500, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'st_gcn.feeder.Feeder_kinetics', 'num_worker': 128, 'train_feeder_args': {'mode': 'train', 'data_path': './convert-openpose/cyclist_st-gcn_format/train', 'label_path': './convert-openpose/cyclist_labels/train.json', 'random_choose': True, 'random_move': True, 'window_size': 150}, 'test_feeder_args': {'mode': 'test', 'data_path': './convert-openpose/cyclist_st-gcn_format/test', 'label_path': './convert-openpose/cyclist_labels/test.json', 'window_size': 150}, 'model': 'st_gcn.net.ST_GCN', 'model_args': {'num_class': 3, 'channel': 3, 'window_size': 150, 'num_person': 2, 'num_point': 18, 'dropout': 0, 'graph': 'st_gcn.graph.Kinetics', 'graph_args': {'labeling_mode': 'spatial'}, 'mask_learning': True, 'use_data_bn': True}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [2000, 3000, 4000, 5000], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 6000, 'weight_decay': 0.0001}

[ Wed Apr 25 09:14:18 2018 ] Training epoch: 1
[ Wed Apr 25 09:14:25 2018 ] 	Batch(0/1) done. Loss: 19.2616  lr:0.100000
[ Wed Apr 25 09:14:25 2018 ] 	Mean training loss: 19.2616.
[ Wed Apr 25 09:14:25 2018 ] 	Time consumption: [Data]40%, [Network]60%
[ Wed Apr 25 09:14:25 2018 ] Training epoch: 2
[ Wed Apr 25 09:14:29 2018 ] 	Batch(0/1) done. Loss: 17.2203  lr:0.100000
[ Wed Apr 25 09:14:29 2018 ] 	Mean training loss: 17.2203.
[ Wed Apr 25 09:14:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:14:29 2018 ] Training epoch: 3
[ Wed Apr 25 09:14:33 2018 ] 	Batch(0/1) done. Loss: 22.8005  lr:0.100000
[ Wed Apr 25 09:14:33 2018 ] 	Mean training loss: 22.8005.
[ Wed Apr 25 09:14:33 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:14:33 2018 ] Training epoch: 4
[ Wed Apr 25 09:14:36 2018 ] 	Batch(0/1) done. Loss: 6.0378  lr:0.100000
[ Wed Apr 25 09:14:36 2018 ] 	Mean training loss: 6.0378.
[ Wed Apr 25 09:14:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:14:36 2018 ] Training epoch: 5
[ Wed Apr 25 09:14:41 2018 ] 	Batch(0/1) done. Loss: 1.4107  lr:0.100000
[ Wed Apr 25 09:14:41 2018 ] 	Mean training loss: 1.4107.
[ Wed Apr 25 09:14:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:14:41 2018 ] Eval epoch: 5
[ Wed Apr 25 09:14:44 2018 ] 	Mean test loss of 1 batches: 25347.453125.
[ Wed Apr 25 09:14:44 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:14:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:14:44 2018 ] Training epoch: 6
[ Wed Apr 25 09:14:47 2018 ] 	Batch(0/1) done. Loss: 1.2965  lr:0.100000
[ Wed Apr 25 09:14:47 2018 ] 	Mean training loss: 1.2965.
[ Wed Apr 25 09:14:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:14:47 2018 ] Training epoch: 7
[ Wed Apr 25 09:14:51 2018 ] 	Batch(0/1) done. Loss: 1.7396  lr:0.100000
[ Wed Apr 25 09:14:51 2018 ] 	Mean training loss: 1.7396.
[ Wed Apr 25 09:14:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:14:51 2018 ] Training epoch: 8
[ Wed Apr 25 09:14:55 2018 ] 	Batch(0/1) done. Loss: 1.3363  lr:0.100000
[ Wed Apr 25 09:14:55 2018 ] 	Mean training loss: 1.3363.
[ Wed Apr 25 09:14:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:14:55 2018 ] Training epoch: 9
[ Wed Apr 25 09:14:59 2018 ] 	Batch(0/1) done. Loss: 1.1601  lr:0.100000
[ Wed Apr 25 09:14:59 2018 ] 	Mean training loss: 1.1601.
[ Wed Apr 25 09:14:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:14:59 2018 ] Training epoch: 10
[ Wed Apr 25 09:15:03 2018 ] 	Batch(0/1) done. Loss: 1.9151  lr:0.100000
[ Wed Apr 25 09:15:03 2018 ] 	Mean training loss: 1.9151.
[ Wed Apr 25 09:15:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:15:03 2018 ] Eval epoch: 10
[ Wed Apr 25 09:15:06 2018 ] 	Mean test loss of 1 batches: 198.7109375.
[ Wed Apr 25 09:15:06 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:15:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:15:06 2018 ] Training epoch: 11
[ Wed Apr 25 09:15:10 2018 ] 	Batch(0/1) done. Loss: 1.1219  lr:0.100000
[ Wed Apr 25 09:15:10 2018 ] 	Mean training loss: 1.1219.
[ Wed Apr 25 09:15:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:15:10 2018 ] Training epoch: 12
[ Wed Apr 25 09:15:14 2018 ] 	Batch(0/1) done. Loss: 1.1851  lr:0.100000
[ Wed Apr 25 09:15:14 2018 ] 	Mean training loss: 1.1851.
[ Wed Apr 25 09:15:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:15:14 2018 ] Training epoch: 13
[ Wed Apr 25 09:15:18 2018 ] 	Batch(0/1) done. Loss: 1.1910  lr:0.100000
[ Wed Apr 25 09:15:18 2018 ] 	Mean training loss: 1.1910.
[ Wed Apr 25 09:15:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:15:18 2018 ] Training epoch: 14
[ Wed Apr 25 09:15:22 2018 ] 	Batch(0/1) done. Loss: 1.2047  lr:0.100000
[ Wed Apr 25 09:15:22 2018 ] 	Mean training loss: 1.2047.
[ Wed Apr 25 09:15:22 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:15:22 2018 ] Training epoch: 15
[ Wed Apr 25 09:15:26 2018 ] 	Batch(0/1) done. Loss: 1.0945  lr:0.100000
[ Wed Apr 25 09:15:26 2018 ] 	Mean training loss: 1.0945.
[ Wed Apr 25 09:15:26 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:15:26 2018 ] Eval epoch: 15
[ Wed Apr 25 09:15:29 2018 ] 	Mean test loss of 1 batches: 1.3966013193130493.
[ Wed Apr 25 09:15:29 2018 ] 	Top1: 48.15%
[ Wed Apr 25 09:15:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:15:29 2018 ] Training epoch: 16
[ Wed Apr 25 09:15:33 2018 ] 	Batch(0/1) done. Loss: 1.1509  lr:0.100000
[ Wed Apr 25 09:15:33 2018 ] 	Mean training loss: 1.1509.
[ Wed Apr 25 09:15:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:15:33 2018 ] Training epoch: 17
[ Wed Apr 25 09:15:37 2018 ] 	Batch(0/1) done. Loss: 1.1086  lr:0.100000
[ Wed Apr 25 09:15:37 2018 ] 	Mean training loss: 1.1086.
[ Wed Apr 25 09:15:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:15:37 2018 ] Training epoch: 18
[ Wed Apr 25 09:15:41 2018 ] 	Batch(0/1) done. Loss: 1.0536  lr:0.100000
[ Wed Apr 25 09:15:41 2018 ] 	Mean training loss: 1.0536.
[ Wed Apr 25 09:15:41 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:15:41 2018 ] Training epoch: 19
[ Wed Apr 25 09:15:45 2018 ] 	Batch(0/1) done. Loss: 1.0776  lr:0.100000
[ Wed Apr 25 09:15:45 2018 ] 	Mean training loss: 1.0776.
[ Wed Apr 25 09:15:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:15:45 2018 ] Training epoch: 20
[ Wed Apr 25 09:15:49 2018 ] 	Batch(0/1) done. Loss: 1.1061  lr:0.100000
[ Wed Apr 25 09:15:49 2018 ] 	Mean training loss: 1.1061.
[ Wed Apr 25 09:15:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:15:49 2018 ] Eval epoch: 20
[ Wed Apr 25 09:15:52 2018 ] 	Mean test loss of 1 batches: 1.1088767051696777.
[ Wed Apr 25 09:15:52 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:15:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:15:52 2018 ] Training epoch: 21
[ Wed Apr 25 09:15:56 2018 ] 	Batch(0/1) done. Loss: 1.0974  lr:0.100000
[ Wed Apr 25 09:15:56 2018 ] 	Mean training loss: 1.0974.
[ Wed Apr 25 09:15:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:15:56 2018 ] Training epoch: 22
[ Wed Apr 25 09:16:00 2018 ] 	Batch(0/1) done. Loss: 1.1094  lr:0.100000
[ Wed Apr 25 09:16:00 2018 ] 	Mean training loss: 1.1094.
[ Wed Apr 25 09:16:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:16:00 2018 ] Training epoch: 23
[ Wed Apr 25 09:16:04 2018 ] 	Batch(0/1) done. Loss: 1.0245  lr:0.100000
[ Wed Apr 25 09:16:04 2018 ] 	Mean training loss: 1.0245.
[ Wed Apr 25 09:16:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:16:04 2018 ] Training epoch: 24
[ Wed Apr 25 09:16:08 2018 ] 	Batch(0/1) done. Loss: 1.0654  lr:0.100000
[ Wed Apr 25 09:16:08 2018 ] 	Mean training loss: 1.0654.
[ Wed Apr 25 09:16:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:08 2018 ] Training epoch: 25
[ Wed Apr 25 09:16:12 2018 ] 	Batch(0/1) done. Loss: 1.0767  lr:0.100000
[ Wed Apr 25 09:16:12 2018 ] 	Mean training loss: 1.0767.
[ Wed Apr 25 09:16:12 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:16:12 2018 ] Eval epoch: 25
[ Wed Apr 25 09:16:15 2018 ] 	Mean test loss of 1 batches: 1.0884571075439453.
[ Wed Apr 25 09:16:15 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:16:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:16:15 2018 ] Training epoch: 26
[ Wed Apr 25 09:16:19 2018 ] 	Batch(0/1) done. Loss: 1.0822  lr:0.100000
[ Wed Apr 25 09:16:19 2018 ] 	Mean training loss: 1.0822.
[ Wed Apr 25 09:16:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:19 2018 ] Training epoch: 27
[ Wed Apr 25 09:16:23 2018 ] 	Batch(0/1) done. Loss: 1.0528  lr:0.100000
[ Wed Apr 25 09:16:23 2018 ] 	Mean training loss: 1.0528.
[ Wed Apr 25 09:16:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:23 2018 ] Training epoch: 28
[ Wed Apr 25 09:16:27 2018 ] 	Batch(0/1) done. Loss: 1.0471  lr:0.100000
[ Wed Apr 25 09:16:27 2018 ] 	Mean training loss: 1.0471.
[ Wed Apr 25 09:16:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:16:27 2018 ] Training epoch: 29
[ Wed Apr 25 09:16:31 2018 ] 	Batch(0/1) done. Loss: 1.0597  lr:0.100000
[ Wed Apr 25 09:16:31 2018 ] 	Mean training loss: 1.0597.
[ Wed Apr 25 09:16:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:31 2018 ] Training epoch: 30
[ Wed Apr 25 09:16:35 2018 ] 	Batch(0/1) done. Loss: 1.1143  lr:0.100000
[ Wed Apr 25 09:16:35 2018 ] 	Mean training loss: 1.1143.
[ Wed Apr 25 09:16:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:16:35 2018 ] Eval epoch: 30
[ Wed Apr 25 09:16:38 2018 ] 	Mean test loss of 1 batches: 1.107968807220459.
[ Wed Apr 25 09:16:38 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:16:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:16:38 2018 ] Training epoch: 31
[ Wed Apr 25 09:16:42 2018 ] 	Batch(0/1) done. Loss: 1.1170  lr:0.100000
[ Wed Apr 25 09:16:42 2018 ] 	Mean training loss: 1.1170.
[ Wed Apr 25 09:16:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:16:42 2018 ] Training epoch: 32
[ Wed Apr 25 09:16:46 2018 ] 	Batch(0/1) done. Loss: 1.0614  lr:0.100000
[ Wed Apr 25 09:16:46 2018 ] 	Mean training loss: 1.0614.
[ Wed Apr 25 09:16:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:16:46 2018 ] Training epoch: 33
[ Wed Apr 25 09:16:50 2018 ] 	Batch(0/1) done. Loss: 1.0689  lr:0.100000
[ Wed Apr 25 09:16:50 2018 ] 	Mean training loss: 1.0689.
[ Wed Apr 25 09:16:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:50 2018 ] Training epoch: 34
[ Wed Apr 25 09:16:54 2018 ] 	Batch(0/1) done. Loss: 1.0348  lr:0.100000
[ Wed Apr 25 09:16:54 2018 ] 	Mean training loss: 1.0348.
[ Wed Apr 25 09:16:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:54 2018 ] Training epoch: 35
[ Wed Apr 25 09:16:58 2018 ] 	Batch(0/1) done. Loss: 1.0511  lr:0.100000
[ Wed Apr 25 09:16:58 2018 ] 	Mean training loss: 1.0511.
[ Wed Apr 25 09:16:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:16:58 2018 ] Eval epoch: 35
[ Wed Apr 25 09:17:01 2018 ] 	Mean test loss of 1 batches: 1.0893045663833618.
[ Wed Apr 25 09:17:01 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:17:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:17:01 2018 ] Training epoch: 36
[ Wed Apr 25 09:17:05 2018 ] 	Batch(0/1) done. Loss: 1.1054  lr:0.100000
[ Wed Apr 25 09:17:05 2018 ] 	Mean training loss: 1.1054.
[ Wed Apr 25 09:17:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:17:05 2018 ] Training epoch: 37
[ Wed Apr 25 09:17:09 2018 ] 	Batch(0/1) done. Loss: 1.0765  lr:0.100000
[ Wed Apr 25 09:17:09 2018 ] 	Mean training loss: 1.0765.
[ Wed Apr 25 09:17:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:09 2018 ] Training epoch: 38
[ Wed Apr 25 09:17:13 2018 ] 	Batch(0/1) done. Loss: 1.0794  lr:0.100000
[ Wed Apr 25 09:17:13 2018 ] 	Mean training loss: 1.0794.
[ Wed Apr 25 09:17:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:17:13 2018 ] Training epoch: 39
[ Wed Apr 25 09:17:17 2018 ] 	Batch(0/1) done. Loss: 1.1079  lr:0.100000
[ Wed Apr 25 09:17:17 2018 ] 	Mean training loss: 1.1079.
[ Wed Apr 25 09:17:17 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:17:17 2018 ] Training epoch: 40
[ Wed Apr 25 09:17:21 2018 ] 	Batch(0/1) done. Loss: 1.0740  lr:0.100000
[ Wed Apr 25 09:17:21 2018 ] 	Mean training loss: 1.0740.
[ Wed Apr 25 09:17:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:17:21 2018 ] Eval epoch: 40
[ Wed Apr 25 09:17:24 2018 ] 	Mean test loss of 1 batches: 1.0918169021606445.
[ Wed Apr 25 09:17:24 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:17:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:17:24 2018 ] Training epoch: 41
[ Wed Apr 25 09:17:28 2018 ] 	Batch(0/1) done. Loss: 1.0551  lr:0.100000
[ Wed Apr 25 09:17:28 2018 ] 	Mean training loss: 1.0551.
[ Wed Apr 25 09:17:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:28 2018 ] Training epoch: 42
[ Wed Apr 25 09:17:31 2018 ] 	Batch(0/1) done. Loss: 1.1373  lr:0.100000
[ Wed Apr 25 09:17:31 2018 ] 	Mean training loss: 1.1373.
[ Wed Apr 25 09:17:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:31 2018 ] Training epoch: 43
[ Wed Apr 25 09:17:36 2018 ] 	Batch(0/1) done. Loss: 1.0597  lr:0.100000
[ Wed Apr 25 09:17:36 2018 ] 	Mean training loss: 1.0597.
[ Wed Apr 25 09:17:36 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:17:36 2018 ] Training epoch: 44
[ Wed Apr 25 09:17:40 2018 ] 	Batch(0/1) done. Loss: 1.0638  lr:0.100000
[ Wed Apr 25 09:17:40 2018 ] 	Mean training loss: 1.0638.
[ Wed Apr 25 09:17:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:40 2018 ] Training epoch: 45
[ Wed Apr 25 09:17:43 2018 ] 	Batch(0/1) done. Loss: 1.0420  lr:0.100000
[ Wed Apr 25 09:17:43 2018 ] 	Mean training loss: 1.0420.
[ Wed Apr 25 09:17:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:43 2018 ] Eval epoch: 45
[ Wed Apr 25 09:17:46 2018 ] 	Mean test loss of 1 batches: 1.1006841659545898.
[ Wed Apr 25 09:17:46 2018 ] 	Top1: 25.93%
[ Wed Apr 25 09:17:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:17:46 2018 ] Training epoch: 46
[ Wed Apr 25 09:17:50 2018 ] 	Batch(0/1) done. Loss: 1.0570  lr:0.100000
[ Wed Apr 25 09:17:50 2018 ] 	Mean training loss: 1.0570.
[ Wed Apr 25 09:17:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:17:50 2018 ] Training epoch: 47
[ Wed Apr 25 09:17:54 2018 ] 	Batch(0/1) done. Loss: 1.0470  lr:0.100000
[ Wed Apr 25 09:17:54 2018 ] 	Mean training loss: 1.0470.
[ Wed Apr 25 09:17:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:54 2018 ] Training epoch: 48
[ Wed Apr 25 09:17:58 2018 ] 	Batch(0/1) done. Loss: 1.0972  lr:0.100000
[ Wed Apr 25 09:17:58 2018 ] 	Mean training loss: 1.0972.
[ Wed Apr 25 09:17:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:17:58 2018 ] Training epoch: 49
[ Wed Apr 25 09:18:02 2018 ] 	Batch(0/1) done. Loss: 1.0499  lr:0.100000
[ Wed Apr 25 09:18:02 2018 ] 	Mean training loss: 1.0499.
[ Wed Apr 25 09:18:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:02 2018 ] Training epoch: 50
[ Wed Apr 25 09:18:06 2018 ] 	Batch(0/1) done. Loss: 1.0648  lr:0.100000
[ Wed Apr 25 09:18:06 2018 ] 	Mean training loss: 1.0648.
[ Wed Apr 25 09:18:06 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:18:06 2018 ] Eval epoch: 50
[ Wed Apr 25 09:18:08 2018 ] 	Mean test loss of 1 batches: 1.1075040102005005.
[ Wed Apr 25 09:18:08 2018 ] 	Top1: 22.22%
[ Wed Apr 25 09:18:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:18:08 2018 ] Training epoch: 51
[ Wed Apr 25 09:18:12 2018 ] 	Batch(0/1) done. Loss: 1.0641  lr:0.100000
[ Wed Apr 25 09:18:12 2018 ] 	Mean training loss: 1.0641.
[ Wed Apr 25 09:18:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:18:12 2018 ] Training epoch: 52
[ Wed Apr 25 09:18:16 2018 ] 	Batch(0/1) done. Loss: 1.0696  lr:0.100000
[ Wed Apr 25 09:18:16 2018 ] 	Mean training loss: 1.0696.
[ Wed Apr 25 09:18:16 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:18:16 2018 ] Training epoch: 53
[ Wed Apr 25 09:18:20 2018 ] 	Batch(0/1) done. Loss: 1.0572  lr:0.100000
[ Wed Apr 25 09:18:20 2018 ] 	Mean training loss: 1.0572.
[ Wed Apr 25 09:18:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:20 2018 ] Training epoch: 54
[ Wed Apr 25 09:18:24 2018 ] 	Batch(0/1) done. Loss: 1.0792  lr:0.100000
[ Wed Apr 25 09:18:24 2018 ] 	Mean training loss: 1.0792.
[ Wed Apr 25 09:18:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:18:24 2018 ] Training epoch: 55
[ Wed Apr 25 09:18:28 2018 ] 	Batch(0/1) done. Loss: 1.0531  lr:0.100000
[ Wed Apr 25 09:18:28 2018 ] 	Mean training loss: 1.0531.
[ Wed Apr 25 09:18:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:28 2018 ] Eval epoch: 55
[ Wed Apr 25 09:18:31 2018 ] 	Mean test loss of 1 batches: 1.1075869798660278.
[ Wed Apr 25 09:18:31 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:18:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:18:31 2018 ] Training epoch: 56
[ Wed Apr 25 09:18:35 2018 ] 	Batch(0/1) done. Loss: 1.0525  lr:0.100000
[ Wed Apr 25 09:18:35 2018 ] 	Mean training loss: 1.0525.
[ Wed Apr 25 09:18:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:35 2018 ] Training epoch: 57
[ Wed Apr 25 09:18:39 2018 ] 	Batch(0/1) done. Loss: 1.0351  lr:0.100000
[ Wed Apr 25 09:18:39 2018 ] 	Mean training loss: 1.0351.
[ Wed Apr 25 09:18:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:18:39 2018 ] Training epoch: 58
[ Wed Apr 25 09:18:43 2018 ] 	Batch(0/1) done. Loss: 1.0540  lr:0.100000
[ Wed Apr 25 09:18:43 2018 ] 	Mean training loss: 1.0540.
[ Wed Apr 25 09:18:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:43 2018 ] Training epoch: 59
[ Wed Apr 25 09:18:47 2018 ] 	Batch(0/1) done. Loss: 1.1008  lr:0.100000
[ Wed Apr 25 09:18:47 2018 ] 	Mean training loss: 1.1008.
[ Wed Apr 25 09:18:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:47 2018 ] Training epoch: 60
[ Wed Apr 25 09:18:51 2018 ] 	Batch(0/1) done. Loss: 1.0695  lr:0.100000
[ Wed Apr 25 09:18:51 2018 ] 	Mean training loss: 1.0695.
[ Wed Apr 25 09:18:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:18:51 2018 ] Eval epoch: 60
[ Wed Apr 25 09:18:54 2018 ] 	Mean test loss of 1 batches: 1.1066927909851074.
[ Wed Apr 25 09:18:54 2018 ] 	Top1: 22.22%
[ Wed Apr 25 09:18:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:18:54 2018 ] Training epoch: 61
[ Wed Apr 25 09:18:58 2018 ] 	Batch(0/1) done. Loss: 1.0565  lr:0.100000
[ Wed Apr 25 09:18:58 2018 ] 	Mean training loss: 1.0565.
[ Wed Apr 25 09:18:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:18:58 2018 ] Training epoch: 62
[ Wed Apr 25 09:19:02 2018 ] 	Batch(0/1) done. Loss: 1.0778  lr:0.100000
[ Wed Apr 25 09:19:02 2018 ] 	Mean training loss: 1.0778.
[ Wed Apr 25 09:19:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:02 2018 ] Training epoch: 63
[ Wed Apr 25 09:19:06 2018 ] 	Batch(0/1) done. Loss: 1.0614  lr:0.100000
[ Wed Apr 25 09:19:06 2018 ] 	Mean training loss: 1.0614.
[ Wed Apr 25 09:19:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:19:06 2018 ] Training epoch: 64
[ Wed Apr 25 09:19:10 2018 ] 	Batch(0/1) done. Loss: 1.0582  lr:0.100000
[ Wed Apr 25 09:19:10 2018 ] 	Mean training loss: 1.0582.
[ Wed Apr 25 09:19:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:10 2018 ] Training epoch: 65
[ Wed Apr 25 09:19:14 2018 ] 	Batch(0/1) done. Loss: 1.1149  lr:0.100000
[ Wed Apr 25 09:19:14 2018 ] 	Mean training loss: 1.1149.
[ Wed Apr 25 09:19:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:14 2018 ] Eval epoch: 65
[ Wed Apr 25 09:19:16 2018 ] 	Mean test loss of 1 batches: 1.112168550491333.
[ Wed Apr 25 09:19:16 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:19:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:19:16 2018 ] Training epoch: 66
[ Wed Apr 25 09:19:20 2018 ] 	Batch(0/1) done. Loss: 1.0621  lr:0.100000
[ Wed Apr 25 09:19:20 2018 ] 	Mean training loss: 1.0621.
[ Wed Apr 25 09:19:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:19:20 2018 ] Training epoch: 67
[ Wed Apr 25 09:19:24 2018 ] 	Batch(0/1) done. Loss: 1.0353  lr:0.100000
[ Wed Apr 25 09:19:24 2018 ] 	Mean training loss: 1.0353.
[ Wed Apr 25 09:19:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:24 2018 ] Training epoch: 68
[ Wed Apr 25 09:19:28 2018 ] 	Batch(0/1) done. Loss: 1.0810  lr:0.100000
[ Wed Apr 25 09:19:28 2018 ] 	Mean training loss: 1.0810.
[ Wed Apr 25 09:19:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:28 2018 ] Training epoch: 69
[ Wed Apr 25 09:19:32 2018 ] 	Batch(0/1) done. Loss: 1.0654  lr:0.100000
[ Wed Apr 25 09:19:32 2018 ] 	Mean training loss: 1.0654.
[ Wed Apr 25 09:19:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:19:32 2018 ] Training epoch: 70
[ Wed Apr 25 09:19:36 2018 ] 	Batch(0/1) done. Loss: 1.0408  lr:0.100000
[ Wed Apr 25 09:19:36 2018 ] 	Mean training loss: 1.0408.
[ Wed Apr 25 09:19:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:36 2018 ] Eval epoch: 70
[ Wed Apr 25 09:19:39 2018 ] 	Mean test loss of 1 batches: 1.0978844165802002.
[ Wed Apr 25 09:19:39 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:19:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:19:39 2018 ] Training epoch: 71
[ Wed Apr 25 09:19:43 2018 ] 	Batch(0/1) done. Loss: 1.0260  lr:0.100000
[ Wed Apr 25 09:19:43 2018 ] 	Mean training loss: 1.0260.
[ Wed Apr 25 09:19:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:43 2018 ] Training epoch: 72
[ Wed Apr 25 09:19:47 2018 ] 	Batch(0/1) done. Loss: 1.0375  lr:0.100000
[ Wed Apr 25 09:19:47 2018 ] 	Mean training loss: 1.0375.
[ Wed Apr 25 09:19:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:19:47 2018 ] Training epoch: 73
[ Wed Apr 25 09:19:51 2018 ] 	Batch(0/1) done. Loss: 1.0560  lr:0.100000
[ Wed Apr 25 09:19:51 2018 ] 	Mean training loss: 1.0560.
[ Wed Apr 25 09:19:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:51 2018 ] Training epoch: 74
[ Wed Apr 25 09:19:55 2018 ] 	Batch(0/1) done. Loss: 1.0692  lr:0.100000
[ Wed Apr 25 09:19:55 2018 ] 	Mean training loss: 1.0692.
[ Wed Apr 25 09:19:55 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:19:55 2018 ] Training epoch: 75
[ Wed Apr 25 09:19:59 2018 ] 	Batch(0/1) done. Loss: 1.0727  lr:0.100000
[ Wed Apr 25 09:19:59 2018 ] 	Mean training loss: 1.0727.
[ Wed Apr 25 09:19:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:19:59 2018 ] Eval epoch: 75
[ Wed Apr 25 09:20:02 2018 ] 	Mean test loss of 1 batches: 1.1046907901763916.
[ Wed Apr 25 09:20:02 2018 ] 	Top1: 29.63%
[ Wed Apr 25 09:20:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:20:02 2018 ] Training epoch: 76
[ Wed Apr 25 09:20:06 2018 ] 	Batch(0/1) done. Loss: 1.1376  lr:0.100000
[ Wed Apr 25 09:20:06 2018 ] 	Mean training loss: 1.1376.
[ Wed Apr 25 09:20:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:06 2018 ] Training epoch: 77
[ Wed Apr 25 09:20:10 2018 ] 	Batch(0/1) done. Loss: 1.0379  lr:0.100000
[ Wed Apr 25 09:20:10 2018 ] 	Mean training loss: 1.0379.
[ Wed Apr 25 09:20:10 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:20:10 2018 ] Training epoch: 78
[ Wed Apr 25 09:20:14 2018 ] 	Batch(0/1) done. Loss: 1.0544  lr:0.100000
[ Wed Apr 25 09:20:14 2018 ] 	Mean training loss: 1.0544.
[ Wed Apr 25 09:20:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:14 2018 ] Training epoch: 79
[ Wed Apr 25 09:20:18 2018 ] 	Batch(0/1) done. Loss: 1.1302  lr:0.100000
[ Wed Apr 25 09:20:18 2018 ] 	Mean training loss: 1.1302.
[ Wed Apr 25 09:20:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:18 2018 ] Training epoch: 80
[ Wed Apr 25 09:20:21 2018 ] 	Batch(0/1) done. Loss: 1.0463  lr:0.100000
[ Wed Apr 25 09:20:21 2018 ] 	Mean training loss: 1.0463.
[ Wed Apr 25 09:20:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:21 2018 ] Eval epoch: 80
[ Wed Apr 25 09:20:24 2018 ] 	Mean test loss of 1 batches: 1.105517029762268.
[ Wed Apr 25 09:20:24 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:20:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:20:24 2018 ] Training epoch: 81
[ Wed Apr 25 09:20:28 2018 ] 	Batch(0/1) done. Loss: 1.0602  lr:0.100000
[ Wed Apr 25 09:20:28 2018 ] 	Mean training loss: 1.0602.
[ Wed Apr 25 09:20:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:28 2018 ] Training epoch: 82
[ Wed Apr 25 09:20:32 2018 ] 	Batch(0/1) done. Loss: 1.0517  lr:0.100000
[ Wed Apr 25 09:20:32 2018 ] 	Mean training loss: 1.0517.
[ Wed Apr 25 09:20:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:32 2018 ] Training epoch: 83
[ Wed Apr 25 09:20:36 2018 ] 	Batch(0/1) done. Loss: 1.0437  lr:0.100000
[ Wed Apr 25 09:20:36 2018 ] 	Mean training loss: 1.0437.
[ Wed Apr 25 09:20:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:20:36 2018 ] Training epoch: 84
[ Wed Apr 25 09:20:40 2018 ] 	Batch(0/1) done. Loss: 1.0641  lr:0.100000
[ Wed Apr 25 09:20:40 2018 ] 	Mean training loss: 1.0641.
[ Wed Apr 25 09:20:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:20:40 2018 ] Training epoch: 85
[ Wed Apr 25 09:20:44 2018 ] 	Batch(0/1) done. Loss: 1.0143  lr:0.100000
[ Wed Apr 25 09:20:44 2018 ] 	Mean training loss: 1.0143.
[ Wed Apr 25 09:20:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:20:44 2018 ] Eval epoch: 85
[ Wed Apr 25 09:20:47 2018 ] 	Mean test loss of 1 batches: 1.0885696411132812.
[ Wed Apr 25 09:20:47 2018 ] 	Top1: 48.15%
[ Wed Apr 25 09:20:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:20:47 2018 ] Training epoch: 86
[ Wed Apr 25 09:20:51 2018 ] 	Batch(0/1) done. Loss: 1.0235  lr:0.100000
[ Wed Apr 25 09:20:51 2018 ] 	Mean training loss: 1.0235.
[ Wed Apr 25 09:20:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:20:51 2018 ] Training epoch: 87
[ Wed Apr 25 09:20:55 2018 ] 	Batch(0/1) done. Loss: 1.0246  lr:0.100000
[ Wed Apr 25 09:20:55 2018 ] 	Mean training loss: 1.0246.
[ Wed Apr 25 09:20:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:20:55 2018 ] Training epoch: 88
[ Wed Apr 25 09:20:59 2018 ] 	Batch(0/1) done. Loss: 1.0373  lr:0.100000
[ Wed Apr 25 09:20:59 2018 ] 	Mean training loss: 1.0373.
[ Wed Apr 25 09:20:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:20:59 2018 ] Training epoch: 89
[ Wed Apr 25 09:21:03 2018 ] 	Batch(0/1) done. Loss: 1.0119  lr:0.100000
[ Wed Apr 25 09:21:03 2018 ] 	Mean training loss: 1.0119.
[ Wed Apr 25 09:21:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:03 2018 ] Training epoch: 90
[ Wed Apr 25 09:21:07 2018 ] 	Batch(0/1) done. Loss: 1.0532  lr:0.100000
[ Wed Apr 25 09:21:07 2018 ] 	Mean training loss: 1.0532.
[ Wed Apr 25 09:21:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:07 2018 ] Eval epoch: 90
[ Wed Apr 25 09:21:10 2018 ] 	Mean test loss of 1 batches: 1.1032891273498535.
[ Wed Apr 25 09:21:10 2018 ] 	Top1: 29.63%
[ Wed Apr 25 09:21:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:21:10 2018 ] Training epoch: 91
[ Wed Apr 25 09:21:13 2018 ] 	Batch(0/1) done. Loss: 1.0413  lr:0.100000
[ Wed Apr 25 09:21:13 2018 ] 	Mean training loss: 1.0413.
[ Wed Apr 25 09:21:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:13 2018 ] Training epoch: 92
[ Wed Apr 25 09:21:17 2018 ] 	Batch(0/1) done. Loss: 1.0296  lr:0.100000
[ Wed Apr 25 09:21:17 2018 ] 	Mean training loss: 1.0296.
[ Wed Apr 25 09:21:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:17 2018 ] Training epoch: 93
[ Wed Apr 25 09:21:21 2018 ] 	Batch(0/1) done. Loss: 1.0557  lr:0.100000
[ Wed Apr 25 09:21:21 2018 ] 	Mean training loss: 1.0557.
[ Wed Apr 25 09:21:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:21 2018 ] Training epoch: 94
[ Wed Apr 25 09:21:25 2018 ] 	Batch(0/1) done. Loss: 1.0332  lr:0.100000
[ Wed Apr 25 09:21:25 2018 ] 	Mean training loss: 1.0332.
[ Wed Apr 25 09:21:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:25 2018 ] Training epoch: 95
[ Wed Apr 25 09:21:29 2018 ] 	Batch(0/1) done. Loss: 1.0113  lr:0.100000
[ Wed Apr 25 09:21:29 2018 ] 	Mean training loss: 1.0113.
[ Wed Apr 25 09:21:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:29 2018 ] Eval epoch: 95
[ Wed Apr 25 09:21:32 2018 ] 	Mean test loss of 1 batches: 1.082266092300415.
[ Wed Apr 25 09:21:32 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:21:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:21:32 2018 ] Training epoch: 96
[ Wed Apr 25 09:21:36 2018 ] 	Batch(0/1) done. Loss: 1.0498  lr:0.100000
[ Wed Apr 25 09:21:36 2018 ] 	Mean training loss: 1.0498.
[ Wed Apr 25 09:21:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:36 2018 ] Training epoch: 97
[ Wed Apr 25 09:21:40 2018 ] 	Batch(0/1) done. Loss: 1.0840  lr:0.100000
[ Wed Apr 25 09:21:40 2018 ] 	Mean training loss: 1.0840.
[ Wed Apr 25 09:21:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:40 2018 ] Training epoch: 98
[ Wed Apr 25 09:21:44 2018 ] 	Batch(0/1) done. Loss: 1.0222  lr:0.100000
[ Wed Apr 25 09:21:44 2018 ] 	Mean training loss: 1.0222.
[ Wed Apr 25 09:21:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:44 2018 ] Training epoch: 99
[ Wed Apr 25 09:21:47 2018 ] 	Batch(0/1) done. Loss: 1.0361  lr:0.100000
[ Wed Apr 25 09:21:47 2018 ] 	Mean training loss: 1.0361.
[ Wed Apr 25 09:21:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:21:47 2018 ] Training epoch: 100
[ Wed Apr 25 09:21:51 2018 ] 	Batch(0/1) done. Loss: 1.0322  lr:0.100000
[ Wed Apr 25 09:21:51 2018 ] 	Mean training loss: 1.0322.
[ Wed Apr 25 09:21:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:51 2018 ] Eval epoch: 100
[ Wed Apr 25 09:21:54 2018 ] 	Mean test loss of 1 batches: 1.084254503250122.
[ Wed Apr 25 09:21:54 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:21:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:21:54 2018 ] Training epoch: 101
[ Wed Apr 25 09:21:58 2018 ] 	Batch(0/1) done. Loss: 1.0345  lr:0.100000
[ Wed Apr 25 09:21:58 2018 ] 	Mean training loss: 1.0345.
[ Wed Apr 25 09:21:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:21:58 2018 ] Training epoch: 102
[ Wed Apr 25 09:22:02 2018 ] 	Batch(0/1) done. Loss: 1.0460  lr:0.100000
[ Wed Apr 25 09:22:02 2018 ] 	Mean training loss: 1.0460.
[ Wed Apr 25 09:22:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:22:02 2018 ] Training epoch: 103
[ Wed Apr 25 09:22:06 2018 ] 	Batch(0/1) done. Loss: 1.0320  lr:0.100000
[ Wed Apr 25 09:22:06 2018 ] 	Mean training loss: 1.0320.
[ Wed Apr 25 09:22:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:06 2018 ] Training epoch: 104
[ Wed Apr 25 09:22:10 2018 ] 	Batch(0/1) done. Loss: 1.0238  lr:0.100000
[ Wed Apr 25 09:22:10 2018 ] 	Mean training loss: 1.0238.
[ Wed Apr 25 09:22:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:10 2018 ] Training epoch: 105
[ Wed Apr 25 09:22:14 2018 ] 	Batch(0/1) done. Loss: 1.0588  lr:0.100000
[ Wed Apr 25 09:22:14 2018 ] 	Mean training loss: 1.0588.
[ Wed Apr 25 09:22:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:14 2018 ] Eval epoch: 105
[ Wed Apr 25 09:22:17 2018 ] 	Mean test loss of 1 batches: 1.0893220901489258.
[ Wed Apr 25 09:22:17 2018 ] 	Top1: 33.33%
[ Wed Apr 25 09:22:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:22:17 2018 ] Training epoch: 106
[ Wed Apr 25 09:22:21 2018 ] 	Batch(0/1) done. Loss: 1.0035  lr:0.100000
[ Wed Apr 25 09:22:21 2018 ] 	Mean training loss: 1.0035.
[ Wed Apr 25 09:22:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:21 2018 ] Training epoch: 107
[ Wed Apr 25 09:22:24 2018 ] 	Batch(0/1) done. Loss: 1.0665  lr:0.100000
[ Wed Apr 25 09:22:24 2018 ] 	Mean training loss: 1.0665.
[ Wed Apr 25 09:22:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:24 2018 ] Training epoch: 108
[ Wed Apr 25 09:22:28 2018 ] 	Batch(0/1) done. Loss: 1.0316  lr:0.100000
[ Wed Apr 25 09:22:28 2018 ] 	Mean training loss: 1.0316.
[ Wed Apr 25 09:22:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:28 2018 ] Training epoch: 109
[ Wed Apr 25 09:22:32 2018 ] 	Batch(0/1) done. Loss: 1.0546  lr:0.100000
[ Wed Apr 25 09:22:32 2018 ] 	Mean training loss: 1.0546.
[ Wed Apr 25 09:22:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:32 2018 ] Training epoch: 110
[ Wed Apr 25 09:22:36 2018 ] 	Batch(0/1) done. Loss: 1.0123  lr:0.100000
[ Wed Apr 25 09:22:36 2018 ] 	Mean training loss: 1.0123.
[ Wed Apr 25 09:22:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:36 2018 ] Eval epoch: 110
[ Wed Apr 25 09:22:39 2018 ] 	Mean test loss of 1 batches: 1.074905514717102.
[ Wed Apr 25 09:22:39 2018 ] 	Top1: 29.63%
[ Wed Apr 25 09:22:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:22:39 2018 ] Training epoch: 111
[ Wed Apr 25 09:22:43 2018 ] 	Batch(0/1) done. Loss: 1.0171  lr:0.100000
[ Wed Apr 25 09:22:43 2018 ] 	Mean training loss: 1.0171.
[ Wed Apr 25 09:22:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:43 2018 ] Training epoch: 112
[ Wed Apr 25 09:22:47 2018 ] 	Batch(0/1) done. Loss: 1.0638  lr:0.100000
[ Wed Apr 25 09:22:47 2018 ] 	Mean training loss: 1.0638.
[ Wed Apr 25 09:22:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:47 2018 ] Training epoch: 113
[ Wed Apr 25 09:22:51 2018 ] 	Batch(0/1) done. Loss: 1.0050  lr:0.100000
[ Wed Apr 25 09:22:51 2018 ] 	Mean training loss: 1.0050.
[ Wed Apr 25 09:22:51 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:22:51 2018 ] Training epoch: 114
[ Wed Apr 25 09:22:55 2018 ] 	Batch(0/1) done. Loss: 1.0073  lr:0.100000
[ Wed Apr 25 09:22:55 2018 ] 	Mean training loss: 1.0073.
[ Wed Apr 25 09:22:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:55 2018 ] Training epoch: 115
[ Wed Apr 25 09:22:59 2018 ] 	Batch(0/1) done. Loss: 0.9975  lr:0.100000
[ Wed Apr 25 09:22:59 2018 ] 	Mean training loss: 0.9975.
[ Wed Apr 25 09:22:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:22:59 2018 ] Eval epoch: 115
[ Wed Apr 25 09:23:01 2018 ] 	Mean test loss of 1 batches: 1.0708993673324585.
[ Wed Apr 25 09:23:01 2018 ] 	Top1: 40.74%
[ Wed Apr 25 09:23:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:23:01 2018 ] Training epoch: 116
[ Wed Apr 25 09:23:05 2018 ] 	Batch(0/1) done. Loss: 1.0193  lr:0.100000
[ Wed Apr 25 09:23:05 2018 ] 	Mean training loss: 1.0193.
[ Wed Apr 25 09:23:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:23:05 2018 ] Training epoch: 117
[ Wed Apr 25 09:23:09 2018 ] 	Batch(0/1) done. Loss: 1.0139  lr:0.100000
[ Wed Apr 25 09:23:09 2018 ] 	Mean training loss: 1.0139.
[ Wed Apr 25 09:23:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:09 2018 ] Training epoch: 118
[ Wed Apr 25 09:23:13 2018 ] 	Batch(0/1) done. Loss: 0.9816  lr:0.100000
[ Wed Apr 25 09:23:13 2018 ] 	Mean training loss: 0.9816.
[ Wed Apr 25 09:23:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:13 2018 ] Training epoch: 119
[ Wed Apr 25 09:23:17 2018 ] 	Batch(0/1) done. Loss: 1.0438  lr:0.100000
[ Wed Apr 25 09:23:17 2018 ] 	Mean training loss: 1.0438.
[ Wed Apr 25 09:23:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:17 2018 ] Training epoch: 120
[ Wed Apr 25 09:23:21 2018 ] 	Batch(0/1) done. Loss: 0.9761  lr:0.100000
[ Wed Apr 25 09:23:21 2018 ] 	Mean training loss: 0.9761.
[ Wed Apr 25 09:23:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:21 2018 ] Eval epoch: 120
[ Wed Apr 25 09:23:24 2018 ] 	Mean test loss of 1 batches: 1.066540002822876.
[ Wed Apr 25 09:23:24 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:23:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:23:24 2018 ] Training epoch: 121
[ Wed Apr 25 09:23:28 2018 ] 	Batch(0/1) done. Loss: 0.9492  lr:0.100000
[ Wed Apr 25 09:23:28 2018 ] 	Mean training loss: 0.9492.
[ Wed Apr 25 09:23:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:23:28 2018 ] Training epoch: 122
[ Wed Apr 25 09:23:32 2018 ] 	Batch(0/1) done. Loss: 0.9534  lr:0.100000
[ Wed Apr 25 09:23:32 2018 ] 	Mean training loss: 0.9534.
[ Wed Apr 25 09:23:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:32 2018 ] Training epoch: 123
[ Wed Apr 25 09:23:36 2018 ] 	Batch(0/1) done. Loss: 1.0104  lr:0.100000
[ Wed Apr 25 09:23:36 2018 ] 	Mean training loss: 1.0104.
[ Wed Apr 25 09:23:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:36 2018 ] Training epoch: 124
[ Wed Apr 25 09:23:40 2018 ] 	Batch(0/1) done. Loss: 1.0269  lr:0.100000
[ Wed Apr 25 09:23:40 2018 ] 	Mean training loss: 1.0269.
[ Wed Apr 25 09:23:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:40 2018 ] Training epoch: 125
[ Wed Apr 25 09:23:43 2018 ] 	Batch(0/1) done. Loss: 1.0280  lr:0.100000
[ Wed Apr 25 09:23:43 2018 ] 	Mean training loss: 1.0280.
[ Wed Apr 25 09:23:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:43 2018 ] Eval epoch: 125
[ Wed Apr 25 09:23:46 2018 ] 	Mean test loss of 1 batches: 1.0618106126785278.
[ Wed Apr 25 09:23:46 2018 ] 	Top1: 44.44%
[ Wed Apr 25 09:23:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:23:46 2018 ] Training epoch: 126
[ Wed Apr 25 09:23:50 2018 ] 	Batch(0/1) done. Loss: 1.0123  lr:0.100000
[ Wed Apr 25 09:23:50 2018 ] 	Mean training loss: 1.0123.
[ Wed Apr 25 09:23:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:50 2018 ] Training epoch: 127
[ Wed Apr 25 09:23:54 2018 ] 	Batch(0/1) done. Loss: 0.9561  lr:0.100000
[ Wed Apr 25 09:23:54 2018 ] 	Mean training loss: 0.9561.
[ Wed Apr 25 09:23:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:23:54 2018 ] Training epoch: 128
[ Wed Apr 25 09:23:58 2018 ] 	Batch(0/1) done. Loss: 0.9837  lr:0.100000
[ Wed Apr 25 09:23:58 2018 ] 	Mean training loss: 0.9837.
[ Wed Apr 25 09:23:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:23:58 2018 ] Training epoch: 129
[ Wed Apr 25 09:24:02 2018 ] 	Batch(0/1) done. Loss: 0.9757  lr:0.100000
[ Wed Apr 25 09:24:02 2018 ] 	Mean training loss: 0.9757.
[ Wed Apr 25 09:24:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:24:02 2018 ] Training epoch: 130
[ Wed Apr 25 09:24:06 2018 ] 	Batch(0/1) done. Loss: 0.9769  lr:0.100000
[ Wed Apr 25 09:24:06 2018 ] 	Mean training loss: 0.9769.
[ Wed Apr 25 09:24:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:24:06 2018 ] Eval epoch: 130
[ Wed Apr 25 09:24:09 2018 ] 	Mean test loss of 1 batches: 1.0533074140548706.
[ Wed Apr 25 09:24:09 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:24:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:24:09 2018 ] Training epoch: 131
[ Wed Apr 25 09:24:13 2018 ] 	Batch(0/1) done. Loss: 0.9823  lr:0.100000
[ Wed Apr 25 09:24:13 2018 ] 	Mean training loss: 0.9823.
[ Wed Apr 25 09:24:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:24:13 2018 ] Training epoch: 132
[ Wed Apr 25 09:24:17 2018 ] 	Batch(0/1) done. Loss: 0.9755  lr:0.100000
[ Wed Apr 25 09:24:17 2018 ] 	Mean training loss: 0.9755.
[ Wed Apr 25 09:24:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:24:17 2018 ] Training epoch: 133
[ Wed Apr 25 09:24:21 2018 ] 	Batch(0/1) done. Loss: 0.9858  lr:0.100000
[ Wed Apr 25 09:24:21 2018 ] 	Mean training loss: 0.9858.
[ Wed Apr 25 09:24:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:21 2018 ] Training epoch: 134
[ Wed Apr 25 09:24:25 2018 ] 	Batch(0/1) done. Loss: 1.0361  lr:0.100000
[ Wed Apr 25 09:24:25 2018 ] 	Mean training loss: 1.0361.
[ Wed Apr 25 09:24:25 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:24:25 2018 ] Training epoch: 135
[ Wed Apr 25 09:24:29 2018 ] 	Batch(0/1) done. Loss: 0.9368  lr:0.100000
[ Wed Apr 25 09:24:29 2018 ] 	Mean training loss: 0.9368.
[ Wed Apr 25 09:24:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:29 2018 ] Eval epoch: 135
[ Wed Apr 25 09:24:32 2018 ] 	Mean test loss of 1 batches: 1.048993468284607.
[ Wed Apr 25 09:24:32 2018 ] 	Top1: 40.74%
[ Wed Apr 25 09:24:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:24:32 2018 ] Training epoch: 136
[ Wed Apr 25 09:24:36 2018 ] 	Batch(0/1) done. Loss: 1.0153  lr:0.100000
[ Wed Apr 25 09:24:36 2018 ] 	Mean training loss: 1.0153.
[ Wed Apr 25 09:24:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:36 2018 ] Training epoch: 137
[ Wed Apr 25 09:24:40 2018 ] 	Batch(0/1) done. Loss: 0.9441  lr:0.100000
[ Wed Apr 25 09:24:40 2018 ] 	Mean training loss: 0.9441.
[ Wed Apr 25 09:24:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:40 2018 ] Training epoch: 138
[ Wed Apr 25 09:24:44 2018 ] 	Batch(0/1) done. Loss: 0.9601  lr:0.100000
[ Wed Apr 25 09:24:44 2018 ] 	Mean training loss: 0.9601.
[ Wed Apr 25 09:24:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:44 2018 ] Training epoch: 139
[ Wed Apr 25 09:24:48 2018 ] 	Batch(0/1) done. Loss: 0.9886  lr:0.100000
[ Wed Apr 25 09:24:48 2018 ] 	Mean training loss: 0.9886.
[ Wed Apr 25 09:24:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:24:48 2018 ] Training epoch: 140
[ Wed Apr 25 09:24:52 2018 ] 	Batch(0/1) done. Loss: 0.9950  lr:0.100000
[ Wed Apr 25 09:24:52 2018 ] 	Mean training loss: 0.9950.
[ Wed Apr 25 09:24:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:24:52 2018 ] Eval epoch: 140
[ Wed Apr 25 09:24:55 2018 ] 	Mean test loss of 1 batches: 1.0440376996994019.
[ Wed Apr 25 09:24:55 2018 ] 	Top1: 40.74%
[ Wed Apr 25 09:24:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:24:55 2018 ] Training epoch: 141
[ Wed Apr 25 09:24:59 2018 ] 	Batch(0/1) done. Loss: 0.9675  lr:0.100000
[ Wed Apr 25 09:24:59 2018 ] 	Mean training loss: 0.9675.
[ Wed Apr 25 09:24:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:24:59 2018 ] Training epoch: 142
[ Wed Apr 25 09:25:03 2018 ] 	Batch(0/1) done. Loss: 0.9806  lr:0.100000
[ Wed Apr 25 09:25:03 2018 ] 	Mean training loss: 0.9806.
[ Wed Apr 25 09:25:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:03 2018 ] Training epoch: 143
[ Wed Apr 25 09:25:07 2018 ] 	Batch(0/1) done. Loss: 0.9884  lr:0.100000
[ Wed Apr 25 09:25:07 2018 ] 	Mean training loss: 0.9884.
[ Wed Apr 25 09:25:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:25:07 2018 ] Training epoch: 144
[ Wed Apr 25 09:25:11 2018 ] 	Batch(0/1) done. Loss: 0.9757  lr:0.100000
[ Wed Apr 25 09:25:11 2018 ] 	Mean training loss: 0.9757.
[ Wed Apr 25 09:25:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:11 2018 ] Training epoch: 145
[ Wed Apr 25 09:25:15 2018 ] 	Batch(0/1) done. Loss: 0.9773  lr:0.100000
[ Wed Apr 25 09:25:15 2018 ] 	Mean training loss: 0.9773.
[ Wed Apr 25 09:25:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:15 2018 ] Eval epoch: 145
[ Wed Apr 25 09:25:18 2018 ] 	Mean test loss of 1 batches: 1.0611568689346313.
[ Wed Apr 25 09:25:18 2018 ] 	Top1: 37.04%
[ Wed Apr 25 09:25:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:25:18 2018 ] Training epoch: 146
[ Wed Apr 25 09:25:21 2018 ] 	Batch(0/1) done. Loss: 0.8985  lr:0.100000
[ Wed Apr 25 09:25:21 2018 ] 	Mean training loss: 0.8985.
[ Wed Apr 25 09:25:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:21 2018 ] Training epoch: 147
[ Wed Apr 25 09:25:25 2018 ] 	Batch(0/1) done. Loss: 0.9894  lr:0.100000
[ Wed Apr 25 09:25:25 2018 ] 	Mean training loss: 0.9894.
[ Wed Apr 25 09:25:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:25 2018 ] Training epoch: 148
[ Wed Apr 25 09:25:29 2018 ] 	Batch(0/1) done. Loss: 0.9093  lr:0.100000
[ Wed Apr 25 09:25:29 2018 ] 	Mean training loss: 0.9093.
[ Wed Apr 25 09:25:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:29 2018 ] Training epoch: 149
[ Wed Apr 25 09:25:33 2018 ] 	Batch(0/1) done. Loss: 1.0137  lr:0.100000
[ Wed Apr 25 09:25:33 2018 ] 	Mean training loss: 1.0137.
[ Wed Apr 25 09:25:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:33 2018 ] Training epoch: 150
[ Wed Apr 25 09:25:37 2018 ] 	Batch(0/1) done. Loss: 0.9718  lr:0.100000
[ Wed Apr 25 09:25:37 2018 ] 	Mean training loss: 0.9718.
[ Wed Apr 25 09:25:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:37 2018 ] Eval epoch: 150
[ Wed Apr 25 09:25:40 2018 ] 	Mean test loss of 1 batches: 1.0390126705169678.
[ Wed Apr 25 09:25:40 2018 ] 	Top1: 40.74%
[ Wed Apr 25 09:25:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:25:40 2018 ] Training epoch: 151
[ Wed Apr 25 09:25:44 2018 ] 	Batch(0/1) done. Loss: 0.9259  lr:0.100000
[ Wed Apr 25 09:25:44 2018 ] 	Mean training loss: 0.9259.
[ Wed Apr 25 09:25:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:44 2018 ] Training epoch: 152
[ Wed Apr 25 09:25:48 2018 ] 	Batch(0/1) done. Loss: 0.8728  lr:0.100000
[ Wed Apr 25 09:25:48 2018 ] 	Mean training loss: 0.8728.
[ Wed Apr 25 09:25:48 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:25:48 2018 ] Training epoch: 153
[ Wed Apr 25 09:25:52 2018 ] 	Batch(0/1) done. Loss: 0.9241  lr:0.100000
[ Wed Apr 25 09:25:52 2018 ] 	Mean training loss: 0.9241.
[ Wed Apr 25 09:25:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:52 2018 ] Training epoch: 154
[ Wed Apr 25 09:25:56 2018 ] 	Batch(0/1) done. Loss: 0.9493  lr:0.100000
[ Wed Apr 25 09:25:56 2018 ] 	Mean training loss: 0.9493.
[ Wed Apr 25 09:25:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:25:56 2018 ] Training epoch: 155
[ Wed Apr 25 09:26:01 2018 ] 	Batch(0/1) done. Loss: 0.9507  lr:0.100000
[ Wed Apr 25 09:26:01 2018 ] 	Mean training loss: 0.9507.
[ Wed Apr 25 09:26:01 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:26:01 2018 ] Eval epoch: 155
[ Wed Apr 25 09:26:03 2018 ] 	Mean test loss of 1 batches: 1.0686982870101929.
[ Wed Apr 25 09:26:03 2018 ] 	Top1: 44.44%
[ Wed Apr 25 09:26:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:26:03 2018 ] Training epoch: 156
[ Wed Apr 25 09:26:07 2018 ] 	Batch(0/1) done. Loss: 0.9785  lr:0.100000
[ Wed Apr 25 09:26:07 2018 ] 	Mean training loss: 0.9785.
[ Wed Apr 25 09:26:07 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:26:07 2018 ] Training epoch: 157
[ Wed Apr 25 09:26:11 2018 ] 	Batch(0/1) done. Loss: 0.8792  lr:0.100000
[ Wed Apr 25 09:26:11 2018 ] 	Mean training loss: 0.8792.
[ Wed Apr 25 09:26:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:11 2018 ] Training epoch: 158
[ Wed Apr 25 09:26:15 2018 ] 	Batch(0/1) done. Loss: 0.8492  lr:0.100000
[ Wed Apr 25 09:26:15 2018 ] 	Mean training loss: 0.8492.
[ Wed Apr 25 09:26:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:15 2018 ] Training epoch: 159
[ Wed Apr 25 09:26:19 2018 ] 	Batch(0/1) done. Loss: 0.9123  lr:0.100000
[ Wed Apr 25 09:26:19 2018 ] 	Mean training loss: 0.9123.
[ Wed Apr 25 09:26:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:19 2018 ] Training epoch: 160
[ Wed Apr 25 09:26:23 2018 ] 	Batch(0/1) done. Loss: 0.9912  lr:0.100000
[ Wed Apr 25 09:26:23 2018 ] 	Mean training loss: 0.9912.
[ Wed Apr 25 09:26:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:26:23 2018 ] Eval epoch: 160
[ Wed Apr 25 09:26:25 2018 ] 	Mean test loss of 1 batches: 1.0869977474212646.
[ Wed Apr 25 09:26:25 2018 ] 	Top1: 40.74%
[ Wed Apr 25 09:26:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:26:25 2018 ] Training epoch: 161
[ Wed Apr 25 09:26:29 2018 ] 	Batch(0/1) done. Loss: 0.9394  lr:0.100000
[ Wed Apr 25 09:26:29 2018 ] 	Mean training loss: 0.9394.
[ Wed Apr 25 09:26:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:29 2018 ] Training epoch: 162
[ Wed Apr 25 09:26:33 2018 ] 	Batch(0/1) done. Loss: 0.9978  lr:0.100000
[ Wed Apr 25 09:26:33 2018 ] 	Mean training loss: 0.9978.
[ Wed Apr 25 09:26:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:33 2018 ] Training epoch: 163
[ Wed Apr 25 09:26:37 2018 ] 	Batch(0/1) done. Loss: 0.9312  lr:0.100000
[ Wed Apr 25 09:26:37 2018 ] 	Mean training loss: 0.9312.
[ Wed Apr 25 09:26:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:37 2018 ] Training epoch: 164
[ Wed Apr 25 09:26:41 2018 ] 	Batch(0/1) done. Loss: 0.9320  lr:0.100000
[ Wed Apr 25 09:26:41 2018 ] 	Mean training loss: 0.9320.
[ Wed Apr 25 09:26:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:41 2018 ] Training epoch: 165
[ Wed Apr 25 09:26:45 2018 ] 	Batch(0/1) done. Loss: 0.9219  lr:0.100000
[ Wed Apr 25 09:26:45 2018 ] 	Mean training loss: 0.9219.
[ Wed Apr 25 09:26:45 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:26:45 2018 ] Eval epoch: 165
[ Wed Apr 25 09:26:48 2018 ] 	Mean test loss of 1 batches: 1.0263254642486572.
[ Wed Apr 25 09:26:48 2018 ] 	Top1: 29.63%
[ Wed Apr 25 09:26:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:26:48 2018 ] Training epoch: 166
[ Wed Apr 25 09:26:52 2018 ] 	Batch(0/1) done. Loss: 0.9085  lr:0.100000
[ Wed Apr 25 09:26:52 2018 ] 	Mean training loss: 0.9085.
[ Wed Apr 25 09:26:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:26:52 2018 ] Training epoch: 167
[ Wed Apr 25 09:26:56 2018 ] 	Batch(0/1) done. Loss: 0.8864  lr:0.100000
[ Wed Apr 25 09:26:56 2018 ] 	Mean training loss: 0.8864.
[ Wed Apr 25 09:26:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:26:56 2018 ] Training epoch: 168
[ Wed Apr 25 09:27:00 2018 ] 	Batch(0/1) done. Loss: 0.9144  lr:0.100000
[ Wed Apr 25 09:27:00 2018 ] 	Mean training loss: 0.9144.
[ Wed Apr 25 09:27:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:00 2018 ] Training epoch: 169
[ Wed Apr 25 09:27:04 2018 ] 	Batch(0/1) done. Loss: 0.8661  lr:0.100000
[ Wed Apr 25 09:27:04 2018 ] 	Mean training loss: 0.8661.
[ Wed Apr 25 09:27:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:04 2018 ] Training epoch: 170
[ Wed Apr 25 09:27:08 2018 ] 	Batch(0/1) done. Loss: 0.8950  lr:0.100000
[ Wed Apr 25 09:27:08 2018 ] 	Mean training loss: 0.8950.
[ Wed Apr 25 09:27:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:08 2018 ] Eval epoch: 170
[ Wed Apr 25 09:27:11 2018 ] 	Mean test loss of 1 batches: 1.0355277061462402.
[ Wed Apr 25 09:27:11 2018 ] 	Top1: 51.85%
[ Wed Apr 25 09:27:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:27:11 2018 ] Training epoch: 171
[ Wed Apr 25 09:27:14 2018 ] 	Batch(0/1) done. Loss: 0.9640  lr:0.100000
[ Wed Apr 25 09:27:14 2018 ] 	Mean training loss: 0.9640.
[ Wed Apr 25 09:27:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:14 2018 ] Training epoch: 172
[ Wed Apr 25 09:27:18 2018 ] 	Batch(0/1) done. Loss: 0.8963  lr:0.100000
[ Wed Apr 25 09:27:18 2018 ] 	Mean training loss: 0.8963.
[ Wed Apr 25 09:27:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:18 2018 ] Training epoch: 173
[ Wed Apr 25 09:27:22 2018 ] 	Batch(0/1) done. Loss: 0.9219  lr:0.100000
[ Wed Apr 25 09:27:22 2018 ] 	Mean training loss: 0.9219.
[ Wed Apr 25 09:27:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:27:22 2018 ] Training epoch: 174
[ Wed Apr 25 09:27:26 2018 ] 	Batch(0/1) done. Loss: 0.8574  lr:0.100000
[ Wed Apr 25 09:27:26 2018 ] 	Mean training loss: 0.8574.
[ Wed Apr 25 09:27:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:26 2018 ] Training epoch: 175
[ Wed Apr 25 09:27:30 2018 ] 	Batch(0/1) done. Loss: 0.8180  lr:0.100000
[ Wed Apr 25 09:27:31 2018 ] 	Mean training loss: 0.8180.
[ Wed Apr 25 09:27:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:27:31 2018 ] Eval epoch: 175
[ Wed Apr 25 09:27:33 2018 ] 	Mean test loss of 1 batches: 0.9155741930007935.
[ Wed Apr 25 09:27:33 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:27:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:27:33 2018 ] Training epoch: 176
[ Wed Apr 25 09:27:37 2018 ] 	Batch(0/1) done. Loss: 0.8603  lr:0.100000
[ Wed Apr 25 09:27:37 2018 ] 	Mean training loss: 0.8603.
[ Wed Apr 25 09:27:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:37 2018 ] Training epoch: 177
[ Wed Apr 25 09:27:41 2018 ] 	Batch(0/1) done. Loss: 0.8091  lr:0.100000
[ Wed Apr 25 09:27:41 2018 ] 	Mean training loss: 0.8091.
[ Wed Apr 25 09:27:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:41 2018 ] Training epoch: 178
[ Wed Apr 25 09:27:45 2018 ] 	Batch(0/1) done. Loss: 0.8355  lr:0.100000
[ Wed Apr 25 09:27:45 2018 ] 	Mean training loss: 0.8355.
[ Wed Apr 25 09:27:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:45 2018 ] Training epoch: 179
[ Wed Apr 25 09:27:49 2018 ] 	Batch(0/1) done. Loss: 0.8361  lr:0.100000
[ Wed Apr 25 09:27:49 2018 ] 	Mean training loss: 0.8361.
[ Wed Apr 25 09:27:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:27:49 2018 ] Training epoch: 180
[ Wed Apr 25 09:27:53 2018 ] 	Batch(0/1) done. Loss: 0.8268  lr:0.100000
[ Wed Apr 25 09:27:53 2018 ] 	Mean training loss: 0.8268.
[ Wed Apr 25 09:27:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:27:53 2018 ] Eval epoch: 180
[ Wed Apr 25 09:27:56 2018 ] 	Mean test loss of 1 batches: 1.0311846733093262.
[ Wed Apr 25 09:27:56 2018 ] 	Top1: 55.56%
[ Wed Apr 25 09:27:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:27:56 2018 ] Training epoch: 181
[ Wed Apr 25 09:28:00 2018 ] 	Batch(0/1) done. Loss: 0.7745  lr:0.100000
[ Wed Apr 25 09:28:00 2018 ] 	Mean training loss: 0.7745.
[ Wed Apr 25 09:28:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:00 2018 ] Training epoch: 182
[ Wed Apr 25 09:28:04 2018 ] 	Batch(0/1) done. Loss: 0.7939  lr:0.100000
[ Wed Apr 25 09:28:04 2018 ] 	Mean training loss: 0.7939.
[ Wed Apr 25 09:28:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:04 2018 ] Training epoch: 183
[ Wed Apr 25 09:28:08 2018 ] 	Batch(0/1) done. Loss: 0.8897  lr:0.100000
[ Wed Apr 25 09:28:08 2018 ] 	Mean training loss: 0.8897.
[ Wed Apr 25 09:28:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:28:08 2018 ] Training epoch: 184
[ Wed Apr 25 09:28:12 2018 ] 	Batch(0/1) done. Loss: 0.7909  lr:0.100000
[ Wed Apr 25 09:28:12 2018 ] 	Mean training loss: 0.7909.
[ Wed Apr 25 09:28:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:28:12 2018 ] Training epoch: 185
[ Wed Apr 25 09:28:17 2018 ] 	Batch(0/1) done. Loss: 0.8084  lr:0.100000
[ Wed Apr 25 09:28:17 2018 ] 	Mean training loss: 0.8084.
[ Wed Apr 25 09:28:17 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:28:17 2018 ] Eval epoch: 185
[ Wed Apr 25 09:28:19 2018 ] 	Mean test loss of 1 batches: 1.3124338388442993.
[ Wed Apr 25 09:28:19 2018 ] 	Top1: 48.15%
[ Wed Apr 25 09:28:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:28:19 2018 ] Training epoch: 186
[ Wed Apr 25 09:28:23 2018 ] 	Batch(0/1) done. Loss: 0.8245  lr:0.100000
[ Wed Apr 25 09:28:23 2018 ] 	Mean training loss: 0.8245.
[ Wed Apr 25 09:28:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:23 2018 ] Training epoch: 187
[ Wed Apr 25 09:28:27 2018 ] 	Batch(0/1) done. Loss: 0.7819  lr:0.100000
[ Wed Apr 25 09:28:27 2018 ] 	Mean training loss: 0.7819.
[ Wed Apr 25 09:28:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:27 2018 ] Training epoch: 188
[ Wed Apr 25 09:28:31 2018 ] 	Batch(0/1) done. Loss: 0.7944  lr:0.100000
[ Wed Apr 25 09:28:31 2018 ] 	Mean training loss: 0.7944.
[ Wed Apr 25 09:28:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:31 2018 ] Training epoch: 189
[ Wed Apr 25 09:28:35 2018 ] 	Batch(0/1) done. Loss: 0.7694  lr:0.100000
[ Wed Apr 25 09:28:35 2018 ] 	Mean training loss: 0.7694.
[ Wed Apr 25 09:28:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:28:35 2018 ] Training epoch: 190
[ Wed Apr 25 09:28:39 2018 ] 	Batch(0/1) done. Loss: 0.7652  lr:0.100000
[ Wed Apr 25 09:28:39 2018 ] 	Mean training loss: 0.7652.
[ Wed Apr 25 09:28:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:39 2018 ] Eval epoch: 190
[ Wed Apr 25 09:28:42 2018 ] 	Mean test loss of 1 batches: 0.8163973689079285.
[ Wed Apr 25 09:28:42 2018 ] 	Top1: 55.56%
[ Wed Apr 25 09:28:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:28:42 2018 ] Training epoch: 191
[ Wed Apr 25 09:28:46 2018 ] 	Batch(0/1) done. Loss: 0.7116  lr:0.100000
[ Wed Apr 25 09:28:46 2018 ] 	Mean training loss: 0.7116.
[ Wed Apr 25 09:28:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:28:46 2018 ] Training epoch: 192
[ Wed Apr 25 09:28:50 2018 ] 	Batch(0/1) done. Loss: 0.7296  lr:0.100000
[ Wed Apr 25 09:28:50 2018 ] 	Mean training loss: 0.7296.
[ Wed Apr 25 09:28:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:50 2018 ] Training epoch: 193
[ Wed Apr 25 09:28:54 2018 ] 	Batch(0/1) done. Loss: 0.8328  lr:0.100000
[ Wed Apr 25 09:28:54 2018 ] 	Mean training loss: 0.8328.
[ Wed Apr 25 09:28:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:54 2018 ] Training epoch: 194
[ Wed Apr 25 09:28:58 2018 ] 	Batch(0/1) done. Loss: 0.7334  lr:0.100000
[ Wed Apr 25 09:28:58 2018 ] 	Mean training loss: 0.7334.
[ Wed Apr 25 09:28:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:28:58 2018 ] Training epoch: 195
[ Wed Apr 25 09:29:02 2018 ] 	Batch(0/1) done. Loss: 0.6733  lr:0.100000
[ Wed Apr 25 09:29:02 2018 ] 	Mean training loss: 0.6733.
[ Wed Apr 25 09:29:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:29:02 2018 ] Eval epoch: 195
[ Wed Apr 25 09:29:05 2018 ] 	Mean test loss of 1 batches: 0.7448034882545471.
[ Wed Apr 25 09:29:05 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:29:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:29:05 2018 ] Training epoch: 196
[ Wed Apr 25 09:29:09 2018 ] 	Batch(0/1) done. Loss: 0.6654  lr:0.100000
[ Wed Apr 25 09:29:09 2018 ] 	Mean training loss: 0.6654.
[ Wed Apr 25 09:29:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:29:09 2018 ] Training epoch: 197
[ Wed Apr 25 09:29:13 2018 ] 	Batch(0/1) done. Loss: 0.7418  lr:0.100000
[ Wed Apr 25 09:29:13 2018 ] 	Mean training loss: 0.7418.
[ Wed Apr 25 09:29:13 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:29:13 2018 ] Training epoch: 198
[ Wed Apr 25 09:29:17 2018 ] 	Batch(0/1) done. Loss: 0.7624  lr:0.100000
[ Wed Apr 25 09:29:17 2018 ] 	Mean training loss: 0.7624.
[ Wed Apr 25 09:29:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:29:17 2018 ] Training epoch: 199
[ Wed Apr 25 09:29:21 2018 ] 	Batch(0/1) done. Loss: 0.7219  lr:0.100000
[ Wed Apr 25 09:29:21 2018 ] 	Mean training loss: 0.7219.
[ Wed Apr 25 09:29:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:29:21 2018 ] Training epoch: 200
[ Wed Apr 25 09:29:25 2018 ] 	Batch(0/1) done. Loss: 0.6077  lr:0.100000
[ Wed Apr 25 09:29:25 2018 ] 	Mean training loss: 0.6077.
[ Wed Apr 25 09:29:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:29:25 2018 ] Eval epoch: 200
[ Wed Apr 25 09:29:28 2018 ] 	Mean test loss of 1 batches: 0.8059525489807129.
[ Wed Apr 25 09:29:28 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:29:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:29:28 2018 ] Training epoch: 201
[ Wed Apr 25 09:29:32 2018 ] 	Batch(0/1) done. Loss: 0.7096  lr:0.100000
[ Wed Apr 25 09:29:32 2018 ] 	Mean training loss: 0.7096.
[ Wed Apr 25 09:29:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:29:32 2018 ] Training epoch: 202
[ Wed Apr 25 09:29:36 2018 ] 	Batch(0/1) done. Loss: 0.6312  lr:0.100000
[ Wed Apr 25 09:29:36 2018 ] 	Mean training loss: 0.6312.
[ Wed Apr 25 09:29:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:29:36 2018 ] Training epoch: 203
[ Wed Apr 25 09:29:40 2018 ] 	Batch(0/1) done. Loss: 0.7808  lr:0.100000
[ Wed Apr 25 09:29:40 2018 ] 	Mean training loss: 0.7808.
[ Wed Apr 25 09:29:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:29:40 2018 ] Training epoch: 204
[ Wed Apr 25 09:29:44 2018 ] 	Batch(0/1) done. Loss: 0.6731  lr:0.100000
[ Wed Apr 25 09:29:44 2018 ] 	Mean training loss: 0.6731.
[ Wed Apr 25 09:29:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:29:44 2018 ] Training epoch: 205
[ Wed Apr 25 09:29:48 2018 ] 	Batch(0/1) done. Loss: 0.7705  lr:0.100000
[ Wed Apr 25 09:29:48 2018 ] 	Mean training loss: 0.7705.
[ Wed Apr 25 09:29:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:29:48 2018 ] Eval epoch: 205
[ Wed Apr 25 09:29:51 2018 ] 	Mean test loss of 1 batches: 0.8001455664634705.
[ Wed Apr 25 09:29:51 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:29:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:29:51 2018 ] Training epoch: 206
[ Wed Apr 25 09:29:55 2018 ] 	Batch(0/1) done. Loss: 0.6521  lr:0.100000
[ Wed Apr 25 09:29:55 2018 ] 	Mean training loss: 0.6521.
[ Wed Apr 25 09:29:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:29:55 2018 ] Training epoch: 207
[ Wed Apr 25 09:29:59 2018 ] 	Batch(0/1) done. Loss: 0.6386  lr:0.100000
[ Wed Apr 25 09:29:59 2018 ] 	Mean training loss: 0.6386.
[ Wed Apr 25 09:29:59 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:29:59 2018 ] Training epoch: 208
[ Wed Apr 25 09:30:03 2018 ] 	Batch(0/1) done. Loss: 0.6433  lr:0.100000
[ Wed Apr 25 09:30:03 2018 ] 	Mean training loss: 0.6433.
[ Wed Apr 25 09:30:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:30:03 2018 ] Training epoch: 209
[ Wed Apr 25 09:30:07 2018 ] 	Batch(0/1) done. Loss: 0.6751  lr:0.100000
[ Wed Apr 25 09:30:07 2018 ] 	Mean training loss: 0.6751.
[ Wed Apr 25 09:30:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:30:07 2018 ] Training epoch: 210
[ Wed Apr 25 09:30:11 2018 ] 	Batch(0/1) done. Loss: 0.6228  lr:0.100000
[ Wed Apr 25 09:30:11 2018 ] 	Mean training loss: 0.6228.
[ Wed Apr 25 09:30:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:11 2018 ] Eval epoch: 210
[ Wed Apr 25 09:30:14 2018 ] 	Mean test loss of 1 batches: 0.6467773914337158.
[ Wed Apr 25 09:30:14 2018 ] 	Top1: 59.26%
[ Wed Apr 25 09:30:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:30:14 2018 ] Training epoch: 211
[ Wed Apr 25 09:30:18 2018 ] 	Batch(0/1) done. Loss: 0.7576  lr:0.100000
[ Wed Apr 25 09:30:18 2018 ] 	Mean training loss: 0.7576.
[ Wed Apr 25 09:30:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:18 2018 ] Training epoch: 212
[ Wed Apr 25 09:30:22 2018 ] 	Batch(0/1) done. Loss: 0.5732  lr:0.100000
[ Wed Apr 25 09:30:22 2018 ] 	Mean training loss: 0.5732.
[ Wed Apr 25 09:30:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:22 2018 ] Training epoch: 213
[ Wed Apr 25 09:30:26 2018 ] 	Batch(0/1) done. Loss: 0.6266  lr:0.100000
[ Wed Apr 25 09:30:26 2018 ] 	Mean training loss: 0.6266.
[ Wed Apr 25 09:30:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:30:26 2018 ] Training epoch: 214
[ Wed Apr 25 09:30:30 2018 ] 	Batch(0/1) done. Loss: 0.5912  lr:0.100000
[ Wed Apr 25 09:30:30 2018 ] 	Mean training loss: 0.5912.
[ Wed Apr 25 09:30:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:30 2018 ] Training epoch: 215
[ Wed Apr 25 09:30:34 2018 ] 	Batch(0/1) done. Loss: 0.5822  lr:0.100000
[ Wed Apr 25 09:30:34 2018 ] 	Mean training loss: 0.5822.
[ Wed Apr 25 09:30:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:34 2018 ] Eval epoch: 215
[ Wed Apr 25 09:30:37 2018 ] 	Mean test loss of 1 batches: 0.6044514179229736.
[ Wed Apr 25 09:30:37 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:30:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:30:37 2018 ] Training epoch: 216
[ Wed Apr 25 09:30:41 2018 ] 	Batch(0/1) done. Loss: 0.7798  lr:0.100000
[ Wed Apr 25 09:30:41 2018 ] 	Mean training loss: 0.7798.
[ Wed Apr 25 09:30:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:41 2018 ] Training epoch: 217
[ Wed Apr 25 09:30:45 2018 ] 	Batch(0/1) done. Loss: 0.7122  lr:0.100000
[ Wed Apr 25 09:30:45 2018 ] 	Mean training loss: 0.7122.
[ Wed Apr 25 09:30:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:45 2018 ] Training epoch: 218
[ Wed Apr 25 09:30:49 2018 ] 	Batch(0/1) done. Loss: 0.5462  lr:0.100000
[ Wed Apr 25 09:30:49 2018 ] 	Mean training loss: 0.5462.
[ Wed Apr 25 09:30:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:30:49 2018 ] Training epoch: 219
[ Wed Apr 25 09:30:53 2018 ] 	Batch(0/1) done. Loss: 0.5634  lr:0.100000
[ Wed Apr 25 09:30:53 2018 ] 	Mean training loss: 0.5634.
[ Wed Apr 25 09:30:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:53 2018 ] Training epoch: 220
[ Wed Apr 25 09:30:56 2018 ] 	Batch(0/1) done. Loss: 0.5076  lr:0.100000
[ Wed Apr 25 09:30:56 2018 ] 	Mean training loss: 0.5076.
[ Wed Apr 25 09:30:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:30:56 2018 ] Eval epoch: 220
[ Wed Apr 25 09:30:59 2018 ] 	Mean test loss of 1 batches: 0.5617644190788269.
[ Wed Apr 25 09:30:59 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:30:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:30:59 2018 ] Training epoch: 221
[ Wed Apr 25 09:31:03 2018 ] 	Batch(0/1) done. Loss: 0.5412  lr:0.100000
[ Wed Apr 25 09:31:03 2018 ] 	Mean training loss: 0.5412.
[ Wed Apr 25 09:31:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:03 2018 ] Training epoch: 222
[ Wed Apr 25 09:31:07 2018 ] 	Batch(0/1) done. Loss: 0.6002  lr:0.100000
[ Wed Apr 25 09:31:07 2018 ] 	Mean training loss: 0.6002.
[ Wed Apr 25 09:31:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:07 2018 ] Training epoch: 223
[ Wed Apr 25 09:31:11 2018 ] 	Batch(0/1) done. Loss: 0.7542  lr:0.100000
[ Wed Apr 25 09:31:11 2018 ] 	Mean training loss: 0.7542.
[ Wed Apr 25 09:31:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:11 2018 ] Training epoch: 224
[ Wed Apr 25 09:31:15 2018 ] 	Batch(0/1) done. Loss: 0.6511  lr:0.100000
[ Wed Apr 25 09:31:15 2018 ] 	Mean training loss: 0.6511.
[ Wed Apr 25 09:31:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:15 2018 ] Training epoch: 225
[ Wed Apr 25 09:31:19 2018 ] 	Batch(0/1) done. Loss: 0.5788  lr:0.100000
[ Wed Apr 25 09:31:19 2018 ] 	Mean training loss: 0.5788.
[ Wed Apr 25 09:31:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:19 2018 ] Eval epoch: 225
[ Wed Apr 25 09:31:22 2018 ] 	Mean test loss of 1 batches: 0.6617099046707153.
[ Wed Apr 25 09:31:22 2018 ] 	Top1: 66.67%
[ Wed Apr 25 09:31:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:31:22 2018 ] Training epoch: 226
[ Wed Apr 25 09:31:26 2018 ] 	Batch(0/1) done. Loss: 0.5889  lr:0.100000
[ Wed Apr 25 09:31:26 2018 ] 	Mean training loss: 0.5889.
[ Wed Apr 25 09:31:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:26 2018 ] Training epoch: 227
[ Wed Apr 25 09:31:30 2018 ] 	Batch(0/1) done. Loss: 0.5618  lr:0.100000
[ Wed Apr 25 09:31:30 2018 ] 	Mean training loss: 0.5618.
[ Wed Apr 25 09:31:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:31:30 2018 ] Training epoch: 228
[ Wed Apr 25 09:31:34 2018 ] 	Batch(0/1) done. Loss: 0.5446  lr:0.100000
[ Wed Apr 25 09:31:34 2018 ] 	Mean training loss: 0.5446.
[ Wed Apr 25 09:31:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:34 2018 ] Training epoch: 229
[ Wed Apr 25 09:31:37 2018 ] 	Batch(0/1) done. Loss: 0.4354  lr:0.100000
[ Wed Apr 25 09:31:37 2018 ] 	Mean training loss: 0.4354.
[ Wed Apr 25 09:31:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:37 2018 ] Training epoch: 230
[ Wed Apr 25 09:31:41 2018 ] 	Batch(0/1) done. Loss: 0.5338  lr:0.100000
[ Wed Apr 25 09:31:41 2018 ] 	Mean training loss: 0.5338.
[ Wed Apr 25 09:31:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:41 2018 ] Eval epoch: 230
[ Wed Apr 25 09:31:44 2018 ] 	Mean test loss of 1 batches: 0.7360860109329224.
[ Wed Apr 25 09:31:44 2018 ] 	Top1: 59.26%
[ Wed Apr 25 09:31:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:31:44 2018 ] Training epoch: 231
[ Wed Apr 25 09:31:48 2018 ] 	Batch(0/1) done. Loss: 0.4009  lr:0.100000
[ Wed Apr 25 09:31:48 2018 ] 	Mean training loss: 0.4009.
[ Wed Apr 25 09:31:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:48 2018 ] Training epoch: 232
[ Wed Apr 25 09:31:52 2018 ] 	Batch(0/1) done. Loss: 0.4659  lr:0.100000
[ Wed Apr 25 09:31:52 2018 ] 	Mean training loss: 0.4659.
[ Wed Apr 25 09:31:52 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:31:52 2018 ] Training epoch: 233
[ Wed Apr 25 09:31:56 2018 ] 	Batch(0/1) done. Loss: 0.4687  lr:0.100000
[ Wed Apr 25 09:31:56 2018 ] 	Mean training loss: 0.4687.
[ Wed Apr 25 09:31:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:31:56 2018 ] Training epoch: 234
[ Wed Apr 25 09:32:00 2018 ] 	Batch(0/1) done. Loss: 0.4902  lr:0.100000
[ Wed Apr 25 09:32:00 2018 ] 	Mean training loss: 0.4902.
[ Wed Apr 25 09:32:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:00 2018 ] Training epoch: 235
[ Wed Apr 25 09:32:04 2018 ] 	Batch(0/1) done. Loss: 0.4193  lr:0.100000
[ Wed Apr 25 09:32:04 2018 ] 	Mean training loss: 0.4193.
[ Wed Apr 25 09:32:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:04 2018 ] Eval epoch: 235
[ Wed Apr 25 09:32:07 2018 ] 	Mean test loss of 1 batches: 0.7415699362754822.
[ Wed Apr 25 09:32:07 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:32:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:32:07 2018 ] Training epoch: 236
[ Wed Apr 25 09:32:11 2018 ] 	Batch(0/1) done. Loss: 0.4711  lr:0.100000
[ Wed Apr 25 09:32:11 2018 ] 	Mean training loss: 0.4711.
[ Wed Apr 25 09:32:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:11 2018 ] Training epoch: 237
[ Wed Apr 25 09:32:15 2018 ] 	Batch(0/1) done. Loss: 0.3734  lr:0.100000
[ Wed Apr 25 09:32:15 2018 ] 	Mean training loss: 0.3734.
[ Wed Apr 25 09:32:15 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:32:15 2018 ] Training epoch: 238
[ Wed Apr 25 09:32:19 2018 ] 	Batch(0/1) done. Loss: 0.4108  lr:0.100000
[ Wed Apr 25 09:32:19 2018 ] 	Mean training loss: 0.4108.
[ Wed Apr 25 09:32:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:32:19 2018 ] Training epoch: 239
[ Wed Apr 25 09:32:23 2018 ] 	Batch(0/1) done. Loss: 0.3660  lr:0.100000
[ Wed Apr 25 09:32:23 2018 ] 	Mean training loss: 0.3660.
[ Wed Apr 25 09:32:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:23 2018 ] Training epoch: 240
[ Wed Apr 25 09:32:26 2018 ] 	Batch(0/1) done. Loss: 0.3272  lr:0.100000
[ Wed Apr 25 09:32:26 2018 ] 	Mean training loss: 0.3272.
[ Wed Apr 25 09:32:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:26 2018 ] Eval epoch: 240
[ Wed Apr 25 09:32:29 2018 ] 	Mean test loss of 1 batches: 0.5623875260353088.
[ Wed Apr 25 09:32:29 2018 ] 	Top1: 66.67%
[ Wed Apr 25 09:32:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:32:29 2018 ] Training epoch: 241
[ Wed Apr 25 09:32:33 2018 ] 	Batch(0/1) done. Loss: 0.4196  lr:0.100000
[ Wed Apr 25 09:32:33 2018 ] 	Mean training loss: 0.4196.
[ Wed Apr 25 09:32:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:33 2018 ] Training epoch: 242
[ Wed Apr 25 09:32:37 2018 ] 	Batch(0/1) done. Loss: 0.4936  lr:0.100000
[ Wed Apr 25 09:32:37 2018 ] 	Mean training loss: 0.4936.
[ Wed Apr 25 09:32:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:32:37 2018 ] Training epoch: 243
[ Wed Apr 25 09:32:41 2018 ] 	Batch(0/1) done. Loss: 0.4611  lr:0.100000
[ Wed Apr 25 09:32:41 2018 ] 	Mean training loss: 0.4611.
[ Wed Apr 25 09:32:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:41 2018 ] Training epoch: 244
[ Wed Apr 25 09:32:45 2018 ] 	Batch(0/1) done. Loss: 0.4341  lr:0.100000
[ Wed Apr 25 09:32:45 2018 ] 	Mean training loss: 0.4341.
[ Wed Apr 25 09:32:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:45 2018 ] Training epoch: 245
[ Wed Apr 25 09:32:49 2018 ] 	Batch(0/1) done. Loss: 0.4689  lr:0.100000
[ Wed Apr 25 09:32:49 2018 ] 	Mean training loss: 0.4689.
[ Wed Apr 25 09:32:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:32:49 2018 ] Eval epoch: 245
[ Wed Apr 25 09:32:52 2018 ] 	Mean test loss of 1 batches: 0.5115435719490051.
[ Wed Apr 25 09:32:52 2018 ] 	Top1: 77.78%
[ Wed Apr 25 09:32:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:32:52 2018 ] Training epoch: 246
[ Wed Apr 25 09:32:56 2018 ] 	Batch(0/1) done. Loss: 0.4272  lr:0.100000
[ Wed Apr 25 09:32:56 2018 ] 	Mean training loss: 0.4272.
[ Wed Apr 25 09:32:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:32:56 2018 ] Training epoch: 247
[ Wed Apr 25 09:33:00 2018 ] 	Batch(0/1) done. Loss: 0.4646  lr:0.100000
[ Wed Apr 25 09:33:00 2018 ] 	Mean training loss: 0.4646.
[ Wed Apr 25 09:33:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:33:00 2018 ] Training epoch: 248
[ Wed Apr 25 09:33:04 2018 ] 	Batch(0/1) done. Loss: 0.4952  lr:0.100000
[ Wed Apr 25 09:33:04 2018 ] 	Mean training loss: 0.4952.
[ Wed Apr 25 09:33:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:04 2018 ] Training epoch: 249
[ Wed Apr 25 09:33:08 2018 ] 	Batch(0/1) done. Loss: 0.4385  lr:0.100000
[ Wed Apr 25 09:33:08 2018 ] 	Mean training loss: 0.4385.
[ Wed Apr 25 09:33:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:33:08 2018 ] Training epoch: 250
[ Wed Apr 25 09:33:12 2018 ] 	Batch(0/1) done. Loss: 0.4031  lr:0.100000
[ Wed Apr 25 09:33:12 2018 ] 	Mean training loss: 0.4031.
[ Wed Apr 25 09:33:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:12 2018 ] Eval epoch: 250
[ Wed Apr 25 09:33:14 2018 ] 	Mean test loss of 1 batches: 0.525479793548584.
[ Wed Apr 25 09:33:14 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:33:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:33:14 2018 ] Training epoch: 251
[ Wed Apr 25 09:33:18 2018 ] 	Batch(0/1) done. Loss: 0.4370  lr:0.100000
[ Wed Apr 25 09:33:18 2018 ] 	Mean training loss: 0.4370.
[ Wed Apr 25 09:33:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:18 2018 ] Training epoch: 252
[ Wed Apr 25 09:33:22 2018 ] 	Batch(0/1) done. Loss: 0.3936  lr:0.100000
[ Wed Apr 25 09:33:22 2018 ] 	Mean training loss: 0.3936.
[ Wed Apr 25 09:33:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:33:22 2018 ] Training epoch: 253
[ Wed Apr 25 09:33:26 2018 ] 	Batch(0/1) done. Loss: 0.3514  lr:0.100000
[ Wed Apr 25 09:33:26 2018 ] 	Mean training loss: 0.3514.
[ Wed Apr 25 09:33:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:26 2018 ] Training epoch: 254
[ Wed Apr 25 09:33:30 2018 ] 	Batch(0/1) done. Loss: 0.2830  lr:0.100000
[ Wed Apr 25 09:33:30 2018 ] 	Mean training loss: 0.2830.
[ Wed Apr 25 09:33:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:30 2018 ] Training epoch: 255
[ Wed Apr 25 09:33:34 2018 ] 	Batch(0/1) done. Loss: 0.5008  lr:0.100000
[ Wed Apr 25 09:33:34 2018 ] 	Mean training loss: 0.5008.
[ Wed Apr 25 09:33:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:34 2018 ] Eval epoch: 255
[ Wed Apr 25 09:33:37 2018 ] 	Mean test loss of 1 batches: 1.0752897262573242.
[ Wed Apr 25 09:33:37 2018 ] 	Top1: 48.15%
[ Wed Apr 25 09:33:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:33:37 2018 ] Training epoch: 256
[ Wed Apr 25 09:33:41 2018 ] 	Batch(0/1) done. Loss: 0.4590  lr:0.100000
[ Wed Apr 25 09:33:41 2018 ] 	Mean training loss: 0.4590.
[ Wed Apr 25 09:33:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:41 2018 ] Training epoch: 257
[ Wed Apr 25 09:33:45 2018 ] 	Batch(0/1) done. Loss: 0.3789  lr:0.100000
[ Wed Apr 25 09:33:45 2018 ] 	Mean training loss: 0.3789.
[ Wed Apr 25 09:33:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:33:45 2018 ] Training epoch: 258
[ Wed Apr 25 09:33:49 2018 ] 	Batch(0/1) done. Loss: 0.3384  lr:0.100000
[ Wed Apr 25 09:33:49 2018 ] 	Mean training loss: 0.3384.
[ Wed Apr 25 09:33:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:49 2018 ] Training epoch: 259
[ Wed Apr 25 09:33:53 2018 ] 	Batch(0/1) done. Loss: 0.3408  lr:0.100000
[ Wed Apr 25 09:33:53 2018 ] 	Mean training loss: 0.3408.
[ Wed Apr 25 09:33:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:53 2018 ] Training epoch: 260
[ Wed Apr 25 09:33:57 2018 ] 	Batch(0/1) done. Loss: 0.4095  lr:0.100000
[ Wed Apr 25 09:33:57 2018 ] 	Mean training loss: 0.4095.
[ Wed Apr 25 09:33:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:33:57 2018 ] Eval epoch: 260
[ Wed Apr 25 09:34:00 2018 ] 	Mean test loss of 1 batches: 0.5188547968864441.
[ Wed Apr 25 09:34:00 2018 ] 	Top1: 66.67%
[ Wed Apr 25 09:34:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:34:00 2018 ] Training epoch: 261
[ Wed Apr 25 09:34:04 2018 ] 	Batch(0/1) done. Loss: 0.3898  lr:0.100000
[ Wed Apr 25 09:34:04 2018 ] 	Mean training loss: 0.3898.
[ Wed Apr 25 09:34:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:04 2018 ] Training epoch: 262
[ Wed Apr 25 09:34:08 2018 ] 	Batch(0/1) done. Loss: 0.3755  lr:0.100000
[ Wed Apr 25 09:34:08 2018 ] 	Mean training loss: 0.3755.
[ Wed Apr 25 09:34:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:34:08 2018 ] Training epoch: 263
[ Wed Apr 25 09:34:12 2018 ] 	Batch(0/1) done. Loss: 0.3068  lr:0.100000
[ Wed Apr 25 09:34:12 2018 ] 	Mean training loss: 0.3068.
[ Wed Apr 25 09:34:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:12 2018 ] Training epoch: 264
[ Wed Apr 25 09:34:16 2018 ] 	Batch(0/1) done. Loss: 0.3701  lr:0.100000
[ Wed Apr 25 09:34:16 2018 ] 	Mean training loss: 0.3701.
[ Wed Apr 25 09:34:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:16 2018 ] Training epoch: 265
[ Wed Apr 25 09:34:20 2018 ] 	Batch(0/1) done. Loss: 0.5268  lr:0.100000
[ Wed Apr 25 09:34:20 2018 ] 	Mean training loss: 0.5268.
[ Wed Apr 25 09:34:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:34:20 2018 ] Eval epoch: 265
[ Wed Apr 25 09:34:22 2018 ] 	Mean test loss of 1 batches: 0.5838153958320618.
[ Wed Apr 25 09:34:22 2018 ] 	Top1: 77.78%
[ Wed Apr 25 09:34:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:34:22 2018 ] Training epoch: 266
[ Wed Apr 25 09:34:26 2018 ] 	Batch(0/1) done. Loss: 0.3962  lr:0.100000
[ Wed Apr 25 09:34:26 2018 ] 	Mean training loss: 0.3962.
[ Wed Apr 25 09:34:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:26 2018 ] Training epoch: 267
[ Wed Apr 25 09:34:30 2018 ] 	Batch(0/1) done. Loss: 0.3492  lr:0.100000
[ Wed Apr 25 09:34:30 2018 ] 	Mean training loss: 0.3492.
[ Wed Apr 25 09:34:30 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 09:34:30 2018 ] Training epoch: 268
[ Wed Apr 25 09:34:34 2018 ] 	Batch(0/1) done. Loss: 0.3074  lr:0.100000
[ Wed Apr 25 09:34:34 2018 ] 	Mean training loss: 0.3074.
[ Wed Apr 25 09:34:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:34 2018 ] Training epoch: 269
[ Wed Apr 25 09:34:38 2018 ] 	Batch(0/1) done. Loss: 0.3933  lr:0.100000
[ Wed Apr 25 09:34:38 2018 ] 	Mean training loss: 0.3933.
[ Wed Apr 25 09:34:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:38 2018 ] Training epoch: 270
[ Wed Apr 25 09:34:42 2018 ] 	Batch(0/1) done. Loss: 0.2761  lr:0.100000
[ Wed Apr 25 09:34:42 2018 ] 	Mean training loss: 0.2761.
[ Wed Apr 25 09:34:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:42 2018 ] Eval epoch: 270
[ Wed Apr 25 09:34:45 2018 ] 	Mean test loss of 1 batches: 0.6313120722770691.
[ Wed Apr 25 09:34:45 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:34:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:34:45 2018 ] Training epoch: 271
[ Wed Apr 25 09:34:49 2018 ] 	Batch(0/1) done. Loss: 0.2299  lr:0.100000
[ Wed Apr 25 09:34:49 2018 ] 	Mean training loss: 0.2299.
[ Wed Apr 25 09:34:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:49 2018 ] Training epoch: 272
[ Wed Apr 25 09:34:53 2018 ] 	Batch(0/1) done. Loss: 0.3719  lr:0.100000
[ Wed Apr 25 09:34:53 2018 ] 	Mean training loss: 0.3719.
[ Wed Apr 25 09:34:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:53 2018 ] Training epoch: 273
[ Wed Apr 25 09:34:57 2018 ] 	Batch(0/1) done. Loss: 0.3917  lr:0.100000
[ Wed Apr 25 09:34:57 2018 ] 	Mean training loss: 0.3917.
[ Wed Apr 25 09:34:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:34:57 2018 ] Training epoch: 274
[ Wed Apr 25 09:35:01 2018 ] 	Batch(0/1) done. Loss: 0.2586  lr:0.100000
[ Wed Apr 25 09:35:01 2018 ] 	Mean training loss: 0.2586.
[ Wed Apr 25 09:35:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:01 2018 ] Training epoch: 275
[ Wed Apr 25 09:35:05 2018 ] 	Batch(0/1) done. Loss: 0.4641  lr:0.100000
[ Wed Apr 25 09:35:05 2018 ] 	Mean training loss: 0.4641.
[ Wed Apr 25 09:35:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:05 2018 ] Eval epoch: 275
[ Wed Apr 25 09:35:07 2018 ] 	Mean test loss of 1 batches: 0.6964115500450134.
[ Wed Apr 25 09:35:07 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:35:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:35:07 2018 ] Training epoch: 276
[ Wed Apr 25 09:35:11 2018 ] 	Batch(0/1) done. Loss: 0.4416  lr:0.100000
[ Wed Apr 25 09:35:11 2018 ] 	Mean training loss: 0.4416.
[ Wed Apr 25 09:35:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:11 2018 ] Training epoch: 277
[ Wed Apr 25 09:35:15 2018 ] 	Batch(0/1) done. Loss: 0.3941  lr:0.100000
[ Wed Apr 25 09:35:15 2018 ] 	Mean training loss: 0.3941.
[ Wed Apr 25 09:35:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:35:15 2018 ] Training epoch: 278
[ Wed Apr 25 09:35:19 2018 ] 	Batch(0/1) done. Loss: 0.3295  lr:0.100000
[ Wed Apr 25 09:35:19 2018 ] 	Mean training loss: 0.3295.
[ Wed Apr 25 09:35:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:35:19 2018 ] Training epoch: 279
[ Wed Apr 25 09:35:23 2018 ] 	Batch(0/1) done. Loss: 0.3486  lr:0.100000
[ Wed Apr 25 09:35:23 2018 ] 	Mean training loss: 0.3486.
[ Wed Apr 25 09:35:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:23 2018 ] Training epoch: 280
[ Wed Apr 25 09:35:27 2018 ] 	Batch(0/1) done. Loss: 0.3461  lr:0.100000
[ Wed Apr 25 09:35:27 2018 ] 	Mean training loss: 0.3461.
[ Wed Apr 25 09:35:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:27 2018 ] Eval epoch: 280
[ Wed Apr 25 09:35:30 2018 ] 	Mean test loss of 1 batches: 0.6665028929710388.
[ Wed Apr 25 09:35:30 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:35:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:35:30 2018 ] Training epoch: 281
[ Wed Apr 25 09:35:34 2018 ] 	Batch(0/1) done. Loss: 0.4071  lr:0.100000
[ Wed Apr 25 09:35:34 2018 ] 	Mean training loss: 0.4071.
[ Wed Apr 25 09:35:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:34 2018 ] Training epoch: 282
[ Wed Apr 25 09:35:38 2018 ] 	Batch(0/1) done. Loss: 0.3056  lr:0.100000
[ Wed Apr 25 09:35:38 2018 ] 	Mean training loss: 0.3056.
[ Wed Apr 25 09:35:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:38 2018 ] Training epoch: 283
[ Wed Apr 25 09:35:42 2018 ] 	Batch(0/1) done. Loss: 0.2818  lr:0.100000
[ Wed Apr 25 09:35:42 2018 ] 	Mean training loss: 0.2818.
[ Wed Apr 25 09:35:42 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 09:35:42 2018 ] Training epoch: 284
[ Wed Apr 25 09:35:46 2018 ] 	Batch(0/1) done. Loss: 0.2443  lr:0.100000
[ Wed Apr 25 09:35:46 2018 ] 	Mean training loss: 0.2443.
[ Wed Apr 25 09:35:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:46 2018 ] Training epoch: 285
[ Wed Apr 25 09:35:50 2018 ] 	Batch(0/1) done. Loss: 0.3284  lr:0.100000
[ Wed Apr 25 09:35:50 2018 ] 	Mean training loss: 0.3284.
[ Wed Apr 25 09:35:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:50 2018 ] Eval epoch: 285
[ Wed Apr 25 09:35:53 2018 ] 	Mean test loss of 1 batches: 0.5988268852233887.
[ Wed Apr 25 09:35:53 2018 ] 	Top1: 77.78%
[ Wed Apr 25 09:35:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:35:53 2018 ] Training epoch: 286
[ Wed Apr 25 09:35:57 2018 ] 	Batch(0/1) done. Loss: 0.3581  lr:0.100000
[ Wed Apr 25 09:35:57 2018 ] 	Mean training loss: 0.3581.
[ Wed Apr 25 09:35:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:35:57 2018 ] Training epoch: 287
[ Wed Apr 25 09:36:01 2018 ] 	Batch(0/1) done. Loss: 0.2071  lr:0.100000
[ Wed Apr 25 09:36:01 2018 ] 	Mean training loss: 0.2071.
[ Wed Apr 25 09:36:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:01 2018 ] Training epoch: 288
[ Wed Apr 25 09:36:05 2018 ] 	Batch(0/1) done. Loss: 0.3455  lr:0.100000
[ Wed Apr 25 09:36:05 2018 ] 	Mean training loss: 0.3455.
[ Wed Apr 25 09:36:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:05 2018 ] Training epoch: 289
[ Wed Apr 25 09:36:09 2018 ] 	Batch(0/1) done. Loss: 0.3042  lr:0.100000
[ Wed Apr 25 09:36:09 2018 ] 	Mean training loss: 0.3042.
[ Wed Apr 25 09:36:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:09 2018 ] Training epoch: 290
[ Wed Apr 25 09:36:12 2018 ] 	Batch(0/1) done. Loss: 0.3519  lr:0.100000
[ Wed Apr 25 09:36:12 2018 ] 	Mean training loss: 0.3519.
[ Wed Apr 25 09:36:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:12 2018 ] Eval epoch: 290
[ Wed Apr 25 09:36:15 2018 ] 	Mean test loss of 1 batches: 0.45570868253707886.
[ Wed Apr 25 09:36:15 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:36:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:36:15 2018 ] Training epoch: 291
[ Wed Apr 25 09:36:19 2018 ] 	Batch(0/1) done. Loss: 0.2469  lr:0.100000
[ Wed Apr 25 09:36:19 2018 ] 	Mean training loss: 0.2469.
[ Wed Apr 25 09:36:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:19 2018 ] Training epoch: 292
[ Wed Apr 25 09:36:23 2018 ] 	Batch(0/1) done. Loss: 0.2255  lr:0.100000
[ Wed Apr 25 09:36:23 2018 ] 	Mean training loss: 0.2255.
[ Wed Apr 25 09:36:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:36:23 2018 ] Training epoch: 293
[ Wed Apr 25 09:36:27 2018 ] 	Batch(0/1) done. Loss: 0.1959  lr:0.100000
[ Wed Apr 25 09:36:27 2018 ] 	Mean training loss: 0.1959.
[ Wed Apr 25 09:36:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:27 2018 ] Training epoch: 294
[ Wed Apr 25 09:36:31 2018 ] 	Batch(0/1) done. Loss: 0.2520  lr:0.100000
[ Wed Apr 25 09:36:31 2018 ] 	Mean training loss: 0.2520.
[ Wed Apr 25 09:36:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:31 2018 ] Training epoch: 295
[ Wed Apr 25 09:36:35 2018 ] 	Batch(0/1) done. Loss: 0.2283  lr:0.100000
[ Wed Apr 25 09:36:35 2018 ] 	Mean training loss: 0.2283.
[ Wed Apr 25 09:36:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:35 2018 ] Eval epoch: 295
[ Wed Apr 25 09:36:38 2018 ] 	Mean test loss of 1 batches: 0.4310859739780426.
[ Wed Apr 25 09:36:38 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:36:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:36:38 2018 ] Training epoch: 296
[ Wed Apr 25 09:36:42 2018 ] 	Batch(0/1) done. Loss: 0.2113  lr:0.100000
[ Wed Apr 25 09:36:42 2018 ] 	Mean training loss: 0.2113.
[ Wed Apr 25 09:36:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:36:42 2018 ] Training epoch: 297
[ Wed Apr 25 09:36:46 2018 ] 	Batch(0/1) done. Loss: 0.2317  lr:0.100000
[ Wed Apr 25 09:36:46 2018 ] 	Mean training loss: 0.2317.
[ Wed Apr 25 09:36:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:46 2018 ] Training epoch: 298
[ Wed Apr 25 09:36:50 2018 ] 	Batch(0/1) done. Loss: 0.2585  lr:0.100000
[ Wed Apr 25 09:36:50 2018 ] 	Mean training loss: 0.2585.
[ Wed Apr 25 09:36:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:50 2018 ] Training epoch: 299
[ Wed Apr 25 09:36:54 2018 ] 	Batch(0/1) done. Loss: 0.3309  lr:0.100000
[ Wed Apr 25 09:36:54 2018 ] 	Mean training loss: 0.3309.
[ Wed Apr 25 09:36:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:54 2018 ] Training epoch: 300
[ Wed Apr 25 09:36:58 2018 ] 	Batch(0/1) done. Loss: 0.4236  lr:0.100000
[ Wed Apr 25 09:36:58 2018 ] 	Mean training loss: 0.4236.
[ Wed Apr 25 09:36:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:36:58 2018 ] Eval epoch: 300
[ Wed Apr 25 09:37:00 2018 ] 	Mean test loss of 1 batches: 0.7441352605819702.
[ Wed Apr 25 09:37:00 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:37:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:37:00 2018 ] Training epoch: 301
[ Wed Apr 25 09:37:04 2018 ] 	Batch(0/1) done. Loss: 0.2685  lr:0.100000
[ Wed Apr 25 09:37:04 2018 ] 	Mean training loss: 0.2685.
[ Wed Apr 25 09:37:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:04 2018 ] Training epoch: 302
[ Wed Apr 25 09:37:08 2018 ] 	Batch(0/1) done. Loss: 0.3081  lr:0.100000
[ Wed Apr 25 09:37:08 2018 ] 	Mean training loss: 0.3081.
[ Wed Apr 25 09:37:08 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:37:08 2018 ] Training epoch: 303
[ Wed Apr 25 09:37:12 2018 ] 	Batch(0/1) done. Loss: 0.3084  lr:0.100000
[ Wed Apr 25 09:37:12 2018 ] 	Mean training loss: 0.3084.
[ Wed Apr 25 09:37:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:12 2018 ] Training epoch: 304
[ Wed Apr 25 09:37:16 2018 ] 	Batch(0/1) done. Loss: 0.2280  lr:0.100000
[ Wed Apr 25 09:37:16 2018 ] 	Mean training loss: 0.2280.
[ Wed Apr 25 09:37:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:37:16 2018 ] Training epoch: 305
[ Wed Apr 25 09:37:20 2018 ] 	Batch(0/1) done. Loss: 0.2500  lr:0.100000
[ Wed Apr 25 09:37:20 2018 ] 	Mean training loss: 0.2500.
[ Wed Apr 25 09:37:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:20 2018 ] Eval epoch: 305
[ Wed Apr 25 09:37:23 2018 ] 	Mean test loss of 1 batches: 1.2884312868118286.
[ Wed Apr 25 09:37:23 2018 ] 	Top1: 59.26%
[ Wed Apr 25 09:37:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:37:23 2018 ] Training epoch: 306
[ Wed Apr 25 09:37:27 2018 ] 	Batch(0/1) done. Loss: 0.3192  lr:0.100000
[ Wed Apr 25 09:37:27 2018 ] 	Mean training loss: 0.3192.
[ Wed Apr 25 09:37:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:37:27 2018 ] Training epoch: 307
[ Wed Apr 25 09:37:31 2018 ] 	Batch(0/1) done. Loss: 0.3387  lr:0.100000
[ Wed Apr 25 09:37:31 2018 ] 	Mean training loss: 0.3387.
[ Wed Apr 25 09:37:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:31 2018 ] Training epoch: 308
[ Wed Apr 25 09:37:35 2018 ] 	Batch(0/1) done. Loss: 0.2656  lr:0.100000
[ Wed Apr 25 09:37:35 2018 ] 	Mean training loss: 0.2656.
[ Wed Apr 25 09:37:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:37:35 2018 ] Training epoch: 309
[ Wed Apr 25 09:37:39 2018 ] 	Batch(0/1) done. Loss: 0.2009  lr:0.100000
[ Wed Apr 25 09:37:39 2018 ] 	Mean training loss: 0.2009.
[ Wed Apr 25 09:37:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:39 2018 ] Training epoch: 310
[ Wed Apr 25 09:37:43 2018 ] 	Batch(0/1) done. Loss: 0.1705  lr:0.100000
[ Wed Apr 25 09:37:43 2018 ] 	Mean training loss: 0.1705.
[ Wed Apr 25 09:37:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:43 2018 ] Eval epoch: 310
[ Wed Apr 25 09:37:46 2018 ] 	Mean test loss of 1 batches: 1.3858520984649658.
[ Wed Apr 25 09:37:46 2018 ] 	Top1: 55.56%
[ Wed Apr 25 09:37:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:37:46 2018 ] Training epoch: 311
[ Wed Apr 25 09:37:50 2018 ] 	Batch(0/1) done. Loss: 0.2189  lr:0.100000
[ Wed Apr 25 09:37:50 2018 ] 	Mean training loss: 0.2189.
[ Wed Apr 25 09:37:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:37:50 2018 ] Training epoch: 312
[ Wed Apr 25 09:37:54 2018 ] 	Batch(0/1) done. Loss: 0.2550  lr:0.100000
[ Wed Apr 25 09:37:54 2018 ] 	Mean training loss: 0.2550.
[ Wed Apr 25 09:37:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:37:54 2018 ] Training epoch: 313
[ Wed Apr 25 09:37:58 2018 ] 	Batch(0/1) done. Loss: 0.2048  lr:0.100000
[ Wed Apr 25 09:37:58 2018 ] 	Mean training loss: 0.2048.
[ Wed Apr 25 09:37:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:37:58 2018 ] Training epoch: 314
[ Wed Apr 25 09:38:02 2018 ] 	Batch(0/1) done. Loss: 0.1978  lr:0.100000
[ Wed Apr 25 09:38:02 2018 ] 	Mean training loss: 0.1978.
[ Wed Apr 25 09:38:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:38:02 2018 ] Training epoch: 315
[ Wed Apr 25 09:38:06 2018 ] 	Batch(0/1) done. Loss: 0.1273  lr:0.100000
[ Wed Apr 25 09:38:06 2018 ] 	Mean training loss: 0.1273.
[ Wed Apr 25 09:38:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:06 2018 ] Eval epoch: 315
[ Wed Apr 25 09:38:09 2018 ] 	Mean test loss of 1 batches: 0.5325118899345398.
[ Wed Apr 25 09:38:09 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:38:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:38:09 2018 ] Training epoch: 316
[ Wed Apr 25 09:38:13 2018 ] 	Batch(0/1) done. Loss: 0.1661  lr:0.100000
[ Wed Apr 25 09:38:13 2018 ] 	Mean training loss: 0.1661.
[ Wed Apr 25 09:38:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:13 2018 ] Training epoch: 317
[ Wed Apr 25 09:38:17 2018 ] 	Batch(0/1) done. Loss: 0.2737  lr:0.100000
[ Wed Apr 25 09:38:17 2018 ] 	Mean training loss: 0.2737.
[ Wed Apr 25 09:38:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:17 2018 ] Training epoch: 318
[ Wed Apr 25 09:38:21 2018 ] 	Batch(0/1) done. Loss: 0.1306  lr:0.100000
[ Wed Apr 25 09:38:21 2018 ] 	Mean training loss: 0.1306.
[ Wed Apr 25 09:38:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:21 2018 ] Training epoch: 319
[ Wed Apr 25 09:38:24 2018 ] 	Batch(0/1) done. Loss: 0.1081  lr:0.100000
[ Wed Apr 25 09:38:24 2018 ] 	Mean training loss: 0.1081.
[ Wed Apr 25 09:38:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:24 2018 ] Training epoch: 320
[ Wed Apr 25 09:38:29 2018 ] 	Batch(0/1) done. Loss: 0.1757  lr:0.100000
[ Wed Apr 25 09:38:29 2018 ] 	Mean training loss: 0.1757.
[ Wed Apr 25 09:38:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:38:29 2018 ] Eval epoch: 320
[ Wed Apr 25 09:38:31 2018 ] 	Mean test loss of 1 batches: 0.500477135181427.
[ Wed Apr 25 09:38:31 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:38:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:38:31 2018 ] Training epoch: 321
[ Wed Apr 25 09:38:35 2018 ] 	Batch(0/1) done. Loss: 0.1199  lr:0.100000
[ Wed Apr 25 09:38:35 2018 ] 	Mean training loss: 0.1199.
[ Wed Apr 25 09:38:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:35 2018 ] Training epoch: 322
[ Wed Apr 25 09:38:39 2018 ] 	Batch(0/1) done. Loss: 0.1673  lr:0.100000
[ Wed Apr 25 09:38:39 2018 ] 	Mean training loss: 0.1673.
[ Wed Apr 25 09:38:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:38:39 2018 ] Training epoch: 323
[ Wed Apr 25 09:38:43 2018 ] 	Batch(0/1) done. Loss: 0.1207  lr:0.100000
[ Wed Apr 25 09:38:43 2018 ] 	Mean training loss: 0.1207.
[ Wed Apr 25 09:38:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:43 2018 ] Training epoch: 324
[ Wed Apr 25 09:38:47 2018 ] 	Batch(0/1) done. Loss: 0.1164  lr:0.100000
[ Wed Apr 25 09:38:47 2018 ] 	Mean training loss: 0.1164.
[ Wed Apr 25 09:38:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:38:47 2018 ] Training epoch: 325
[ Wed Apr 25 09:38:51 2018 ] 	Batch(0/1) done. Loss: 0.1007  lr:0.100000
[ Wed Apr 25 09:38:51 2018 ] 	Mean training loss: 0.1007.
[ Wed Apr 25 09:38:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:51 2018 ] Eval epoch: 325
[ Wed Apr 25 09:38:54 2018 ] 	Mean test loss of 1 batches: 0.29162412881851196.
[ Wed Apr 25 09:38:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:38:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:38:54 2018 ] Training epoch: 326
[ Wed Apr 25 09:38:58 2018 ] 	Batch(0/1) done. Loss: 0.1354  lr:0.100000
[ Wed Apr 25 09:38:58 2018 ] 	Mean training loss: 0.1354.
[ Wed Apr 25 09:38:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:38:58 2018 ] Training epoch: 327
[ Wed Apr 25 09:39:02 2018 ] 	Batch(0/1) done. Loss: 0.0553  lr:0.100000
[ Wed Apr 25 09:39:02 2018 ] 	Mean training loss: 0.0553.
[ Wed Apr 25 09:39:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:02 2018 ] Training epoch: 328
[ Wed Apr 25 09:39:06 2018 ] 	Batch(0/1) done. Loss: 0.1331  lr:0.100000
[ Wed Apr 25 09:39:06 2018 ] 	Mean training loss: 0.1331.
[ Wed Apr 25 09:39:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:06 2018 ] Training epoch: 329
[ Wed Apr 25 09:39:10 2018 ] 	Batch(0/1) done. Loss: 0.2390  lr:0.100000
[ Wed Apr 25 09:39:10 2018 ] 	Mean training loss: 0.2390.
[ Wed Apr 25 09:39:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:10 2018 ] Training epoch: 330
[ Wed Apr 25 09:39:14 2018 ] 	Batch(0/1) done. Loss: 0.3291  lr:0.100000
[ Wed Apr 25 09:39:14 2018 ] 	Mean training loss: 0.3291.
[ Wed Apr 25 09:39:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:14 2018 ] Eval epoch: 330
[ Wed Apr 25 09:39:16 2018 ] 	Mean test loss of 1 batches: 0.20237427949905396.
[ Wed Apr 25 09:39:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:39:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:39:16 2018 ] Training epoch: 331
[ Wed Apr 25 09:39:20 2018 ] 	Batch(0/1) done. Loss: 0.1025  lr:0.100000
[ Wed Apr 25 09:39:20 2018 ] 	Mean training loss: 0.1025.
[ Wed Apr 25 09:39:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:39:20 2018 ] Training epoch: 332
[ Wed Apr 25 09:39:24 2018 ] 	Batch(0/1) done. Loss: 0.1831  lr:0.100000
[ Wed Apr 25 09:39:24 2018 ] 	Mean training loss: 0.1831.
[ Wed Apr 25 09:39:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:24 2018 ] Training epoch: 333
[ Wed Apr 25 09:39:28 2018 ] 	Batch(0/1) done. Loss: 0.1469  lr:0.100000
[ Wed Apr 25 09:39:28 2018 ] 	Mean training loss: 0.1469.
[ Wed Apr 25 09:39:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:28 2018 ] Training epoch: 334
[ Wed Apr 25 09:39:32 2018 ] 	Batch(0/1) done. Loss: 0.1052  lr:0.100000
[ Wed Apr 25 09:39:32 2018 ] 	Mean training loss: 0.1052.
[ Wed Apr 25 09:39:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:39:32 2018 ] Training epoch: 335
[ Wed Apr 25 09:39:36 2018 ] 	Batch(0/1) done. Loss: 0.1013  lr:0.100000
[ Wed Apr 25 09:39:36 2018 ] 	Mean training loss: 0.1013.
[ Wed Apr 25 09:39:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:36 2018 ] Eval epoch: 335
[ Wed Apr 25 09:39:39 2018 ] 	Mean test loss of 1 batches: 1.026781678199768.
[ Wed Apr 25 09:39:39 2018 ] 	Top1: 55.56%
[ Wed Apr 25 09:39:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:39:39 2018 ] Training epoch: 336
[ Wed Apr 25 09:39:43 2018 ] 	Batch(0/1) done. Loss: 0.0623  lr:0.100000
[ Wed Apr 25 09:39:43 2018 ] 	Mean training loss: 0.0623.
[ Wed Apr 25 09:39:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:43 2018 ] Training epoch: 337
[ Wed Apr 25 09:39:47 2018 ] 	Batch(0/1) done. Loss: 0.0626  lr:0.100000
[ Wed Apr 25 09:39:47 2018 ] 	Mean training loss: 0.0626.
[ Wed Apr 25 09:39:47 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:39:47 2018 ] Training epoch: 338
[ Wed Apr 25 09:39:51 2018 ] 	Batch(0/1) done. Loss: 0.0841  lr:0.100000
[ Wed Apr 25 09:39:51 2018 ] 	Mean training loss: 0.0841.
[ Wed Apr 25 09:39:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:51 2018 ] Training epoch: 339
[ Wed Apr 25 09:39:55 2018 ] 	Batch(0/1) done. Loss: 0.0476  lr:0.100000
[ Wed Apr 25 09:39:55 2018 ] 	Mean training loss: 0.0476.
[ Wed Apr 25 09:39:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:55 2018 ] Training epoch: 340
[ Wed Apr 25 09:39:59 2018 ] 	Batch(0/1) done. Loss: 0.1476  lr:0.100000
[ Wed Apr 25 09:39:59 2018 ] 	Mean training loss: 0.1476.
[ Wed Apr 25 09:39:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:39:59 2018 ] Eval epoch: 340
[ Wed Apr 25 09:40:02 2018 ] 	Mean test loss of 1 batches: 0.6913514733314514.
[ Wed Apr 25 09:40:02 2018 ] 	Top1: 77.78%
[ Wed Apr 25 09:40:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:40:02 2018 ] Training epoch: 341
[ Wed Apr 25 09:40:06 2018 ] 	Batch(0/1) done. Loss: 0.1791  lr:0.100000
[ Wed Apr 25 09:40:06 2018 ] 	Mean training loss: 0.1791.
[ Wed Apr 25 09:40:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:06 2018 ] Training epoch: 342
[ Wed Apr 25 09:40:10 2018 ] 	Batch(0/1) done. Loss: 0.0319  lr:0.100000
[ Wed Apr 25 09:40:10 2018 ] 	Mean training loss: 0.0319.
[ Wed Apr 25 09:40:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:40:10 2018 ] Training epoch: 343
[ Wed Apr 25 09:40:14 2018 ] 	Batch(0/1) done. Loss: 0.1905  lr:0.100000
[ Wed Apr 25 09:40:14 2018 ] 	Mean training loss: 0.1905.
[ Wed Apr 25 09:40:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:14 2018 ] Training epoch: 344
[ Wed Apr 25 09:40:18 2018 ] 	Batch(0/1) done. Loss: 0.0819  lr:0.100000
[ Wed Apr 25 09:40:18 2018 ] 	Mean training loss: 0.0819.
[ Wed Apr 25 09:40:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:18 2018 ] Training epoch: 345
[ Wed Apr 25 09:40:22 2018 ] 	Batch(0/1) done. Loss: 0.0652  lr:0.100000
[ Wed Apr 25 09:40:22 2018 ] 	Mean training loss: 0.0652.
[ Wed Apr 25 09:40:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:40:22 2018 ] Eval epoch: 345
[ Wed Apr 25 09:40:25 2018 ] 	Mean test loss of 1 batches: 0.4517957270145416.
[ Wed Apr 25 09:40:25 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:40:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:40:25 2018 ] Training epoch: 346
[ Wed Apr 25 09:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0789  lr:0.100000
[ Wed Apr 25 09:40:28 2018 ] 	Mean training loss: 0.0789.
[ Wed Apr 25 09:40:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:28 2018 ] Training epoch: 347
[ Wed Apr 25 09:40:33 2018 ] 	Batch(0/1) done. Loss: 0.0979  lr:0.100000
[ Wed Apr 25 09:40:33 2018 ] 	Mean training loss: 0.0979.
[ Wed Apr 25 09:40:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:40:33 2018 ] Training epoch: 348
[ Wed Apr 25 09:40:36 2018 ] 	Batch(0/1) done. Loss: 0.0770  lr:0.100000
[ Wed Apr 25 09:40:36 2018 ] 	Mean training loss: 0.0770.
[ Wed Apr 25 09:40:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:36 2018 ] Training epoch: 349
[ Wed Apr 25 09:40:41 2018 ] 	Batch(0/1) done. Loss: 0.0798  lr:0.100000
[ Wed Apr 25 09:40:41 2018 ] 	Mean training loss: 0.0798.
[ Wed Apr 25 09:40:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:40:41 2018 ] Training epoch: 350
[ Wed Apr 25 09:40:44 2018 ] 	Batch(0/1) done. Loss: 0.0714  lr:0.100000
[ Wed Apr 25 09:40:44 2018 ] 	Mean training loss: 0.0714.
[ Wed Apr 25 09:40:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:44 2018 ] Eval epoch: 350
[ Wed Apr 25 09:40:47 2018 ] 	Mean test loss of 1 batches: 0.5001218318939209.
[ Wed Apr 25 09:40:47 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:40:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:40:47 2018 ] Training epoch: 351
[ Wed Apr 25 09:40:51 2018 ] 	Batch(0/1) done. Loss: 0.0833  lr:0.100000
[ Wed Apr 25 09:40:51 2018 ] 	Mean training loss: 0.0833.
[ Wed Apr 25 09:40:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:51 2018 ] Training epoch: 352
[ Wed Apr 25 09:40:55 2018 ] 	Batch(0/1) done. Loss: 0.0772  lr:0.100000
[ Wed Apr 25 09:40:55 2018 ] 	Mean training loss: 0.0772.
[ Wed Apr 25 09:40:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:55 2018 ] Training epoch: 353
[ Wed Apr 25 09:40:59 2018 ] 	Batch(0/1) done. Loss: 0.1023  lr:0.100000
[ Wed Apr 25 09:40:59 2018 ] 	Mean training loss: 0.1023.
[ Wed Apr 25 09:40:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:40:59 2018 ] Training epoch: 354
[ Wed Apr 25 09:41:03 2018 ] 	Batch(0/1) done. Loss: 0.1284  lr:0.100000
[ Wed Apr 25 09:41:03 2018 ] 	Mean training loss: 0.1284.
[ Wed Apr 25 09:41:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:03 2018 ] Training epoch: 355
[ Wed Apr 25 09:41:07 2018 ] 	Batch(0/1) done. Loss: 0.0836  lr:0.100000
[ Wed Apr 25 09:41:07 2018 ] 	Mean training loss: 0.0836.
[ Wed Apr 25 09:41:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:41:07 2018 ] Eval epoch: 355
[ Wed Apr 25 09:41:10 2018 ] 	Mean test loss of 1 batches: 0.3846668004989624.
[ Wed Apr 25 09:41:10 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:41:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:41:10 2018 ] Training epoch: 356
[ Wed Apr 25 09:41:14 2018 ] 	Batch(0/1) done. Loss: 0.0971  lr:0.100000
[ Wed Apr 25 09:41:14 2018 ] 	Mean training loss: 0.0971.
[ Wed Apr 25 09:41:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:14 2018 ] Training epoch: 357
[ Wed Apr 25 09:41:17 2018 ] 	Batch(0/1) done. Loss: 0.1622  lr:0.100000
[ Wed Apr 25 09:41:17 2018 ] 	Mean training loss: 0.1622.
[ Wed Apr 25 09:41:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:17 2018 ] Training epoch: 358
[ Wed Apr 25 09:41:21 2018 ] 	Batch(0/1) done. Loss: 0.0982  lr:0.100000
[ Wed Apr 25 09:41:21 2018 ] 	Mean training loss: 0.0982.
[ Wed Apr 25 09:41:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:41:21 2018 ] Training epoch: 359
[ Wed Apr 25 09:41:25 2018 ] 	Batch(0/1) done. Loss: 0.1173  lr:0.100000
[ Wed Apr 25 09:41:25 2018 ] 	Mean training loss: 0.1173.
[ Wed Apr 25 09:41:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:25 2018 ] Training epoch: 360
[ Wed Apr 25 09:41:29 2018 ] 	Batch(0/1) done. Loss: 0.0649  lr:0.100000
[ Wed Apr 25 09:41:29 2018 ] 	Mean training loss: 0.0649.
[ Wed Apr 25 09:41:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:29 2018 ] Eval epoch: 360
[ Wed Apr 25 09:41:32 2018 ] 	Mean test loss of 1 batches: 0.18125945329666138.
[ Wed Apr 25 09:41:32 2018 ] 	Top1: 96.30%
[ Wed Apr 25 09:41:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:41:32 2018 ] Training epoch: 361
[ Wed Apr 25 09:41:36 2018 ] 	Batch(0/1) done. Loss: 0.0942  lr:0.100000
[ Wed Apr 25 09:41:36 2018 ] 	Mean training loss: 0.0942.
[ Wed Apr 25 09:41:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:36 2018 ] Training epoch: 362
[ Wed Apr 25 09:41:40 2018 ] 	Batch(0/1) done. Loss: 0.0580  lr:0.100000
[ Wed Apr 25 09:41:40 2018 ] 	Mean training loss: 0.0580.
[ Wed Apr 25 09:41:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:41:40 2018 ] Training epoch: 363
[ Wed Apr 25 09:41:44 2018 ] 	Batch(0/1) done. Loss: 0.1086  lr:0.100000
[ Wed Apr 25 09:41:44 2018 ] 	Mean training loss: 0.1086.
[ Wed Apr 25 09:41:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:44 2018 ] Training epoch: 364
[ Wed Apr 25 09:41:48 2018 ] 	Batch(0/1) done. Loss: 0.0691  lr:0.100000
[ Wed Apr 25 09:41:48 2018 ] 	Mean training loss: 0.0691.
[ Wed Apr 25 09:41:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:48 2018 ] Training epoch: 365
[ Wed Apr 25 09:41:52 2018 ] 	Batch(0/1) done. Loss: 0.0424  lr:0.100000
[ Wed Apr 25 09:41:52 2018 ] 	Mean training loss: 0.0424.
[ Wed Apr 25 09:41:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:41:52 2018 ] Eval epoch: 365
[ Wed Apr 25 09:41:55 2018 ] 	Mean test loss of 1 batches: 0.6953148245811462.
[ Wed Apr 25 09:41:55 2018 ] 	Top1: 62.96%
[ Wed Apr 25 09:41:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:41:55 2018 ] Training epoch: 366
[ Wed Apr 25 09:41:59 2018 ] 	Batch(0/1) done. Loss: 0.1625  lr:0.100000
[ Wed Apr 25 09:41:59 2018 ] 	Mean training loss: 0.1625.
[ Wed Apr 25 09:41:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:41:59 2018 ] Training epoch: 367
[ Wed Apr 25 09:42:03 2018 ] 	Batch(0/1) done. Loss: 0.1509  lr:0.100000
[ Wed Apr 25 09:42:03 2018 ] 	Mean training loss: 0.1509.
[ Wed Apr 25 09:42:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:03 2018 ] Training epoch: 368
[ Wed Apr 25 09:42:07 2018 ] 	Batch(0/1) done. Loss: 0.1090  lr:0.100000
[ Wed Apr 25 09:42:07 2018 ] 	Mean training loss: 0.1090.
[ Wed Apr 25 09:42:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:07 2018 ] Training epoch: 369
[ Wed Apr 25 09:42:10 2018 ] 	Batch(0/1) done. Loss: 0.0421  lr:0.100000
[ Wed Apr 25 09:42:10 2018 ] 	Mean training loss: 0.0421.
[ Wed Apr 25 09:42:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:10 2018 ] Training epoch: 370
[ Wed Apr 25 09:42:14 2018 ] 	Batch(0/1) done. Loss: 0.1577  lr:0.100000
[ Wed Apr 25 09:42:14 2018 ] 	Mean training loss: 0.1577.
[ Wed Apr 25 09:42:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:14 2018 ] Eval epoch: 370
[ Wed Apr 25 09:42:17 2018 ] 	Mean test loss of 1 batches: 0.3942367434501648.
[ Wed Apr 25 09:42:17 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:42:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:42:17 2018 ] Training epoch: 371
[ Wed Apr 25 09:42:21 2018 ] 	Batch(0/1) done. Loss: 0.0768  lr:0.100000
[ Wed Apr 25 09:42:21 2018 ] 	Mean training loss: 0.0768.
[ Wed Apr 25 09:42:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:21 2018 ] Training epoch: 372
[ Wed Apr 25 09:42:25 2018 ] 	Batch(0/1) done. Loss: 0.1189  lr:0.100000
[ Wed Apr 25 09:42:25 2018 ] 	Mean training loss: 0.1189.
[ Wed Apr 25 09:42:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:25 2018 ] Training epoch: 373
[ Wed Apr 25 09:42:29 2018 ] 	Batch(0/1) done. Loss: 0.1113  lr:0.100000
[ Wed Apr 25 09:42:29 2018 ] 	Mean training loss: 0.1113.
[ Wed Apr 25 09:42:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:42:29 2018 ] Training epoch: 374
[ Wed Apr 25 09:42:33 2018 ] 	Batch(0/1) done. Loss: 0.1044  lr:0.100000
[ Wed Apr 25 09:42:33 2018 ] 	Mean training loss: 0.1044.
[ Wed Apr 25 09:42:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:42:33 2018 ] Training epoch: 375
[ Wed Apr 25 09:42:37 2018 ] 	Batch(0/1) done. Loss: 0.0696  lr:0.100000
[ Wed Apr 25 09:42:37 2018 ] 	Mean training loss: 0.0696.
[ Wed Apr 25 09:42:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:37 2018 ] Eval epoch: 375
[ Wed Apr 25 09:42:40 2018 ] 	Mean test loss of 1 batches: 0.23385021090507507.
[ Wed Apr 25 09:42:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:42:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:42:40 2018 ] Training epoch: 376
[ Wed Apr 25 09:42:44 2018 ] 	Batch(0/1) done. Loss: 0.1183  lr:0.100000
[ Wed Apr 25 09:42:44 2018 ] 	Mean training loss: 0.1183.
[ Wed Apr 25 09:42:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:44 2018 ] Training epoch: 377
[ Wed Apr 25 09:42:47 2018 ] 	Batch(0/1) done. Loss: 0.0421  lr:0.100000
[ Wed Apr 25 09:42:47 2018 ] 	Mean training loss: 0.0421.
[ Wed Apr 25 09:42:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:47 2018 ] Training epoch: 378
[ Wed Apr 25 09:42:51 2018 ] 	Batch(0/1) done. Loss: 0.0481  lr:0.100000
[ Wed Apr 25 09:42:51 2018 ] 	Mean training loss: 0.0481.
[ Wed Apr 25 09:42:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:51 2018 ] Training epoch: 379
[ Wed Apr 25 09:42:55 2018 ] 	Batch(0/1) done. Loss: 0.0952  lr:0.100000
[ Wed Apr 25 09:42:55 2018 ] 	Mean training loss: 0.0952.
[ Wed Apr 25 09:42:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:55 2018 ] Training epoch: 380
[ Wed Apr 25 09:42:59 2018 ] 	Batch(0/1) done. Loss: 0.0783  lr:0.100000
[ Wed Apr 25 09:42:59 2018 ] 	Mean training loss: 0.0783.
[ Wed Apr 25 09:42:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:42:59 2018 ] Eval epoch: 380
[ Wed Apr 25 09:43:02 2018 ] 	Mean test loss of 1 batches: 0.20349083840847015.
[ Wed Apr 25 09:43:02 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:43:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:43:02 2018 ] Training epoch: 381
[ Wed Apr 25 09:43:06 2018 ] 	Batch(0/1) done. Loss: 0.0739  lr:0.100000
[ Wed Apr 25 09:43:06 2018 ] 	Mean training loss: 0.0739.
[ Wed Apr 25 09:43:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:06 2018 ] Training epoch: 382
[ Wed Apr 25 09:43:10 2018 ] 	Batch(0/1) done. Loss: 0.1349  lr:0.100000
[ Wed Apr 25 09:43:10 2018 ] 	Mean training loss: 0.1349.
[ Wed Apr 25 09:43:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:10 2018 ] Training epoch: 383
[ Wed Apr 25 09:43:14 2018 ] 	Batch(0/1) done. Loss: 0.0634  lr:0.100000
[ Wed Apr 25 09:43:14 2018 ] 	Mean training loss: 0.0634.
[ Wed Apr 25 09:43:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:43:14 2018 ] Training epoch: 384
[ Wed Apr 25 09:43:18 2018 ] 	Batch(0/1) done. Loss: 0.0702  lr:0.100000
[ Wed Apr 25 09:43:18 2018 ] 	Mean training loss: 0.0702.
[ Wed Apr 25 09:43:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:18 2018 ] Training epoch: 385
[ Wed Apr 25 09:43:22 2018 ] 	Batch(0/1) done. Loss: 0.0432  lr:0.100000
[ Wed Apr 25 09:43:22 2018 ] 	Mean training loss: 0.0432.
[ Wed Apr 25 09:43:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:43:22 2018 ] Eval epoch: 385
[ Wed Apr 25 09:43:25 2018 ] 	Mean test loss of 1 batches: 0.285046249628067.
[ Wed Apr 25 09:43:25 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:43:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:43:25 2018 ] Training epoch: 386
[ Wed Apr 25 09:43:28 2018 ] 	Batch(0/1) done. Loss: 0.0936  lr:0.100000
[ Wed Apr 25 09:43:28 2018 ] 	Mean training loss: 0.0936.
[ Wed Apr 25 09:43:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:28 2018 ] Training epoch: 387
[ Wed Apr 25 09:43:32 2018 ] 	Batch(0/1) done. Loss: 0.0477  lr:0.100000
[ Wed Apr 25 09:43:32 2018 ] 	Mean training loss: 0.0477.
[ Wed Apr 25 09:43:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:32 2018 ] Training epoch: 388
[ Wed Apr 25 09:43:36 2018 ] 	Batch(0/1) done. Loss: 0.0451  lr:0.100000
[ Wed Apr 25 09:43:36 2018 ] 	Mean training loss: 0.0451.
[ Wed Apr 25 09:43:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:36 2018 ] Training epoch: 389
[ Wed Apr 25 09:43:40 2018 ] 	Batch(0/1) done. Loss: 0.0420  lr:0.100000
[ Wed Apr 25 09:43:40 2018 ] 	Mean training loss: 0.0420.
[ Wed Apr 25 09:43:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:40 2018 ] Training epoch: 390
[ Wed Apr 25 09:43:44 2018 ] 	Batch(0/1) done. Loss: 0.1767  lr:0.100000
[ Wed Apr 25 09:43:44 2018 ] 	Mean training loss: 0.1767.
[ Wed Apr 25 09:43:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:43:44 2018 ] Eval epoch: 390
[ Wed Apr 25 09:43:47 2018 ] 	Mean test loss of 1 batches: 0.33545058965682983.
[ Wed Apr 25 09:43:47 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:43:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:43:47 2018 ] Training epoch: 391
[ Wed Apr 25 09:43:51 2018 ] 	Batch(0/1) done. Loss: 0.0736  lr:0.100000
[ Wed Apr 25 09:43:51 2018 ] 	Mean training loss: 0.0736.
[ Wed Apr 25 09:43:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:51 2018 ] Training epoch: 392
[ Wed Apr 25 09:43:55 2018 ] 	Batch(0/1) done. Loss: 0.0808  lr:0.100000
[ Wed Apr 25 09:43:55 2018 ] 	Mean training loss: 0.0808.
[ Wed Apr 25 09:43:55 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:43:55 2018 ] Training epoch: 393
[ Wed Apr 25 09:43:59 2018 ] 	Batch(0/1) done. Loss: 0.0745  lr:0.100000
[ Wed Apr 25 09:43:59 2018 ] 	Mean training loss: 0.0745.
[ Wed Apr 25 09:43:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:43:59 2018 ] Training epoch: 394
[ Wed Apr 25 09:44:03 2018 ] 	Batch(0/1) done. Loss: 0.1457  lr:0.100000
[ Wed Apr 25 09:44:03 2018 ] 	Mean training loss: 0.1457.
[ Wed Apr 25 09:44:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:03 2018 ] Training epoch: 395
[ Wed Apr 25 09:44:07 2018 ] 	Batch(0/1) done. Loss: 0.1114  lr:0.100000
[ Wed Apr 25 09:44:07 2018 ] 	Mean training loss: 0.1114.
[ Wed Apr 25 09:44:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:07 2018 ] Eval epoch: 395
[ Wed Apr 25 09:44:10 2018 ] 	Mean test loss of 1 batches: 1.0250905752182007.
[ Wed Apr 25 09:44:10 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:44:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:44:10 2018 ] Training epoch: 396
[ Wed Apr 25 09:44:14 2018 ] 	Batch(0/1) done. Loss: 0.0551  lr:0.100000
[ Wed Apr 25 09:44:14 2018 ] 	Mean training loss: 0.0551.
[ Wed Apr 25 09:44:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:14 2018 ] Training epoch: 397
[ Wed Apr 25 09:44:18 2018 ] 	Batch(0/1) done. Loss: 0.0565  lr:0.100000
[ Wed Apr 25 09:44:18 2018 ] 	Mean training loss: 0.0565.
[ Wed Apr 25 09:44:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:18 2018 ] Training epoch: 398
[ Wed Apr 25 09:44:21 2018 ] 	Batch(0/1) done. Loss: 0.0782  lr:0.100000
[ Wed Apr 25 09:44:21 2018 ] 	Mean training loss: 0.0782.
[ Wed Apr 25 09:44:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:21 2018 ] Training epoch: 399
[ Wed Apr 25 09:44:25 2018 ] 	Batch(0/1) done. Loss: 0.0471  lr:0.100000
[ Wed Apr 25 09:44:25 2018 ] 	Mean training loss: 0.0471.
[ Wed Apr 25 09:44:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:25 2018 ] Training epoch: 400
[ Wed Apr 25 09:44:29 2018 ] 	Batch(0/1) done. Loss: 0.0250  lr:0.100000
[ Wed Apr 25 09:44:29 2018 ] 	Mean training loss: 0.0250.
[ Wed Apr 25 09:44:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:29 2018 ] Eval epoch: 400
[ Wed Apr 25 09:44:32 2018 ] 	Mean test loss of 1 batches: 1.1874327659606934.
[ Wed Apr 25 09:44:32 2018 ] 	Top1: 55.56%
[ Wed Apr 25 09:44:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:44:32 2018 ] Training epoch: 401
[ Wed Apr 25 09:44:36 2018 ] 	Batch(0/1) done. Loss: 0.0855  lr:0.100000
[ Wed Apr 25 09:44:36 2018 ] 	Mean training loss: 0.0855.
[ Wed Apr 25 09:44:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:36 2018 ] Training epoch: 402
[ Wed Apr 25 09:44:40 2018 ] 	Batch(0/1) done. Loss: 0.0664  lr:0.100000
[ Wed Apr 25 09:44:40 2018 ] 	Mean training loss: 0.0664.
[ Wed Apr 25 09:44:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:44:40 2018 ] Training epoch: 403
[ Wed Apr 25 09:44:44 2018 ] 	Batch(0/1) done. Loss: 0.0477  lr:0.100000
[ Wed Apr 25 09:44:44 2018 ] 	Mean training loss: 0.0477.
[ Wed Apr 25 09:44:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:44 2018 ] Training epoch: 404
[ Wed Apr 25 09:44:48 2018 ] 	Batch(0/1) done. Loss: 0.0731  lr:0.100000
[ Wed Apr 25 09:44:48 2018 ] 	Mean training loss: 0.0731.
[ Wed Apr 25 09:44:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:48 2018 ] Training epoch: 405
[ Wed Apr 25 09:44:52 2018 ] 	Batch(0/1) done. Loss: 0.1461  lr:0.100000
[ Wed Apr 25 09:44:52 2018 ] 	Mean training loss: 0.1461.
[ Wed Apr 25 09:44:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:44:52 2018 ] Eval epoch: 405
[ Wed Apr 25 09:44:55 2018 ] 	Mean test loss of 1 batches: 0.5631135106086731.
[ Wed Apr 25 09:44:55 2018 ] 	Top1: 77.78%
[ Wed Apr 25 09:44:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:44:55 2018 ] Training epoch: 406
[ Wed Apr 25 09:44:59 2018 ] 	Batch(0/1) done. Loss: 0.1336  lr:0.100000
[ Wed Apr 25 09:44:59 2018 ] 	Mean training loss: 0.1336.
[ Wed Apr 25 09:44:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:44:59 2018 ] Training epoch: 407
[ Wed Apr 25 09:45:03 2018 ] 	Batch(0/1) done. Loss: 0.0449  lr:0.100000
[ Wed Apr 25 09:45:03 2018 ] 	Mean training loss: 0.0449.
[ Wed Apr 25 09:45:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:03 2018 ] Training epoch: 408
[ Wed Apr 25 09:45:07 2018 ] 	Batch(0/1) done. Loss: 0.0278  lr:0.100000
[ Wed Apr 25 09:45:07 2018 ] 	Mean training loss: 0.0278.
[ Wed Apr 25 09:45:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:07 2018 ] Training epoch: 409
[ Wed Apr 25 09:45:11 2018 ] 	Batch(0/1) done. Loss: 0.0548  lr:0.100000
[ Wed Apr 25 09:45:11 2018 ] 	Mean training loss: 0.0548.
[ Wed Apr 25 09:45:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:45:11 2018 ] Training epoch: 410
[ Wed Apr 25 09:45:15 2018 ] 	Batch(0/1) done. Loss: 0.1705  lr:0.100000
[ Wed Apr 25 09:45:15 2018 ] 	Mean training loss: 0.1705.
[ Wed Apr 25 09:45:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:15 2018 ] Eval epoch: 410
[ Wed Apr 25 09:45:17 2018 ] 	Mean test loss of 1 batches: 0.7187052965164185.
[ Wed Apr 25 09:45:17 2018 ] 	Top1: 66.67%
[ Wed Apr 25 09:45:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:45:17 2018 ] Training epoch: 411
[ Wed Apr 25 09:45:21 2018 ] 	Batch(0/1) done. Loss: 0.0347  lr:0.100000
[ Wed Apr 25 09:45:21 2018 ] 	Mean training loss: 0.0347.
[ Wed Apr 25 09:45:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:21 2018 ] Training epoch: 412
[ Wed Apr 25 09:45:25 2018 ] 	Batch(0/1) done. Loss: 0.0779  lr:0.100000
[ Wed Apr 25 09:45:25 2018 ] 	Mean training loss: 0.0779.
[ Wed Apr 25 09:45:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:45:25 2018 ] Training epoch: 413
[ Wed Apr 25 09:45:29 2018 ] 	Batch(0/1) done. Loss: 0.0302  lr:0.100000
[ Wed Apr 25 09:45:29 2018 ] 	Mean training loss: 0.0302.
[ Wed Apr 25 09:45:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:45:29 2018 ] Training epoch: 414
[ Wed Apr 25 09:45:33 2018 ] 	Batch(0/1) done. Loss: 0.0520  lr:0.100000
[ Wed Apr 25 09:45:33 2018 ] 	Mean training loss: 0.0520.
[ Wed Apr 25 09:45:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:33 2018 ] Training epoch: 415
[ Wed Apr 25 09:45:37 2018 ] 	Batch(0/1) done. Loss: 0.1002  lr:0.100000
[ Wed Apr 25 09:45:37 2018 ] 	Mean training loss: 0.1002.
[ Wed Apr 25 09:45:37 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:45:37 2018 ] Eval epoch: 415
[ Wed Apr 25 09:45:40 2018 ] 	Mean test loss of 1 batches: 0.5637580156326294.
[ Wed Apr 25 09:45:40 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:45:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:45:40 2018 ] Training epoch: 416
[ Wed Apr 25 09:45:44 2018 ] 	Batch(0/1) done. Loss: 0.0613  lr:0.100000
[ Wed Apr 25 09:45:44 2018 ] 	Mean training loss: 0.0613.
[ Wed Apr 25 09:45:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:45:44 2018 ] Training epoch: 417
[ Wed Apr 25 09:45:48 2018 ] 	Batch(0/1) done. Loss: 0.1012  lr:0.100000
[ Wed Apr 25 09:45:48 2018 ] 	Mean training loss: 0.1012.
[ Wed Apr 25 09:45:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:48 2018 ] Training epoch: 418
[ Wed Apr 25 09:45:52 2018 ] 	Batch(0/1) done. Loss: 0.0410  lr:0.100000
[ Wed Apr 25 09:45:52 2018 ] 	Mean training loss: 0.0410.
[ Wed Apr 25 09:45:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:52 2018 ] Training epoch: 419
[ Wed Apr 25 09:45:56 2018 ] 	Batch(0/1) done. Loss: 0.2057  lr:0.100000
[ Wed Apr 25 09:45:56 2018 ] 	Mean training loss: 0.2057.
[ Wed Apr 25 09:45:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:45:56 2018 ] Training epoch: 420
[ Wed Apr 25 09:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0279  lr:0.100000
[ Wed Apr 25 09:46:00 2018 ] 	Mean training loss: 0.0279.
[ Wed Apr 25 09:46:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:00 2018 ] Eval epoch: 420
[ Wed Apr 25 09:46:02 2018 ] 	Mean test loss of 1 batches: 0.30901414155960083.
[ Wed Apr 25 09:46:02 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:46:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:46:02 2018 ] Training epoch: 421
[ Wed Apr 25 09:46:06 2018 ] 	Batch(0/1) done. Loss: 0.0401  lr:0.100000
[ Wed Apr 25 09:46:06 2018 ] 	Mean training loss: 0.0401.
[ Wed Apr 25 09:46:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:06 2018 ] Training epoch: 422
[ Wed Apr 25 09:46:10 2018 ] 	Batch(0/1) done. Loss: 0.1146  lr:0.100000
[ Wed Apr 25 09:46:10 2018 ] 	Mean training loss: 0.1146.
[ Wed Apr 25 09:46:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:10 2018 ] Training epoch: 423
[ Wed Apr 25 09:46:14 2018 ] 	Batch(0/1) done. Loss: 0.0490  lr:0.100000
[ Wed Apr 25 09:46:14 2018 ] 	Mean training loss: 0.0490.
[ Wed Apr 25 09:46:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:14 2018 ] Training epoch: 424
[ Wed Apr 25 09:46:18 2018 ] 	Batch(0/1) done. Loss: 0.0407  lr:0.100000
[ Wed Apr 25 09:46:18 2018 ] 	Mean training loss: 0.0407.
[ Wed Apr 25 09:46:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:18 2018 ] Training epoch: 425
[ Wed Apr 25 09:46:22 2018 ] 	Batch(0/1) done. Loss: 0.0528  lr:0.100000
[ Wed Apr 25 09:46:22 2018 ] 	Mean training loss: 0.0528.
[ Wed Apr 25 09:46:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:22 2018 ] Eval epoch: 425
[ Wed Apr 25 09:46:25 2018 ] 	Mean test loss of 1 batches: 0.18228530883789062.
[ Wed Apr 25 09:46:25 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:46:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:46:25 2018 ] Training epoch: 426
[ Wed Apr 25 09:46:29 2018 ] 	Batch(0/1) done. Loss: 0.0499  lr:0.100000
[ Wed Apr 25 09:46:29 2018 ] 	Mean training loss: 0.0499.
[ Wed Apr 25 09:46:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:29 2018 ] Training epoch: 427
[ Wed Apr 25 09:46:33 2018 ] 	Batch(0/1) done. Loss: 0.0425  lr:0.100000
[ Wed Apr 25 09:46:33 2018 ] 	Mean training loss: 0.0425.
[ Wed Apr 25 09:46:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:33 2018 ] Training epoch: 428
[ Wed Apr 25 09:46:37 2018 ] 	Batch(0/1) done. Loss: 0.0260  lr:0.100000
[ Wed Apr 25 09:46:37 2018 ] 	Mean training loss: 0.0260.
[ Wed Apr 25 09:46:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:37 2018 ] Training epoch: 429
[ Wed Apr 25 09:46:41 2018 ] 	Batch(0/1) done. Loss: 0.0181  lr:0.100000
[ Wed Apr 25 09:46:41 2018 ] 	Mean training loss: 0.0181.
[ Wed Apr 25 09:46:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:41 2018 ] Training epoch: 430
[ Wed Apr 25 09:46:45 2018 ] 	Batch(0/1) done. Loss: 0.0187  lr:0.100000
[ Wed Apr 25 09:46:45 2018 ] 	Mean training loss: 0.0187.
[ Wed Apr 25 09:46:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:45 2018 ] Eval epoch: 430
[ Wed Apr 25 09:46:48 2018 ] 	Mean test loss of 1 batches: 0.24574482440948486.
[ Wed Apr 25 09:46:48 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:46:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:46:48 2018 ] Training epoch: 431
[ Wed Apr 25 09:46:52 2018 ] 	Batch(0/1) done. Loss: 0.0244  lr:0.100000
[ Wed Apr 25 09:46:52 2018 ] 	Mean training loss: 0.0244.
[ Wed Apr 25 09:46:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:46:52 2018 ] Training epoch: 432
[ Wed Apr 25 09:46:56 2018 ] 	Batch(0/1) done. Loss: 0.0940  lr:0.100000
[ Wed Apr 25 09:46:56 2018 ] 	Mean training loss: 0.0940.
[ Wed Apr 25 09:46:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:46:56 2018 ] Training epoch: 433
[ Wed Apr 25 09:47:00 2018 ] 	Batch(0/1) done. Loss: 0.0548  lr:0.100000
[ Wed Apr 25 09:47:00 2018 ] 	Mean training loss: 0.0548.
[ Wed Apr 25 09:47:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:00 2018 ] Training epoch: 434
[ Wed Apr 25 09:47:04 2018 ] 	Batch(0/1) done. Loss: 0.0493  lr:0.100000
[ Wed Apr 25 09:47:04 2018 ] 	Mean training loss: 0.0493.
[ Wed Apr 25 09:47:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:04 2018 ] Training epoch: 435
[ Wed Apr 25 09:47:08 2018 ] 	Batch(0/1) done. Loss: 0.0944  lr:0.100000
[ Wed Apr 25 09:47:08 2018 ] 	Mean training loss: 0.0944.
[ Wed Apr 25 09:47:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:08 2018 ] Eval epoch: 435
[ Wed Apr 25 09:47:10 2018 ] 	Mean test loss of 1 batches: 0.16131627559661865.
[ Wed Apr 25 09:47:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:47:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:47:10 2018 ] Training epoch: 436
[ Wed Apr 25 09:47:14 2018 ] 	Batch(0/1) done. Loss: 0.0600  lr:0.100000
[ Wed Apr 25 09:47:14 2018 ] 	Mean training loss: 0.0600.
[ Wed Apr 25 09:47:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:14 2018 ] Training epoch: 437
[ Wed Apr 25 09:47:18 2018 ] 	Batch(0/1) done. Loss: 0.0813  lr:0.100000
[ Wed Apr 25 09:47:18 2018 ] 	Mean training loss: 0.0813.
[ Wed Apr 25 09:47:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:18 2018 ] Training epoch: 438
[ Wed Apr 25 09:47:22 2018 ] 	Batch(0/1) done. Loss: 0.0360  lr:0.100000
[ Wed Apr 25 09:47:22 2018 ] 	Mean training loss: 0.0360.
[ Wed Apr 25 09:47:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:47:22 2018 ] Training epoch: 439
[ Wed Apr 25 09:47:26 2018 ] 	Batch(0/1) done. Loss: 0.0572  lr:0.100000
[ Wed Apr 25 09:47:26 2018 ] 	Mean training loss: 0.0572.
[ Wed Apr 25 09:47:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:47:26 2018 ] Training epoch: 440
[ Wed Apr 25 09:47:30 2018 ] 	Batch(0/1) done. Loss: 0.2457  lr:0.100000
[ Wed Apr 25 09:47:30 2018 ] 	Mean training loss: 0.2457.
[ Wed Apr 25 09:47:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:30 2018 ] Eval epoch: 440
[ Wed Apr 25 09:47:33 2018 ] 	Mean test loss of 1 batches: 0.24019396305084229.
[ Wed Apr 25 09:47:33 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:47:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:47:33 2018 ] Training epoch: 441
[ Wed Apr 25 09:47:37 2018 ] 	Batch(0/1) done. Loss: 0.1519  lr:0.100000
[ Wed Apr 25 09:47:37 2018 ] 	Mean training loss: 0.1519.
[ Wed Apr 25 09:47:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:47:37 2018 ] Training epoch: 442
[ Wed Apr 25 09:47:41 2018 ] 	Batch(0/1) done. Loss: 0.0554  lr:0.100000
[ Wed Apr 25 09:47:41 2018 ] 	Mean training loss: 0.0554.
[ Wed Apr 25 09:47:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:47:41 2018 ] Training epoch: 443
[ Wed Apr 25 09:47:46 2018 ] 	Batch(0/1) done. Loss: 0.1715  lr:0.100000
[ Wed Apr 25 09:47:46 2018 ] 	Mean training loss: 0.1715.
[ Wed Apr 25 09:47:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:47:46 2018 ] Training epoch: 444
[ Wed Apr 25 09:47:50 2018 ] 	Batch(0/1) done. Loss: 0.1043  lr:0.100000
[ Wed Apr 25 09:47:50 2018 ] 	Mean training loss: 0.1043.
[ Wed Apr 25 09:47:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:50 2018 ] Training epoch: 445
[ Wed Apr 25 09:47:53 2018 ] 	Batch(0/1) done. Loss: 0.1070  lr:0.100000
[ Wed Apr 25 09:47:53 2018 ] 	Mean training loss: 0.1070.
[ Wed Apr 25 09:47:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:47:53 2018 ] Eval epoch: 445
[ Wed Apr 25 09:47:56 2018 ] 	Mean test loss of 1 batches: 0.17746174335479736.
[ Wed Apr 25 09:47:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:47:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:47:56 2018 ] Training epoch: 446
[ Wed Apr 25 09:48:00 2018 ] 	Batch(0/1) done. Loss: 0.0532  lr:0.100000
[ Wed Apr 25 09:48:00 2018 ] 	Mean training loss: 0.0532.
[ Wed Apr 25 09:48:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:00 2018 ] Training epoch: 447
[ Wed Apr 25 09:48:04 2018 ] 	Batch(0/1) done. Loss: 0.0411  lr:0.100000
[ Wed Apr 25 09:48:04 2018 ] 	Mean training loss: 0.0411.
[ Wed Apr 25 09:48:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:04 2018 ] Training epoch: 448
[ Wed Apr 25 09:48:08 2018 ] 	Batch(0/1) done. Loss: 0.1229  lr:0.100000
[ Wed Apr 25 09:48:08 2018 ] 	Mean training loss: 0.1229.
[ Wed Apr 25 09:48:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:08 2018 ] Training epoch: 449
[ Wed Apr 25 09:48:12 2018 ] 	Batch(0/1) done. Loss: 0.0259  lr:0.100000
[ Wed Apr 25 09:48:12 2018 ] 	Mean training loss: 0.0259.
[ Wed Apr 25 09:48:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:12 2018 ] Training epoch: 450
[ Wed Apr 25 09:48:16 2018 ] 	Batch(0/1) done. Loss: 0.0855  lr:0.100000
[ Wed Apr 25 09:48:16 2018 ] 	Mean training loss: 0.0855.
[ Wed Apr 25 09:48:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:16 2018 ] Eval epoch: 450
[ Wed Apr 25 09:48:19 2018 ] 	Mean test loss of 1 batches: 0.1869107335805893.
[ Wed Apr 25 09:48:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:48:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:48:19 2018 ] Training epoch: 451
[ Wed Apr 25 09:48:23 2018 ] 	Batch(0/1) done. Loss: 0.0701  lr:0.100000
[ Wed Apr 25 09:48:23 2018 ] 	Mean training loss: 0.0701.
[ Wed Apr 25 09:48:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:23 2018 ] Training epoch: 452
[ Wed Apr 25 09:48:27 2018 ] 	Batch(0/1) done. Loss: 0.0519  lr:0.100000
[ Wed Apr 25 09:48:27 2018 ] 	Mean training loss: 0.0519.
[ Wed Apr 25 09:48:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:27 2018 ] Training epoch: 453
[ Wed Apr 25 09:48:30 2018 ] 	Batch(0/1) done. Loss: 0.0573  lr:0.100000
[ Wed Apr 25 09:48:30 2018 ] 	Mean training loss: 0.0573.
[ Wed Apr 25 09:48:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:30 2018 ] Training epoch: 454
[ Wed Apr 25 09:48:34 2018 ] 	Batch(0/1) done. Loss: 0.0271  lr:0.100000
[ Wed Apr 25 09:48:34 2018 ] 	Mean training loss: 0.0271.
[ Wed Apr 25 09:48:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:48:34 2018 ] Training epoch: 455
[ Wed Apr 25 09:48:38 2018 ] 	Batch(0/1) done. Loss: 0.0403  lr:0.100000
[ Wed Apr 25 09:48:38 2018 ] 	Mean training loss: 0.0403.
[ Wed Apr 25 09:48:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:38 2018 ] Eval epoch: 455
[ Wed Apr 25 09:48:41 2018 ] 	Mean test loss of 1 batches: 0.20646989345550537.
[ Wed Apr 25 09:48:41 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:48:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:48:41 2018 ] Training epoch: 456
[ Wed Apr 25 09:48:45 2018 ] 	Batch(0/1) done. Loss: 0.0381  lr:0.100000
[ Wed Apr 25 09:48:45 2018 ] 	Mean training loss: 0.0381.
[ Wed Apr 25 09:48:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:45 2018 ] Training epoch: 457
[ Wed Apr 25 09:48:49 2018 ] 	Batch(0/1) done. Loss: 0.0762  lr:0.100000
[ Wed Apr 25 09:48:49 2018 ] 	Mean training loss: 0.0762.
[ Wed Apr 25 09:48:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:49 2018 ] Training epoch: 458
[ Wed Apr 25 09:48:53 2018 ] 	Batch(0/1) done. Loss: 0.0486  lr:0.100000
[ Wed Apr 25 09:48:53 2018 ] 	Mean training loss: 0.0486.
[ Wed Apr 25 09:48:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:48:53 2018 ] Training epoch: 459
[ Wed Apr 25 09:48:57 2018 ] 	Batch(0/1) done. Loss: 0.0347  lr:0.100000
[ Wed Apr 25 09:48:57 2018 ] 	Mean training loss: 0.0347.
[ Wed Apr 25 09:48:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:48:57 2018 ] Training epoch: 460
[ Wed Apr 25 09:49:01 2018 ] 	Batch(0/1) done. Loss: 0.0520  lr:0.100000
[ Wed Apr 25 09:49:01 2018 ] 	Mean training loss: 0.0520.
[ Wed Apr 25 09:49:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:01 2018 ] Eval epoch: 460
[ Wed Apr 25 09:49:04 2018 ] 	Mean test loss of 1 batches: 0.5215118527412415.
[ Wed Apr 25 09:49:04 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:49:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:49:04 2018 ] Training epoch: 461
[ Wed Apr 25 09:49:08 2018 ] 	Batch(0/1) done. Loss: 0.0520  lr:0.100000
[ Wed Apr 25 09:49:08 2018 ] 	Mean training loss: 0.0520.
[ Wed Apr 25 09:49:08 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:49:08 2018 ] Training epoch: 462
[ Wed Apr 25 09:49:12 2018 ] 	Batch(0/1) done. Loss: 0.0627  lr:0.100000
[ Wed Apr 25 09:49:12 2018 ] 	Mean training loss: 0.0627.
[ Wed Apr 25 09:49:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:12 2018 ] Training epoch: 463
[ Wed Apr 25 09:49:16 2018 ] 	Batch(0/1) done. Loss: 0.1027  lr:0.100000
[ Wed Apr 25 09:49:16 2018 ] 	Mean training loss: 0.1027.
[ Wed Apr 25 09:49:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:49:16 2018 ] Training epoch: 464
[ Wed Apr 25 09:49:20 2018 ] 	Batch(0/1) done. Loss: 0.0737  lr:0.100000
[ Wed Apr 25 09:49:20 2018 ] 	Mean training loss: 0.0737.
[ Wed Apr 25 09:49:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:20 2018 ] Training epoch: 465
[ Wed Apr 25 09:49:24 2018 ] 	Batch(0/1) done. Loss: 0.0276  lr:0.100000
[ Wed Apr 25 09:49:24 2018 ] 	Mean training loss: 0.0276.
[ Wed Apr 25 09:49:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:49:24 2018 ] Eval epoch: 465
[ Wed Apr 25 09:49:27 2018 ] 	Mean test loss of 1 batches: 0.5583967566490173.
[ Wed Apr 25 09:49:27 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:49:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:49:27 2018 ] Training epoch: 466
[ Wed Apr 25 09:49:31 2018 ] 	Batch(0/1) done. Loss: 0.0717  lr:0.100000
[ Wed Apr 25 09:49:31 2018 ] 	Mean training loss: 0.0717.
[ Wed Apr 25 09:49:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:31 2018 ] Training epoch: 467
[ Wed Apr 25 09:49:35 2018 ] 	Batch(0/1) done. Loss: 0.0484  lr:0.100000
[ Wed Apr 25 09:49:35 2018 ] 	Mean training loss: 0.0484.
[ Wed Apr 25 09:49:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:49:35 2018 ] Training epoch: 468
[ Wed Apr 25 09:49:39 2018 ] 	Batch(0/1) done. Loss: 0.0264  lr:0.100000
[ Wed Apr 25 09:49:39 2018 ] 	Mean training loss: 0.0264.
[ Wed Apr 25 09:49:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:39 2018 ] Training epoch: 469
[ Wed Apr 25 09:49:43 2018 ] 	Batch(0/1) done. Loss: 0.0261  lr:0.100000
[ Wed Apr 25 09:49:43 2018 ] 	Mean training loss: 0.0261.
[ Wed Apr 25 09:49:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:43 2018 ] Training epoch: 470
[ Wed Apr 25 09:49:47 2018 ] 	Batch(0/1) done. Loss: 0.0966  lr:0.100000
[ Wed Apr 25 09:49:47 2018 ] 	Mean training loss: 0.0966.
[ Wed Apr 25 09:49:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:49:47 2018 ] Eval epoch: 470
[ Wed Apr 25 09:49:50 2018 ] 	Mean test loss of 1 batches: 0.18866056203842163.
[ Wed Apr 25 09:49:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:49:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:49:50 2018 ] Training epoch: 471
[ Wed Apr 25 09:49:54 2018 ] 	Batch(0/1) done. Loss: 0.0339  lr:0.100000
[ Wed Apr 25 09:49:54 2018 ] 	Mean training loss: 0.0339.
[ Wed Apr 25 09:49:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:49:54 2018 ] Training epoch: 472
[ Wed Apr 25 09:49:58 2018 ] 	Batch(0/1) done. Loss: 0.0862  lr:0.100000
[ Wed Apr 25 09:49:58 2018 ] 	Mean training loss: 0.0862.
[ Wed Apr 25 09:49:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:49:58 2018 ] Training epoch: 473
[ Wed Apr 25 09:50:02 2018 ] 	Batch(0/1) done. Loss: 0.0200  lr:0.100000
[ Wed Apr 25 09:50:02 2018 ] 	Mean training loss: 0.0200.
[ Wed Apr 25 09:50:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:02 2018 ] Training epoch: 474
[ Wed Apr 25 09:50:06 2018 ] 	Batch(0/1) done. Loss: 0.1005  lr:0.100000
[ Wed Apr 25 09:50:06 2018 ] 	Mean training loss: 0.1005.
[ Wed Apr 25 09:50:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:06 2018 ] Training epoch: 475
[ Wed Apr 25 09:50:10 2018 ] 	Batch(0/1) done. Loss: 0.0221  lr:0.100000
[ Wed Apr 25 09:50:10 2018 ] 	Mean training loss: 0.0221.
[ Wed Apr 25 09:50:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:10 2018 ] Eval epoch: 475
[ Wed Apr 25 09:50:12 2018 ] 	Mean test loss of 1 batches: 0.2645094692707062.
[ Wed Apr 25 09:50:12 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:50:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:50:12 2018 ] Training epoch: 476
[ Wed Apr 25 09:50:16 2018 ] 	Batch(0/1) done. Loss: 0.0200  lr:0.100000
[ Wed Apr 25 09:50:16 2018 ] 	Mean training loss: 0.0200.
[ Wed Apr 25 09:50:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:16 2018 ] Training epoch: 477
[ Wed Apr 25 09:50:20 2018 ] 	Batch(0/1) done. Loss: 0.0338  lr:0.100000
[ Wed Apr 25 09:50:20 2018 ] 	Mean training loss: 0.0338.
[ Wed Apr 25 09:50:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:20 2018 ] Training epoch: 478
[ Wed Apr 25 09:50:24 2018 ] 	Batch(0/1) done. Loss: 0.0387  lr:0.100000
[ Wed Apr 25 09:50:24 2018 ] 	Mean training loss: 0.0387.
[ Wed Apr 25 09:50:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:50:24 2018 ] Training epoch: 479
[ Wed Apr 25 09:50:28 2018 ] 	Batch(0/1) done. Loss: 0.0625  lr:0.100000
[ Wed Apr 25 09:50:28 2018 ] 	Mean training loss: 0.0625.
[ Wed Apr 25 09:50:28 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:50:28 2018 ] Training epoch: 480
[ Wed Apr 25 09:50:32 2018 ] 	Batch(0/1) done. Loss: 0.1849  lr:0.100000
[ Wed Apr 25 09:50:32 2018 ] 	Mean training loss: 0.1849.
[ Wed Apr 25 09:50:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:32 2018 ] Eval epoch: 480
[ Wed Apr 25 09:50:35 2018 ] 	Mean test loss of 1 batches: 0.20012611150741577.
[ Wed Apr 25 09:50:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:50:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:50:35 2018 ] Training epoch: 481
[ Wed Apr 25 09:50:39 2018 ] 	Batch(0/1) done. Loss: 0.1157  lr:0.100000
[ Wed Apr 25 09:50:39 2018 ] 	Mean training loss: 0.1157.
[ Wed Apr 25 09:50:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:50:39 2018 ] Training epoch: 482
[ Wed Apr 25 09:50:43 2018 ] 	Batch(0/1) done. Loss: 0.0897  lr:0.100000
[ Wed Apr 25 09:50:43 2018 ] 	Mean training loss: 0.0897.
[ Wed Apr 25 09:50:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:50:43 2018 ] Training epoch: 483
[ Wed Apr 25 09:50:47 2018 ] 	Batch(0/1) done. Loss: 0.1141  lr:0.100000
[ Wed Apr 25 09:50:47 2018 ] 	Mean training loss: 0.1141.
[ Wed Apr 25 09:50:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:47 2018 ] Training epoch: 484
[ Wed Apr 25 09:50:51 2018 ] 	Batch(0/1) done. Loss: 0.0205  lr:0.100000
[ Wed Apr 25 09:50:51 2018 ] 	Mean training loss: 0.0205.
[ Wed Apr 25 09:50:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:50:51 2018 ] Training epoch: 485
[ Wed Apr 25 09:50:55 2018 ] 	Batch(0/1) done. Loss: 0.0523  lr:0.100000
[ Wed Apr 25 09:50:55 2018 ] 	Mean training loss: 0.0523.
[ Wed Apr 25 09:50:55 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:50:55 2018 ] Eval epoch: 485
[ Wed Apr 25 09:50:58 2018 ] 	Mean test loss of 1 batches: 0.26967108249664307.
[ Wed Apr 25 09:50:58 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:50:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:50:58 2018 ] Training epoch: 486
[ Wed Apr 25 09:51:02 2018 ] 	Batch(0/1) done. Loss: 0.0168  lr:0.100000
[ Wed Apr 25 09:51:02 2018 ] 	Mean training loss: 0.0168.
[ Wed Apr 25 09:51:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:02 2018 ] Training epoch: 487
[ Wed Apr 25 09:51:06 2018 ] 	Batch(0/1) done. Loss: 0.0589  lr:0.100000
[ Wed Apr 25 09:51:06 2018 ] 	Mean training loss: 0.0589.
[ Wed Apr 25 09:51:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:06 2018 ] Training epoch: 488
[ Wed Apr 25 09:51:10 2018 ] 	Batch(0/1) done. Loss: 0.0290  lr:0.100000
[ Wed Apr 25 09:51:10 2018 ] 	Mean training loss: 0.0290.
[ Wed Apr 25 09:51:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:10 2018 ] Training epoch: 489
[ Wed Apr 25 09:51:14 2018 ] 	Batch(0/1) done. Loss: 0.0206  lr:0.100000
[ Wed Apr 25 09:51:14 2018 ] 	Mean training loss: 0.0206.
[ Wed Apr 25 09:51:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:14 2018 ] Training epoch: 490
[ Wed Apr 25 09:51:18 2018 ] 	Batch(0/1) done. Loss: 0.0559  lr:0.100000
[ Wed Apr 25 09:51:18 2018 ] 	Mean training loss: 0.0559.
[ Wed Apr 25 09:51:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:18 2018 ] Eval epoch: 490
[ Wed Apr 25 09:51:21 2018 ] 	Mean test loss of 1 batches: 0.365342378616333.
[ Wed Apr 25 09:51:21 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:51:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:51:21 2018 ] Training epoch: 491
[ Wed Apr 25 09:51:24 2018 ] 	Batch(0/1) done. Loss: 0.1262  lr:0.100000
[ Wed Apr 25 09:51:24 2018 ] 	Mean training loss: 0.1262.
[ Wed Apr 25 09:51:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:51:24 2018 ] Training epoch: 492
[ Wed Apr 25 09:51:29 2018 ] 	Batch(0/1) done. Loss: 0.0107  lr:0.100000
[ Wed Apr 25 09:51:29 2018 ] 	Mean training loss: 0.0107.
[ Wed Apr 25 09:51:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:51:29 2018 ] Training epoch: 493
[ Wed Apr 25 09:51:33 2018 ] 	Batch(0/1) done. Loss: 0.0296  lr:0.100000
[ Wed Apr 25 09:51:33 2018 ] 	Mean training loss: 0.0296.
[ Wed Apr 25 09:51:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:51:33 2018 ] Training epoch: 494
[ Wed Apr 25 09:51:37 2018 ] 	Batch(0/1) done. Loss: 0.1080  lr:0.100000
[ Wed Apr 25 09:51:37 2018 ] 	Mean training loss: 0.1080.
[ Wed Apr 25 09:51:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:37 2018 ] Training epoch: 495
[ Wed Apr 25 09:51:40 2018 ] 	Batch(0/1) done. Loss: 0.0553  lr:0.100000
[ Wed Apr 25 09:51:40 2018 ] 	Mean training loss: 0.0553.
[ Wed Apr 25 09:51:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:41 2018 ] Eval epoch: 495
[ Wed Apr 25 09:51:43 2018 ] 	Mean test loss of 1 batches: 0.726134717464447.
[ Wed Apr 25 09:51:43 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:51:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:51:43 2018 ] Training epoch: 496
[ Wed Apr 25 09:51:47 2018 ] 	Batch(0/1) done. Loss: 0.0247  lr:0.100000
[ Wed Apr 25 09:51:47 2018 ] 	Mean training loss: 0.0247.
[ Wed Apr 25 09:51:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:47 2018 ] Training epoch: 497
[ Wed Apr 25 09:51:51 2018 ] 	Batch(0/1) done. Loss: 0.0316  lr:0.100000
[ Wed Apr 25 09:51:51 2018 ] 	Mean training loss: 0.0316.
[ Wed Apr 25 09:51:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:51 2018 ] Training epoch: 498
[ Wed Apr 25 09:51:55 2018 ] 	Batch(0/1) done. Loss: 0.0340  lr:0.100000
[ Wed Apr 25 09:51:55 2018 ] 	Mean training loss: 0.0340.
[ Wed Apr 25 09:51:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:55 2018 ] Training epoch: 499
[ Wed Apr 25 09:51:59 2018 ] 	Batch(0/1) done. Loss: 0.0819  lr:0.100000
[ Wed Apr 25 09:51:59 2018 ] 	Mean training loss: 0.0819.
[ Wed Apr 25 09:51:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:51:59 2018 ] Training epoch: 500
[ Wed Apr 25 09:52:03 2018 ] 	Batch(0/1) done. Loss: 0.1091  lr:0.100000
[ Wed Apr 25 09:52:03 2018 ] 	Mean training loss: 0.1091.
[ Wed Apr 25 09:52:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:03 2018 ] Eval epoch: 500
[ Wed Apr 25 09:52:06 2018 ] 	Mean test loss of 1 batches: 0.6939085721969604.
[ Wed Apr 25 09:52:06 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:52:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:52:06 2018 ] Training epoch: 501
[ Wed Apr 25 09:52:09 2018 ] 	Batch(0/1) done. Loss: 0.0500  lr:0.100000
[ Wed Apr 25 09:52:10 2018 ] 	Mean training loss: 0.0500.
[ Wed Apr 25 09:52:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:10 2018 ] Training epoch: 502
[ Wed Apr 25 09:52:14 2018 ] 	Batch(0/1) done. Loss: 0.0550  lr:0.100000
[ Wed Apr 25 09:52:14 2018 ] 	Mean training loss: 0.0550.
[ Wed Apr 25 09:52:14 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:52:14 2018 ] Training epoch: 503
[ Wed Apr 25 09:52:18 2018 ] 	Batch(0/1) done. Loss: 0.0213  lr:0.100000
[ Wed Apr 25 09:52:18 2018 ] 	Mean training loss: 0.0213.
[ Wed Apr 25 09:52:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:18 2018 ] Training epoch: 504
[ Wed Apr 25 09:52:22 2018 ] 	Batch(0/1) done. Loss: 0.0812  lr:0.100000
[ Wed Apr 25 09:52:22 2018 ] 	Mean training loss: 0.0812.
[ Wed Apr 25 09:52:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:22 2018 ] Training epoch: 505
[ Wed Apr 25 09:52:26 2018 ] 	Batch(0/1) done. Loss: 0.0620  lr:0.100000
[ Wed Apr 25 09:52:26 2018 ] 	Mean training loss: 0.0620.
[ Wed Apr 25 09:52:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:26 2018 ] Eval epoch: 505
[ Wed Apr 25 09:52:28 2018 ] 	Mean test loss of 1 batches: 0.1810527890920639.
[ Wed Apr 25 09:52:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:52:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:52:28 2018 ] Training epoch: 506
[ Wed Apr 25 09:52:32 2018 ] 	Batch(0/1) done. Loss: 0.0507  lr:0.100000
[ Wed Apr 25 09:52:32 2018 ] 	Mean training loss: 0.0507.
[ Wed Apr 25 09:52:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:52:32 2018 ] Training epoch: 507
[ Wed Apr 25 09:52:36 2018 ] 	Batch(0/1) done. Loss: 0.0711  lr:0.100000
[ Wed Apr 25 09:52:36 2018 ] 	Mean training loss: 0.0711.
[ Wed Apr 25 09:52:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:36 2018 ] Training epoch: 508
[ Wed Apr 25 09:52:40 2018 ] 	Batch(0/1) done. Loss: 0.0282  lr:0.100000
[ Wed Apr 25 09:52:40 2018 ] 	Mean training loss: 0.0282.
[ Wed Apr 25 09:52:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:40 2018 ] Training epoch: 509
[ Wed Apr 25 09:52:44 2018 ] 	Batch(0/1) done. Loss: 0.0257  lr:0.100000
[ Wed Apr 25 09:52:44 2018 ] 	Mean training loss: 0.0257.
[ Wed Apr 25 09:52:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:44 2018 ] Training epoch: 510
[ Wed Apr 25 09:52:48 2018 ] 	Batch(0/1) done. Loss: 0.0322  lr:0.100000
[ Wed Apr 25 09:52:48 2018 ] 	Mean training loss: 0.0322.
[ Wed Apr 25 09:52:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:52:48 2018 ] Eval epoch: 510
[ Wed Apr 25 09:52:51 2018 ] 	Mean test loss of 1 batches: 0.39486682415008545.
[ Wed Apr 25 09:52:51 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:52:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:52:51 2018 ] Training epoch: 511
[ Wed Apr 25 09:52:55 2018 ] 	Batch(0/1) done. Loss: 0.0424  lr:0.100000
[ Wed Apr 25 09:52:55 2018 ] 	Mean training loss: 0.0424.
[ Wed Apr 25 09:52:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:52:55 2018 ] Training epoch: 512
[ Wed Apr 25 09:52:59 2018 ] 	Batch(0/1) done. Loss: 0.0390  lr:0.100000
[ Wed Apr 25 09:52:59 2018 ] 	Mean training loss: 0.0390.
[ Wed Apr 25 09:52:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:52:59 2018 ] Training epoch: 513
[ Wed Apr 25 09:53:03 2018 ] 	Batch(0/1) done. Loss: 0.0353  lr:0.100000
[ Wed Apr 25 09:53:03 2018 ] 	Mean training loss: 0.0353.
[ Wed Apr 25 09:53:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:03 2018 ] Training epoch: 514
[ Wed Apr 25 09:53:07 2018 ] 	Batch(0/1) done. Loss: 0.0105  lr:0.100000
[ Wed Apr 25 09:53:07 2018 ] 	Mean training loss: 0.0105.
[ Wed Apr 25 09:53:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:07 2018 ] Training epoch: 515
[ Wed Apr 25 09:53:11 2018 ] 	Batch(0/1) done. Loss: 0.0721  lr:0.100000
[ Wed Apr 25 09:53:11 2018 ] 	Mean training loss: 0.0721.
[ Wed Apr 25 09:53:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:11 2018 ] Eval epoch: 515
[ Wed Apr 25 09:53:14 2018 ] 	Mean test loss of 1 batches: 0.5020439028739929.
[ Wed Apr 25 09:53:14 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:53:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:53:14 2018 ] Training epoch: 516
[ Wed Apr 25 09:53:17 2018 ] 	Batch(0/1) done. Loss: 0.0273  lr:0.100000
[ Wed Apr 25 09:53:18 2018 ] 	Mean training loss: 0.0273.
[ Wed Apr 25 09:53:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:18 2018 ] Training epoch: 517
[ Wed Apr 25 09:53:21 2018 ] 	Batch(0/1) done. Loss: 0.0165  lr:0.100000
[ Wed Apr 25 09:53:21 2018 ] 	Mean training loss: 0.0165.
[ Wed Apr 25 09:53:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:21 2018 ] Training epoch: 518
[ Wed Apr 25 09:53:25 2018 ] 	Batch(0/1) done. Loss: 0.0098  lr:0.100000
[ Wed Apr 25 09:53:25 2018 ] 	Mean training loss: 0.0098.
[ Wed Apr 25 09:53:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:25 2018 ] Training epoch: 519
[ Wed Apr 25 09:53:29 2018 ] 	Batch(0/1) done. Loss: 0.0272  lr:0.100000
[ Wed Apr 25 09:53:29 2018 ] 	Mean training loss: 0.0272.
[ Wed Apr 25 09:53:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:29 2018 ] Training epoch: 520
[ Wed Apr 25 09:53:33 2018 ] 	Batch(0/1) done. Loss: 0.0575  lr:0.100000
[ Wed Apr 25 09:53:33 2018 ] 	Mean training loss: 0.0575.
[ Wed Apr 25 09:53:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:33 2018 ] Eval epoch: 520
[ Wed Apr 25 09:53:36 2018 ] 	Mean test loss of 1 batches: 0.3873814344406128.
[ Wed Apr 25 09:53:36 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:53:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:53:36 2018 ] Training epoch: 521
[ Wed Apr 25 09:53:40 2018 ] 	Batch(0/1) done. Loss: 0.0202  lr:0.100000
[ Wed Apr 25 09:53:40 2018 ] 	Mean training loss: 0.0202.
[ Wed Apr 25 09:53:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:40 2018 ] Training epoch: 522
[ Wed Apr 25 09:53:44 2018 ] 	Batch(0/1) done. Loss: 0.0059  lr:0.100000
[ Wed Apr 25 09:53:44 2018 ] 	Mean training loss: 0.0059.
[ Wed Apr 25 09:53:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:44 2018 ] Training epoch: 523
[ Wed Apr 25 09:53:48 2018 ] 	Batch(0/1) done. Loss: 0.0260  lr:0.100000
[ Wed Apr 25 09:53:48 2018 ] 	Mean training loss: 0.0260.
[ Wed Apr 25 09:53:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:48 2018 ] Training epoch: 524
[ Wed Apr 25 09:53:52 2018 ] 	Batch(0/1) done. Loss: 0.0637  lr:0.100000
[ Wed Apr 25 09:53:52 2018 ] 	Mean training loss: 0.0637.
[ Wed Apr 25 09:53:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:52 2018 ] Training epoch: 525
[ Wed Apr 25 09:53:55 2018 ] 	Batch(0/1) done. Loss: 0.0118  lr:0.100000
[ Wed Apr 25 09:53:55 2018 ] 	Mean training loss: 0.0118.
[ Wed Apr 25 09:53:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:53:55 2018 ] Eval epoch: 525
[ Wed Apr 25 09:53:58 2018 ] 	Mean test loss of 1 batches: 0.20065811276435852.
[ Wed Apr 25 09:53:58 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:53:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:53:58 2018 ] Training epoch: 526
[ Wed Apr 25 09:54:02 2018 ] 	Batch(0/1) done. Loss: 0.0310  lr:0.100000
[ Wed Apr 25 09:54:02 2018 ] 	Mean training loss: 0.0310.
[ Wed Apr 25 09:54:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:02 2018 ] Training epoch: 527
[ Wed Apr 25 09:54:06 2018 ] 	Batch(0/1) done. Loss: 0.0157  lr:0.100000
[ Wed Apr 25 09:54:06 2018 ] 	Mean training loss: 0.0157.
[ Wed Apr 25 09:54:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:54:06 2018 ] Training epoch: 528
[ Wed Apr 25 09:54:10 2018 ] 	Batch(0/1) done. Loss: 0.0372  lr:0.100000
[ Wed Apr 25 09:54:10 2018 ] 	Mean training loss: 0.0372.
[ Wed Apr 25 09:54:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:10 2018 ] Training epoch: 529
[ Wed Apr 25 09:54:14 2018 ] 	Batch(0/1) done. Loss: 0.0300  lr:0.100000
[ Wed Apr 25 09:54:14 2018 ] 	Mean training loss: 0.0300.
[ Wed Apr 25 09:54:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:54:14 2018 ] Training epoch: 530
[ Wed Apr 25 09:54:18 2018 ] 	Batch(0/1) done. Loss: 0.0226  lr:0.100000
[ Wed Apr 25 09:54:18 2018 ] 	Mean training loss: 0.0226.
[ Wed Apr 25 09:54:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:18 2018 ] Eval epoch: 530
[ Wed Apr 25 09:54:21 2018 ] 	Mean test loss of 1 batches: 0.4922860562801361.
[ Wed Apr 25 09:54:21 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:54:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:54:21 2018 ] Training epoch: 531
[ Wed Apr 25 09:54:25 2018 ] 	Batch(0/1) done. Loss: 0.0091  lr:0.100000
[ Wed Apr 25 09:54:25 2018 ] 	Mean training loss: 0.0091.
[ Wed Apr 25 09:54:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:25 2018 ] Training epoch: 532
[ Wed Apr 25 09:54:29 2018 ] 	Batch(0/1) done. Loss: 0.0152  lr:0.100000
[ Wed Apr 25 09:54:29 2018 ] 	Mean training loss: 0.0152.
[ Wed Apr 25 09:54:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:54:29 2018 ] Training epoch: 533
[ Wed Apr 25 09:54:33 2018 ] 	Batch(0/1) done. Loss: 0.0230  lr:0.100000
[ Wed Apr 25 09:54:33 2018 ] 	Mean training loss: 0.0230.
[ Wed Apr 25 09:54:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:33 2018 ] Training epoch: 534
[ Wed Apr 25 09:54:37 2018 ] 	Batch(0/1) done. Loss: 0.0098  lr:0.100000
[ Wed Apr 25 09:54:37 2018 ] 	Mean training loss: 0.0098.
[ Wed Apr 25 09:54:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:37 2018 ] Training epoch: 535
[ Wed Apr 25 09:54:41 2018 ] 	Batch(0/1) done. Loss: 0.0248  lr:0.100000
[ Wed Apr 25 09:54:41 2018 ] 	Mean training loss: 0.0248.
[ Wed Apr 25 09:54:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:54:41 2018 ] Eval epoch: 535
[ Wed Apr 25 09:54:43 2018 ] 	Mean test loss of 1 batches: 0.46679821610450745.
[ Wed Apr 25 09:54:43 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:54:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:54:43 2018 ] Training epoch: 536
[ Wed Apr 25 09:54:47 2018 ] 	Batch(0/1) done. Loss: 0.0198  lr:0.100000
[ Wed Apr 25 09:54:47 2018 ] 	Mean training loss: 0.0198.
[ Wed Apr 25 09:54:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:47 2018 ] Training epoch: 537
[ Wed Apr 25 09:54:51 2018 ] 	Batch(0/1) done. Loss: 0.0706  lr:0.100000
[ Wed Apr 25 09:54:51 2018 ] 	Mean training loss: 0.0706.
[ Wed Apr 25 09:54:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:51 2018 ] Training epoch: 538
[ Wed Apr 25 09:54:55 2018 ] 	Batch(0/1) done. Loss: 0.0246  lr:0.100000
[ Wed Apr 25 09:54:55 2018 ] 	Mean training loss: 0.0246.
[ Wed Apr 25 09:54:55 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:54:55 2018 ] Training epoch: 539
[ Wed Apr 25 09:54:59 2018 ] 	Batch(0/1) done. Loss: 0.0295  lr:0.100000
[ Wed Apr 25 09:54:59 2018 ] 	Mean training loss: 0.0295.
[ Wed Apr 25 09:54:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:54:59 2018 ] Training epoch: 540
[ Wed Apr 25 09:55:03 2018 ] 	Batch(0/1) done. Loss: 0.0680  lr:0.100000
[ Wed Apr 25 09:55:03 2018 ] 	Mean training loss: 0.0680.
[ Wed Apr 25 09:55:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:03 2018 ] Eval epoch: 540
[ Wed Apr 25 09:55:06 2018 ] 	Mean test loss of 1 batches: 0.20482361316680908.
[ Wed Apr 25 09:55:06 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:55:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:55:06 2018 ] Training epoch: 541
[ Wed Apr 25 09:55:10 2018 ] 	Batch(0/1) done. Loss: 0.0149  lr:0.100000
[ Wed Apr 25 09:55:10 2018 ] 	Mean training loss: 0.0149.
[ Wed Apr 25 09:55:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:10 2018 ] Training epoch: 542
[ Wed Apr 25 09:55:14 2018 ] 	Batch(0/1) done. Loss: 0.0145  lr:0.100000
[ Wed Apr 25 09:55:14 2018 ] 	Mean training loss: 0.0145.
[ Wed Apr 25 09:55:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:14 2018 ] Training epoch: 543
[ Wed Apr 25 09:55:18 2018 ] 	Batch(0/1) done. Loss: 0.0116  lr:0.100000
[ Wed Apr 25 09:55:18 2018 ] 	Mean training loss: 0.0116.
[ Wed Apr 25 09:55:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:18 2018 ] Training epoch: 544
[ Wed Apr 25 09:55:22 2018 ] 	Batch(0/1) done. Loss: 0.0127  lr:0.100000
[ Wed Apr 25 09:55:22 2018 ] 	Mean training loss: 0.0127.
[ Wed Apr 25 09:55:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:22 2018 ] Training epoch: 545
[ Wed Apr 25 09:55:26 2018 ] 	Batch(0/1) done. Loss: 0.0284  lr:0.100000
[ Wed Apr 25 09:55:26 2018 ] 	Mean training loss: 0.0284.
[ Wed Apr 25 09:55:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:26 2018 ] Eval epoch: 545
[ Wed Apr 25 09:55:28 2018 ] 	Mean test loss of 1 batches: 0.17227254807949066.
[ Wed Apr 25 09:55:28 2018 ] 	Top1: 96.30%
[ Wed Apr 25 09:55:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:55:28 2018 ] Training epoch: 546
[ Wed Apr 25 09:55:32 2018 ] 	Batch(0/1) done. Loss: 0.0323  lr:0.100000
[ Wed Apr 25 09:55:32 2018 ] 	Mean training loss: 0.0323.
[ Wed Apr 25 09:55:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:32 2018 ] Training epoch: 547
[ Wed Apr 25 09:55:36 2018 ] 	Batch(0/1) done. Loss: 0.0212  lr:0.100000
[ Wed Apr 25 09:55:36 2018 ] 	Mean training loss: 0.0212.
[ Wed Apr 25 09:55:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:36 2018 ] Training epoch: 548
[ Wed Apr 25 09:55:40 2018 ] 	Batch(0/1) done. Loss: 0.0025  lr:0.100000
[ Wed Apr 25 09:55:40 2018 ] 	Mean training loss: 0.0025.
[ Wed Apr 25 09:55:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:55:40 2018 ] Training epoch: 549
[ Wed Apr 25 09:55:44 2018 ] 	Batch(0/1) done. Loss: 0.0259  lr:0.100000
[ Wed Apr 25 09:55:44 2018 ] 	Mean training loss: 0.0259.
[ Wed Apr 25 09:55:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:44 2018 ] Training epoch: 550
[ Wed Apr 25 09:55:48 2018 ] 	Batch(0/1) done. Loss: 0.0116  lr:0.100000
[ Wed Apr 25 09:55:48 2018 ] 	Mean training loss: 0.0116.
[ Wed Apr 25 09:55:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:48 2018 ] Eval epoch: 550
[ Wed Apr 25 09:55:51 2018 ] 	Mean test loss of 1 batches: 0.24437323212623596.
[ Wed Apr 25 09:55:51 2018 ] 	Top1: 88.89%
[ Wed Apr 25 09:55:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:55:51 2018 ] Training epoch: 551
[ Wed Apr 25 09:55:55 2018 ] 	Batch(0/1) done. Loss: 0.0069  lr:0.100000
[ Wed Apr 25 09:55:55 2018 ] 	Mean training loss: 0.0069.
[ Wed Apr 25 09:55:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:55 2018 ] Training epoch: 552
[ Wed Apr 25 09:55:59 2018 ] 	Batch(0/1) done. Loss: 0.0549  lr:0.100000
[ Wed Apr 25 09:55:59 2018 ] 	Mean training loss: 0.0549.
[ Wed Apr 25 09:55:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:55:59 2018 ] Training epoch: 553
[ Wed Apr 25 09:56:03 2018 ] 	Batch(0/1) done. Loss: 0.0126  lr:0.100000
[ Wed Apr 25 09:56:03 2018 ] 	Mean training loss: 0.0126.
[ Wed Apr 25 09:56:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:03 2018 ] Training epoch: 554
[ Wed Apr 25 09:56:07 2018 ] 	Batch(0/1) done. Loss: 0.0191  lr:0.100000
[ Wed Apr 25 09:56:07 2018 ] 	Mean training loss: 0.0191.
[ Wed Apr 25 09:56:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:07 2018 ] Training epoch: 555
[ Wed Apr 25 09:56:11 2018 ] 	Batch(0/1) done. Loss: 0.0042  lr:0.100000
[ Wed Apr 25 09:56:11 2018 ] 	Mean training loss: 0.0042.
[ Wed Apr 25 09:56:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:11 2018 ] Eval epoch: 555
[ Wed Apr 25 09:56:14 2018 ] 	Mean test loss of 1 batches: 0.2835301160812378.
[ Wed Apr 25 09:56:14 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:56:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:56:14 2018 ] Training epoch: 556
[ Wed Apr 25 09:56:18 2018 ] 	Batch(0/1) done. Loss: 0.0365  lr:0.100000
[ Wed Apr 25 09:56:18 2018 ] 	Mean training loss: 0.0365.
[ Wed Apr 25 09:56:18 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:56:18 2018 ] Training epoch: 557
[ Wed Apr 25 09:56:22 2018 ] 	Batch(0/1) done. Loss: 0.0153  lr:0.100000
[ Wed Apr 25 09:56:22 2018 ] 	Mean training loss: 0.0153.
[ Wed Apr 25 09:56:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:56:22 2018 ] Training epoch: 558
[ Wed Apr 25 09:56:26 2018 ] 	Batch(0/1) done. Loss: 0.0343  lr:0.100000
[ Wed Apr 25 09:56:26 2018 ] 	Mean training loss: 0.0343.
[ Wed Apr 25 09:56:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:56:26 2018 ] Training epoch: 559
[ Wed Apr 25 09:56:30 2018 ] 	Batch(0/1) done. Loss: 0.0147  lr:0.100000
[ Wed Apr 25 09:56:30 2018 ] 	Mean training loss: 0.0147.
[ Wed Apr 25 09:56:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:30 2018 ] Training epoch: 560
[ Wed Apr 25 09:56:34 2018 ] 	Batch(0/1) done. Loss: 0.0340  lr:0.100000
[ Wed Apr 25 09:56:34 2018 ] 	Mean training loss: 0.0340.
[ Wed Apr 25 09:56:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:56:34 2018 ] Eval epoch: 560
[ Wed Apr 25 09:56:36 2018 ] 	Mean test loss of 1 batches: 0.46531641483306885.
[ Wed Apr 25 09:56:36 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:56:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:56:36 2018 ] Training epoch: 561
[ Wed Apr 25 09:56:40 2018 ] 	Batch(0/1) done. Loss: 0.0051  lr:0.100000
[ Wed Apr 25 09:56:40 2018 ] 	Mean training loss: 0.0051.
[ Wed Apr 25 09:56:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:40 2018 ] Training epoch: 562
[ Wed Apr 25 09:56:44 2018 ] 	Batch(0/1) done. Loss: 0.0127  lr:0.100000
[ Wed Apr 25 09:56:44 2018 ] 	Mean training loss: 0.0127.
[ Wed Apr 25 09:56:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:44 2018 ] Training epoch: 563
[ Wed Apr 25 09:56:48 2018 ] 	Batch(0/1) done. Loss: 0.0125  lr:0.100000
[ Wed Apr 25 09:56:48 2018 ] 	Mean training loss: 0.0125.
[ Wed Apr 25 09:56:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:56:48 2018 ] Training epoch: 564
[ Wed Apr 25 09:56:52 2018 ] 	Batch(0/1) done. Loss: 0.0336  lr:0.100000
[ Wed Apr 25 09:56:52 2018 ] 	Mean training loss: 0.0336.
[ Wed Apr 25 09:56:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:52 2018 ] Training epoch: 565
[ Wed Apr 25 09:56:56 2018 ] 	Batch(0/1) done. Loss: 0.0474  lr:0.100000
[ Wed Apr 25 09:56:56 2018 ] 	Mean training loss: 0.0474.
[ Wed Apr 25 09:56:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:56:56 2018 ] Eval epoch: 565
[ Wed Apr 25 09:56:59 2018 ] 	Mean test loss of 1 batches: 0.5986917018890381.
[ Wed Apr 25 09:56:59 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:56:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:56:59 2018 ] Training epoch: 566
[ Wed Apr 25 09:57:03 2018 ] 	Batch(0/1) done. Loss: 0.0178  lr:0.100000
[ Wed Apr 25 09:57:03 2018 ] 	Mean training loss: 0.0178.
[ Wed Apr 25 09:57:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:03 2018 ] Training epoch: 567
[ Wed Apr 25 09:57:07 2018 ] 	Batch(0/1) done. Loss: 0.0408  lr:0.100000
[ Wed Apr 25 09:57:07 2018 ] 	Mean training loss: 0.0408.
[ Wed Apr 25 09:57:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:57:07 2018 ] Training epoch: 568
[ Wed Apr 25 09:57:11 2018 ] 	Batch(0/1) done. Loss: 0.0140  lr:0.100000
[ Wed Apr 25 09:57:11 2018 ] 	Mean training loss: 0.0140.
[ Wed Apr 25 09:57:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:11 2018 ] Training epoch: 569
[ Wed Apr 25 09:57:15 2018 ] 	Batch(0/1) done. Loss: 0.0328  lr:0.100000
[ Wed Apr 25 09:57:15 2018 ] 	Mean training loss: 0.0328.
[ Wed Apr 25 09:57:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:15 2018 ] Training epoch: 570
[ Wed Apr 25 09:57:19 2018 ] 	Batch(0/1) done. Loss: 0.0439  lr:0.100000
[ Wed Apr 25 09:57:19 2018 ] 	Mean training loss: 0.0439.
[ Wed Apr 25 09:57:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:57:19 2018 ] Eval epoch: 570
[ Wed Apr 25 09:57:22 2018 ] 	Mean test loss of 1 batches: 0.3503645360469818.
[ Wed Apr 25 09:57:22 2018 ] 	Top1: 85.19%
[ Wed Apr 25 09:57:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:57:22 2018 ] Training epoch: 571
[ Wed Apr 25 09:57:26 2018 ] 	Batch(0/1) done. Loss: 0.0267  lr:0.100000
[ Wed Apr 25 09:57:26 2018 ] 	Mean training loss: 0.0267.
[ Wed Apr 25 09:57:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:26 2018 ] Training epoch: 572
[ Wed Apr 25 09:57:30 2018 ] 	Batch(0/1) done. Loss: 0.0554  lr:0.100000
[ Wed Apr 25 09:57:30 2018 ] 	Mean training loss: 0.0554.
[ Wed Apr 25 09:57:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:30 2018 ] Training epoch: 573
[ Wed Apr 25 09:57:34 2018 ] 	Batch(0/1) done. Loss: 0.0452  lr:0.100000
[ Wed Apr 25 09:57:34 2018 ] 	Mean training loss: 0.0452.
[ Wed Apr 25 09:57:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:57:34 2018 ] Training epoch: 574
[ Wed Apr 25 09:57:38 2018 ] 	Batch(0/1) done. Loss: 0.1388  lr:0.100000
[ Wed Apr 25 09:57:38 2018 ] 	Mean training loss: 0.1388.
[ Wed Apr 25 09:57:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:38 2018 ] Training epoch: 575
[ Wed Apr 25 09:57:42 2018 ] 	Batch(0/1) done. Loss: 0.0091  lr:0.100000
[ Wed Apr 25 09:57:42 2018 ] 	Mean training loss: 0.0091.
[ Wed Apr 25 09:57:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:57:42 2018 ] Eval epoch: 575
[ Wed Apr 25 09:57:45 2018 ] 	Mean test loss of 1 batches: 0.2254432737827301.
[ Wed Apr 25 09:57:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 09:57:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:57:45 2018 ] Training epoch: 576
[ Wed Apr 25 09:57:49 2018 ] 	Batch(0/1) done. Loss: 0.0658  lr:0.100000
[ Wed Apr 25 09:57:49 2018 ] 	Mean training loss: 0.0658.
[ Wed Apr 25 09:57:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:49 2018 ] Training epoch: 577
[ Wed Apr 25 09:57:53 2018 ] 	Batch(0/1) done. Loss: 0.0167  lr:0.100000
[ Wed Apr 25 09:57:53 2018 ] 	Mean training loss: 0.0167.
[ Wed Apr 25 09:57:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:57:53 2018 ] Training epoch: 578
[ Wed Apr 25 09:57:57 2018 ] 	Batch(0/1) done. Loss: 0.0328  lr:0.100000
[ Wed Apr 25 09:57:57 2018 ] 	Mean training loss: 0.0328.
[ Wed Apr 25 09:57:57 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:57:57 2018 ] Training epoch: 579
[ Wed Apr 25 09:58:01 2018 ] 	Batch(0/1) done. Loss: 0.0252  lr:0.100000
[ Wed Apr 25 09:58:01 2018 ] 	Mean training loss: 0.0252.
[ Wed Apr 25 09:58:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:01 2018 ] Training epoch: 580
[ Wed Apr 25 09:58:05 2018 ] 	Batch(0/1) done. Loss: 0.1371  lr:0.100000
[ Wed Apr 25 09:58:05 2018 ] 	Mean training loss: 0.1371.
[ Wed Apr 25 09:58:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:05 2018 ] Eval epoch: 580
[ Wed Apr 25 09:58:08 2018 ] 	Mean test loss of 1 batches: 0.7433547973632812.
[ Wed Apr 25 09:58:08 2018 ] 	Top1: 74.07%
[ Wed Apr 25 09:58:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:58:08 2018 ] Training epoch: 581
[ Wed Apr 25 09:58:12 2018 ] 	Batch(0/1) done. Loss: 0.0501  lr:0.100000
[ Wed Apr 25 09:58:12 2018 ] 	Mean training loss: 0.0501.
[ Wed Apr 25 09:58:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:12 2018 ] Training epoch: 582
[ Wed Apr 25 09:58:16 2018 ] 	Batch(0/1) done. Loss: 0.1337  lr:0.100000
[ Wed Apr 25 09:58:16 2018 ] 	Mean training loss: 0.1337.
[ Wed Apr 25 09:58:16 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 09:58:16 2018 ] Training epoch: 583
[ Wed Apr 25 09:58:20 2018 ] 	Batch(0/1) done. Loss: 0.0525  lr:0.100000
[ Wed Apr 25 09:58:20 2018 ] 	Mean training loss: 0.0525.
[ Wed Apr 25 09:58:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:20 2018 ] Training epoch: 584
[ Wed Apr 25 09:58:24 2018 ] 	Batch(0/1) done. Loss: 0.1184  lr:0.100000
[ Wed Apr 25 09:58:24 2018 ] 	Mean training loss: 0.1184.
[ Wed Apr 25 09:58:24 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:58:24 2018 ] Training epoch: 585
[ Wed Apr 25 09:58:28 2018 ] 	Batch(0/1) done. Loss: 0.0876  lr:0.100000
[ Wed Apr 25 09:58:28 2018 ] 	Mean training loss: 0.0876.
[ Wed Apr 25 09:58:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:28 2018 ] Eval epoch: 585
[ Wed Apr 25 09:58:31 2018 ] 	Mean test loss of 1 batches: 1.268164873123169.
[ Wed Apr 25 09:58:31 2018 ] 	Top1: 70.37%
[ Wed Apr 25 09:58:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:58:31 2018 ] Training epoch: 586
[ Wed Apr 25 09:58:35 2018 ] 	Batch(0/1) done. Loss: 0.1002  lr:0.100000
[ Wed Apr 25 09:58:35 2018 ] 	Mean training loss: 0.1002.
[ Wed Apr 25 09:58:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:58:35 2018 ] Training epoch: 587
[ Wed Apr 25 09:58:39 2018 ] 	Batch(0/1) done. Loss: 0.0771  lr:0.100000
[ Wed Apr 25 09:58:39 2018 ] 	Mean training loss: 0.0771.
[ Wed Apr 25 09:58:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:58:39 2018 ] Training epoch: 588
[ Wed Apr 25 09:58:44 2018 ] 	Batch(0/1) done. Loss: 0.0567  lr:0.100000
[ Wed Apr 25 09:58:44 2018 ] 	Mean training loss: 0.0567.
[ Wed Apr 25 09:58:44 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:58:44 2018 ] Training epoch: 589
[ Wed Apr 25 09:58:48 2018 ] 	Batch(0/1) done. Loss: 0.0234  lr:0.100000
[ Wed Apr 25 09:58:48 2018 ] 	Mean training loss: 0.0234.
[ Wed Apr 25 09:58:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:58:48 2018 ] Training epoch: 590
[ Wed Apr 25 09:58:51 2018 ] 	Batch(0/1) done. Loss: 0.0225  lr:0.100000
[ Wed Apr 25 09:58:51 2018 ] 	Mean training loss: 0.0225.
[ Wed Apr 25 09:58:51 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 09:58:51 2018 ] Eval epoch: 590
[ Wed Apr 25 09:58:54 2018 ] 	Mean test loss of 1 batches: 1.516538381576538.
[ Wed Apr 25 09:58:54 2018 ] 	Top1: 51.85%
[ Wed Apr 25 09:58:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:58:54 2018 ] Training epoch: 591
[ Wed Apr 25 09:58:58 2018 ] 	Batch(0/1) done. Loss: 0.0327  lr:0.100000
[ Wed Apr 25 09:58:58 2018 ] 	Mean training loss: 0.0327.
[ Wed Apr 25 09:58:58 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:58:58 2018 ] Training epoch: 592
[ Wed Apr 25 09:59:02 2018 ] 	Batch(0/1) done. Loss: 0.0479  lr:0.100000
[ Wed Apr 25 09:59:02 2018 ] 	Mean training loss: 0.0479.
[ Wed Apr 25 09:59:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:02 2018 ] Training epoch: 593
[ Wed Apr 25 09:59:06 2018 ] 	Batch(0/1) done. Loss: 0.0556  lr:0.100000
[ Wed Apr 25 09:59:06 2018 ] 	Mean training loss: 0.0556.
[ Wed Apr 25 09:59:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:06 2018 ] Training epoch: 594
[ Wed Apr 25 09:59:10 2018 ] 	Batch(0/1) done. Loss: 0.0186  lr:0.100000
[ Wed Apr 25 09:59:10 2018 ] 	Mean training loss: 0.0186.
[ Wed Apr 25 09:59:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:10 2018 ] Training epoch: 595
[ Wed Apr 25 09:59:14 2018 ] 	Batch(0/1) done. Loss: 0.0516  lr:0.100000
[ Wed Apr 25 09:59:14 2018 ] 	Mean training loss: 0.0516.
[ Wed Apr 25 09:59:14 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:59:14 2018 ] Eval epoch: 595
[ Wed Apr 25 09:59:17 2018 ] 	Mean test loss of 1 batches: 0.7803953886032104.
[ Wed Apr 25 09:59:17 2018 ] 	Top1: 59.26%
[ Wed Apr 25 09:59:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:59:17 2018 ] Training epoch: 596
[ Wed Apr 25 09:59:21 2018 ] 	Batch(0/1) done. Loss: 0.0214  lr:0.100000
[ Wed Apr 25 09:59:21 2018 ] 	Mean training loss: 0.0214.
[ Wed Apr 25 09:59:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:59:21 2018 ] Training epoch: 597
[ Wed Apr 25 09:59:25 2018 ] 	Batch(0/1) done. Loss: 0.0486  lr:0.100000
[ Wed Apr 25 09:59:25 2018 ] 	Mean training loss: 0.0486.
[ Wed Apr 25 09:59:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 09:59:25 2018 ] Training epoch: 598
[ Wed Apr 25 09:59:29 2018 ] 	Batch(0/1) done. Loss: 0.0087  lr:0.100000
[ Wed Apr 25 09:59:29 2018 ] 	Mean training loss: 0.0087.
[ Wed Apr 25 09:59:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:29 2018 ] Training epoch: 599
[ Wed Apr 25 09:59:34 2018 ] 	Batch(0/1) done. Loss: 0.0436  lr:0.100000
[ Wed Apr 25 09:59:34 2018 ] 	Mean training loss: 0.0436.
[ Wed Apr 25 09:59:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 09:59:34 2018 ] Training epoch: 600
[ Wed Apr 25 09:59:38 2018 ] 	Batch(0/1) done. Loss: 0.1065  lr:0.100000
[ Wed Apr 25 09:59:38 2018 ] 	Mean training loss: 0.1065.
[ Wed Apr 25 09:59:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:38 2018 ] Eval epoch: 600
[ Wed Apr 25 09:59:41 2018 ] 	Mean test loss of 1 batches: 0.32655778527259827.
[ Wed Apr 25 09:59:41 2018 ] 	Top1: 81.48%
[ Wed Apr 25 09:59:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 09:59:41 2018 ] Training epoch: 601
[ Wed Apr 25 09:59:45 2018 ] 	Batch(0/1) done. Loss: 0.0297  lr:0.100000
[ Wed Apr 25 09:59:45 2018 ] 	Mean training loss: 0.0297.
[ Wed Apr 25 09:59:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:59:45 2018 ] Training epoch: 602
[ Wed Apr 25 09:59:49 2018 ] 	Batch(0/1) done. Loss: 0.0294  lr:0.100000
[ Wed Apr 25 09:59:49 2018 ] 	Mean training loss: 0.0294.
[ Wed Apr 25 09:59:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 09:59:49 2018 ] Training epoch: 603
[ Wed Apr 25 09:59:52 2018 ] 	Batch(0/1) done. Loss: 0.0450  lr:0.100000
[ Wed Apr 25 09:59:52 2018 ] 	Mean training loss: 0.0450.
[ Wed Apr 25 09:59:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 09:59:52 2018 ] Training epoch: 604
[ Wed Apr 25 09:59:56 2018 ] 	Batch(0/1) done. Loss: 0.0219  lr:0.100000
[ Wed Apr 25 09:59:56 2018 ] 	Mean training loss: 0.0219.
[ Wed Apr 25 09:59:56 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 09:59:56 2018 ] Training epoch: 605
[ Wed Apr 25 10:00:00 2018 ] 	Batch(0/1) done. Loss: 0.0560  lr:0.100000
[ Wed Apr 25 10:00:00 2018 ] 	Mean training loss: 0.0560.
[ Wed Apr 25 10:00:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:00:00 2018 ] Eval epoch: 605
[ Wed Apr 25 10:00:03 2018 ] 	Mean test loss of 1 batches: 0.24074362218379974.
[ Wed Apr 25 10:00:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:00:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:00:03 2018 ] Training epoch: 606
[ Wed Apr 25 10:00:07 2018 ] 	Batch(0/1) done. Loss: 0.0272  lr:0.100000
[ Wed Apr 25 10:00:07 2018 ] 	Mean training loss: 0.0272.
[ Wed Apr 25 10:00:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:07 2018 ] Training epoch: 607
[ Wed Apr 25 10:00:11 2018 ] 	Batch(0/1) done. Loss: 0.0216  lr:0.100000
[ Wed Apr 25 10:00:11 2018 ] 	Mean training loss: 0.0216.
[ Wed Apr 25 10:00:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:00:11 2018 ] Training epoch: 608
[ Wed Apr 25 10:00:15 2018 ] 	Batch(0/1) done. Loss: 0.0181  lr:0.100000
[ Wed Apr 25 10:00:15 2018 ] 	Mean training loss: 0.0181.
[ Wed Apr 25 10:00:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:15 2018 ] Training epoch: 609
[ Wed Apr 25 10:00:19 2018 ] 	Batch(0/1) done. Loss: 0.0328  lr:0.100000
[ Wed Apr 25 10:00:19 2018 ] 	Mean training loss: 0.0328.
[ Wed Apr 25 10:00:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:19 2018 ] Training epoch: 610
[ Wed Apr 25 10:00:23 2018 ] 	Batch(0/1) done. Loss: 0.0120  lr:0.100000
[ Wed Apr 25 10:00:23 2018 ] 	Mean training loss: 0.0120.
[ Wed Apr 25 10:00:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:23 2018 ] Eval epoch: 610
[ Wed Apr 25 10:00:26 2018 ] 	Mean test loss of 1 batches: 0.33980587124824524.
[ Wed Apr 25 10:00:26 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:00:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:00:26 2018 ] Training epoch: 611
[ Wed Apr 25 10:00:30 2018 ] 	Batch(0/1) done. Loss: 0.0441  lr:0.100000
[ Wed Apr 25 10:00:30 2018 ] 	Mean training loss: 0.0441.
[ Wed Apr 25 10:00:30 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:00:30 2018 ] Training epoch: 612
[ Wed Apr 25 10:00:34 2018 ] 	Batch(0/1) done. Loss: 0.0149  lr:0.100000
[ Wed Apr 25 10:00:34 2018 ] 	Mean training loss: 0.0149.
[ Wed Apr 25 10:00:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:34 2018 ] Training epoch: 613
[ Wed Apr 25 10:00:38 2018 ] 	Batch(0/1) done. Loss: 0.0113  lr:0.100000
[ Wed Apr 25 10:00:38 2018 ] 	Mean training loss: 0.0113.
[ Wed Apr 25 10:00:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:38 2018 ] Training epoch: 614
[ Wed Apr 25 10:00:42 2018 ] 	Batch(0/1) done. Loss: 0.0079  lr:0.100000
[ Wed Apr 25 10:00:42 2018 ] 	Mean training loss: 0.0079.
[ Wed Apr 25 10:00:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:00:42 2018 ] Training epoch: 615
[ Wed Apr 25 10:00:46 2018 ] 	Batch(0/1) done. Loss: 0.0224  lr:0.100000
[ Wed Apr 25 10:00:46 2018 ] 	Mean training loss: 0.0224.
[ Wed Apr 25 10:00:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:00:46 2018 ] Eval epoch: 615
[ Wed Apr 25 10:00:48 2018 ] 	Mean test loss of 1 batches: 0.5998297929763794.
[ Wed Apr 25 10:00:48 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:00:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:00:48 2018 ] Training epoch: 616
[ Wed Apr 25 10:00:52 2018 ] 	Batch(0/1) done. Loss: 0.0333  lr:0.100000
[ Wed Apr 25 10:00:52 2018 ] 	Mean training loss: 0.0333.
[ Wed Apr 25 10:00:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:00:52 2018 ] Training epoch: 617
[ Wed Apr 25 10:00:57 2018 ] 	Batch(0/1) done. Loss: 0.0263  lr:0.100000
[ Wed Apr 25 10:00:57 2018 ] 	Mean training loss: 0.0263.
[ Wed Apr 25 10:00:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:00:57 2018 ] Training epoch: 618
[ Wed Apr 25 10:01:01 2018 ] 	Batch(0/1) done. Loss: 0.0237  lr:0.100000
[ Wed Apr 25 10:01:01 2018 ] 	Mean training loss: 0.0237.
[ Wed Apr 25 10:01:01 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:01:01 2018 ] Training epoch: 619
[ Wed Apr 25 10:01:04 2018 ] 	Batch(0/1) done. Loss: 0.0181  lr:0.100000
[ Wed Apr 25 10:01:04 2018 ] 	Mean training loss: 0.0181.
[ Wed Apr 25 10:01:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:04 2018 ] Training epoch: 620
[ Wed Apr 25 10:01:08 2018 ] 	Batch(0/1) done. Loss: 0.0055  lr:0.100000
[ Wed Apr 25 10:01:08 2018 ] 	Mean training loss: 0.0055.
[ Wed Apr 25 10:01:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:08 2018 ] Eval epoch: 620
[ Wed Apr 25 10:01:11 2018 ] 	Mean test loss of 1 batches: 0.5466351509094238.
[ Wed Apr 25 10:01:11 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:01:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:01:11 2018 ] Training epoch: 621
[ Wed Apr 25 10:01:15 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:01:15 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:01:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:01:15 2018 ] Training epoch: 622
[ Wed Apr 25 10:01:19 2018 ] 	Batch(0/1) done. Loss: 0.0045  lr:0.100000
[ Wed Apr 25 10:01:19 2018 ] 	Mean training loss: 0.0045.
[ Wed Apr 25 10:01:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:01:19 2018 ] Training epoch: 623
[ Wed Apr 25 10:01:23 2018 ] 	Batch(0/1) done. Loss: 0.0070  lr:0.100000
[ Wed Apr 25 10:01:23 2018 ] 	Mean training loss: 0.0070.
[ Wed Apr 25 10:01:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:23 2018 ] Training epoch: 624
[ Wed Apr 25 10:01:27 2018 ] 	Batch(0/1) done. Loss: 0.0064  lr:0.100000
[ Wed Apr 25 10:01:27 2018 ] 	Mean training loss: 0.0064.
[ Wed Apr 25 10:01:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:27 2018 ] Training epoch: 625
[ Wed Apr 25 10:01:31 2018 ] 	Batch(0/1) done. Loss: 0.0154  lr:0.100000
[ Wed Apr 25 10:01:31 2018 ] 	Mean training loss: 0.0154.
[ Wed Apr 25 10:01:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:01:31 2018 ] Eval epoch: 625
[ Wed Apr 25 10:01:34 2018 ] 	Mean test loss of 1 batches: 0.6310694217681885.
[ Wed Apr 25 10:01:34 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:01:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:01:34 2018 ] Training epoch: 626
[ Wed Apr 25 10:01:38 2018 ] 	Batch(0/1) done. Loss: 0.0135  lr:0.100000
[ Wed Apr 25 10:01:38 2018 ] 	Mean training loss: 0.0135.
[ Wed Apr 25 10:01:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:38 2018 ] Training epoch: 627
[ Wed Apr 25 10:01:42 2018 ] 	Batch(0/1) done. Loss: 0.0091  lr:0.100000
[ Wed Apr 25 10:01:42 2018 ] 	Mean training loss: 0.0091.
[ Wed Apr 25 10:01:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:42 2018 ] Training epoch: 628
[ Wed Apr 25 10:01:46 2018 ] 	Batch(0/1) done. Loss: 0.0274  lr:0.100000
[ Wed Apr 25 10:01:46 2018 ] 	Mean training loss: 0.0274.
[ Wed Apr 25 10:01:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:46 2018 ] Training epoch: 629
[ Wed Apr 25 10:01:50 2018 ] 	Batch(0/1) done. Loss: 0.0166  lr:0.100000
[ Wed Apr 25 10:01:50 2018 ] 	Mean training loss: 0.0166.
[ Wed Apr 25 10:01:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:50 2018 ] Training epoch: 630
[ Wed Apr 25 10:01:54 2018 ] 	Batch(0/1) done. Loss: 0.0583  lr:0.100000
[ Wed Apr 25 10:01:54 2018 ] 	Mean training loss: 0.0583.
[ Wed Apr 25 10:01:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:01:54 2018 ] Eval epoch: 630
[ Wed Apr 25 10:01:56 2018 ] 	Mean test loss of 1 batches: 0.25934088230133057.
[ Wed Apr 25 10:01:56 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:01:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:01:56 2018 ] Training epoch: 631
[ Wed Apr 25 10:02:00 2018 ] 	Batch(0/1) done. Loss: 0.0116  lr:0.100000
[ Wed Apr 25 10:02:00 2018 ] 	Mean training loss: 0.0116.
[ Wed Apr 25 10:02:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:00 2018 ] Training epoch: 632
[ Wed Apr 25 10:02:04 2018 ] 	Batch(0/1) done. Loss: 0.0135  lr:0.100000
[ Wed Apr 25 10:02:04 2018 ] 	Mean training loss: 0.0135.
[ Wed Apr 25 10:02:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:02:04 2018 ] Training epoch: 633
[ Wed Apr 25 10:02:09 2018 ] 	Batch(0/1) done. Loss: 0.0109  lr:0.100000
[ Wed Apr 25 10:02:09 2018 ] 	Mean training loss: 0.0109.
[ Wed Apr 25 10:02:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:02:09 2018 ] Training epoch: 634
[ Wed Apr 25 10:02:13 2018 ] 	Batch(0/1) done. Loss: 0.0172  lr:0.100000
[ Wed Apr 25 10:02:13 2018 ] 	Mean training loss: 0.0172.
[ Wed Apr 25 10:02:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:13 2018 ] Training epoch: 635
[ Wed Apr 25 10:02:17 2018 ] 	Batch(0/1) done. Loss: 0.0056  lr:0.100000
[ Wed Apr 25 10:02:17 2018 ] 	Mean training loss: 0.0056.
[ Wed Apr 25 10:02:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:17 2018 ] Eval epoch: 635
[ Wed Apr 25 10:02:19 2018 ] 	Mean test loss of 1 batches: 0.28622353076934814.
[ Wed Apr 25 10:02:19 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:02:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:02:19 2018 ] Training epoch: 636
[ Wed Apr 25 10:02:23 2018 ] 	Batch(0/1) done. Loss: 0.0109  lr:0.100000
[ Wed Apr 25 10:02:23 2018 ] 	Mean training loss: 0.0109.
[ Wed Apr 25 10:02:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:23 2018 ] Training epoch: 637
[ Wed Apr 25 10:02:27 2018 ] 	Batch(0/1) done. Loss: 0.0234  lr:0.100000
[ Wed Apr 25 10:02:27 2018 ] 	Mean training loss: 0.0234.
[ Wed Apr 25 10:02:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:27 2018 ] Training epoch: 638
[ Wed Apr 25 10:02:31 2018 ] 	Batch(0/1) done. Loss: 0.0100  lr:0.100000
[ Wed Apr 25 10:02:31 2018 ] 	Mean training loss: 0.0100.
[ Wed Apr 25 10:02:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:02:31 2018 ] Training epoch: 639
[ Wed Apr 25 10:02:35 2018 ] 	Batch(0/1) done. Loss: 0.0326  lr:0.100000
[ Wed Apr 25 10:02:35 2018 ] 	Mean training loss: 0.0326.
[ Wed Apr 25 10:02:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:35 2018 ] Training epoch: 640
[ Wed Apr 25 10:02:39 2018 ] 	Batch(0/1) done. Loss: 0.0222  lr:0.100000
[ Wed Apr 25 10:02:39 2018 ] 	Mean training loss: 0.0222.
[ Wed Apr 25 10:02:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:39 2018 ] Eval epoch: 640
[ Wed Apr 25 10:02:42 2018 ] 	Mean test loss of 1 batches: 0.21086692810058594.
[ Wed Apr 25 10:02:42 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:02:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:02:42 2018 ] Training epoch: 641
[ Wed Apr 25 10:02:46 2018 ] 	Batch(0/1) done. Loss: 0.0061  lr:0.100000
[ Wed Apr 25 10:02:46 2018 ] 	Mean training loss: 0.0061.
[ Wed Apr 25 10:02:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:46 2018 ] Training epoch: 642
[ Wed Apr 25 10:02:50 2018 ] 	Batch(0/1) done. Loss: 0.0221  lr:0.100000
[ Wed Apr 25 10:02:50 2018 ] 	Mean training loss: 0.0221.
[ Wed Apr 25 10:02:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:02:50 2018 ] Training epoch: 643
[ Wed Apr 25 10:02:54 2018 ] 	Batch(0/1) done. Loss: 0.0419  lr:0.100000
[ Wed Apr 25 10:02:54 2018 ] 	Mean training loss: 0.0419.
[ Wed Apr 25 10:02:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:02:54 2018 ] Training epoch: 644
[ Wed Apr 25 10:02:58 2018 ] 	Batch(0/1) done. Loss: 0.0089  lr:0.100000
[ Wed Apr 25 10:02:58 2018 ] 	Mean training loss: 0.0089.
[ Wed Apr 25 10:02:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:02:58 2018 ] Training epoch: 645
[ Wed Apr 25 10:03:02 2018 ] 	Batch(0/1) done. Loss: 0.0073  lr:0.100000
[ Wed Apr 25 10:03:02 2018 ] 	Mean training loss: 0.0073.
[ Wed Apr 25 10:03:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:02 2018 ] Eval epoch: 645
[ Wed Apr 25 10:03:04 2018 ] 	Mean test loss of 1 batches: 0.3015042543411255.
[ Wed Apr 25 10:03:04 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:03:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:03:04 2018 ] Training epoch: 646
[ Wed Apr 25 10:03:08 2018 ] 	Batch(0/1) done. Loss: 0.0307  lr:0.100000
[ Wed Apr 25 10:03:08 2018 ] 	Mean training loss: 0.0307.
[ Wed Apr 25 10:03:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:08 2018 ] Training epoch: 647
[ Wed Apr 25 10:03:12 2018 ] 	Batch(0/1) done. Loss: 0.0125  lr:0.100000
[ Wed Apr 25 10:03:12 2018 ] 	Mean training loss: 0.0125.
[ Wed Apr 25 10:03:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:12 2018 ] Training epoch: 648
[ Wed Apr 25 10:03:16 2018 ] 	Batch(0/1) done. Loss: 0.0096  lr:0.100000
[ Wed Apr 25 10:03:16 2018 ] 	Mean training loss: 0.0096.
[ Wed Apr 25 10:03:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:16 2018 ] Training epoch: 649
[ Wed Apr 25 10:03:20 2018 ] 	Batch(0/1) done. Loss: 0.0123  lr:0.100000
[ Wed Apr 25 10:03:20 2018 ] 	Mean training loss: 0.0123.
[ Wed Apr 25 10:03:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:03:20 2018 ] Training epoch: 650
[ Wed Apr 25 10:03:24 2018 ] 	Batch(0/1) done. Loss: 0.0145  lr:0.100000
[ Wed Apr 25 10:03:24 2018 ] 	Mean training loss: 0.0145.
[ Wed Apr 25 10:03:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:03:24 2018 ] Eval epoch: 650
[ Wed Apr 25 10:03:27 2018 ] 	Mean test loss of 1 batches: 0.6024336814880371.
[ Wed Apr 25 10:03:27 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:03:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:03:27 2018 ] Training epoch: 651
[ Wed Apr 25 10:03:31 2018 ] 	Batch(0/1) done. Loss: 0.0153  lr:0.100000
[ Wed Apr 25 10:03:31 2018 ] 	Mean training loss: 0.0153.
[ Wed Apr 25 10:03:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:31 2018 ] Training epoch: 652
[ Wed Apr 25 10:03:35 2018 ] 	Batch(0/1) done. Loss: 0.0122  lr:0.100000
[ Wed Apr 25 10:03:35 2018 ] 	Mean training loss: 0.0122.
[ Wed Apr 25 10:03:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:35 2018 ] Training epoch: 653
[ Wed Apr 25 10:03:39 2018 ] 	Batch(0/1) done. Loss: 0.1003  lr:0.100000
[ Wed Apr 25 10:03:39 2018 ] 	Mean training loss: 0.1003.
[ Wed Apr 25 10:03:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:03:39 2018 ] Training epoch: 654
[ Wed Apr 25 10:03:43 2018 ] 	Batch(0/1) done. Loss: 0.0105  lr:0.100000
[ Wed Apr 25 10:03:43 2018 ] 	Mean training loss: 0.0105.
[ Wed Apr 25 10:03:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:03:43 2018 ] Training epoch: 655
[ Wed Apr 25 10:03:47 2018 ] 	Batch(0/1) done. Loss: 0.0050  lr:0.100000
[ Wed Apr 25 10:03:47 2018 ] 	Mean training loss: 0.0050.
[ Wed Apr 25 10:03:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:47 2018 ] Eval epoch: 655
[ Wed Apr 25 10:03:50 2018 ] 	Mean test loss of 1 batches: 0.322029709815979.
[ Wed Apr 25 10:03:50 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:03:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:03:50 2018 ] Training epoch: 656
[ Wed Apr 25 10:03:54 2018 ] 	Batch(0/1) done. Loss: 0.0184  lr:0.100000
[ Wed Apr 25 10:03:54 2018 ] 	Mean training loss: 0.0184.
[ Wed Apr 25 10:03:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:03:54 2018 ] Training epoch: 657
[ Wed Apr 25 10:03:58 2018 ] 	Batch(0/1) done. Loss: 0.0117  lr:0.100000
[ Wed Apr 25 10:03:58 2018 ] 	Mean training loss: 0.0117.
[ Wed Apr 25 10:03:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:03:58 2018 ] Training epoch: 658
[ Wed Apr 25 10:04:02 2018 ] 	Batch(0/1) done. Loss: 0.0090  lr:0.100000
[ Wed Apr 25 10:04:02 2018 ] 	Mean training loss: 0.0090.
[ Wed Apr 25 10:04:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:04:02 2018 ] Training epoch: 659
[ Wed Apr 25 10:04:06 2018 ] 	Batch(0/1) done. Loss: 0.0176  lr:0.100000
[ Wed Apr 25 10:04:06 2018 ] 	Mean training loss: 0.0176.
[ Wed Apr 25 10:04:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:04:06 2018 ] Training epoch: 660
[ Wed Apr 25 10:04:10 2018 ] 	Batch(0/1) done. Loss: 0.0245  lr:0.100000
[ Wed Apr 25 10:04:10 2018 ] 	Mean training loss: 0.0245.
[ Wed Apr 25 10:04:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:10 2018 ] Eval epoch: 660
[ Wed Apr 25 10:04:13 2018 ] 	Mean test loss of 1 batches: 0.2751750648021698.
[ Wed Apr 25 10:04:13 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:04:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:04:13 2018 ] Training epoch: 661
[ Wed Apr 25 10:04:16 2018 ] 	Batch(0/1) done. Loss: 0.0217  lr:0.100000
[ Wed Apr 25 10:04:16 2018 ] 	Mean training loss: 0.0217.
[ Wed Apr 25 10:04:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:16 2018 ] Training epoch: 662
[ Wed Apr 25 10:04:20 2018 ] 	Batch(0/1) done. Loss: 0.0098  lr:0.100000
[ Wed Apr 25 10:04:20 2018 ] 	Mean training loss: 0.0098.
[ Wed Apr 25 10:04:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:20 2018 ] Training epoch: 663
[ Wed Apr 25 10:04:24 2018 ] 	Batch(0/1) done. Loss: 0.0402  lr:0.100000
[ Wed Apr 25 10:04:24 2018 ] 	Mean training loss: 0.0402.
[ Wed Apr 25 10:04:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:24 2018 ] Training epoch: 664
[ Wed Apr 25 10:04:28 2018 ] 	Batch(0/1) done. Loss: 0.0319  lr:0.100000
[ Wed Apr 25 10:04:28 2018 ] 	Mean training loss: 0.0319.
[ Wed Apr 25 10:04:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:28 2018 ] Training epoch: 665
[ Wed Apr 25 10:04:32 2018 ] 	Batch(0/1) done. Loss: 0.0207  lr:0.100000
[ Wed Apr 25 10:04:32 2018 ] 	Mean training loss: 0.0207.
[ Wed Apr 25 10:04:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:04:32 2018 ] Eval epoch: 665
[ Wed Apr 25 10:04:35 2018 ] 	Mean test loss of 1 batches: 0.4287168085575104.
[ Wed Apr 25 10:04:35 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:04:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:04:35 2018 ] Training epoch: 666
[ Wed Apr 25 10:04:39 2018 ] 	Batch(0/1) done. Loss: 0.0345  lr:0.100000
[ Wed Apr 25 10:04:39 2018 ] 	Mean training loss: 0.0345.
[ Wed Apr 25 10:04:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:39 2018 ] Training epoch: 667
[ Wed Apr 25 10:04:43 2018 ] 	Batch(0/1) done. Loss: 0.0076  lr:0.100000
[ Wed Apr 25 10:04:43 2018 ] 	Mean training loss: 0.0076.
[ Wed Apr 25 10:04:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:04:43 2018 ] Training epoch: 668
[ Wed Apr 25 10:04:47 2018 ] 	Batch(0/1) done. Loss: 0.0443  lr:0.100000
[ Wed Apr 25 10:04:47 2018 ] 	Mean training loss: 0.0443.
[ Wed Apr 25 10:04:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:47 2018 ] Training epoch: 669
[ Wed Apr 25 10:04:51 2018 ] 	Batch(0/1) done. Loss: 0.1095  lr:0.100000
[ Wed Apr 25 10:04:51 2018 ] 	Mean training loss: 0.1095.
[ Wed Apr 25 10:04:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:51 2018 ] Training epoch: 670
[ Wed Apr 25 10:04:55 2018 ] 	Batch(0/1) done. Loss: 0.0352  lr:0.100000
[ Wed Apr 25 10:04:55 2018 ] 	Mean training loss: 0.0352.
[ Wed Apr 25 10:04:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:04:55 2018 ] Eval epoch: 670
[ Wed Apr 25 10:04:58 2018 ] 	Mean test loss of 1 batches: 0.1882183849811554.
[ Wed Apr 25 10:04:58 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:04:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:04:58 2018 ] Training epoch: 671
[ Wed Apr 25 10:05:02 2018 ] 	Batch(0/1) done. Loss: 0.0171  lr:0.100000
[ Wed Apr 25 10:05:02 2018 ] 	Mean training loss: 0.0171.
[ Wed Apr 25 10:05:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:05:02 2018 ] Training epoch: 672
[ Wed Apr 25 10:05:06 2018 ] 	Batch(0/1) done. Loss: 0.0052  lr:0.100000
[ Wed Apr 25 10:05:06 2018 ] 	Mean training loss: 0.0052.
[ Wed Apr 25 10:05:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:05:06 2018 ] Training epoch: 673
[ Wed Apr 25 10:05:10 2018 ] 	Batch(0/1) done. Loss: 0.0298  lr:0.100000
[ Wed Apr 25 10:05:10 2018 ] 	Mean training loss: 0.0298.
[ Wed Apr 25 10:05:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:10 2018 ] Training epoch: 674
[ Wed Apr 25 10:05:14 2018 ] 	Batch(0/1) done. Loss: 0.0063  lr:0.100000
[ Wed Apr 25 10:05:14 2018 ] 	Mean training loss: 0.0063.
[ Wed Apr 25 10:05:14 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:05:14 2018 ] Training epoch: 675
[ Wed Apr 25 10:05:18 2018 ] 	Batch(0/1) done. Loss: 0.0080  lr:0.100000
[ Wed Apr 25 10:05:18 2018 ] 	Mean training loss: 0.0080.
[ Wed Apr 25 10:05:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:18 2018 ] Eval epoch: 675
[ Wed Apr 25 10:05:20 2018 ] 	Mean test loss of 1 batches: 0.5978909134864807.
[ Wed Apr 25 10:05:20 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:05:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:05:20 2018 ] Training epoch: 676
[ Wed Apr 25 10:05:24 2018 ] 	Batch(0/1) done. Loss: 0.0831  lr:0.100000
[ Wed Apr 25 10:05:24 2018 ] 	Mean training loss: 0.0831.
[ Wed Apr 25 10:05:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:24 2018 ] Training epoch: 677
[ Wed Apr 25 10:05:28 2018 ] 	Batch(0/1) done. Loss: 0.0162  lr:0.100000
[ Wed Apr 25 10:05:28 2018 ] 	Mean training loss: 0.0162.
[ Wed Apr 25 10:05:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:28 2018 ] Training epoch: 678
[ Wed Apr 25 10:05:32 2018 ] 	Batch(0/1) done. Loss: 0.0178  lr:0.100000
[ Wed Apr 25 10:05:32 2018 ] 	Mean training loss: 0.0178.
[ Wed Apr 25 10:05:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:32 2018 ] Training epoch: 679
[ Wed Apr 25 10:05:36 2018 ] 	Batch(0/1) done. Loss: 0.0401  lr:0.100000
[ Wed Apr 25 10:05:36 2018 ] 	Mean training loss: 0.0401.
[ Wed Apr 25 10:05:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:36 2018 ] Training epoch: 680
[ Wed Apr 25 10:05:40 2018 ] 	Batch(0/1) done. Loss: 0.0089  lr:0.100000
[ Wed Apr 25 10:05:40 2018 ] 	Mean training loss: 0.0089.
[ Wed Apr 25 10:05:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:40 2018 ] Eval epoch: 680
[ Wed Apr 25 10:05:43 2018 ] 	Mean test loss of 1 batches: 0.3925764262676239.
[ Wed Apr 25 10:05:43 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:05:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:05:43 2018 ] Training epoch: 681
[ Wed Apr 25 10:05:46 2018 ] 	Batch(0/1) done. Loss: 0.0118  lr:0.100000
[ Wed Apr 25 10:05:46 2018 ] 	Mean training loss: 0.0118.
[ Wed Apr 25 10:05:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:47 2018 ] Training epoch: 682
[ Wed Apr 25 10:05:50 2018 ] 	Batch(0/1) done. Loss: 0.0051  lr:0.100000
[ Wed Apr 25 10:05:50 2018 ] 	Mean training loss: 0.0051.
[ Wed Apr 25 10:05:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:50 2018 ] Training epoch: 683
[ Wed Apr 25 10:05:54 2018 ] 	Batch(0/1) done. Loss: 0.0424  lr:0.100000
[ Wed Apr 25 10:05:54 2018 ] 	Mean training loss: 0.0424.
[ Wed Apr 25 10:05:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:54 2018 ] Training epoch: 684
[ Wed Apr 25 10:05:58 2018 ] 	Batch(0/1) done. Loss: 0.0523  lr:0.100000
[ Wed Apr 25 10:05:58 2018 ] 	Mean training loss: 0.0523.
[ Wed Apr 25 10:05:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:05:58 2018 ] Training epoch: 685
[ Wed Apr 25 10:06:02 2018 ] 	Batch(0/1) done. Loss: 0.0259  lr:0.100000
[ Wed Apr 25 10:06:02 2018 ] 	Mean training loss: 0.0259.
[ Wed Apr 25 10:06:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:06:02 2018 ] Eval epoch: 685
[ Wed Apr 25 10:06:05 2018 ] 	Mean test loss of 1 batches: 0.3209126889705658.
[ Wed Apr 25 10:06:05 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:06:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:06:05 2018 ] Training epoch: 686
[ Wed Apr 25 10:06:09 2018 ] 	Batch(0/1) done. Loss: 0.0123  lr:0.100000
[ Wed Apr 25 10:06:09 2018 ] 	Mean training loss: 0.0123.
[ Wed Apr 25 10:06:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:09 2018 ] Training epoch: 687
[ Wed Apr 25 10:06:13 2018 ] 	Batch(0/1) done. Loss: 0.0100  lr:0.100000
[ Wed Apr 25 10:06:13 2018 ] 	Mean training loss: 0.0100.
[ Wed Apr 25 10:06:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:13 2018 ] Training epoch: 688
[ Wed Apr 25 10:06:17 2018 ] 	Batch(0/1) done. Loss: 0.0112  lr:0.100000
[ Wed Apr 25 10:06:17 2018 ] 	Mean training loss: 0.0112.
[ Wed Apr 25 10:06:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:17 2018 ] Training epoch: 689
[ Wed Apr 25 10:06:21 2018 ] 	Batch(0/1) done. Loss: 0.0054  lr:0.100000
[ Wed Apr 25 10:06:21 2018 ] 	Mean training loss: 0.0054.
[ Wed Apr 25 10:06:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:21 2018 ] Training epoch: 690
[ Wed Apr 25 10:06:25 2018 ] 	Batch(0/1) done. Loss: 0.0092  lr:0.100000
[ Wed Apr 25 10:06:25 2018 ] 	Mean training loss: 0.0092.
[ Wed Apr 25 10:06:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:25 2018 ] Eval epoch: 690
[ Wed Apr 25 10:06:28 2018 ] 	Mean test loss of 1 batches: 0.40720707178115845.
[ Wed Apr 25 10:06:28 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:06:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:06:28 2018 ] Training epoch: 691
[ Wed Apr 25 10:06:31 2018 ] 	Batch(0/1) done. Loss: 0.0635  lr:0.100000
[ Wed Apr 25 10:06:31 2018 ] 	Mean training loss: 0.0635.
[ Wed Apr 25 10:06:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:31 2018 ] Training epoch: 692
[ Wed Apr 25 10:06:35 2018 ] 	Batch(0/1) done. Loss: 0.0081  lr:0.100000
[ Wed Apr 25 10:06:35 2018 ] 	Mean training loss: 0.0081.
[ Wed Apr 25 10:06:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:35 2018 ] Training epoch: 693
[ Wed Apr 25 10:06:39 2018 ] 	Batch(0/1) done. Loss: 0.0146  lr:0.100000
[ Wed Apr 25 10:06:39 2018 ] 	Mean training loss: 0.0146.
[ Wed Apr 25 10:06:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:06:39 2018 ] Training epoch: 694
[ Wed Apr 25 10:06:44 2018 ] 	Batch(0/1) done. Loss: 0.0067  lr:0.100000
[ Wed Apr 25 10:06:44 2018 ] 	Mean training loss: 0.0067.
[ Wed Apr 25 10:06:44 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:06:44 2018 ] Training epoch: 695
[ Wed Apr 25 10:06:48 2018 ] 	Batch(0/1) done. Loss: 0.0445  lr:0.100000
[ Wed Apr 25 10:06:48 2018 ] 	Mean training loss: 0.0445.
[ Wed Apr 25 10:06:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:06:48 2018 ] Eval epoch: 695
[ Wed Apr 25 10:06:50 2018 ] 	Mean test loss of 1 batches: 0.4858606159687042.
[ Wed Apr 25 10:06:50 2018 ] 	Top1: 77.78%
[ Wed Apr 25 10:06:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:06:50 2018 ] Training epoch: 696
[ Wed Apr 25 10:06:54 2018 ] 	Batch(0/1) done. Loss: 0.0290  lr:0.100000
[ Wed Apr 25 10:06:54 2018 ] 	Mean training loss: 0.0290.
[ Wed Apr 25 10:06:54 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:06:54 2018 ] Training epoch: 697
[ Wed Apr 25 10:06:59 2018 ] 	Batch(0/1) done. Loss: 0.0263  lr:0.100000
[ Wed Apr 25 10:06:59 2018 ] 	Mean training loss: 0.0263.
[ Wed Apr 25 10:06:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:06:59 2018 ] Training epoch: 698
[ Wed Apr 25 10:07:02 2018 ] 	Batch(0/1) done. Loss: 0.0111  lr:0.100000
[ Wed Apr 25 10:07:02 2018 ] 	Mean training loss: 0.0111.
[ Wed Apr 25 10:07:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:02 2018 ] Training epoch: 699
[ Wed Apr 25 10:07:07 2018 ] 	Batch(0/1) done. Loss: 0.0085  lr:0.100000
[ Wed Apr 25 10:07:07 2018 ] 	Mean training loss: 0.0085.
[ Wed Apr 25 10:07:07 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:07:07 2018 ] Training epoch: 700
[ Wed Apr 25 10:07:11 2018 ] 	Batch(0/1) done. Loss: 0.0050  lr:0.100000
[ Wed Apr 25 10:07:11 2018 ] 	Mean training loss: 0.0050.
[ Wed Apr 25 10:07:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:11 2018 ] Eval epoch: 700
[ Wed Apr 25 10:07:14 2018 ] 	Mean test loss of 1 batches: 0.38599810004234314.
[ Wed Apr 25 10:07:14 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:07:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:07:14 2018 ] Training epoch: 701
[ Wed Apr 25 10:07:18 2018 ] 	Batch(0/1) done. Loss: 0.0123  lr:0.100000
[ Wed Apr 25 10:07:18 2018 ] 	Mean training loss: 0.0123.
[ Wed Apr 25 10:07:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:18 2018 ] Training epoch: 702
[ Wed Apr 25 10:07:21 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:07:21 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:07:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:07:21 2018 ] Training epoch: 703
[ Wed Apr 25 10:07:25 2018 ] 	Batch(0/1) done. Loss: 0.0030  lr:0.100000
[ Wed Apr 25 10:07:25 2018 ] 	Mean training loss: 0.0030.
[ Wed Apr 25 10:07:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:25 2018 ] Training epoch: 704
[ Wed Apr 25 10:07:29 2018 ] 	Batch(0/1) done. Loss: 0.0109  lr:0.100000
[ Wed Apr 25 10:07:29 2018 ] 	Mean training loss: 0.0109.
[ Wed Apr 25 10:07:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:29 2018 ] Training epoch: 705
[ Wed Apr 25 10:07:33 2018 ] 	Batch(0/1) done. Loss: 0.0098  lr:0.100000
[ Wed Apr 25 10:07:33 2018 ] 	Mean training loss: 0.0098.
[ Wed Apr 25 10:07:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:33 2018 ] Eval epoch: 705
[ Wed Apr 25 10:07:36 2018 ] 	Mean test loss of 1 batches: 0.3185238242149353.
[ Wed Apr 25 10:07:36 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:07:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:07:36 2018 ] Training epoch: 706
[ Wed Apr 25 10:07:40 2018 ] 	Batch(0/1) done. Loss: 0.0246  lr:0.100000
[ Wed Apr 25 10:07:40 2018 ] 	Mean training loss: 0.0246.
[ Wed Apr 25 10:07:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:40 2018 ] Training epoch: 707
[ Wed Apr 25 10:07:44 2018 ] 	Batch(0/1) done. Loss: 0.0080  lr:0.100000
[ Wed Apr 25 10:07:44 2018 ] 	Mean training loss: 0.0080.
[ Wed Apr 25 10:07:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:07:44 2018 ] Training epoch: 708
[ Wed Apr 25 10:07:48 2018 ] 	Batch(0/1) done. Loss: 0.0074  lr:0.100000
[ Wed Apr 25 10:07:48 2018 ] 	Mean training loss: 0.0074.
[ Wed Apr 25 10:07:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:07:48 2018 ] Training epoch: 709
[ Wed Apr 25 10:07:52 2018 ] 	Batch(0/1) done. Loss: 0.0278  lr:0.100000
[ Wed Apr 25 10:07:52 2018 ] 	Mean training loss: 0.0278.
[ Wed Apr 25 10:07:52 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:07:52 2018 ] Training epoch: 710
[ Wed Apr 25 10:07:56 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:07:56 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:07:56 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:07:56 2018 ] Eval epoch: 710
[ Wed Apr 25 10:07:59 2018 ] 	Mean test loss of 1 batches: 0.26347705721855164.
[ Wed Apr 25 10:07:59 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:07:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:07:59 2018 ] Training epoch: 711
[ Wed Apr 25 10:08:03 2018 ] 	Batch(0/1) done. Loss: 0.0108  lr:0.100000
[ Wed Apr 25 10:08:03 2018 ] 	Mean training loss: 0.0108.
[ Wed Apr 25 10:08:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:08:03 2018 ] Training epoch: 712
[ Wed Apr 25 10:08:07 2018 ] 	Batch(0/1) done. Loss: 0.0133  lr:0.100000
[ Wed Apr 25 10:08:07 2018 ] 	Mean training loss: 0.0133.
[ Wed Apr 25 10:08:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:08:07 2018 ] Training epoch: 713
[ Wed Apr 25 10:08:11 2018 ] 	Batch(0/1) done. Loss: 0.0050  lr:0.100000
[ Wed Apr 25 10:08:11 2018 ] 	Mean training loss: 0.0050.
[ Wed Apr 25 10:08:11 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:08:11 2018 ] Training epoch: 714
[ Wed Apr 25 10:08:15 2018 ] 	Batch(0/1) done. Loss: 0.0034  lr:0.100000
[ Wed Apr 25 10:08:15 2018 ] 	Mean training loss: 0.0034.
[ Wed Apr 25 10:08:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:08:15 2018 ] Training epoch: 715
[ Wed Apr 25 10:08:19 2018 ] 	Batch(0/1) done. Loss: 0.0055  lr:0.100000
[ Wed Apr 25 10:08:19 2018 ] 	Mean training loss: 0.0055.
[ Wed Apr 25 10:08:19 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:08:19 2018 ] Eval epoch: 715
[ Wed Apr 25 10:08:21 2018 ] 	Mean test loss of 1 batches: 0.5004768371582031.
[ Wed Apr 25 10:08:21 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:08:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:08:21 2018 ] Training epoch: 716
[ Wed Apr 25 10:08:25 2018 ] 	Batch(0/1) done. Loss: 0.0181  lr:0.100000
[ Wed Apr 25 10:08:25 2018 ] 	Mean training loss: 0.0181.
[ Wed Apr 25 10:08:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:08:25 2018 ] Training epoch: 717
[ Wed Apr 25 10:08:30 2018 ] 	Batch(0/1) done. Loss: 0.0101  lr:0.100000
[ Wed Apr 25 10:08:30 2018 ] 	Mean training loss: 0.0101.
[ Wed Apr 25 10:08:30 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:08:30 2018 ] Training epoch: 718
[ Wed Apr 25 10:08:34 2018 ] 	Batch(0/1) done. Loss: 0.0070  lr:0.100000
[ Wed Apr 25 10:08:34 2018 ] 	Mean training loss: 0.0070.
[ Wed Apr 25 10:08:34 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:08:34 2018 ] Training epoch: 719
[ Wed Apr 25 10:08:38 2018 ] 	Batch(0/1) done. Loss: 0.0044  lr:0.100000
[ Wed Apr 25 10:08:38 2018 ] 	Mean training loss: 0.0044.
[ Wed Apr 25 10:08:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:08:38 2018 ] Training epoch: 720
[ Wed Apr 25 10:08:42 2018 ] 	Batch(0/1) done. Loss: 0.0219  lr:0.100000
[ Wed Apr 25 10:08:42 2018 ] 	Mean training loss: 0.0219.
[ Wed Apr 25 10:08:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:08:42 2018 ] Eval epoch: 720
[ Wed Apr 25 10:08:45 2018 ] 	Mean test loss of 1 batches: 0.18281549215316772.
[ Wed Apr 25 10:08:45 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:08:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:08:45 2018 ] Training epoch: 721
[ Wed Apr 25 10:08:48 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:08:48 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:08:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:08:48 2018 ] Training epoch: 722
[ Wed Apr 25 10:08:52 2018 ] 	Batch(0/1) done. Loss: 0.0600  lr:0.100000
[ Wed Apr 25 10:08:52 2018 ] 	Mean training loss: 0.0600.
[ Wed Apr 25 10:08:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:08:52 2018 ] Training epoch: 723
[ Wed Apr 25 10:08:56 2018 ] 	Batch(0/1) done. Loss: 0.0105  lr:0.100000
[ Wed Apr 25 10:08:56 2018 ] 	Mean training loss: 0.0105.
[ Wed Apr 25 10:08:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:08:56 2018 ] Training epoch: 724
[ Wed Apr 25 10:09:00 2018 ] 	Batch(0/1) done. Loss: 0.0222  lr:0.100000
[ Wed Apr 25 10:09:00 2018 ] 	Mean training loss: 0.0222.
[ Wed Apr 25 10:09:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:00 2018 ] Training epoch: 725
[ Wed Apr 25 10:09:05 2018 ] 	Batch(0/1) done. Loss: 0.0549  lr:0.100000
[ Wed Apr 25 10:09:05 2018 ] 	Mean training loss: 0.0549.
[ Wed Apr 25 10:09:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:09:05 2018 ] Eval epoch: 725
[ Wed Apr 25 10:09:07 2018 ] 	Mean test loss of 1 batches: 0.17065413296222687.
[ Wed Apr 25 10:09:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:09:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:09:07 2018 ] Training epoch: 726
[ Wed Apr 25 10:09:11 2018 ] 	Batch(0/1) done. Loss: 0.0056  lr:0.100000
[ Wed Apr 25 10:09:11 2018 ] 	Mean training loss: 0.0056.
[ Wed Apr 25 10:09:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:09:11 2018 ] Training epoch: 727
[ Wed Apr 25 10:09:15 2018 ] 	Batch(0/1) done. Loss: 0.0114  lr:0.100000
[ Wed Apr 25 10:09:15 2018 ] 	Mean training loss: 0.0114.
[ Wed Apr 25 10:09:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:15 2018 ] Training epoch: 728
[ Wed Apr 25 10:09:19 2018 ] 	Batch(0/1) done. Loss: 0.0246  lr:0.100000
[ Wed Apr 25 10:09:19 2018 ] 	Mean training loss: 0.0246.
[ Wed Apr 25 10:09:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:19 2018 ] Training epoch: 729
[ Wed Apr 25 10:09:23 2018 ] 	Batch(0/1) done. Loss: 0.0241  lr:0.100000
[ Wed Apr 25 10:09:23 2018 ] 	Mean training loss: 0.0241.
[ Wed Apr 25 10:09:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:23 2018 ] Training epoch: 730
[ Wed Apr 25 10:09:27 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:09:27 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:09:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:27 2018 ] Eval epoch: 730
[ Wed Apr 25 10:09:30 2018 ] 	Mean test loss of 1 batches: 0.3052748143672943.
[ Wed Apr 25 10:09:30 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:09:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:09:30 2018 ] Training epoch: 731
[ Wed Apr 25 10:09:34 2018 ] 	Batch(0/1) done. Loss: 0.0135  lr:0.100000
[ Wed Apr 25 10:09:34 2018 ] 	Mean training loss: 0.0135.
[ Wed Apr 25 10:09:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:34 2018 ] Training epoch: 732
[ Wed Apr 25 10:09:38 2018 ] 	Batch(0/1) done. Loss: 0.0313  lr:0.100000
[ Wed Apr 25 10:09:38 2018 ] 	Mean training loss: 0.0313.
[ Wed Apr 25 10:09:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:09:38 2018 ] Training epoch: 733
[ Wed Apr 25 10:09:42 2018 ] 	Batch(0/1) done. Loss: 0.0063  lr:0.100000
[ Wed Apr 25 10:09:42 2018 ] 	Mean training loss: 0.0063.
[ Wed Apr 25 10:09:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:09:42 2018 ] Training epoch: 734
[ Wed Apr 25 10:09:46 2018 ] 	Batch(0/1) done. Loss: 0.0209  lr:0.100000
[ Wed Apr 25 10:09:46 2018 ] 	Mean training loss: 0.0209.
[ Wed Apr 25 10:09:46 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:09:46 2018 ] Training epoch: 735
[ Wed Apr 25 10:09:50 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:09:50 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:09:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:09:50 2018 ] Eval epoch: 735
[ Wed Apr 25 10:09:53 2018 ] 	Mean test loss of 1 batches: 0.18051744997501373.
[ Wed Apr 25 10:09:53 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:09:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:09:53 2018 ] Training epoch: 736
[ Wed Apr 25 10:09:57 2018 ] 	Batch(0/1) done. Loss: 0.0082  lr:0.100000
[ Wed Apr 25 10:09:57 2018 ] 	Mean training loss: 0.0082.
[ Wed Apr 25 10:09:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:09:57 2018 ] Training epoch: 737
[ Wed Apr 25 10:10:01 2018 ] 	Batch(0/1) done. Loss: 0.0052  lr:0.100000
[ Wed Apr 25 10:10:01 2018 ] 	Mean training loss: 0.0052.
[ Wed Apr 25 10:10:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:10:01 2018 ] Training epoch: 738
[ Wed Apr 25 10:10:05 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:10:05 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:10:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:10:05 2018 ] Training epoch: 739
[ Wed Apr 25 10:10:09 2018 ] 	Batch(0/1) done. Loss: 0.0090  lr:0.100000
[ Wed Apr 25 10:10:09 2018 ] 	Mean training loss: 0.0090.
[ Wed Apr 25 10:10:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:10:09 2018 ] Training epoch: 740
[ Wed Apr 25 10:10:14 2018 ] 	Batch(0/1) done. Loss: 0.0066  lr:0.100000
[ Wed Apr 25 10:10:14 2018 ] 	Mean training loss: 0.0066.
[ Wed Apr 25 10:10:14 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:10:14 2018 ] Eval epoch: 740
[ Wed Apr 25 10:10:16 2018 ] 	Mean test loss of 1 batches: 0.21877889335155487.
[ Wed Apr 25 10:10:16 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:10:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:10:16 2018 ] Training epoch: 741
[ Wed Apr 25 10:10:20 2018 ] 	Batch(0/1) done. Loss: 0.0041  lr:0.100000
[ Wed Apr 25 10:10:20 2018 ] 	Mean training loss: 0.0041.
[ Wed Apr 25 10:10:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:10:20 2018 ] Training epoch: 742
[ Wed Apr 25 10:10:24 2018 ] 	Batch(0/1) done. Loss: 0.0070  lr:0.100000
[ Wed Apr 25 10:10:24 2018 ] 	Mean training loss: 0.0070.
[ Wed Apr 25 10:10:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:10:24 2018 ] Training epoch: 743
[ Wed Apr 25 10:10:28 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:10:28 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:10:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:10:28 2018 ] Training epoch: 744
[ Wed Apr 25 10:10:32 2018 ] 	Batch(0/1) done. Loss: 0.0094  lr:0.100000
[ Wed Apr 25 10:10:32 2018 ] 	Mean training loss: 0.0094.
[ Wed Apr 25 10:10:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:10:32 2018 ] Training epoch: 745
[ Wed Apr 25 10:10:37 2018 ] 	Batch(0/1) done. Loss: 0.0048  lr:0.100000
[ Wed Apr 25 10:10:37 2018 ] 	Mean training loss: 0.0048.
[ Wed Apr 25 10:10:37 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 10:10:37 2018 ] Eval epoch: 745
[ Wed Apr 25 10:10:40 2018 ] 	Mean test loss of 1 batches: 0.363155335187912.
[ Wed Apr 25 10:10:40 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:10:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:10:40 2018 ] Training epoch: 746
[ Wed Apr 25 10:10:44 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:10:44 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:10:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:10:44 2018 ] Training epoch: 747
[ Wed Apr 25 10:10:47 2018 ] 	Batch(0/1) done. Loss: 0.0056  lr:0.100000
[ Wed Apr 25 10:10:47 2018 ] 	Mean training loss: 0.0056.
[ Wed Apr 25 10:10:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:10:47 2018 ] Training epoch: 748
[ Wed Apr 25 10:10:51 2018 ] 	Batch(0/1) done. Loss: 0.0321  lr:0.100000
[ Wed Apr 25 10:10:51 2018 ] 	Mean training loss: 0.0321.
[ Wed Apr 25 10:10:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:10:51 2018 ] Training epoch: 749
[ Wed Apr 25 10:10:56 2018 ] 	Batch(0/1) done. Loss: 0.0126  lr:0.100000
[ Wed Apr 25 10:10:56 2018 ] 	Mean training loss: 0.0126.
[ Wed Apr 25 10:10:56 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:10:56 2018 ] Training epoch: 750
[ Wed Apr 25 10:11:00 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:11:00 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:11:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:00 2018 ] Eval epoch: 750
[ Wed Apr 25 10:11:03 2018 ] 	Mean test loss of 1 batches: 0.3392046391963959.
[ Wed Apr 25 10:11:03 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:11:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:11:03 2018 ] Training epoch: 751
[ Wed Apr 25 10:11:07 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:11:07 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:11:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:11:07 2018 ] Training epoch: 752
[ Wed Apr 25 10:11:11 2018 ] 	Batch(0/1) done. Loss: 0.0079  lr:0.100000
[ Wed Apr 25 10:11:11 2018 ] 	Mean training loss: 0.0079.
[ Wed Apr 25 10:11:11 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:11:11 2018 ] Training epoch: 753
[ Wed Apr 25 10:11:15 2018 ] 	Batch(0/1) done. Loss: 0.0052  lr:0.100000
[ Wed Apr 25 10:11:15 2018 ] 	Mean training loss: 0.0052.
[ Wed Apr 25 10:11:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:15 2018 ] Training epoch: 754
[ Wed Apr 25 10:11:19 2018 ] 	Batch(0/1) done. Loss: 0.0155  lr:0.100000
[ Wed Apr 25 10:11:19 2018 ] 	Mean training loss: 0.0155.
[ Wed Apr 25 10:11:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:19 2018 ] Training epoch: 755
[ Wed Apr 25 10:11:23 2018 ] 	Batch(0/1) done. Loss: 0.0129  lr:0.100000
[ Wed Apr 25 10:11:23 2018 ] 	Mean training loss: 0.0129.
[ Wed Apr 25 10:11:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:23 2018 ] Eval epoch: 755
[ Wed Apr 25 10:11:26 2018 ] 	Mean test loss of 1 batches: 0.31303709745407104.
[ Wed Apr 25 10:11:26 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:11:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:11:26 2018 ] Training epoch: 756
[ Wed Apr 25 10:11:30 2018 ] 	Batch(0/1) done. Loss: 0.0029  lr:0.100000
[ Wed Apr 25 10:11:30 2018 ] 	Mean training loss: 0.0029.
[ Wed Apr 25 10:11:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:11:30 2018 ] Training epoch: 757
[ Wed Apr 25 10:11:34 2018 ] 	Batch(0/1) done. Loss: 0.0028  lr:0.100000
[ Wed Apr 25 10:11:34 2018 ] 	Mean training loss: 0.0028.
[ Wed Apr 25 10:11:34 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:11:34 2018 ] Training epoch: 758
[ Wed Apr 25 10:11:38 2018 ] 	Batch(0/1) done. Loss: 0.0167  lr:0.100000
[ Wed Apr 25 10:11:38 2018 ] 	Mean training loss: 0.0167.
[ Wed Apr 25 10:11:38 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:11:38 2018 ] Training epoch: 759
[ Wed Apr 25 10:11:42 2018 ] 	Batch(0/1) done. Loss: 0.0038  lr:0.100000
[ Wed Apr 25 10:11:42 2018 ] 	Mean training loss: 0.0038.
[ Wed Apr 25 10:11:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:11:42 2018 ] Training epoch: 760
[ Wed Apr 25 10:11:46 2018 ] 	Batch(0/1) done. Loss: 0.0280  lr:0.100000
[ Wed Apr 25 10:11:46 2018 ] 	Mean training loss: 0.0280.
[ Wed Apr 25 10:11:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:46 2018 ] Eval epoch: 760
[ Wed Apr 25 10:11:48 2018 ] 	Mean test loss of 1 batches: 0.336751252412796.
[ Wed Apr 25 10:11:48 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:11:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:11:48 2018 ] Training epoch: 761
[ Wed Apr 25 10:11:52 2018 ] 	Batch(0/1) done. Loss: 0.0202  lr:0.100000
[ Wed Apr 25 10:11:52 2018 ] 	Mean training loss: 0.0202.
[ Wed Apr 25 10:11:52 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 10:11:52 2018 ] Training epoch: 762
[ Wed Apr 25 10:11:56 2018 ] 	Batch(0/1) done. Loss: 0.0046  lr:0.100000
[ Wed Apr 25 10:11:56 2018 ] 	Mean training loss: 0.0046.
[ Wed Apr 25 10:11:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:11:56 2018 ] Training epoch: 763
[ Wed Apr 25 10:12:00 2018 ] 	Batch(0/1) done. Loss: 0.0059  lr:0.100000
[ Wed Apr 25 10:12:00 2018 ] 	Mean training loss: 0.0059.
[ Wed Apr 25 10:12:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:12:00 2018 ] Training epoch: 764
[ Wed Apr 25 10:12:04 2018 ] 	Batch(0/1) done. Loss: 0.0076  lr:0.100000
[ Wed Apr 25 10:12:04 2018 ] 	Mean training loss: 0.0076.
[ Wed Apr 25 10:12:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:12:04 2018 ] Training epoch: 765
[ Wed Apr 25 10:12:08 2018 ] 	Batch(0/1) done. Loss: 0.0125  lr:0.100000
[ Wed Apr 25 10:12:08 2018 ] 	Mean training loss: 0.0125.
[ Wed Apr 25 10:12:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:12:08 2018 ] Eval epoch: 765
[ Wed Apr 25 10:12:11 2018 ] 	Mean test loss of 1 batches: 0.22742100059986115.
[ Wed Apr 25 10:12:11 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:12:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:12:11 2018 ] Training epoch: 766
[ Wed Apr 25 10:12:15 2018 ] 	Batch(0/1) done. Loss: 0.0135  lr:0.100000
[ Wed Apr 25 10:12:15 2018 ] 	Mean training loss: 0.0135.
[ Wed Apr 25 10:12:15 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 10:12:15 2018 ] Training epoch: 767
[ Wed Apr 25 10:12:19 2018 ] 	Batch(0/1) done. Loss: 0.0289  lr:0.100000
[ Wed Apr 25 10:12:19 2018 ] 	Mean training loss: 0.0289.
[ Wed Apr 25 10:12:19 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:12:19 2018 ] Training epoch: 768
[ Wed Apr 25 10:12:23 2018 ] 	Batch(0/1) done. Loss: 0.0083  lr:0.100000
[ Wed Apr 25 10:12:23 2018 ] 	Mean training loss: 0.0083.
[ Wed Apr 25 10:12:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:12:23 2018 ] Training epoch: 769
[ Wed Apr 25 10:12:27 2018 ] 	Batch(0/1) done. Loss: 0.0041  lr:0.100000
[ Wed Apr 25 10:12:27 2018 ] 	Mean training loss: 0.0041.
[ Wed Apr 25 10:12:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:12:27 2018 ] Training epoch: 770
[ Wed Apr 25 10:12:31 2018 ] 	Batch(0/1) done. Loss: 0.0119  lr:0.100000
[ Wed Apr 25 10:12:31 2018 ] 	Mean training loss: 0.0119.
[ Wed Apr 25 10:12:31 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:12:31 2018 ] Eval epoch: 770
[ Wed Apr 25 10:12:34 2018 ] 	Mean test loss of 1 batches: 0.32920071482658386.
[ Wed Apr 25 10:12:34 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:12:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:12:34 2018 ] Training epoch: 771
[ Wed Apr 25 10:12:38 2018 ] 	Batch(0/1) done. Loss: 0.0258  lr:0.100000
[ Wed Apr 25 10:12:38 2018 ] 	Mean training loss: 0.0258.
[ Wed Apr 25 10:12:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:12:38 2018 ] Training epoch: 772
[ Wed Apr 25 10:12:42 2018 ] 	Batch(0/1) done. Loss: 0.0073  lr:0.100000
[ Wed Apr 25 10:12:42 2018 ] 	Mean training loss: 0.0073.
[ Wed Apr 25 10:12:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:12:42 2018 ] Training epoch: 773
[ Wed Apr 25 10:12:46 2018 ] 	Batch(0/1) done. Loss: 0.0247  lr:0.100000
[ Wed Apr 25 10:12:46 2018 ] 	Mean training loss: 0.0247.
[ Wed Apr 25 10:12:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:12:46 2018 ] Training epoch: 774
[ Wed Apr 25 10:12:50 2018 ] 	Batch(0/1) done. Loss: 0.0065  lr:0.100000
[ Wed Apr 25 10:12:50 2018 ] 	Mean training loss: 0.0065.
[ Wed Apr 25 10:12:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:12:50 2018 ] Training epoch: 775
[ Wed Apr 25 10:12:54 2018 ] 	Batch(0/1) done. Loss: 0.0195  lr:0.100000
[ Wed Apr 25 10:12:54 2018 ] 	Mean training loss: 0.0195.
[ Wed Apr 25 10:12:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:12:54 2018 ] Eval epoch: 775
[ Wed Apr 25 10:12:57 2018 ] 	Mean test loss of 1 batches: 0.4036213457584381.
[ Wed Apr 25 10:12:57 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:12:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:12:57 2018 ] Training epoch: 776
[ Wed Apr 25 10:13:00 2018 ] 	Batch(0/1) done. Loss: 0.0081  lr:0.100000
[ Wed Apr 25 10:13:00 2018 ] 	Mean training loss: 0.0081.
[ Wed Apr 25 10:13:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:00 2018 ] Training epoch: 777
[ Wed Apr 25 10:13:04 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:13:04 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:13:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:04 2018 ] Training epoch: 778
[ Wed Apr 25 10:13:08 2018 ] 	Batch(0/1) done. Loss: 0.0034  lr:0.100000
[ Wed Apr 25 10:13:08 2018 ] 	Mean training loss: 0.0034.
[ Wed Apr 25 10:13:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:08 2018 ] Training epoch: 779
[ Wed Apr 25 10:13:12 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:13:12 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:13:12 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:12 2018 ] Training epoch: 780
[ Wed Apr 25 10:13:16 2018 ] 	Batch(0/1) done. Loss: 0.0033  lr:0.100000
[ Wed Apr 25 10:13:16 2018 ] 	Mean training loss: 0.0033.
[ Wed Apr 25 10:13:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:16 2018 ] Eval epoch: 780
[ Wed Apr 25 10:13:19 2018 ] 	Mean test loss of 1 batches: 0.3571299910545349.
[ Wed Apr 25 10:13:19 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:13:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:13:19 2018 ] Training epoch: 781
[ Wed Apr 25 10:13:23 2018 ] 	Batch(0/1) done. Loss: 0.0073  lr:0.100000
[ Wed Apr 25 10:13:23 2018 ] 	Mean training loss: 0.0073.
[ Wed Apr 25 10:13:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:23 2018 ] Training epoch: 782
[ Wed Apr 25 10:13:27 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:13:27 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:13:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:13:27 2018 ] Training epoch: 783
[ Wed Apr 25 10:13:31 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:13:31 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:13:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:31 2018 ] Training epoch: 784
[ Wed Apr 25 10:13:35 2018 ] 	Batch(0/1) done. Loss: 0.0122  lr:0.100000
[ Wed Apr 25 10:13:35 2018 ] 	Mean training loss: 0.0122.
[ Wed Apr 25 10:13:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:35 2018 ] Training epoch: 785
[ Wed Apr 25 10:13:39 2018 ] 	Batch(0/1) done. Loss: 0.0126  lr:0.100000
[ Wed Apr 25 10:13:39 2018 ] 	Mean training loss: 0.0126.
[ Wed Apr 25 10:13:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:13:39 2018 ] Eval epoch: 785
[ Wed Apr 25 10:13:42 2018 ] 	Mean test loss of 1 batches: 0.28262487053871155.
[ Wed Apr 25 10:13:42 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:13:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:13:42 2018 ] Training epoch: 786
[ Wed Apr 25 10:13:45 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:13:45 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:13:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:45 2018 ] Training epoch: 787
[ Wed Apr 25 10:13:49 2018 ] 	Batch(0/1) done. Loss: 0.0059  lr:0.100000
[ Wed Apr 25 10:13:49 2018 ] 	Mean training loss: 0.0059.
[ Wed Apr 25 10:13:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:49 2018 ] Training epoch: 788
[ Wed Apr 25 10:13:53 2018 ] 	Batch(0/1) done. Loss: 0.0047  lr:0.100000
[ Wed Apr 25 10:13:53 2018 ] 	Mean training loss: 0.0047.
[ Wed Apr 25 10:13:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:53 2018 ] Training epoch: 789
[ Wed Apr 25 10:13:57 2018 ] 	Batch(0/1) done. Loss: 0.0053  lr:0.100000
[ Wed Apr 25 10:13:57 2018 ] 	Mean training loss: 0.0053.
[ Wed Apr 25 10:13:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:13:57 2018 ] Training epoch: 790
[ Wed Apr 25 10:14:01 2018 ] 	Batch(0/1) done. Loss: 0.0045  lr:0.100000
[ Wed Apr 25 10:14:01 2018 ] 	Mean training loss: 0.0045.
[ Wed Apr 25 10:14:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:01 2018 ] Eval epoch: 790
[ Wed Apr 25 10:14:04 2018 ] 	Mean test loss of 1 batches: 0.21723969280719757.
[ Wed Apr 25 10:14:04 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:14:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:14:04 2018 ] Training epoch: 791
[ Wed Apr 25 10:14:08 2018 ] 	Batch(0/1) done. Loss: 0.0040  lr:0.100000
[ Wed Apr 25 10:14:08 2018 ] 	Mean training loss: 0.0040.
[ Wed Apr 25 10:14:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:08 2018 ] Training epoch: 792
[ Wed Apr 25 10:14:12 2018 ] 	Batch(0/1) done. Loss: 0.0035  lr:0.100000
[ Wed Apr 25 10:14:12 2018 ] 	Mean training loss: 0.0035.
[ Wed Apr 25 10:14:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:14:12 2018 ] Training epoch: 793
[ Wed Apr 25 10:14:16 2018 ] 	Batch(0/1) done. Loss: 0.0049  lr:0.100000
[ Wed Apr 25 10:14:16 2018 ] 	Mean training loss: 0.0049.
[ Wed Apr 25 10:14:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:16 2018 ] Training epoch: 794
[ Wed Apr 25 10:14:20 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:14:20 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:14:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:20 2018 ] Training epoch: 795
[ Wed Apr 25 10:14:24 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:14:24 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:14:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:24 2018 ] Eval epoch: 795
[ Wed Apr 25 10:14:26 2018 ] 	Mean test loss of 1 batches: 0.1880219578742981.
[ Wed Apr 25 10:14:26 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:14:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:14:26 2018 ] Training epoch: 796
[ Wed Apr 25 10:14:30 2018 ] 	Batch(0/1) done. Loss: 0.0048  lr:0.100000
[ Wed Apr 25 10:14:30 2018 ] 	Mean training loss: 0.0048.
[ Wed Apr 25 10:14:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:30 2018 ] Training epoch: 797
[ Wed Apr 25 10:14:34 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:14:35 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:14:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:14:35 2018 ] Training epoch: 798
[ Wed Apr 25 10:14:38 2018 ] 	Batch(0/1) done. Loss: 0.0056  lr:0.100000
[ Wed Apr 25 10:14:38 2018 ] 	Mean training loss: 0.0056.
[ Wed Apr 25 10:14:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:38 2018 ] Training epoch: 799
[ Wed Apr 25 10:14:42 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:14:42 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:14:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:14:42 2018 ] Training epoch: 800
[ Wed Apr 25 10:14:46 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:14:46 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:14:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:46 2018 ] Eval epoch: 800
[ Wed Apr 25 10:14:49 2018 ] 	Mean test loss of 1 batches: 0.21576468646526337.
[ Wed Apr 25 10:14:49 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:14:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:14:49 2018 ] Training epoch: 801
[ Wed Apr 25 10:14:53 2018 ] 	Batch(0/1) done. Loss: 0.0040  lr:0.100000
[ Wed Apr 25 10:14:53 2018 ] 	Mean training loss: 0.0040.
[ Wed Apr 25 10:14:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:53 2018 ] Training epoch: 802
[ Wed Apr 25 10:14:57 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:14:57 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:14:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:14:57 2018 ] Training epoch: 803
[ Wed Apr 25 10:15:01 2018 ] 	Batch(0/1) done. Loss: 0.0069  lr:0.100000
[ Wed Apr 25 10:15:01 2018 ] 	Mean training loss: 0.0069.
[ Wed Apr 25 10:15:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:01 2018 ] Training epoch: 804
[ Wed Apr 25 10:15:05 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:15:05 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:15:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:05 2018 ] Training epoch: 805
[ Wed Apr 25 10:15:09 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:15:09 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:15:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:15:09 2018 ] Eval epoch: 805
[ Wed Apr 25 10:15:12 2018 ] 	Mean test loss of 1 batches: 0.19718477129936218.
[ Wed Apr 25 10:15:12 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:15:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:15:12 2018 ] Training epoch: 806
[ Wed Apr 25 10:15:16 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:15:16 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:15:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:16 2018 ] Training epoch: 807
[ Wed Apr 25 10:15:20 2018 ] 	Batch(0/1) done. Loss: 0.0029  lr:0.100000
[ Wed Apr 25 10:15:20 2018 ] 	Mean training loss: 0.0029.
[ Wed Apr 25 10:15:20 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:15:20 2018 ] Training epoch: 808
[ Wed Apr 25 10:15:24 2018 ] 	Batch(0/1) done. Loss: 0.0057  lr:0.100000
[ Wed Apr 25 10:15:24 2018 ] 	Mean training loss: 0.0057.
[ Wed Apr 25 10:15:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:24 2018 ] Training epoch: 809
[ Wed Apr 25 10:15:28 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:15:28 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:15:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:28 2018 ] Training epoch: 810
[ Wed Apr 25 10:15:31 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:15:31 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:15:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:31 2018 ] Eval epoch: 810
[ Wed Apr 25 10:15:34 2018 ] 	Mean test loss of 1 batches: 0.22300441563129425.
[ Wed Apr 25 10:15:34 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:15:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:15:34 2018 ] Training epoch: 811
[ Wed Apr 25 10:15:38 2018 ] 	Batch(0/1) done. Loss: 0.0090  lr:0.100000
[ Wed Apr 25 10:15:38 2018 ] 	Mean training loss: 0.0090.
[ Wed Apr 25 10:15:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:38 2018 ] Training epoch: 812
[ Wed Apr 25 10:15:42 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:15:42 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:15:42 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:15:42 2018 ] Training epoch: 813
[ Wed Apr 25 10:15:46 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:15:46 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:15:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:15:46 2018 ] Training epoch: 814
[ Wed Apr 25 10:15:50 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:15:50 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:15:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:15:50 2018 ] Training epoch: 815
[ Wed Apr 25 10:15:54 2018 ] 	Batch(0/1) done. Loss: 0.0057  lr:0.100000
[ Wed Apr 25 10:15:54 2018 ] 	Mean training loss: 0.0057.
[ Wed Apr 25 10:15:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:15:54 2018 ] Eval epoch: 815
[ Wed Apr 25 10:15:57 2018 ] 	Mean test loss of 1 batches: 0.2391994595527649.
[ Wed Apr 25 10:15:57 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:15:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:15:57 2018 ] Training epoch: 816
[ Wed Apr 25 10:16:01 2018 ] 	Batch(0/1) done. Loss: 0.0043  lr:0.100000
[ Wed Apr 25 10:16:01 2018 ] 	Mean training loss: 0.0043.
[ Wed Apr 25 10:16:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:01 2018 ] Training epoch: 817
[ Wed Apr 25 10:16:05 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:16:05 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:16:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:05 2018 ] Training epoch: 818
[ Wed Apr 25 10:16:09 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:16:09 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:16:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:09 2018 ] Training epoch: 819
[ Wed Apr 25 10:16:12 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:16:12 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:16:12 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 10:16:12 2018 ] Training epoch: 820
[ Wed Apr 25 10:16:16 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:16:16 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:16:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:16 2018 ] Eval epoch: 820
[ Wed Apr 25 10:16:19 2018 ] 	Mean test loss of 1 batches: 0.25490668416023254.
[ Wed Apr 25 10:16:19 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:16:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:16:19 2018 ] Training epoch: 821
[ Wed Apr 25 10:16:23 2018 ] 	Batch(0/1) done. Loss: 0.0041  lr:0.100000
[ Wed Apr 25 10:16:23 2018 ] 	Mean training loss: 0.0041.
[ Wed Apr 25 10:16:23 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:23 2018 ] Training epoch: 822
[ Wed Apr 25 10:16:27 2018 ] 	Batch(0/1) done. Loss: 0.0072  lr:0.100000
[ Wed Apr 25 10:16:27 2018 ] 	Mean training loss: 0.0072.
[ Wed Apr 25 10:16:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:27 2018 ] Training epoch: 823
[ Wed Apr 25 10:16:31 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:16:31 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:16:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:31 2018 ] Training epoch: 824
[ Wed Apr 25 10:16:35 2018 ] 	Batch(0/1) done. Loss: 0.0035  lr:0.100000
[ Wed Apr 25 10:16:35 2018 ] 	Mean training loss: 0.0035.
[ Wed Apr 25 10:16:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:35 2018 ] Training epoch: 825
[ Wed Apr 25 10:16:39 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:16:39 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:16:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:16:39 2018 ] Eval epoch: 825
[ Wed Apr 25 10:16:42 2018 ] 	Mean test loss of 1 batches: 0.17116610705852509.
[ Wed Apr 25 10:16:42 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:16:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:16:42 2018 ] Training epoch: 826
[ Wed Apr 25 10:16:46 2018 ] 	Batch(0/1) done. Loss: 0.0026  lr:0.100000
[ Wed Apr 25 10:16:46 2018 ] 	Mean training loss: 0.0026.
[ Wed Apr 25 10:16:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:46 2018 ] Training epoch: 827
[ Wed Apr 25 10:16:50 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:16:50 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:16:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:50 2018 ] Training epoch: 828
[ Wed Apr 25 10:16:53 2018 ] 	Batch(0/1) done. Loss: 0.0041  lr:0.100000
[ Wed Apr 25 10:16:54 2018 ] 	Mean training loss: 0.0041.
[ Wed Apr 25 10:16:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:16:54 2018 ] Training epoch: 829
[ Wed Apr 25 10:16:58 2018 ] 	Batch(0/1) done. Loss: 0.0055  lr:0.100000
[ Wed Apr 25 10:16:58 2018 ] 	Mean training loss: 0.0055.
[ Wed Apr 25 10:16:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:16:58 2018 ] Training epoch: 830
[ Wed Apr 25 10:17:01 2018 ] 	Batch(0/1) done. Loss: 0.0046  lr:0.100000
[ Wed Apr 25 10:17:01 2018 ] 	Mean training loss: 0.0046.
[ Wed Apr 25 10:17:01 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 10:17:01 2018 ] Eval epoch: 830
[ Wed Apr 25 10:17:04 2018 ] 	Mean test loss of 1 batches: 0.20464088022708893.
[ Wed Apr 25 10:17:04 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:17:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:17:04 2018 ] Training epoch: 831
[ Wed Apr 25 10:17:08 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:17:08 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:17:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:17:08 2018 ] Training epoch: 832
[ Wed Apr 25 10:17:12 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:17:12 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:17:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:17:12 2018 ] Training epoch: 833
[ Wed Apr 25 10:17:16 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:17:16 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:17:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:16 2018 ] Training epoch: 834
[ Wed Apr 25 10:17:20 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:17:20 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:17:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:20 2018 ] Training epoch: 835
[ Wed Apr 25 10:17:24 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:17:24 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:17:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:24 2018 ] Eval epoch: 835
[ Wed Apr 25 10:17:27 2018 ] 	Mean test loss of 1 batches: 0.24589288234710693.
[ Wed Apr 25 10:17:27 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:17:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:17:27 2018 ] Training epoch: 836
[ Wed Apr 25 10:17:31 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:17:31 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:17:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:31 2018 ] Training epoch: 837
[ Wed Apr 25 10:17:35 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:17:35 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:17:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:17:35 2018 ] Training epoch: 838
[ Wed Apr 25 10:17:39 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:17:39 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:17:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:39 2018 ] Training epoch: 839
[ Wed Apr 25 10:17:43 2018 ] 	Batch(0/1) done. Loss: 0.0045  lr:0.100000
[ Wed Apr 25 10:17:43 2018 ] 	Mean training loss: 0.0045.
[ Wed Apr 25 10:17:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:17:43 2018 ] Training epoch: 840
[ Wed Apr 25 10:17:47 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:17:47 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:17:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:17:47 2018 ] Eval epoch: 840
[ Wed Apr 25 10:17:50 2018 ] 	Mean test loss of 1 batches: 0.17551648616790771.
[ Wed Apr 25 10:17:50 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:17:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:17:50 2018 ] Training epoch: 841
[ Wed Apr 25 10:17:54 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:17:54 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:17:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:17:54 2018 ] Training epoch: 842
[ Wed Apr 25 10:17:58 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:17:58 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:17:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:17:58 2018 ] Training epoch: 843
[ Wed Apr 25 10:18:02 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:18:02 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:18:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:02 2018 ] Training epoch: 844
[ Wed Apr 25 10:18:06 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:18:06 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:18:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:06 2018 ] Training epoch: 845
[ Wed Apr 25 10:18:10 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:18:10 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:18:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:10 2018 ] Eval epoch: 845
[ Wed Apr 25 10:18:13 2018 ] 	Mean test loss of 1 batches: 0.13697683811187744.
[ Wed Apr 25 10:18:13 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:18:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:18:13 2018 ] Training epoch: 846
[ Wed Apr 25 10:18:17 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:18:17 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:18:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:18:17 2018 ] Training epoch: 847
[ Wed Apr 25 10:18:21 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:18:21 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:18:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:18:21 2018 ] Training epoch: 848
[ Wed Apr 25 10:18:25 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:18:25 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:18:25 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:18:25 2018 ] Training epoch: 849
[ Wed Apr 25 10:18:29 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:18:29 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:18:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:29 2018 ] Training epoch: 850
[ Wed Apr 25 10:18:34 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:18:34 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:18:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:18:34 2018 ] Eval epoch: 850
[ Wed Apr 25 10:18:37 2018 ] 	Mean test loss of 1 batches: 0.1685834676027298.
[ Wed Apr 25 10:18:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:18:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:18:37 2018 ] Training epoch: 851
[ Wed Apr 25 10:18:41 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:18:41 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:18:41 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:41 2018 ] Training epoch: 852
[ Wed Apr 25 10:18:45 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:18:45 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:18:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:18:45 2018 ] Training epoch: 853
[ Wed Apr 25 10:18:49 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:18:49 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:18:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:18:49 2018 ] Training epoch: 854
[ Wed Apr 25 10:18:53 2018 ] 	Batch(0/1) done. Loss: 0.0030  lr:0.100000
[ Wed Apr 25 10:18:53 2018 ] 	Mean training loss: 0.0030.
[ Wed Apr 25 10:18:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:53 2018 ] Training epoch: 855
[ Wed Apr 25 10:18:57 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:18:57 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:18:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:18:57 2018 ] Eval epoch: 855
[ Wed Apr 25 10:18:59 2018 ] 	Mean test loss of 1 batches: 0.20697565376758575.
[ Wed Apr 25 10:18:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:18:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:18:59 2018 ] Training epoch: 856
[ Wed Apr 25 10:19:03 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:19:03 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:19:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:19:03 2018 ] Training epoch: 857
[ Wed Apr 25 10:19:08 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:19:08 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:19:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:19:08 2018 ] Training epoch: 858
[ Wed Apr 25 10:19:12 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:19:12 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:19:12 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:19:12 2018 ] Training epoch: 859
[ Wed Apr 25 10:19:16 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:19:16 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:19:16 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:19:16 2018 ] Training epoch: 860
[ Wed Apr 25 10:19:21 2018 ] 	Batch(0/1) done. Loss: 0.0028  lr:0.100000
[ Wed Apr 25 10:19:21 2018 ] 	Mean training loss: 0.0028.
[ Wed Apr 25 10:19:21 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:19:21 2018 ] Eval epoch: 860
[ Wed Apr 25 10:19:23 2018 ] 	Mean test loss of 1 batches: 0.23129121959209442.
[ Wed Apr 25 10:19:23 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:19:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:19:23 2018 ] Training epoch: 861
[ Wed Apr 25 10:19:27 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:19:27 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:19:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:19:27 2018 ] Training epoch: 862
[ Wed Apr 25 10:19:32 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:19:32 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:19:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:19:32 2018 ] Training epoch: 863
[ Wed Apr 25 10:19:35 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:19:35 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:19:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:19:35 2018 ] Training epoch: 864
[ Wed Apr 25 10:19:39 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:19:39 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:19:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:19:39 2018 ] Training epoch: 865
[ Wed Apr 25 10:19:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:19:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:19:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:19:43 2018 ] Eval epoch: 865
[ Wed Apr 25 10:19:46 2018 ] 	Mean test loss of 1 batches: 0.245511993765831.
[ Wed Apr 25 10:19:46 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:19:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:19:46 2018 ] Training epoch: 866
[ Wed Apr 25 10:19:50 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:19:50 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:19:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:19:50 2018 ] Training epoch: 867
[ Wed Apr 25 10:19:54 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:19:54 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:19:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:19:54 2018 ] Training epoch: 868
[ Wed Apr 25 10:19:58 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:19:58 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:19:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:19:58 2018 ] Training epoch: 869
[ Wed Apr 25 10:20:02 2018 ] 	Batch(0/1) done. Loss: 0.0042  lr:0.100000
[ Wed Apr 25 10:20:02 2018 ] 	Mean training loss: 0.0042.
[ Wed Apr 25 10:20:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:20:02 2018 ] Training epoch: 870
[ Wed Apr 25 10:20:06 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:20:06 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:20:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:20:06 2018 ] Eval epoch: 870
[ Wed Apr 25 10:20:09 2018 ] 	Mean test loss of 1 batches: 0.21358193457126617.
[ Wed Apr 25 10:20:09 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:20:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:20:09 2018 ] Training epoch: 871
[ Wed Apr 25 10:20:13 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:20:13 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:20:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:20:13 2018 ] Training epoch: 872
[ Wed Apr 25 10:20:17 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:20:17 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:20:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:20:17 2018 ] Training epoch: 873
[ Wed Apr 25 10:20:21 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:20:21 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:20:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:20:21 2018 ] Training epoch: 874
[ Wed Apr 25 10:20:25 2018 ] 	Batch(0/1) done. Loss: 0.0076  lr:0.100000
[ Wed Apr 25 10:20:25 2018 ] 	Mean training loss: 0.0076.
[ Wed Apr 25 10:20:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:20:25 2018 ] Training epoch: 875
[ Wed Apr 25 10:20:29 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:20:29 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:20:29 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:20:29 2018 ] Eval epoch: 875
[ Wed Apr 25 10:20:32 2018 ] 	Mean test loss of 1 batches: 0.17091910541057587.
[ Wed Apr 25 10:20:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:20:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:20:32 2018 ] Training epoch: 876
[ Wed Apr 25 10:20:36 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:20:36 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:20:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:20:36 2018 ] Training epoch: 877
[ Wed Apr 25 10:20:40 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:20:40 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:20:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:20:40 2018 ] Training epoch: 878
[ Wed Apr 25 10:20:44 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:20:44 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:20:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:20:44 2018 ] Training epoch: 879
[ Wed Apr 25 10:20:48 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:20:48 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:20:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:20:48 2018 ] Training epoch: 880
[ Wed Apr 25 10:20:52 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:20:52 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:20:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:20:52 2018 ] Eval epoch: 880
[ Wed Apr 25 10:20:54 2018 ] 	Mean test loss of 1 batches: 0.18785622715950012.
[ Wed Apr 25 10:20:54 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:20:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:20:54 2018 ] Training epoch: 881
[ Wed Apr 25 10:20:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:20:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:20:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:20:59 2018 ] Training epoch: 882
[ Wed Apr 25 10:21:03 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:21:03 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:21:03 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:21:03 2018 ] Training epoch: 883
[ Wed Apr 25 10:21:07 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:21:07 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:21:07 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:21:07 2018 ] Training epoch: 884
[ Wed Apr 25 10:21:11 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:21:11 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:21:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:21:11 2018 ] Training epoch: 885
[ Wed Apr 25 10:21:16 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:21:16 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:21:16 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:21:16 2018 ] Eval epoch: 885
[ Wed Apr 25 10:21:18 2018 ] 	Mean test loss of 1 batches: 0.21743808686733246.
[ Wed Apr 25 10:21:18 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:21:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:21:18 2018 ] Training epoch: 886
[ Wed Apr 25 10:21:22 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:21:22 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:21:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:22 2018 ] Training epoch: 887
[ Wed Apr 25 10:21:26 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:21:26 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:21:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:26 2018 ] Training epoch: 888
[ Wed Apr 25 10:21:30 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:21:30 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:21:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:30 2018 ] Training epoch: 889
[ Wed Apr 25 10:21:34 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:21:34 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:21:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:34 2018 ] Training epoch: 890
[ Wed Apr 25 10:21:38 2018 ] 	Batch(0/1) done. Loss: 0.0029  lr:0.100000
[ Wed Apr 25 10:21:38 2018 ] 	Mean training loss: 0.0029.
[ Wed Apr 25 10:21:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:38 2018 ] Eval epoch: 890
[ Wed Apr 25 10:21:41 2018 ] 	Mean test loss of 1 batches: 0.20998981595039368.
[ Wed Apr 25 10:21:41 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:21:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:21:41 2018 ] Training epoch: 891
[ Wed Apr 25 10:21:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:21:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:21:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:21:45 2018 ] Training epoch: 892
[ Wed Apr 25 10:21:49 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:21:49 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:21:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:49 2018 ] Training epoch: 893
[ Wed Apr 25 10:21:53 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:21:53 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:21:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:21:53 2018 ] Training epoch: 894
[ Wed Apr 25 10:21:57 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:21:57 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:21:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:21:57 2018 ] Training epoch: 895
[ Wed Apr 25 10:22:01 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:22:01 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:22:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:22:01 2018 ] Eval epoch: 895
[ Wed Apr 25 10:22:04 2018 ] 	Mean test loss of 1 batches: 0.19783489406108856.
[ Wed Apr 25 10:22:04 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:22:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:22:04 2018 ] Training epoch: 896
[ Wed Apr 25 10:22:07 2018 ] 	Batch(0/1) done. Loss: 0.0038  lr:0.100000
[ Wed Apr 25 10:22:07 2018 ] 	Mean training loss: 0.0038.
[ Wed Apr 25 10:22:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:22:07 2018 ] Training epoch: 897
[ Wed Apr 25 10:22:12 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:22:12 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:22:12 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:22:12 2018 ] Training epoch: 898
[ Wed Apr 25 10:22:16 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:22:16 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:22:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:22:16 2018 ] Training epoch: 899
[ Wed Apr 25 10:22:20 2018 ] 	Batch(0/1) done. Loss: 0.0038  lr:0.100000
[ Wed Apr 25 10:22:20 2018 ] 	Mean training loss: 0.0038.
[ Wed Apr 25 10:22:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:22:20 2018 ] Training epoch: 900
[ Wed Apr 25 10:22:24 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:22:24 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:22:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:22:24 2018 ] Eval epoch: 900
[ Wed Apr 25 10:22:27 2018 ] 	Mean test loss of 1 batches: 0.22359932959079742.
[ Wed Apr 25 10:22:27 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:22:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:22:27 2018 ] Training epoch: 901
[ Wed Apr 25 10:22:31 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:22:31 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:22:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:31 2018 ] Training epoch: 902
[ Wed Apr 25 10:22:35 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:22:35 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:22:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:35 2018 ] Training epoch: 903
[ Wed Apr 25 10:22:39 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:22:39 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:22:39 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:22:39 2018 ] Training epoch: 904
[ Wed Apr 25 10:22:43 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:22:43 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:22:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:43 2018 ] Training epoch: 905
[ Wed Apr 25 10:22:47 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:22:47 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:22:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:47 2018 ] Eval epoch: 905
[ Wed Apr 25 10:22:50 2018 ] 	Mean test loss of 1 batches: 0.2146691530942917.
[ Wed Apr 25 10:22:50 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:22:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:22:50 2018 ] Training epoch: 906
[ Wed Apr 25 10:22:54 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:22:54 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:22:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:54 2018 ] Training epoch: 907
[ Wed Apr 25 10:22:58 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:22:58 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:22:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:22:58 2018 ] Training epoch: 908
[ Wed Apr 25 10:23:01 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:23:01 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:23:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:01 2018 ] Training epoch: 909
[ Wed Apr 25 10:23:05 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:23:05 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:23:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:05 2018 ] Training epoch: 910
[ Wed Apr 25 10:23:09 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:23:09 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:23:09 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:09 2018 ] Eval epoch: 910
[ Wed Apr 25 10:23:12 2018 ] 	Mean test loss of 1 batches: 0.2255154401063919.
[ Wed Apr 25 10:23:12 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:23:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:23:12 2018 ] Training epoch: 911
[ Wed Apr 25 10:23:16 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:23:16 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:23:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:23:16 2018 ] Training epoch: 912
[ Wed Apr 25 10:23:20 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:23:20 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:23:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:20 2018 ] Training epoch: 913
[ Wed Apr 25 10:23:24 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:23:24 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:23:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:24 2018 ] Training epoch: 914
[ Wed Apr 25 10:23:28 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:23:28 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:23:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:28 2018 ] Training epoch: 915
[ Wed Apr 25 10:23:32 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:23:32 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:23:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:23:32 2018 ] Eval epoch: 915
[ Wed Apr 25 10:23:35 2018 ] 	Mean test loss of 1 batches: 0.27773913741111755.
[ Wed Apr 25 10:23:35 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:23:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:23:35 2018 ] Training epoch: 916
[ Wed Apr 25 10:23:39 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:23:39 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:23:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:39 2018 ] Training epoch: 917
[ Wed Apr 25 10:23:43 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:23:43 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:23:43 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:43 2018 ] Training epoch: 918
[ Wed Apr 25 10:23:47 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:23:47 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:23:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:47 2018 ] Training epoch: 919
[ Wed Apr 25 10:23:51 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:23:51 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:23:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:23:51 2018 ] Training epoch: 920
[ Wed Apr 25 10:23:55 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:23:55 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:23:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:23:55 2018 ] Eval epoch: 920
[ Wed Apr 25 10:23:58 2018 ] 	Mean test loss of 1 batches: 0.26091158390045166.
[ Wed Apr 25 10:23:58 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:23:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:23:58 2018 ] Training epoch: 921
[ Wed Apr 25 10:24:02 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:24:02 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:24:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:02 2018 ] Training epoch: 922
[ Wed Apr 25 10:24:05 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:24:05 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:24:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:05 2018 ] Training epoch: 923
[ Wed Apr 25 10:24:09 2018 ] 	Batch(0/1) done. Loss: 0.0021  lr:0.100000
[ Wed Apr 25 10:24:09 2018 ] 	Mean training loss: 0.0021.
[ Wed Apr 25 10:24:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:10 2018 ] Training epoch: 924
[ Wed Apr 25 10:24:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:24:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:24:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:13 2018 ] Training epoch: 925
[ Wed Apr 25 10:24:17 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:24:17 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:24:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:24:17 2018 ] Eval epoch: 925
[ Wed Apr 25 10:24:20 2018 ] 	Mean test loss of 1 batches: 0.23269787430763245.
[ Wed Apr 25 10:24:20 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:24:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:24:20 2018 ] Training epoch: 926
[ Wed Apr 25 10:24:24 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:24:24 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:24:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:24:24 2018 ] Training epoch: 927
[ Wed Apr 25 10:24:28 2018 ] 	Batch(0/1) done. Loss: 0.0026  lr:0.100000
[ Wed Apr 25 10:24:28 2018 ] 	Mean training loss: 0.0026.
[ Wed Apr 25 10:24:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:28 2018 ] Training epoch: 928
[ Wed Apr 25 10:24:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:24:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:24:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:24:32 2018 ] Training epoch: 929
[ Wed Apr 25 10:24:36 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:24:36 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:24:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:36 2018 ] Training epoch: 930
[ Wed Apr 25 10:24:40 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:24:40 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:24:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:24:40 2018 ] Eval epoch: 930
[ Wed Apr 25 10:24:43 2018 ] 	Mean test loss of 1 batches: 0.1732023060321808.
[ Wed Apr 25 10:24:43 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:24:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:24:43 2018 ] Training epoch: 931
[ Wed Apr 25 10:24:47 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:24:47 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:24:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:47 2018 ] Training epoch: 932
[ Wed Apr 25 10:24:51 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:24:51 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:24:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:51 2018 ] Training epoch: 933
[ Wed Apr 25 10:24:55 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:24:55 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:24:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:24:55 2018 ] Training epoch: 934
[ Wed Apr 25 10:24:59 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:24:59 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:24:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:24:59 2018 ] Training epoch: 935
[ Wed Apr 25 10:25:03 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:25:03 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:25:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:03 2018 ] Eval epoch: 935
[ Wed Apr 25 10:25:05 2018 ] 	Mean test loss of 1 batches: 0.1691461205482483.
[ Wed Apr 25 10:25:05 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:25:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:25:05 2018 ] Training epoch: 936
[ Wed Apr 25 10:25:09 2018 ] 	Batch(0/1) done. Loss: 0.0026  lr:0.100000
[ Wed Apr 25 10:25:09 2018 ] 	Mean training loss: 0.0026.
[ Wed Apr 25 10:25:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:25:09 2018 ] Training epoch: 937
[ Wed Apr 25 10:25:14 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:25:14 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:25:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:25:14 2018 ] Training epoch: 938
[ Wed Apr 25 10:25:18 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:25:18 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:25:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:18 2018 ] Training epoch: 939
[ Wed Apr 25 10:25:21 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:25:21 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:25:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:21 2018 ] Training epoch: 940
[ Wed Apr 25 10:25:25 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:25:25 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:25:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:25 2018 ] Eval epoch: 940
[ Wed Apr 25 10:25:28 2018 ] 	Mean test loss of 1 batches: 0.22771476209163666.
[ Wed Apr 25 10:25:28 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:25:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:25:28 2018 ] Training epoch: 941
[ Wed Apr 25 10:25:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:25:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:25:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:32 2018 ] Training epoch: 942
[ Wed Apr 25 10:25:36 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:25:36 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:25:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:36 2018 ] Training epoch: 943
[ Wed Apr 25 10:25:40 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:25:40 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:25:40 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:40 2018 ] Training epoch: 944
[ Wed Apr 25 10:25:44 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:25:44 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:25:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:44 2018 ] Training epoch: 945
[ Wed Apr 25 10:25:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:25:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:25:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:48 2018 ] Eval epoch: 945
[ Wed Apr 25 10:25:50 2018 ] 	Mean test loss of 1 batches: 0.27089744806289673.
[ Wed Apr 25 10:25:50 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:25:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:25:50 2018 ] Training epoch: 946
[ Wed Apr 25 10:25:54 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:25:54 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:25:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:54 2018 ] Training epoch: 947
[ Wed Apr 25 10:25:58 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:25:58 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:25:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:25:58 2018 ] Training epoch: 948
[ Wed Apr 25 10:26:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:26:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:26:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:02 2018 ] Training epoch: 949
[ Wed Apr 25 10:26:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:26:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:26:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:26:06 2018 ] Training epoch: 950
[ Wed Apr 25 10:26:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:26:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:26:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:10 2018 ] Eval epoch: 950
[ Wed Apr 25 10:26:13 2018 ] 	Mean test loss of 1 batches: 0.2818215489387512.
[ Wed Apr 25 10:26:13 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:26:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:26:13 2018 ] Training epoch: 951
[ Wed Apr 25 10:26:17 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:26:17 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:26:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:17 2018 ] Training epoch: 952
[ Wed Apr 25 10:26:21 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:26:21 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:26:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:21 2018 ] Training epoch: 953
[ Wed Apr 25 10:26:25 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:26:25 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:26:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:26:25 2018 ] Training epoch: 954
[ Wed Apr 25 10:26:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:26:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:26:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:29 2018 ] Training epoch: 955
[ Wed Apr 25 10:26:33 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:26:33 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:26:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:33 2018 ] Eval epoch: 955
[ Wed Apr 25 10:26:36 2018 ] 	Mean test loss of 1 batches: 0.26975274085998535.
[ Wed Apr 25 10:26:36 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:26:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:26:36 2018 ] Training epoch: 956
[ Wed Apr 25 10:26:39 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:26:39 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:26:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:39 2018 ] Training epoch: 957
[ Wed Apr 25 10:26:44 2018 ] 	Batch(0/1) done. Loss: 0.0021  lr:0.100000
[ Wed Apr 25 10:26:44 2018 ] 	Mean training loss: 0.0021.
[ Wed Apr 25 10:26:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:26:44 2018 ] Training epoch: 958
[ Wed Apr 25 10:26:47 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:26:47 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:26:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:47 2018 ] Training epoch: 959
[ Wed Apr 25 10:26:51 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:26:51 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:26:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:51 2018 ] Training epoch: 960
[ Wed Apr 25 10:26:55 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:26:55 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:26:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:26:55 2018 ] Eval epoch: 960
[ Wed Apr 25 10:26:58 2018 ] 	Mean test loss of 1 batches: 0.24427835643291473.
[ Wed Apr 25 10:26:58 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:26:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:26:58 2018 ] Training epoch: 961
[ Wed Apr 25 10:27:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:27:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:27:02 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:02 2018 ] Training epoch: 962
[ Wed Apr 25 10:27:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:27:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:27:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:27:06 2018 ] Training epoch: 963
[ Wed Apr 25 10:27:10 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:27:10 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:27:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:10 2018 ] Training epoch: 964
[ Wed Apr 25 10:27:14 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:27:14 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:27:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:27:14 2018 ] Training epoch: 965
[ Wed Apr 25 10:27:18 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:27:18 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:27:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:18 2018 ] Eval epoch: 965
[ Wed Apr 25 10:27:21 2018 ] 	Mean test loss of 1 batches: 0.2058318853378296.
[ Wed Apr 25 10:27:21 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:27:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:27:21 2018 ] Training epoch: 966
[ Wed Apr 25 10:27:25 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:27:25 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:27:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:27:25 2018 ] Training epoch: 967
[ Wed Apr 25 10:27:29 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:27:29 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:27:29 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:29 2018 ] Training epoch: 968
[ Wed Apr 25 10:27:34 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:27:34 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:27:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:27:34 2018 ] Training epoch: 969
[ Wed Apr 25 10:27:38 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:27:38 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:27:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:38 2018 ] Training epoch: 970
[ Wed Apr 25 10:27:42 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:27:42 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:27:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:27:42 2018 ] Eval epoch: 970
[ Wed Apr 25 10:27:44 2018 ] 	Mean test loss of 1 batches: 0.19292870163917542.
[ Wed Apr 25 10:27:44 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:27:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:27:44 2018 ] Training epoch: 971
[ Wed Apr 25 10:27:48 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:27:48 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:27:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:27:48 2018 ] Training epoch: 972
[ Wed Apr 25 10:27:52 2018 ] 	Batch(0/1) done. Loss: 0.0133  lr:0.100000
[ Wed Apr 25 10:27:52 2018 ] 	Mean training loss: 0.0133.
[ Wed Apr 25 10:27:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:27:52 2018 ] Training epoch: 973
[ Wed Apr 25 10:27:57 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:27:57 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:27:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:27:57 2018 ] Training epoch: 974
[ Wed Apr 25 10:28:01 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:28:01 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:28:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:01 2018 ] Training epoch: 975
[ Wed Apr 25 10:28:05 2018 ] 	Batch(0/1) done. Loss: 0.0136  lr:0.100000
[ Wed Apr 25 10:28:05 2018 ] 	Mean training loss: 0.0136.
[ Wed Apr 25 10:28:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:28:05 2018 ] Eval epoch: 975
[ Wed Apr 25 10:28:07 2018 ] 	Mean test loss of 1 batches: 0.13495343923568726.
[ Wed Apr 25 10:28:07 2018 ] 	Top1: 96.30%
[ Wed Apr 25 10:28:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:28:07 2018 ] Training epoch: 976
[ Wed Apr 25 10:28:11 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:28:11 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:28:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:11 2018 ] Training epoch: 977
[ Wed Apr 25 10:28:15 2018 ] 	Batch(0/1) done. Loss: 0.0046  lr:0.100000
[ Wed Apr 25 10:28:15 2018 ] 	Mean training loss: 0.0046.
[ Wed Apr 25 10:28:15 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:28:15 2018 ] Training epoch: 978
[ Wed Apr 25 10:28:20 2018 ] 	Batch(0/1) done. Loss: 0.0049  lr:0.100000
[ Wed Apr 25 10:28:20 2018 ] 	Mean training loss: 0.0049.
[ Wed Apr 25 10:28:20 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:28:20 2018 ] Training epoch: 979
[ Wed Apr 25 10:28:24 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:28:24 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:28:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:24 2018 ] Training epoch: 980
[ Wed Apr 25 10:28:28 2018 ] 	Batch(0/1) done. Loss: 0.0164  lr:0.100000
[ Wed Apr 25 10:28:28 2018 ] 	Mean training loss: 0.0164.
[ Wed Apr 25 10:28:28 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:28:28 2018 ] Eval epoch: 980
[ Wed Apr 25 10:28:31 2018 ] 	Mean test loss of 1 batches: 0.38295280933380127.
[ Wed Apr 25 10:28:31 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:28:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:28:31 2018 ] Training epoch: 981
[ Wed Apr 25 10:28:35 2018 ] 	Batch(0/1) done. Loss: 0.0117  lr:0.100000
[ Wed Apr 25 10:28:35 2018 ] 	Mean training loss: 0.0117.
[ Wed Apr 25 10:28:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:28:35 2018 ] Training epoch: 982
[ Wed Apr 25 10:28:39 2018 ] 	Batch(0/1) done. Loss: 0.0046  lr:0.100000
[ Wed Apr 25 10:28:39 2018 ] 	Mean training loss: 0.0046.
[ Wed Apr 25 10:28:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:28:39 2018 ] Training epoch: 983
[ Wed Apr 25 10:28:43 2018 ] 	Batch(0/1) done. Loss: 0.0082  lr:0.100000
[ Wed Apr 25 10:28:43 2018 ] 	Mean training loss: 0.0082.
[ Wed Apr 25 10:28:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:43 2018 ] Training epoch: 984
[ Wed Apr 25 10:28:47 2018 ] 	Batch(0/1) done. Loss: 0.0102  lr:0.100000
[ Wed Apr 25 10:28:47 2018 ] 	Mean training loss: 0.0102.
[ Wed Apr 25 10:28:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:47 2018 ] Training epoch: 985
[ Wed Apr 25 10:28:51 2018 ] 	Batch(0/1) done. Loss: 0.0175  lr:0.100000
[ Wed Apr 25 10:28:51 2018 ] 	Mean training loss: 0.0175.
[ Wed Apr 25 10:28:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:28:51 2018 ] Eval epoch: 985
[ Wed Apr 25 10:28:54 2018 ] 	Mean test loss of 1 batches: 0.4276910126209259.
[ Wed Apr 25 10:28:54 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:28:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:28:54 2018 ] Training epoch: 986
[ Wed Apr 25 10:28:58 2018 ] 	Batch(0/1) done. Loss: 0.0034  lr:0.100000
[ Wed Apr 25 10:28:58 2018 ] 	Mean training loss: 0.0034.
[ Wed Apr 25 10:28:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:28:58 2018 ] Training epoch: 987
[ Wed Apr 25 10:29:02 2018 ] 	Batch(0/1) done. Loss: 0.0061  lr:0.100000
[ Wed Apr 25 10:29:02 2018 ] 	Mean training loss: 0.0061.
[ Wed Apr 25 10:29:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:29:02 2018 ] Training epoch: 988
[ Wed Apr 25 10:29:06 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:29:06 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:29:06 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:29:06 2018 ] Training epoch: 989
[ Wed Apr 25 10:29:10 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:29:10 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:29:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:29:10 2018 ] Training epoch: 990
[ Wed Apr 25 10:29:14 2018 ] 	Batch(0/1) done. Loss: 0.0033  lr:0.100000
[ Wed Apr 25 10:29:14 2018 ] 	Mean training loss: 0.0033.
[ Wed Apr 25 10:29:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:29:14 2018 ] Eval epoch: 990
[ Wed Apr 25 10:29:17 2018 ] 	Mean test loss of 1 batches: 0.623616099357605.
[ Wed Apr 25 10:29:17 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:29:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:29:17 2018 ] Training epoch: 991
[ Wed Apr 25 10:29:21 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:29:21 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:29:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:29:21 2018 ] Training epoch: 992
[ Wed Apr 25 10:29:25 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:29:25 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:29:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:25 2018 ] Training epoch: 993
[ Wed Apr 25 10:29:29 2018 ] 	Batch(0/1) done. Loss: 0.0051  lr:0.100000
[ Wed Apr 25 10:29:29 2018 ] 	Mean training loss: 0.0051.
[ Wed Apr 25 10:29:29 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:29:29 2018 ] Training epoch: 994
[ Wed Apr 25 10:29:33 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:29:33 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:29:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:33 2018 ] Training epoch: 995
[ Wed Apr 25 10:29:37 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:29:37 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:29:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:29:37 2018 ] Eval epoch: 995
[ Wed Apr 25 10:29:40 2018 ] 	Mean test loss of 1 batches: 0.5484533905982971.
[ Wed Apr 25 10:29:40 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:29:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:29:40 2018 ] Training epoch: 996
[ Wed Apr 25 10:29:44 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:29:44 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:29:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:44 2018 ] Training epoch: 997
[ Wed Apr 25 10:29:48 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:29:48 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:29:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:48 2018 ] Training epoch: 998
[ Wed Apr 25 10:29:52 2018 ] 	Batch(0/1) done. Loss: 0.0081  lr:0.100000
[ Wed Apr 25 10:29:52 2018 ] 	Mean training loss: 0.0081.
[ Wed Apr 25 10:29:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:52 2018 ] Training epoch: 999
[ Wed Apr 25 10:29:56 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:29:56 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:29:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:29:56 2018 ] Training epoch: 1000
[ Wed Apr 25 10:30:00 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:30:00 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:30:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:30:00 2018 ] Eval epoch: 1000
[ Wed Apr 25 10:30:02 2018 ] 	Mean test loss of 1 batches: 0.6211426854133606.
[ Wed Apr 25 10:30:02 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:30:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:30:02 2018 ] Training epoch: 1001
[ Wed Apr 25 10:30:07 2018 ] 	Batch(0/1) done. Loss: 0.0045  lr:0.100000
[ Wed Apr 25 10:30:07 2018 ] 	Mean training loss: 0.0045.
[ Wed Apr 25 10:30:07 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:30:07 2018 ] Training epoch: 1002
[ Wed Apr 25 10:30:11 2018 ] 	Batch(0/1) done. Loss: 0.0081  lr:0.100000
[ Wed Apr 25 10:30:11 2018 ] 	Mean training loss: 0.0081.
[ Wed Apr 25 10:30:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:30:11 2018 ] Training epoch: 1003
[ Wed Apr 25 10:30:15 2018 ] 	Batch(0/1) done. Loss: 0.0087  lr:0.100000
[ Wed Apr 25 10:30:15 2018 ] 	Mean training loss: 0.0087.
[ Wed Apr 25 10:30:15 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:30:15 2018 ] Training epoch: 1004
[ Wed Apr 25 10:30:19 2018 ] 	Batch(0/1) done. Loss: 0.0147  lr:0.100000
[ Wed Apr 25 10:30:19 2018 ] 	Mean training loss: 0.0147.
[ Wed Apr 25 10:30:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:30:19 2018 ] Training epoch: 1005
[ Wed Apr 25 10:30:23 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:30:23 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:30:23 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:30:23 2018 ] Eval epoch: 1005
[ Wed Apr 25 10:30:26 2018 ] 	Mean test loss of 1 batches: 0.2530616223812103.
[ Wed Apr 25 10:30:26 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:30:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:30:27 2018 ] Training epoch: 1006
[ Wed Apr 25 10:30:30 2018 ] 	Batch(0/1) done. Loss: 0.0400  lr:0.100000
[ Wed Apr 25 10:30:30 2018 ] 	Mean training loss: 0.0400.
[ Wed Apr 25 10:30:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:30:30 2018 ] Training epoch: 1007
[ Wed Apr 25 10:30:34 2018 ] 	Batch(0/1) done. Loss: 0.0073  lr:0.100000
[ Wed Apr 25 10:30:34 2018 ] 	Mean training loss: 0.0073.
[ Wed Apr 25 10:30:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:30:34 2018 ] Training epoch: 1008
[ Wed Apr 25 10:30:38 2018 ] 	Batch(0/1) done. Loss: 0.0051  lr:0.100000
[ Wed Apr 25 10:30:38 2018 ] 	Mean training loss: 0.0051.
[ Wed Apr 25 10:30:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:30:38 2018 ] Training epoch: 1009
[ Wed Apr 25 10:30:43 2018 ] 	Batch(0/1) done. Loss: 0.0028  lr:0.100000
[ Wed Apr 25 10:30:43 2018 ] 	Mean training loss: 0.0028.
[ Wed Apr 25 10:30:43 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:30:43 2018 ] Training epoch: 1010
[ Wed Apr 25 10:30:47 2018 ] 	Batch(0/1) done. Loss: 0.0176  lr:0.100000
[ Wed Apr 25 10:30:47 2018 ] 	Mean training loss: 0.0176.
[ Wed Apr 25 10:30:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:30:47 2018 ] Eval epoch: 1010
[ Wed Apr 25 10:30:50 2018 ] 	Mean test loss of 1 batches: 0.21564005315303802.
[ Wed Apr 25 10:30:50 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:30:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:30:50 2018 ] Training epoch: 1011
[ Wed Apr 25 10:30:54 2018 ] 	Batch(0/1) done. Loss: 0.0082  lr:0.100000
[ Wed Apr 25 10:30:54 2018 ] 	Mean training loss: 0.0082.
[ Wed Apr 25 10:30:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:30:54 2018 ] Training epoch: 1012
[ Wed Apr 25 10:30:58 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:30:58 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:30:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:30:58 2018 ] Training epoch: 1013
[ Wed Apr 25 10:31:02 2018 ] 	Batch(0/1) done. Loss: 0.0070  lr:0.100000
[ Wed Apr 25 10:31:02 2018 ] 	Mean training loss: 0.0070.
[ Wed Apr 25 10:31:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:31:02 2018 ] Training epoch: 1014
[ Wed Apr 25 10:31:06 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:31:06 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:31:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:31:06 2018 ] Training epoch: 1015
[ Wed Apr 25 10:31:10 2018 ] 	Batch(0/1) done. Loss: 0.0085  lr:0.100000
[ Wed Apr 25 10:31:10 2018 ] 	Mean training loss: 0.0085.
[ Wed Apr 25 10:31:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:31:10 2018 ] Eval epoch: 1015
[ Wed Apr 25 10:31:13 2018 ] 	Mean test loss of 1 batches: 0.1941164880990982.
[ Wed Apr 25 10:31:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:31:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:31:13 2018 ] Training epoch: 1016
[ Wed Apr 25 10:31:18 2018 ] 	Batch(0/1) done. Loss: 0.0616  lr:0.100000
[ Wed Apr 25 10:31:18 2018 ] 	Mean training loss: 0.0616.
[ Wed Apr 25 10:31:18 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:31:18 2018 ] Training epoch: 1017
[ Wed Apr 25 10:31:22 2018 ] 	Batch(0/1) done. Loss: 0.0063  lr:0.100000
[ Wed Apr 25 10:31:22 2018 ] 	Mean training loss: 0.0063.
[ Wed Apr 25 10:31:22 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:31:22 2018 ] Training epoch: 1018
[ Wed Apr 25 10:31:26 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:31:26 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:31:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:31:26 2018 ] Training epoch: 1019
[ Wed Apr 25 10:31:30 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:31:30 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:31:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:31:30 2018 ] Training epoch: 1020
[ Wed Apr 25 10:31:34 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:31:34 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:31:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:31:34 2018 ] Eval epoch: 1020
[ Wed Apr 25 10:31:37 2018 ] 	Mean test loss of 1 batches: 0.5291150212287903.
[ Wed Apr 25 10:31:37 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:31:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:31:37 2018 ] Training epoch: 1021
[ Wed Apr 25 10:31:41 2018 ] 	Batch(0/1) done. Loss: 0.0156  lr:0.100000
[ Wed Apr 25 10:31:41 2018 ] 	Mean training loss: 0.0156.
[ Wed Apr 25 10:31:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:31:41 2018 ] Training epoch: 1022
[ Wed Apr 25 10:31:46 2018 ] 	Batch(0/1) done. Loss: 0.0983  lr:0.100000
[ Wed Apr 25 10:31:46 2018 ] 	Mean training loss: 0.0983.
[ Wed Apr 25 10:31:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:31:46 2018 ] Training epoch: 1023
[ Wed Apr 25 10:31:50 2018 ] 	Batch(0/1) done. Loss: 0.0077  lr:0.100000
[ Wed Apr 25 10:31:50 2018 ] 	Mean training loss: 0.0077.
[ Wed Apr 25 10:31:50 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:31:50 2018 ] Training epoch: 1024
[ Wed Apr 25 10:31:54 2018 ] 	Batch(0/1) done. Loss: 0.0084  lr:0.100000
[ Wed Apr 25 10:31:54 2018 ] 	Mean training loss: 0.0084.
[ Wed Apr 25 10:31:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:31:54 2018 ] Training epoch: 1025
[ Wed Apr 25 10:31:58 2018 ] 	Batch(0/1) done. Loss: 0.0058  lr:0.100000
[ Wed Apr 25 10:31:58 2018 ] 	Mean training loss: 0.0058.
[ Wed Apr 25 10:31:58 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:31:58 2018 ] Eval epoch: 1025
[ Wed Apr 25 10:32:01 2018 ] 	Mean test loss of 1 batches: 0.0828295573592186.
[ Wed Apr 25 10:32:01 2018 ] 	Top1: 96.30%
[ Wed Apr 25 10:32:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:32:01 2018 ] Training epoch: 1026
[ Wed Apr 25 10:32:05 2018 ] 	Batch(0/1) done. Loss: 0.0064  lr:0.100000
[ Wed Apr 25 10:32:05 2018 ] 	Mean training loss: 0.0064.
[ Wed Apr 25 10:32:05 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:32:05 2018 ] Training epoch: 1027
[ Wed Apr 25 10:32:10 2018 ] 	Batch(0/1) done. Loss: 0.0065  lr:0.100000
[ Wed Apr 25 10:32:10 2018 ] 	Mean training loss: 0.0065.
[ Wed Apr 25 10:32:10 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:32:10 2018 ] Training epoch: 1028
[ Wed Apr 25 10:32:14 2018 ] 	Batch(0/1) done. Loss: 0.0614  lr:0.100000
[ Wed Apr 25 10:32:14 2018 ] 	Mean training loss: 0.0614.
[ Wed Apr 25 10:32:14 2018 ] 	Time consumption: [Data]79%, [Network]20%
[ Wed Apr 25 10:32:14 2018 ] Training epoch: 1029
[ Wed Apr 25 10:32:18 2018 ] 	Batch(0/1) done. Loss: 0.0992  lr:0.100000
[ Wed Apr 25 10:32:18 2018 ] 	Mean training loss: 0.0992.
[ Wed Apr 25 10:32:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:18 2018 ] Training epoch: 1030
[ Wed Apr 25 10:32:22 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:32:22 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:32:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:22 2018 ] Eval epoch: 1030
[ Wed Apr 25 10:32:26 2018 ] 	Mean test loss of 1 batches: 0.25139546394348145.
[ Wed Apr 25 10:32:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:32:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:32:26 2018 ] Training epoch: 1031
[ Wed Apr 25 10:32:30 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:32:30 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:32:30 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:32:30 2018 ] Training epoch: 1032
[ Wed Apr 25 10:32:34 2018 ] 	Batch(0/1) done. Loss: 0.0096  lr:0.100000
[ Wed Apr 25 10:32:34 2018 ] 	Mean training loss: 0.0096.
[ Wed Apr 25 10:32:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:34 2018 ] Training epoch: 1033
[ Wed Apr 25 10:32:38 2018 ] 	Batch(0/1) done. Loss: 0.0085  lr:0.100000
[ Wed Apr 25 10:32:38 2018 ] 	Mean training loss: 0.0085.
[ Wed Apr 25 10:32:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:38 2018 ] Training epoch: 1034
[ Wed Apr 25 10:32:42 2018 ] 	Batch(0/1) done. Loss: 0.0082  lr:0.100000
[ Wed Apr 25 10:32:42 2018 ] 	Mean training loss: 0.0082.
[ Wed Apr 25 10:32:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:32:42 2018 ] Training epoch: 1035
[ Wed Apr 25 10:32:46 2018 ] 	Batch(0/1) done. Loss: 0.0354  lr:0.100000
[ Wed Apr 25 10:32:46 2018 ] 	Mean training loss: 0.0354.
[ Wed Apr 25 10:32:46 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:32:46 2018 ] Eval epoch: 1035
[ Wed Apr 25 10:32:49 2018 ] 	Mean test loss of 1 batches: 0.44303324818611145.
[ Wed Apr 25 10:32:49 2018 ] 	Top1: 81.48%
[ Wed Apr 25 10:32:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:32:49 2018 ] Training epoch: 1036
[ Wed Apr 25 10:32:53 2018 ] 	Batch(0/1) done. Loss: 0.0080  lr:0.100000
[ Wed Apr 25 10:32:53 2018 ] 	Mean training loss: 0.0080.
[ Wed Apr 25 10:32:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:53 2018 ] Training epoch: 1037
[ Wed Apr 25 10:32:58 2018 ] 	Batch(0/1) done. Loss: 0.0129  lr:0.100000
[ Wed Apr 25 10:32:58 2018 ] 	Mean training loss: 0.0129.
[ Wed Apr 25 10:32:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:32:58 2018 ] Training epoch: 1038
[ Wed Apr 25 10:33:02 2018 ] 	Batch(0/1) done. Loss: 0.0085  lr:0.100000
[ Wed Apr 25 10:33:02 2018 ] 	Mean training loss: 0.0085.
[ Wed Apr 25 10:33:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:02 2018 ] Training epoch: 1039
[ Wed Apr 25 10:33:06 2018 ] 	Batch(0/1) done. Loss: 0.0040  lr:0.100000
[ Wed Apr 25 10:33:06 2018 ] 	Mean training loss: 0.0040.
[ Wed Apr 25 10:33:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:06 2018 ] Training epoch: 1040
[ Wed Apr 25 10:33:10 2018 ] 	Batch(0/1) done. Loss: 0.0066  lr:0.100000
[ Wed Apr 25 10:33:10 2018 ] 	Mean training loss: 0.0066.
[ Wed Apr 25 10:33:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:10 2018 ] Eval epoch: 1040
[ Wed Apr 25 10:33:13 2018 ] 	Mean test loss of 1 batches: 0.5017815828323364.
[ Wed Apr 25 10:33:13 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:33:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:33:13 2018 ] Training epoch: 1041
[ Wed Apr 25 10:33:17 2018 ] 	Batch(0/1) done. Loss: 0.0101  lr:0.100000
[ Wed Apr 25 10:33:17 2018 ] 	Mean training loss: 0.0101.
[ Wed Apr 25 10:33:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:17 2018 ] Training epoch: 1042
[ Wed Apr 25 10:33:21 2018 ] 	Batch(0/1) done. Loss: 0.0133  lr:0.100000
[ Wed Apr 25 10:33:21 2018 ] 	Mean training loss: 0.0133.
[ Wed Apr 25 10:33:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:21 2018 ] Training epoch: 1043
[ Wed Apr 25 10:33:25 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:33:25 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:33:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:25 2018 ] Training epoch: 1044
[ Wed Apr 25 10:33:29 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:33:29 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:33:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:29 2018 ] Training epoch: 1045
[ Wed Apr 25 10:33:33 2018 ] 	Batch(0/1) done. Loss: 0.0042  lr:0.100000
[ Wed Apr 25 10:33:33 2018 ] 	Mean training loss: 0.0042.
[ Wed Apr 25 10:33:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:33 2018 ] Eval epoch: 1045
[ Wed Apr 25 10:33:36 2018 ] 	Mean test loss of 1 batches: 0.4979908764362335.
[ Wed Apr 25 10:33:36 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:33:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:33:36 2018 ] Training epoch: 1046
[ Wed Apr 25 10:33:40 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 10:33:40 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 10:33:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:40 2018 ] Training epoch: 1047
[ Wed Apr 25 10:33:44 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:33:44 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:33:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:44 2018 ] Training epoch: 1048
[ Wed Apr 25 10:33:48 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:33:48 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:33:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:48 2018 ] Training epoch: 1049
[ Wed Apr 25 10:33:52 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:33:52 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:33:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:52 2018 ] Training epoch: 1050
[ Wed Apr 25 10:33:56 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:33:56 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:33:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:33:56 2018 ] Eval epoch: 1050
[ Wed Apr 25 10:33:59 2018 ] 	Mean test loss of 1 batches: 0.41521167755126953.
[ Wed Apr 25 10:33:59 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:33:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:33:59 2018 ] Training epoch: 1051
[ Wed Apr 25 10:34:03 2018 ] 	Batch(0/1) done. Loss: 0.0025  lr:0.100000
[ Wed Apr 25 10:34:03 2018 ] 	Mean training loss: 0.0025.
[ Wed Apr 25 10:34:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:03 2018 ] Training epoch: 1052
[ Wed Apr 25 10:34:07 2018 ] 	Batch(0/1) done. Loss: 0.0036  lr:0.100000
[ Wed Apr 25 10:34:07 2018 ] 	Mean training loss: 0.0036.
[ Wed Apr 25 10:34:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:07 2018 ] Training epoch: 1053
[ Wed Apr 25 10:34:11 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:34:11 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:34:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:11 2018 ] Training epoch: 1054
[ Wed Apr 25 10:34:15 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:34:15 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:34:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:15 2018 ] Training epoch: 1055
[ Wed Apr 25 10:34:19 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:34:19 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:34:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:19 2018 ] Eval epoch: 1055
[ Wed Apr 25 10:34:22 2018 ] 	Mean test loss of 1 batches: 0.43167635798454285.
[ Wed Apr 25 10:34:22 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:34:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:34:22 2018 ] Training epoch: 1056
[ Wed Apr 25 10:34:26 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:34:26 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:34:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:26 2018 ] Training epoch: 1057
[ Wed Apr 25 10:34:30 2018 ] 	Batch(0/1) done. Loss: 0.0034  lr:0.100000
[ Wed Apr 25 10:34:30 2018 ] 	Mean training loss: 0.0034.
[ Wed Apr 25 10:34:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:30 2018 ] Training epoch: 1058
[ Wed Apr 25 10:34:34 2018 ] 	Batch(0/1) done. Loss: 0.0026  lr:0.100000
[ Wed Apr 25 10:34:34 2018 ] 	Mean training loss: 0.0026.
[ Wed Apr 25 10:34:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:34 2018 ] Training epoch: 1059
[ Wed Apr 25 10:34:38 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:34:38 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:34:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:38 2018 ] Training epoch: 1060
[ Wed Apr 25 10:34:42 2018 ] 	Batch(0/1) done. Loss: 0.0042  lr:0.100000
[ Wed Apr 25 10:34:42 2018 ] 	Mean training loss: 0.0042.
[ Wed Apr 25 10:34:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:42 2018 ] Eval epoch: 1060
[ Wed Apr 25 10:34:45 2018 ] 	Mean test loss of 1 batches: 0.37394073605537415.
[ Wed Apr 25 10:34:45 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:34:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:34:45 2018 ] Training epoch: 1061
[ Wed Apr 25 10:34:49 2018 ] 	Batch(0/1) done. Loss: 0.0028  lr:0.100000
[ Wed Apr 25 10:34:49 2018 ] 	Mean training loss: 0.0028.
[ Wed Apr 25 10:34:49 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:34:49 2018 ] Training epoch: 1062
[ Wed Apr 25 10:34:54 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:34:54 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:34:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:54 2018 ] Training epoch: 1063
[ Wed Apr 25 10:34:58 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:34:58 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:34:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:34:58 2018 ] Training epoch: 1064
[ Wed Apr 25 10:35:02 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:35:02 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:35:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:02 2018 ] Training epoch: 1065
[ Wed Apr 25 10:35:06 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:35:06 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:35:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:06 2018 ] Eval epoch: 1065
[ Wed Apr 25 10:35:09 2018 ] 	Mean test loss of 1 batches: 0.2664966881275177.
[ Wed Apr 25 10:35:09 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:35:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:35:09 2018 ] Training epoch: 1066
[ Wed Apr 25 10:35:13 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:35:13 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:35:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:13 2018 ] Training epoch: 1067
[ Wed Apr 25 10:35:17 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:35:17 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:35:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:17 2018 ] Training epoch: 1068
[ Wed Apr 25 10:35:21 2018 ] 	Batch(0/1) done. Loss: 0.0071  lr:0.100000
[ Wed Apr 25 10:35:21 2018 ] 	Mean training loss: 0.0071.
[ Wed Apr 25 10:35:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:21 2018 ] Training epoch: 1069
[ Wed Apr 25 10:35:25 2018 ] 	Batch(0/1) done. Loss: 0.0029  lr:0.100000
[ Wed Apr 25 10:35:25 2018 ] 	Mean training loss: 0.0029.
[ Wed Apr 25 10:35:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:25 2018 ] Training epoch: 1070
[ Wed Apr 25 10:35:29 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:35:29 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:35:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:29 2018 ] Eval epoch: 1070
[ Wed Apr 25 10:35:31 2018 ] 	Mean test loss of 1 batches: 0.3358413577079773.
[ Wed Apr 25 10:35:31 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:35:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:35:31 2018 ] Training epoch: 1071
[ Wed Apr 25 10:35:35 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:35:35 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:35:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:35 2018 ] Training epoch: 1072
[ Wed Apr 25 10:35:40 2018 ] 	Batch(0/1) done. Loss: 0.0037  lr:0.100000
[ Wed Apr 25 10:35:40 2018 ] 	Mean training loss: 0.0037.
[ Wed Apr 25 10:35:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:40 2018 ] Training epoch: 1073
[ Wed Apr 25 10:35:43 2018 ] 	Batch(0/1) done. Loss: 0.0053  lr:0.100000
[ Wed Apr 25 10:35:44 2018 ] 	Mean training loss: 0.0053.
[ Wed Apr 25 10:35:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:44 2018 ] Training epoch: 1074
[ Wed Apr 25 10:35:48 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:35:48 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:35:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:48 2018 ] Training epoch: 1075
[ Wed Apr 25 10:35:52 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:35:52 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:35:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:52 2018 ] Eval epoch: 1075
[ Wed Apr 25 10:35:54 2018 ] 	Mean test loss of 1 batches: 0.3392132520675659.
[ Wed Apr 25 10:35:54 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:35:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:35:54 2018 ] Training epoch: 1076
[ Wed Apr 25 10:35:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:35:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:35:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:35:58 2018 ] Training epoch: 1077
[ Wed Apr 25 10:36:02 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:36:02 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:36:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:02 2018 ] Training epoch: 1078
[ Wed Apr 25 10:36:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:36:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:36:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:06 2018 ] Training epoch: 1079
[ Wed Apr 25 10:36:10 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:36:10 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:36:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:10 2018 ] Training epoch: 1080
[ Wed Apr 25 10:36:14 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:36:14 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:36:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:14 2018 ] Eval epoch: 1080
[ Wed Apr 25 10:36:17 2018 ] 	Mean test loss of 1 batches: 0.36022433638572693.
[ Wed Apr 25 10:36:17 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:36:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:36:17 2018 ] Training epoch: 1081
[ Wed Apr 25 10:36:21 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:36:21 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:36:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:21 2018 ] Training epoch: 1082
[ Wed Apr 25 10:36:25 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:36:25 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:36:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:25 2018 ] Training epoch: 1083
[ Wed Apr 25 10:36:29 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:36:29 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:36:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:29 2018 ] Training epoch: 1084
[ Wed Apr 25 10:36:33 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:36:33 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:36:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:33 2018 ] Training epoch: 1085
[ Wed Apr 25 10:36:37 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:36:37 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:36:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:37 2018 ] Eval epoch: 1085
[ Wed Apr 25 10:36:40 2018 ] 	Mean test loss of 1 batches: 0.31522348523139954.
[ Wed Apr 25 10:36:40 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:36:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:36:40 2018 ] Training epoch: 1086
[ Wed Apr 25 10:36:44 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:36:44 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:36:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:44 2018 ] Training epoch: 1087
[ Wed Apr 25 10:36:48 2018 ] 	Batch(0/1) done. Loss: 0.0040  lr:0.100000
[ Wed Apr 25 10:36:48 2018 ] 	Mean training loss: 0.0040.
[ Wed Apr 25 10:36:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:48 2018 ] Training epoch: 1088
[ Wed Apr 25 10:36:52 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:36:52 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:36:52 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:36:52 2018 ] Training epoch: 1089
[ Wed Apr 25 10:36:56 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:36:56 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:36:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:36:56 2018 ] Training epoch: 1090
[ Wed Apr 25 10:37:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:37:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:37:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:00 2018 ] Eval epoch: 1090
[ Wed Apr 25 10:37:03 2018 ] 	Mean test loss of 1 batches: 0.4940628409385681.
[ Wed Apr 25 10:37:03 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:37:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:37:03 2018 ] Training epoch: 1091
[ Wed Apr 25 10:37:07 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:37:07 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:37:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:07 2018 ] Training epoch: 1092
[ Wed Apr 25 10:37:11 2018 ] 	Batch(0/1) done. Loss: 0.0054  lr:0.100000
[ Wed Apr 25 10:37:11 2018 ] 	Mean training loss: 0.0054.
[ Wed Apr 25 10:37:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:11 2018 ] Training epoch: 1093
[ Wed Apr 25 10:37:16 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:37:16 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:37:16 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:37:16 2018 ] Training epoch: 1094
[ Wed Apr 25 10:37:20 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:37:20 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:37:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:20 2018 ] Training epoch: 1095
[ Wed Apr 25 10:37:24 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:37:24 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:37:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:24 2018 ] Eval epoch: 1095
[ Wed Apr 25 10:37:27 2018 ] 	Mean test loss of 1 batches: 0.6080595850944519.
[ Wed Apr 25 10:37:27 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:37:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:37:27 2018 ] Training epoch: 1096
[ Wed Apr 25 10:37:31 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:37:31 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:37:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:31 2018 ] Training epoch: 1097
[ Wed Apr 25 10:37:35 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:37:35 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:37:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:35 2018 ] Training epoch: 1098
[ Wed Apr 25 10:37:39 2018 ] 	Batch(0/1) done. Loss: 0.0072  lr:0.100000
[ Wed Apr 25 10:37:39 2018 ] 	Mean training loss: 0.0072.
[ Wed Apr 25 10:37:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:39 2018 ] Training epoch: 1099
[ Wed Apr 25 10:37:43 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:37:43 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:37:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:43 2018 ] Training epoch: 1100
[ Wed Apr 25 10:37:47 2018 ] 	Batch(0/1) done. Loss: 0.0039  lr:0.100000
[ Wed Apr 25 10:37:47 2018 ] 	Mean training loss: 0.0039.
[ Wed Apr 25 10:37:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:47 2018 ] Eval epoch: 1100
[ Wed Apr 25 10:37:50 2018 ] 	Mean test loss of 1 batches: 0.4326586127281189.
[ Wed Apr 25 10:37:50 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:37:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:37:50 2018 ] Training epoch: 1101
[ Wed Apr 25 10:37:54 2018 ] 	Batch(0/1) done. Loss: 0.0156  lr:0.100000
[ Wed Apr 25 10:37:54 2018 ] 	Mean training loss: 0.0156.
[ Wed Apr 25 10:37:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:54 2018 ] Training epoch: 1102
[ Wed Apr 25 10:37:58 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:37:58 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:37:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:37:58 2018 ] Training epoch: 1103
[ Wed Apr 25 10:38:02 2018 ] 	Batch(0/1) done. Loss: 0.0077  lr:0.100000
[ Wed Apr 25 10:38:02 2018 ] 	Mean training loss: 0.0077.
[ Wed Apr 25 10:38:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:02 2018 ] Training epoch: 1104
[ Wed Apr 25 10:38:06 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:38:06 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:38:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:06 2018 ] Training epoch: 1105
[ Wed Apr 25 10:38:10 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:38:10 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:38:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:10 2018 ] Eval epoch: 1105
[ Wed Apr 25 10:38:13 2018 ] 	Mean test loss of 1 batches: 0.47666436433792114.
[ Wed Apr 25 10:38:13 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:38:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:38:13 2018 ] Training epoch: 1106
[ Wed Apr 25 10:38:17 2018 ] 	Batch(0/1) done. Loss: 0.0026  lr:0.100000
[ Wed Apr 25 10:38:17 2018 ] 	Mean training loss: 0.0026.
[ Wed Apr 25 10:38:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:17 2018 ] Training epoch: 1107
[ Wed Apr 25 10:38:21 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:38:21 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:38:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:21 2018 ] Training epoch: 1108
[ Wed Apr 25 10:38:25 2018 ] 	Batch(0/1) done. Loss: 0.0183  lr:0.100000
[ Wed Apr 25 10:38:25 2018 ] 	Mean training loss: 0.0183.
[ Wed Apr 25 10:38:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:25 2018 ] Training epoch: 1109
[ Wed Apr 25 10:38:29 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:38:29 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:38:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:29 2018 ] Training epoch: 1110
[ Wed Apr 25 10:38:33 2018 ] 	Batch(0/1) done. Loss: 0.0033  lr:0.100000
[ Wed Apr 25 10:38:33 2018 ] 	Mean training loss: 0.0033.
[ Wed Apr 25 10:38:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:33 2018 ] Eval epoch: 1110
[ Wed Apr 25 10:38:36 2018 ] 	Mean test loss of 1 batches: 0.40147602558135986.
[ Wed Apr 25 10:38:36 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:38:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:38:36 2018 ] Training epoch: 1111
[ Wed Apr 25 10:38:40 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:38:40 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:38:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:40 2018 ] Training epoch: 1112
[ Wed Apr 25 10:38:44 2018 ] 	Batch(0/1) done. Loss: 0.0087  lr:0.100000
[ Wed Apr 25 10:38:44 2018 ] 	Mean training loss: 0.0087.
[ Wed Apr 25 10:38:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:44 2018 ] Training epoch: 1113
[ Wed Apr 25 10:38:48 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:38:48 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:38:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:48 2018 ] Training epoch: 1114
[ Wed Apr 25 10:38:52 2018 ] 	Batch(0/1) done. Loss: 0.0051  lr:0.100000
[ Wed Apr 25 10:38:52 2018 ] 	Mean training loss: 0.0051.
[ Wed Apr 25 10:38:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:52 2018 ] Training epoch: 1115
[ Wed Apr 25 10:38:56 2018 ] 	Batch(0/1) done. Loss: 0.0080  lr:0.100000
[ Wed Apr 25 10:38:56 2018 ] 	Mean training loss: 0.0080.
[ Wed Apr 25 10:38:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:38:56 2018 ] Eval epoch: 1115
[ Wed Apr 25 10:38:59 2018 ] 	Mean test loss of 1 batches: 0.30954253673553467.
[ Wed Apr 25 10:38:59 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:38:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:38:59 2018 ] Training epoch: 1116
[ Wed Apr 25 10:39:03 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:39:03 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:39:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:03 2018 ] Training epoch: 1117
[ Wed Apr 25 10:39:07 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:39:07 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:39:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:07 2018 ] Training epoch: 1118
[ Wed Apr 25 10:39:11 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:39:11 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:39:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:11 2018 ] Training epoch: 1119
[ Wed Apr 25 10:39:15 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:39:15 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:39:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:15 2018 ] Training epoch: 1120
[ Wed Apr 25 10:39:19 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:39:19 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:39:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:19 2018 ] Eval epoch: 1120
[ Wed Apr 25 10:39:22 2018 ] 	Mean test loss of 1 batches: 0.3146381974220276.
[ Wed Apr 25 10:39:22 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:39:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:39:22 2018 ] Training epoch: 1121
[ Wed Apr 25 10:39:26 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:39:26 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:39:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:26 2018 ] Training epoch: 1122
[ Wed Apr 25 10:39:30 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:39:30 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:39:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:30 2018 ] Training epoch: 1123
[ Wed Apr 25 10:39:34 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:39:34 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:39:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:34 2018 ] Training epoch: 1124
[ Wed Apr 25 10:39:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:39:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:39:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:38 2018 ] Training epoch: 1125
[ Wed Apr 25 10:39:42 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:39:42 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:39:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:42 2018 ] Eval epoch: 1125
[ Wed Apr 25 10:39:45 2018 ] 	Mean test loss of 1 batches: 0.33902639150619507.
[ Wed Apr 25 10:39:45 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:39:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:39:45 2018 ] Training epoch: 1126
[ Wed Apr 25 10:39:49 2018 ] 	Batch(0/1) done. Loss: 0.0032  lr:0.100000
[ Wed Apr 25 10:39:49 2018 ] 	Mean training loss: 0.0032.
[ Wed Apr 25 10:39:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:49 2018 ] Training epoch: 1127
[ Wed Apr 25 10:39:53 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:39:53 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:39:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:53 2018 ] Training epoch: 1128
[ Wed Apr 25 10:39:57 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:39:57 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:39:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:39:57 2018 ] Training epoch: 1129
[ Wed Apr 25 10:40:01 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:40:01 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:40:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:01 2018 ] Training epoch: 1130
[ Wed Apr 25 10:40:05 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:40:05 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:40:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:05 2018 ] Eval epoch: 1130
[ Wed Apr 25 10:40:08 2018 ] 	Mean test loss of 1 batches: 0.31959015130996704.
[ Wed Apr 25 10:40:08 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:40:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:40:08 2018 ] Training epoch: 1131
[ Wed Apr 25 10:40:12 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:40:12 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:40:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:12 2018 ] Training epoch: 1132
[ Wed Apr 25 10:40:16 2018 ] 	Batch(0/1) done. Loss: 0.0067  lr:0.100000
[ Wed Apr 25 10:40:16 2018 ] 	Mean training loss: 0.0067.
[ Wed Apr 25 10:40:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:16 2018 ] Training epoch: 1133
[ Wed Apr 25 10:40:20 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:40:20 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:40:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:20 2018 ] Training epoch: 1134
[ Wed Apr 25 10:40:24 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:40:24 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:40:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:24 2018 ] Training epoch: 1135
[ Wed Apr 25 10:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:40:28 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:40:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:28 2018 ] Eval epoch: 1135
[ Wed Apr 25 10:40:31 2018 ] 	Mean test loss of 1 batches: 0.2745343744754791.
[ Wed Apr 25 10:40:31 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:40:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:40:31 2018 ] Training epoch: 1136
[ Wed Apr 25 10:40:35 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:40:35 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:40:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:35 2018 ] Training epoch: 1137
[ Wed Apr 25 10:40:39 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:40:39 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:40:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:39 2018 ] Training epoch: 1138
[ Wed Apr 25 10:40:43 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:40:43 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:40:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:43 2018 ] Training epoch: 1139
[ Wed Apr 25 10:40:47 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:40:47 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:40:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:47 2018 ] Training epoch: 1140
[ Wed Apr 25 10:40:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:40:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:40:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:52 2018 ] Eval epoch: 1140
[ Wed Apr 25 10:40:54 2018 ] 	Mean test loss of 1 batches: 0.2811729609966278.
[ Wed Apr 25 10:40:54 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:40:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:40:54 2018 ] Training epoch: 1141
[ Wed Apr 25 10:40:58 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:40:58 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:40:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:40:58 2018 ] Training epoch: 1142
[ Wed Apr 25 10:41:02 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:41:02 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:41:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:02 2018 ] Training epoch: 1143
[ Wed Apr 25 10:41:06 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:41:06 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:41:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:06 2018 ] Training epoch: 1144
[ Wed Apr 25 10:41:10 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:41:10 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:41:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:10 2018 ] Training epoch: 1145
[ Wed Apr 25 10:41:14 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:41:14 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:41:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:14 2018 ] Eval epoch: 1145
[ Wed Apr 25 10:41:17 2018 ] 	Mean test loss of 1 batches: 0.3152740001678467.
[ Wed Apr 25 10:41:17 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:41:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:41:17 2018 ] Training epoch: 1146
[ Wed Apr 25 10:41:21 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:41:21 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:41:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:21 2018 ] Training epoch: 1147
[ Wed Apr 25 10:41:25 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:41:25 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:41:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:25 2018 ] Training epoch: 1148
[ Wed Apr 25 10:41:29 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:41:29 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:41:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:29 2018 ] Training epoch: 1149
[ Wed Apr 25 10:41:33 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:41:33 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:41:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:33 2018 ] Training epoch: 1150
[ Wed Apr 25 10:41:38 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:41:38 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:41:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:41:38 2018 ] Eval epoch: 1150
[ Wed Apr 25 10:41:40 2018 ] 	Mean test loss of 1 batches: 0.29472872614860535.
[ Wed Apr 25 10:41:40 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:41:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:41:40 2018 ] Training epoch: 1151
[ Wed Apr 25 10:41:45 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:41:45 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:41:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:45 2018 ] Training epoch: 1152
[ Wed Apr 25 10:41:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:41:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:41:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:49 2018 ] Training epoch: 1153
[ Wed Apr 25 10:41:53 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:41:53 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:41:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:53 2018 ] Training epoch: 1154
[ Wed Apr 25 10:41:57 2018 ] 	Batch(0/1) done. Loss: 0.0177  lr:0.100000
[ Wed Apr 25 10:41:57 2018 ] 	Mean training loss: 0.0177.
[ Wed Apr 25 10:41:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:41:57 2018 ] Training epoch: 1155
[ Wed Apr 25 10:42:01 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:42:01 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:42:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:01 2018 ] Eval epoch: 1155
[ Wed Apr 25 10:42:04 2018 ] 	Mean test loss of 1 batches: 0.3511241674423218.
[ Wed Apr 25 10:42:04 2018 ] 	Top1: 85.19%
[ Wed Apr 25 10:42:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:42:04 2018 ] Training epoch: 1156
[ Wed Apr 25 10:42:08 2018 ] 	Batch(0/1) done. Loss: 0.0090  lr:0.100000
[ Wed Apr 25 10:42:08 2018 ] 	Mean training loss: 0.0090.
[ Wed Apr 25 10:42:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:08 2018 ] Training epoch: 1157
[ Wed Apr 25 10:42:12 2018 ] 	Batch(0/1) done. Loss: 0.0028  lr:0.100000
[ Wed Apr 25 10:42:12 2018 ] 	Mean training loss: 0.0028.
[ Wed Apr 25 10:42:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:12 2018 ] Training epoch: 1158
[ Wed Apr 25 10:42:16 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:42:16 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:42:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:16 2018 ] Training epoch: 1159
[ Wed Apr 25 10:42:20 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:42:20 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:42:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:20 2018 ] Training epoch: 1160
[ Wed Apr 25 10:42:24 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:42:24 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:42:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:24 2018 ] Eval epoch: 1160
[ Wed Apr 25 10:42:27 2018 ] 	Mean test loss of 1 batches: 0.21396218240261078.
[ Wed Apr 25 10:42:27 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:42:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:42:27 2018 ] Training epoch: 1161
[ Wed Apr 25 10:42:31 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:42:31 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:42:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:31 2018 ] Training epoch: 1162
[ Wed Apr 25 10:42:35 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:42:35 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:42:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:35 2018 ] Training epoch: 1163
[ Wed Apr 25 10:42:39 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:42:39 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:42:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:39 2018 ] Training epoch: 1164
[ Wed Apr 25 10:42:43 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:42:43 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:42:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:43 2018 ] Training epoch: 1165
[ Wed Apr 25 10:42:47 2018 ] 	Batch(0/1) done. Loss: 0.0157  lr:0.100000
[ Wed Apr 25 10:42:47 2018 ] 	Mean training loss: 0.0157.
[ Wed Apr 25 10:42:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:47 2018 ] Eval epoch: 1165
[ Wed Apr 25 10:42:50 2018 ] 	Mean test loss of 1 batches: 0.20806732773780823.
[ Wed Apr 25 10:42:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:42:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:42:50 2018 ] Training epoch: 1166
[ Wed Apr 25 10:42:54 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:42:54 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:42:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:54 2018 ] Training epoch: 1167
[ Wed Apr 25 10:42:58 2018 ] 	Batch(0/1) done. Loss: 0.0031  lr:0.100000
[ Wed Apr 25 10:42:58 2018 ] 	Mean training loss: 0.0031.
[ Wed Apr 25 10:42:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:42:58 2018 ] Training epoch: 1168
[ Wed Apr 25 10:43:02 2018 ] 	Batch(0/1) done. Loss: 0.0042  lr:0.100000
[ Wed Apr 25 10:43:02 2018 ] 	Mean training loss: 0.0042.
[ Wed Apr 25 10:43:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:02 2018 ] Training epoch: 1169
[ Wed Apr 25 10:43:06 2018 ] 	Batch(0/1) done. Loss: 0.0128  lr:0.100000
[ Wed Apr 25 10:43:06 2018 ] 	Mean training loss: 0.0128.
[ Wed Apr 25 10:43:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:06 2018 ] Training epoch: 1170
[ Wed Apr 25 10:43:10 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:43:10 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:43:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:10 2018 ] Eval epoch: 1170
[ Wed Apr 25 10:43:13 2018 ] 	Mean test loss of 1 batches: 0.22263231873512268.
[ Wed Apr 25 10:43:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:43:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:43:13 2018 ] Training epoch: 1171
[ Wed Apr 25 10:43:17 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:43:17 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:43:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:17 2018 ] Training epoch: 1172
[ Wed Apr 25 10:43:21 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:43:21 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:43:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:43:21 2018 ] Training epoch: 1173
[ Wed Apr 25 10:43:25 2018 ] 	Batch(0/1) done. Loss: 0.0134  lr:0.100000
[ Wed Apr 25 10:43:25 2018 ] 	Mean training loss: 0.0134.
[ Wed Apr 25 10:43:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:25 2018 ] Training epoch: 1174
[ Wed Apr 25 10:43:29 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:43:29 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:43:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:29 2018 ] Training epoch: 1175
[ Wed Apr 25 10:43:33 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:43:33 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:43:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:33 2018 ] Eval epoch: 1175
[ Wed Apr 25 10:43:36 2018 ] 	Mean test loss of 1 batches: 0.21277417242527008.
[ Wed Apr 25 10:43:36 2018 ] 	Top1: 96.30%
[ Wed Apr 25 10:43:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:43:36 2018 ] Training epoch: 1176
[ Wed Apr 25 10:43:40 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:43:40 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:43:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:40 2018 ] Training epoch: 1177
[ Wed Apr 25 10:43:44 2018 ] 	Batch(0/1) done. Loss: 0.0035  lr:0.100000
[ Wed Apr 25 10:43:44 2018 ] 	Mean training loss: 0.0035.
[ Wed Apr 25 10:43:44 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:43:44 2018 ] Training epoch: 1178
[ Wed Apr 25 10:43:49 2018 ] 	Batch(0/1) done. Loss: 0.0027  lr:0.100000
[ Wed Apr 25 10:43:49 2018 ] 	Mean training loss: 0.0027.
[ Wed Apr 25 10:43:49 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:43:49 2018 ] Training epoch: 1179
[ Wed Apr 25 10:43:53 2018 ] 	Batch(0/1) done. Loss: 0.0049  lr:0.100000
[ Wed Apr 25 10:43:53 2018 ] 	Mean training loss: 0.0049.
[ Wed Apr 25 10:43:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:43:53 2018 ] Training epoch: 1180
[ Wed Apr 25 10:43:57 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:43:57 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:43:57 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 10:43:57 2018 ] Eval epoch: 1180
[ Wed Apr 25 10:44:00 2018 ] 	Mean test loss of 1 batches: 0.25966814160346985.
[ Wed Apr 25 10:44:00 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:44:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:44:00 2018 ] Training epoch: 1181
[ Wed Apr 25 10:44:04 2018 ] 	Batch(0/1) done. Loss: 0.0024  lr:0.100000
[ Wed Apr 25 10:44:04 2018 ] 	Mean training loss: 0.0024.
[ Wed Apr 25 10:44:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:04 2018 ] Training epoch: 1182
[ Wed Apr 25 10:44:08 2018 ] 	Batch(0/1) done. Loss: 0.0154  lr:0.100000
[ Wed Apr 25 10:44:08 2018 ] 	Mean training loss: 0.0154.
[ Wed Apr 25 10:44:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:08 2018 ] Training epoch: 1183
[ Wed Apr 25 10:44:12 2018 ] 	Batch(0/1) done. Loss: 0.0019  lr:0.100000
[ Wed Apr 25 10:44:12 2018 ] 	Mean training loss: 0.0019.
[ Wed Apr 25 10:44:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:12 2018 ] Training epoch: 1184
[ Wed Apr 25 10:44:16 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:44:16 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:44:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:16 2018 ] Training epoch: 1185
[ Wed Apr 25 10:44:21 2018 ] 	Batch(0/1) done. Loss: 0.0057  lr:0.100000
[ Wed Apr 25 10:44:21 2018 ] 	Mean training loss: 0.0057.
[ Wed Apr 25 10:44:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:21 2018 ] Eval epoch: 1185
[ Wed Apr 25 10:44:23 2018 ] 	Mean test loss of 1 batches: 0.2301289290189743.
[ Wed Apr 25 10:44:23 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:44:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:44:23 2018 ] Training epoch: 1186
[ Wed Apr 25 10:44:28 2018 ] 	Batch(0/1) done. Loss: 0.0095  lr:0.100000
[ Wed Apr 25 10:44:28 2018 ] 	Mean training loss: 0.0095.
[ Wed Apr 25 10:44:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:44:28 2018 ] Training epoch: 1187
[ Wed Apr 25 10:44:32 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:44:32 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:44:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:32 2018 ] Training epoch: 1188
[ Wed Apr 25 10:44:36 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.100000
[ Wed Apr 25 10:44:36 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 10:44:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:36 2018 ] Training epoch: 1189
[ Wed Apr 25 10:44:40 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:44:40 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:44:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:40 2018 ] Training epoch: 1190
[ Wed Apr 25 10:44:44 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:44:44 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:44:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:44 2018 ] Eval epoch: 1190
[ Wed Apr 25 10:44:47 2018 ] 	Mean test loss of 1 batches: 0.31201857328414917.
[ Wed Apr 25 10:44:47 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:44:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:44:47 2018 ] Training epoch: 1191
[ Wed Apr 25 10:44:51 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.100000
[ Wed Apr 25 10:44:51 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 10:44:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:51 2018 ] Training epoch: 1192
[ Wed Apr 25 10:44:55 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:44:55 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:44:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:55 2018 ] Training epoch: 1193
[ Wed Apr 25 10:44:59 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:44:59 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:44:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:44:59 2018 ] Training epoch: 1194
[ Wed Apr 25 10:45:03 2018 ] 	Batch(0/1) done. Loss: 0.0052  lr:0.100000
[ Wed Apr 25 10:45:03 2018 ] 	Mean training loss: 0.0052.
[ Wed Apr 25 10:45:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:03 2018 ] Training epoch: 1195
[ Wed Apr 25 10:45:07 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:45:07 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:45:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:45:07 2018 ] Eval epoch: 1195
[ Wed Apr 25 10:45:10 2018 ] 	Mean test loss of 1 batches: 0.42288774251937866.
[ Wed Apr 25 10:45:10 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:45:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:45:10 2018 ] Training epoch: 1196
[ Wed Apr 25 10:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0022  lr:0.100000
[ Wed Apr 25 10:45:14 2018 ] 	Mean training loss: 0.0022.
[ Wed Apr 25 10:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:14 2018 ] Training epoch: 1197
[ Wed Apr 25 10:45:18 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:45:18 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:45:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:18 2018 ] Training epoch: 1198
[ Wed Apr 25 10:45:22 2018 ] 	Batch(0/1) done. Loss: 0.0034  lr:0.100000
[ Wed Apr 25 10:45:22 2018 ] 	Mean training loss: 0.0034.
[ Wed Apr 25 10:45:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:45:22 2018 ] Training epoch: 1199
[ Wed Apr 25 10:45:26 2018 ] 	Batch(0/1) done. Loss: 0.0020  lr:0.100000
[ Wed Apr 25 10:45:26 2018 ] 	Mean training loss: 0.0020.
[ Wed Apr 25 10:45:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:26 2018 ] Training epoch: 1200
[ Wed Apr 25 10:45:30 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:45:30 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:45:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:30 2018 ] Eval epoch: 1200
[ Wed Apr 25 10:45:33 2018 ] 	Mean test loss of 1 batches: 0.36388304829597473.
[ Wed Apr 25 10:45:33 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:45:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:45:33 2018 ] Training epoch: 1201
[ Wed Apr 25 10:45:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:45:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:45:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:37 2018 ] Training epoch: 1202
[ Wed Apr 25 10:45:41 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:45:41 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:45:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:41 2018 ] Training epoch: 1203
[ Wed Apr 25 10:45:45 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:45:45 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:45:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:45 2018 ] Training epoch: 1204
[ Wed Apr 25 10:45:49 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:45:49 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:45:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:45:49 2018 ] Training epoch: 1205
[ Wed Apr 25 10:45:53 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:45:53 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:45:53 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:45:53 2018 ] Eval epoch: 1205
[ Wed Apr 25 10:45:56 2018 ] 	Mean test loss of 1 batches: 0.3401966094970703.
[ Wed Apr 25 10:45:56 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:45:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:45:56 2018 ] Training epoch: 1206
[ Wed Apr 25 10:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:46:00 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:46:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:00 2018 ] Training epoch: 1207
[ Wed Apr 25 10:46:04 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:46:04 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:46:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:04 2018 ] Training epoch: 1208
[ Wed Apr 25 10:46:08 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:46:08 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:46:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:46:08 2018 ] Training epoch: 1209
[ Wed Apr 25 10:46:12 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:46:12 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:46:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:12 2018 ] Training epoch: 1210
[ Wed Apr 25 10:46:17 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:46:17 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:46:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:46:17 2018 ] Eval epoch: 1210
[ Wed Apr 25 10:46:20 2018 ] 	Mean test loss of 1 batches: 0.3283318281173706.
[ Wed Apr 25 10:46:20 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:46:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:46:20 2018 ] Training epoch: 1211
[ Wed Apr 25 10:46:24 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:46:24 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:46:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:24 2018 ] Training epoch: 1212
[ Wed Apr 25 10:46:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:46:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:46:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:28 2018 ] Training epoch: 1213
[ Wed Apr 25 10:46:32 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:46:32 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:46:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:32 2018 ] Training epoch: 1214
[ Wed Apr 25 10:46:36 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:46:36 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:46:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:36 2018 ] Training epoch: 1215
[ Wed Apr 25 10:46:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:46:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:46:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:40 2018 ] Eval epoch: 1215
[ Wed Apr 25 10:46:43 2018 ] 	Mean test loss of 1 batches: 0.29066920280456543.
[ Wed Apr 25 10:46:43 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:46:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:46:43 2018 ] Training epoch: 1216
[ Wed Apr 25 10:46:47 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:46:47 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:46:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:47 2018 ] Training epoch: 1217
[ Wed Apr 25 10:46:51 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:46:51 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:46:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:51 2018 ] Training epoch: 1218
[ Wed Apr 25 10:46:55 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:46:55 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:46:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:55 2018 ] Training epoch: 1219
[ Wed Apr 25 10:46:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:46:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:46:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:46:59 2018 ] Training epoch: 1220
[ Wed Apr 25 10:47:03 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:47:03 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:47:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:03 2018 ] Eval epoch: 1220
[ Wed Apr 25 10:47:06 2018 ] 	Mean test loss of 1 batches: 0.26036104559898376.
[ Wed Apr 25 10:47:06 2018 ] 	Top1: 88.89%
[ Wed Apr 25 10:47:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:47:06 2018 ] Training epoch: 1221
[ Wed Apr 25 10:47:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:47:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:47:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:10 2018 ] Training epoch: 1222
[ Wed Apr 25 10:47:14 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:47:14 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:47:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:14 2018 ] Training epoch: 1223
[ Wed Apr 25 10:47:18 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:47:18 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:47:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:18 2018 ] Training epoch: 1224
[ Wed Apr 25 10:47:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:47:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:47:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:22 2018 ] Training epoch: 1225
[ Wed Apr 25 10:47:26 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:47:26 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:47:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:26 2018 ] Eval epoch: 1225
[ Wed Apr 25 10:47:29 2018 ] 	Mean test loss of 1 batches: 0.2140589952468872.
[ Wed Apr 25 10:47:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:47:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:47:29 2018 ] Training epoch: 1226
[ Wed Apr 25 10:47:33 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:47:33 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:47:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:33 2018 ] Training epoch: 1227
[ Wed Apr 25 10:47:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:47:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:47:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:37 2018 ] Training epoch: 1228
[ Wed Apr 25 10:47:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:47:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:47:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:41 2018 ] Training epoch: 1229
[ Wed Apr 25 10:47:44 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:47:44 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:47:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:44 2018 ] Training epoch: 1230
[ Wed Apr 25 10:47:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:47:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:47:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:48 2018 ] Eval epoch: 1230
[ Wed Apr 25 10:47:51 2018 ] 	Mean test loss of 1 batches: 0.2097543627023697.
[ Wed Apr 25 10:47:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:47:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:47:51 2018 ] Training epoch: 1231
[ Wed Apr 25 10:47:55 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:47:55 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:47:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:47:55 2018 ] Training epoch: 1232
[ Wed Apr 25 10:48:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:48:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:48:00 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:48:00 2018 ] Training epoch: 1233
[ Wed Apr 25 10:48:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:48:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:48:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:04 2018 ] Training epoch: 1234
[ Wed Apr 25 10:48:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:48:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:48:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:48:08 2018 ] Training epoch: 1235
[ Wed Apr 25 10:48:12 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:48:12 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:48:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:12 2018 ] Eval epoch: 1235
[ Wed Apr 25 10:48:15 2018 ] 	Mean test loss of 1 batches: 0.2198541760444641.
[ Wed Apr 25 10:48:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:48:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:48:15 2018 ] Training epoch: 1236
[ Wed Apr 25 10:48:18 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:48:18 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:48:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:19 2018 ] Training epoch: 1237
[ Wed Apr 25 10:48:23 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:48:23 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:48:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:23 2018 ] Training epoch: 1238
[ Wed Apr 25 10:48:27 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:48:27 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:48:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:27 2018 ] Training epoch: 1239
[ Wed Apr 25 10:48:31 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 10:48:31 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 10:48:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:31 2018 ] Training epoch: 1240
[ Wed Apr 25 10:48:35 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:48:35 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:48:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:35 2018 ] Eval epoch: 1240
[ Wed Apr 25 10:48:37 2018 ] 	Mean test loss of 1 batches: 0.2016540765762329.
[ Wed Apr 25 10:48:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:48:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:48:37 2018 ] Training epoch: 1241
[ Wed Apr 25 10:48:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:48:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:48:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:41 2018 ] Training epoch: 1242
[ Wed Apr 25 10:48:45 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:48:45 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:48:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:45 2018 ] Training epoch: 1243
[ Wed Apr 25 10:48:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:48:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:48:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:49 2018 ] Training epoch: 1244
[ Wed Apr 25 10:48:53 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:48:53 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:48:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:53 2018 ] Training epoch: 1245
[ Wed Apr 25 10:48:57 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:48:57 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:48:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:48:57 2018 ] Eval epoch: 1245
[ Wed Apr 25 10:49:00 2018 ] 	Mean test loss of 1 batches: 0.18473242223262787.
[ Wed Apr 25 10:49:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:49:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:49:00 2018 ] Training epoch: 1246
[ Wed Apr 25 10:49:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:49:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:49:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:04 2018 ] Training epoch: 1247
[ Wed Apr 25 10:49:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:49:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:49:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:08 2018 ] Training epoch: 1248
[ Wed Apr 25 10:49:12 2018 ] 	Batch(0/1) done. Loss: 0.0021  lr:0.100000
[ Wed Apr 25 10:49:12 2018 ] 	Mean training loss: 0.0021.
[ Wed Apr 25 10:49:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:12 2018 ] Training epoch: 1249
[ Wed Apr 25 10:49:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:49:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:49:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:16 2018 ] Training epoch: 1250
[ Wed Apr 25 10:49:20 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:49:20 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:49:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:20 2018 ] Eval epoch: 1250
[ Wed Apr 25 10:49:23 2018 ] 	Mean test loss of 1 batches: 0.17674866318702698.
[ Wed Apr 25 10:49:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:49:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:49:23 2018 ] Training epoch: 1251
[ Wed Apr 25 10:49:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:49:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:49:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:27 2018 ] Training epoch: 1252
[ Wed Apr 25 10:49:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:49:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:49:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:49:32 2018 ] Training epoch: 1253
[ Wed Apr 25 10:49:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:49:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:49:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:36 2018 ] Training epoch: 1254
[ Wed Apr 25 10:49:40 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:49:40 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:49:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:40 2018 ] Training epoch: 1255
[ Wed Apr 25 10:49:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:49:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:49:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:44 2018 ] Eval epoch: 1255
[ Wed Apr 25 10:49:46 2018 ] 	Mean test loss of 1 batches: 0.17580263316631317.
[ Wed Apr 25 10:49:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:49:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:49:46 2018 ] Training epoch: 1256
[ Wed Apr 25 10:49:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:49:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:49:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:50 2018 ] Training epoch: 1257
[ Wed Apr 25 10:49:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:49:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:49:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:54 2018 ] Training epoch: 1258
[ Wed Apr 25 10:49:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:49:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:49:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:49:58 2018 ] Training epoch: 1259
[ Wed Apr 25 10:50:03 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:50:03 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:50:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:03 2018 ] Training epoch: 1260
[ Wed Apr 25 10:50:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:50:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:50:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:50:07 2018 ] Eval epoch: 1260
[ Wed Apr 25 10:50:10 2018 ] 	Mean test loss of 1 batches: 0.18354490399360657.
[ Wed Apr 25 10:50:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:50:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:50:10 2018 ] Training epoch: 1261
[ Wed Apr 25 10:50:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:50:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:50:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:14 2018 ] Training epoch: 1262
[ Wed Apr 25 10:50:18 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:50:18 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:50:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:18 2018 ] Training epoch: 1263
[ Wed Apr 25 10:50:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:50:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:50:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:22 2018 ] Training epoch: 1264
[ Wed Apr 25 10:50:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:50:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:50:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:26 2018 ] Training epoch: 1265
[ Wed Apr 25 10:50:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:50:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:50:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:30 2018 ] Eval epoch: 1265
[ Wed Apr 25 10:50:33 2018 ] 	Mean test loss of 1 batches: 0.18814614415168762.
[ Wed Apr 25 10:50:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:50:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:50:33 2018 ] Training epoch: 1266
[ Wed Apr 25 10:50:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:50:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:50:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:37 2018 ] Training epoch: 1267
[ Wed Apr 25 10:50:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:50:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:50:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:41 2018 ] Training epoch: 1268
[ Wed Apr 25 10:50:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:50:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:50:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:45 2018 ] Training epoch: 1269
[ Wed Apr 25 10:50:49 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:50:49 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:50:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:49 2018 ] Training epoch: 1270
[ Wed Apr 25 10:50:53 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:50:53 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:50:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:50:53 2018 ] Eval epoch: 1270
[ Wed Apr 25 10:50:56 2018 ] 	Mean test loss of 1 batches: 0.19330397248268127.
[ Wed Apr 25 10:50:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:50:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:50:56 2018 ] Training epoch: 1271
[ Wed Apr 25 10:51:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:51:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:51:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:00 2018 ] Training epoch: 1272
[ Wed Apr 25 10:51:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:51:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:51:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:51:04 2018 ] Training epoch: 1273
[ Wed Apr 25 10:51:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:51:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:51:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:08 2018 ] Training epoch: 1274
[ Wed Apr 25 10:51:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:51:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:51:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:12 2018 ] Training epoch: 1275
[ Wed Apr 25 10:51:16 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:51:16 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:51:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:16 2018 ] Eval epoch: 1275
[ Wed Apr 25 10:51:19 2018 ] 	Mean test loss of 1 batches: 0.19966086745262146.
[ Wed Apr 25 10:51:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:51:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:51:19 2018 ] Training epoch: 1276
[ Wed Apr 25 10:51:23 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 10:51:23 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 10:51:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:23 2018 ] Training epoch: 1277
[ Wed Apr 25 10:51:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:51:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:51:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:27 2018 ] Training epoch: 1278
[ Wed Apr 25 10:51:31 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:51:31 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:51:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:51:31 2018 ] Training epoch: 1279
[ Wed Apr 25 10:51:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:51:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:51:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:35 2018 ] Training epoch: 1280
[ Wed Apr 25 10:51:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:51:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:51:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:39 2018 ] Eval epoch: 1280
[ Wed Apr 25 10:51:42 2018 ] 	Mean test loss of 1 batches: 0.16318070888519287.
[ Wed Apr 25 10:51:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:51:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:51:42 2018 ] Training epoch: 1281
[ Wed Apr 25 10:51:46 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:51:46 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:51:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:46 2018 ] Training epoch: 1282
[ Wed Apr 25 10:51:50 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:51:50 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:51:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:50 2018 ] Training epoch: 1283
[ Wed Apr 25 10:51:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:51:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:51:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:54 2018 ] Training epoch: 1284
[ Wed Apr 25 10:51:58 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:51:58 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:51:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:51:58 2018 ] Training epoch: 1285
[ Wed Apr 25 10:52:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:52:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:52:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:02 2018 ] Eval epoch: 1285
[ Wed Apr 25 10:52:05 2018 ] 	Mean test loss of 1 batches: 0.15579761564731598.
[ Wed Apr 25 10:52:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:52:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:52:05 2018 ] Training epoch: 1286
[ Wed Apr 25 10:52:09 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:52:09 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:52:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:09 2018 ] Training epoch: 1287
[ Wed Apr 25 10:52:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:52:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:52:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:13 2018 ] Training epoch: 1288
[ Wed Apr 25 10:52:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:52:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:52:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:17 2018 ] Training epoch: 1289
[ Wed Apr 25 10:52:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:52:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:52:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:21 2018 ] Training epoch: 1290
[ Wed Apr 25 10:52:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:52:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:52:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:25 2018 ] Eval epoch: 1290
[ Wed Apr 25 10:52:28 2018 ] 	Mean test loss of 1 batches: 0.16409876942634583.
[ Wed Apr 25 10:52:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:52:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:52:28 2018 ] Training epoch: 1291
[ Wed Apr 25 10:52:32 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 10:52:32 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 10:52:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:32 2018 ] Training epoch: 1292
[ Wed Apr 25 10:52:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:52:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:52:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:36 2018 ] Training epoch: 1293
[ Wed Apr 25 10:52:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:52:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:52:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:40 2018 ] Training epoch: 1294
[ Wed Apr 25 10:52:44 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:52:44 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:52:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:44 2018 ] Training epoch: 1295
[ Wed Apr 25 10:52:48 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:52:48 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:52:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:48 2018 ] Eval epoch: 1295
[ Wed Apr 25 10:52:51 2018 ] 	Mean test loss of 1 batches: 0.17849208414554596.
[ Wed Apr 25 10:52:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:52:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:52:51 2018 ] Training epoch: 1296
[ Wed Apr 25 10:52:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:52:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:52:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:55 2018 ] Training epoch: 1297
[ Wed Apr 25 10:52:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:52:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:52:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:52:59 2018 ] Training epoch: 1298
[ Wed Apr 25 10:53:03 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:53:03 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:53:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:03 2018 ] Training epoch: 1299
[ Wed Apr 25 10:53:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:53:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:53:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:07 2018 ] Training epoch: 1300
[ Wed Apr 25 10:53:11 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:53:11 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:53:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:53:11 2018 ] Eval epoch: 1300
[ Wed Apr 25 10:53:14 2018 ] 	Mean test loss of 1 batches: 0.18248412013053894.
[ Wed Apr 25 10:53:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:53:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:53:14 2018 ] Training epoch: 1301
[ Wed Apr 25 10:53:18 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:53:18 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:53:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:18 2018 ] Training epoch: 1302
[ Wed Apr 25 10:53:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:53:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:53:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:22 2018 ] Training epoch: 1303
[ Wed Apr 25 10:53:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:53:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:53:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:26 2018 ] Training epoch: 1304
[ Wed Apr 25 10:53:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:53:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:53:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:30 2018 ] Training epoch: 1305
[ Wed Apr 25 10:53:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:53:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:53:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:34 2018 ] Eval epoch: 1305
[ Wed Apr 25 10:53:37 2018 ] 	Mean test loss of 1 batches: 0.18929550051689148.
[ Wed Apr 25 10:53:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:53:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:53:37 2018 ] Training epoch: 1306
[ Wed Apr 25 10:53:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:53:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:53:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:41 2018 ] Training epoch: 1307
[ Wed Apr 25 10:53:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:53:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:53:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:45 2018 ] Training epoch: 1308
[ Wed Apr 25 10:53:49 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:53:49 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:53:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:49 2018 ] Training epoch: 1309
[ Wed Apr 25 10:53:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:53:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:53:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:53 2018 ] Training epoch: 1310
[ Wed Apr 25 10:53:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:53:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:53:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:53:57 2018 ] Eval epoch: 1310
[ Wed Apr 25 10:54:00 2018 ] 	Mean test loss of 1 batches: 0.1861354112625122.
[ Wed Apr 25 10:54:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:54:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:54:00 2018 ] Training epoch: 1311
[ Wed Apr 25 10:54:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:54:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:54:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:04 2018 ] Training epoch: 1312
[ Wed Apr 25 10:54:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:54:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:54:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:08 2018 ] Training epoch: 1313
[ Wed Apr 25 10:54:12 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:54:12 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:54:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:12 2018 ] Training epoch: 1314
[ Wed Apr 25 10:54:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:54:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:54:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:16 2018 ] Training epoch: 1315
[ Wed Apr 25 10:54:20 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 10:54:20 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 10:54:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:20 2018 ] Eval epoch: 1315
[ Wed Apr 25 10:54:23 2018 ] 	Mean test loss of 1 batches: 0.1880645751953125.
[ Wed Apr 25 10:54:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:54:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:54:23 2018 ] Training epoch: 1316
[ Wed Apr 25 10:54:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:54:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:54:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:27 2018 ] Training epoch: 1317
[ Wed Apr 25 10:54:31 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:54:31 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:54:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:31 2018 ] Training epoch: 1318
[ Wed Apr 25 10:54:35 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:54:35 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:54:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:35 2018 ] Training epoch: 1319
[ Wed Apr 25 10:54:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:54:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:54:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:54:39 2018 ] Training epoch: 1320
[ Wed Apr 25 10:54:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:54:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:54:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:43 2018 ] Eval epoch: 1320
[ Wed Apr 25 10:54:46 2018 ] 	Mean test loss of 1 batches: 0.2001638263463974.
[ Wed Apr 25 10:54:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:54:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:54:46 2018 ] Training epoch: 1321
[ Wed Apr 25 10:54:50 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:54:50 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:54:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:50 2018 ] Training epoch: 1322
[ Wed Apr 25 10:54:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:54:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:54:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:54 2018 ] Training epoch: 1323
[ Wed Apr 25 10:54:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:54:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:54:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:54:58 2018 ] Training epoch: 1324
[ Wed Apr 25 10:55:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:55:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:55:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:55:02 2018 ] Training epoch: 1325
[ Wed Apr 25 10:55:06 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:55:06 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:55:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:06 2018 ] Eval epoch: 1325
[ Wed Apr 25 10:55:09 2018 ] 	Mean test loss of 1 batches: 0.19658584892749786.
[ Wed Apr 25 10:55:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:55:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:55:09 2018 ] Training epoch: 1326
[ Wed Apr 25 10:55:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:55:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:55:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:13 2018 ] Training epoch: 1327
[ Wed Apr 25 10:55:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:55:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:55:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:17 2018 ] Training epoch: 1328
[ Wed Apr 25 10:55:21 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:55:21 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:55:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:21 2018 ] Training epoch: 1329
[ Wed Apr 25 10:55:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:55:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:55:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:25 2018 ] Training epoch: 1330
[ Wed Apr 25 10:55:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:55:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:55:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:29 2018 ] Eval epoch: 1330
[ Wed Apr 25 10:55:32 2018 ] 	Mean test loss of 1 batches: 0.19622696936130524.
[ Wed Apr 25 10:55:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:55:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:55:32 2018 ] Training epoch: 1331
[ Wed Apr 25 10:55:36 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:55:36 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:55:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:36 2018 ] Training epoch: 1332
[ Wed Apr 25 10:55:40 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:55:40 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:55:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:40 2018 ] Training epoch: 1333
[ Wed Apr 25 10:55:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:55:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:55:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:44 2018 ] Training epoch: 1334
[ Wed Apr 25 10:55:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:55:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:55:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:48 2018 ] Training epoch: 1335
[ Wed Apr 25 10:55:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:55:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:55:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:52 2018 ] Eval epoch: 1335
[ Wed Apr 25 10:55:55 2018 ] 	Mean test loss of 1 batches: 0.20606575906276703.
[ Wed Apr 25 10:55:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:55:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:55:55 2018 ] Training epoch: 1336
[ Wed Apr 25 10:55:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:55:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:55:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:55:59 2018 ] Training epoch: 1337
[ Wed Apr 25 10:56:03 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:56:03 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:56:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:03 2018 ] Training epoch: 1338
[ Wed Apr 25 10:56:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 10:56:08 2018 ] Training epoch: 1339
[ Wed Apr 25 10:56:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:12 2018 ] Training epoch: 1340
[ Wed Apr 25 10:56:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:16 2018 ] Eval epoch: 1340
[ Wed Apr 25 10:56:19 2018 ] 	Mean test loss of 1 batches: 0.2151782363653183.
[ Wed Apr 25 10:56:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:56:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:56:19 2018 ] Training epoch: 1341
[ Wed Apr 25 10:56:23 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:56:23 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:56:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:23 2018 ] Training epoch: 1342
[ Wed Apr 25 10:56:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:27 2018 ] Training epoch: 1343
[ Wed Apr 25 10:56:31 2018 ] 	Batch(0/1) done. Loss: 0.0013  lr:0.100000
[ Wed Apr 25 10:56:31 2018 ] 	Mean training loss: 0.0013.
[ Wed Apr 25 10:56:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:31 2018 ] Training epoch: 1344
[ Wed Apr 25 10:56:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:35 2018 ] Training epoch: 1345
[ Wed Apr 25 10:56:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:56:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:56:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:39 2018 ] Eval epoch: 1345
[ Wed Apr 25 10:56:41 2018 ] 	Mean test loss of 1 batches: 0.20265734195709229.
[ Wed Apr 25 10:56:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:56:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:56:41 2018 ] Training epoch: 1346
[ Wed Apr 25 10:56:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:56:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:56:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:45 2018 ] Training epoch: 1347
[ Wed Apr 25 10:56:49 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:56:49 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:56:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:49 2018 ] Training epoch: 1348
[ Wed Apr 25 10:56:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:56:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:56:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:54 2018 ] Training epoch: 1349
[ Wed Apr 25 10:56:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:56:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:56:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:56:58 2018 ] Training epoch: 1350
[ Wed Apr 25 10:57:02 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:57:02 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:57:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:02 2018 ] Eval epoch: 1350
[ Wed Apr 25 10:57:04 2018 ] 	Mean test loss of 1 batches: 0.18805210292339325.
[ Wed Apr 25 10:57:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:57:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:57:04 2018 ] Training epoch: 1351
[ Wed Apr 25 10:57:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:08 2018 ] Training epoch: 1352
[ Wed Apr 25 10:57:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:12 2018 ] Training epoch: 1353
[ Wed Apr 25 10:57:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:57:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:57:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:16 2018 ] Training epoch: 1354
[ Wed Apr 25 10:57:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:57:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:57:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 10:57:20 2018 ] Training epoch: 1355
[ Wed Apr 25 10:57:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:57:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:57:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:24 2018 ] Eval epoch: 1355
[ Wed Apr 25 10:57:27 2018 ] 	Mean test loss of 1 batches: 0.1951049566268921.
[ Wed Apr 25 10:57:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:57:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:57:27 2018 ] Training epoch: 1356
[ Wed Apr 25 10:57:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:31 2018 ] Training epoch: 1357
[ Wed Apr 25 10:57:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:35 2018 ] Training epoch: 1358
[ Wed Apr 25 10:57:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 10:57:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 10:57:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:39 2018 ] Training epoch: 1359
[ Wed Apr 25 10:57:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:43 2018 ] Training epoch: 1360
[ Wed Apr 25 10:57:47 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 10:57:47 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 10:57:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:47 2018 ] Eval epoch: 1360
[ Wed Apr 25 10:57:50 2018 ] 	Mean test loss of 1 batches: 0.20923058688640594.
[ Wed Apr 25 10:57:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:57:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:57:50 2018 ] Training epoch: 1361
[ Wed Apr 25 10:57:54 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 10:57:54 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 10:57:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:54 2018 ] Training epoch: 1362
[ Wed Apr 25 10:57:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:57:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:57:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:57:58 2018 ] Training epoch: 1363
[ Wed Apr 25 10:58:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:58:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:58:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:02 2018 ] Training epoch: 1364
[ Wed Apr 25 10:58:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:58:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:58:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:06 2018 ] Training epoch: 1365
[ Wed Apr 25 10:58:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:58:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:58:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:10 2018 ] Eval epoch: 1365
[ Wed Apr 25 10:58:13 2018 ] 	Mean test loss of 1 batches: 0.23535169661045074.
[ Wed Apr 25 10:58:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:58:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:58:13 2018 ] Training epoch: 1366
[ Wed Apr 25 10:58:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:58:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:58:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:17 2018 ] Training epoch: 1367
[ Wed Apr 25 10:58:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:58:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:58:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:21 2018 ] Training epoch: 1368
[ Wed Apr 25 10:58:25 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:58:25 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:58:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:25 2018 ] Training epoch: 1369
[ Wed Apr 25 10:58:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:58:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:58:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:29 2018 ] Training epoch: 1370
[ Wed Apr 25 10:58:33 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:58:33 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:58:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:33 2018 ] Eval epoch: 1370
[ Wed Apr 25 10:58:36 2018 ] 	Mean test loss of 1 batches: 0.23709538578987122.
[ Wed Apr 25 10:58:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:58:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:58:36 2018 ] Training epoch: 1371
[ Wed Apr 25 10:58:40 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:58:40 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:58:40 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 10:58:40 2018 ] Training epoch: 1372
[ Wed Apr 25 10:58:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:58:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:58:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:44 2018 ] Training epoch: 1373
[ Wed Apr 25 10:58:48 2018 ] 	Batch(0/1) done. Loss: 0.0015  lr:0.100000
[ Wed Apr 25 10:58:48 2018 ] 	Mean training loss: 0.0015.
[ Wed Apr 25 10:58:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:48 2018 ] Training epoch: 1374
[ Wed Apr 25 10:58:52 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 10:58:52 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 10:58:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:52 2018 ] Training epoch: 1375
[ Wed Apr 25 10:58:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:58:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:58:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:58:56 2018 ] Eval epoch: 1375
[ Wed Apr 25 10:58:59 2018 ] 	Mean test loss of 1 batches: 0.17613032460212708.
[ Wed Apr 25 10:58:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:58:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:58:59 2018 ] Training epoch: 1376
[ Wed Apr 25 10:59:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:03 2018 ] Training epoch: 1377
[ Wed Apr 25 10:59:07 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:59:07 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:59:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:07 2018 ] Training epoch: 1378
[ Wed Apr 25 10:59:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:11 2018 ] Training epoch: 1379
[ Wed Apr 25 10:59:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 10:59:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 10:59:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:15 2018 ] Training epoch: 1380
[ Wed Apr 25 10:59:19 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 10:59:19 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 10:59:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:19 2018 ] Eval epoch: 1380
[ Wed Apr 25 10:59:22 2018 ] 	Mean test loss of 1 batches: 0.15434090793132782.
[ Wed Apr 25 10:59:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:59:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:59:22 2018 ] Training epoch: 1381
[ Wed Apr 25 10:59:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:26 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 10:59:26 2018 ] Training epoch: 1382
[ Wed Apr 25 10:59:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:30 2018 ] Training epoch: 1383
[ Wed Apr 25 10:59:34 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 10:59:34 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 10:59:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:34 2018 ] Training epoch: 1384
[ Wed Apr 25 10:59:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:38 2018 ] Training epoch: 1385
[ Wed Apr 25 10:59:42 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:59:42 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:59:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:42 2018 ] Eval epoch: 1385
[ Wed Apr 25 10:59:45 2018 ] 	Mean test loss of 1 batches: 0.1613619178533554.
[ Wed Apr 25 10:59:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 10:59:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 10:59:45 2018 ] Training epoch: 1386
[ Wed Apr 25 10:59:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 10:59:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 10:59:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:49 2018 ] Training epoch: 1387
[ Wed Apr 25 10:59:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 10:59:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 10:59:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:53 2018 ] Training epoch: 1388
[ Wed Apr 25 10:59:57 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 10:59:57 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 10:59:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 10:59:57 2018 ] Training epoch: 1389
[ Wed Apr 25 11:00:01 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 11:00:01 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 11:00:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:01 2018 ] Training epoch: 1390
[ Wed Apr 25 11:00:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:00:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:00:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:05 2018 ] Eval epoch: 1390
[ Wed Apr 25 11:00:08 2018 ] 	Mean test loss of 1 batches: 0.19209392368793488.
[ Wed Apr 25 11:00:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:00:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:00:08 2018 ] Training epoch: 1391
[ Wed Apr 25 11:00:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:00:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:00:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:12 2018 ] Training epoch: 1392
[ Wed Apr 25 11:00:16 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:00:16 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:00:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:16 2018 ] Training epoch: 1393
[ Wed Apr 25 11:00:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:00:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:00:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:20 2018 ] Training epoch: 1394
[ Wed Apr 25 11:00:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:00:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:00:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:24 2018 ] Training epoch: 1395
[ Wed Apr 25 11:00:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:00:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:00:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:28 2018 ] Eval epoch: 1395
[ Wed Apr 25 11:00:31 2018 ] 	Mean test loss of 1 batches: 0.23646841943264008.
[ Wed Apr 25 11:00:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:00:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:00:31 2018 ] Training epoch: 1396
[ Wed Apr 25 11:00:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:00:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:00:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:35 2018 ] Training epoch: 1397
[ Wed Apr 25 11:00:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:00:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:00:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:00:39 2018 ] Training epoch: 1398
[ Wed Apr 25 11:00:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:00:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:00:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:43 2018 ] Training epoch: 1399
[ Wed Apr 25 11:00:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:00:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:00:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:47 2018 ] Training epoch: 1400
[ Wed Apr 25 11:00:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:00:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:00:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:51 2018 ] Eval epoch: 1400
[ Wed Apr 25 11:00:54 2018 ] 	Mean test loss of 1 batches: 0.2605750560760498.
[ Wed Apr 25 11:00:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:00:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:00:54 2018 ] Training epoch: 1401
[ Wed Apr 25 11:00:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:00:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:00:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:00:58 2018 ] Training epoch: 1402
[ Wed Apr 25 11:01:02 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:01:02 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:01:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:02 2018 ] Training epoch: 1403
[ Wed Apr 25 11:01:06 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:01:06 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:01:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:06 2018 ] Training epoch: 1404
[ Wed Apr 25 11:01:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:01:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:01:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:10 2018 ] Training epoch: 1405
[ Wed Apr 25 11:01:14 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:01:14 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:01:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:14 2018 ] Eval epoch: 1405
[ Wed Apr 25 11:01:17 2018 ] 	Mean test loss of 1 batches: 0.2704603672027588.
[ Wed Apr 25 11:01:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:01:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:01:17 2018 ] Training epoch: 1406
[ Wed Apr 25 11:01:21 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:01:21 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:01:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:21 2018 ] Training epoch: 1407
[ Wed Apr 25 11:01:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:01:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:01:26 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:01:26 2018 ] Training epoch: 1408
[ Wed Apr 25 11:01:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:01:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:01:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:30 2018 ] Training epoch: 1409
[ Wed Apr 25 11:01:34 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 11:01:34 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 11:01:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:34 2018 ] Training epoch: 1410
[ Wed Apr 25 11:01:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:01:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:01:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:38 2018 ] Eval epoch: 1410
[ Wed Apr 25 11:01:41 2018 ] 	Mean test loss of 1 batches: 0.25601521134376526.
[ Wed Apr 25 11:01:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:01:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:01:41 2018 ] Training epoch: 1411
[ Wed Apr 25 11:01:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:01:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:01:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:45 2018 ] Training epoch: 1412
[ Wed Apr 25 11:01:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:01:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:01:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:49 2018 ] Training epoch: 1413
[ Wed Apr 25 11:01:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:01:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:01:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:53 2018 ] Training epoch: 1414
[ Wed Apr 25 11:01:57 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:01:57 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:01:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:01:57 2018 ] Training epoch: 1415
[ Wed Apr 25 11:02:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:02:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:02:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:01 2018 ] Eval epoch: 1415
[ Wed Apr 25 11:02:04 2018 ] 	Mean test loss of 1 batches: 0.21832320094108582.
[ Wed Apr 25 11:02:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:02:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:02:04 2018 ] Training epoch: 1416
[ Wed Apr 25 11:02:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:02:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:02:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:08 2018 ] Training epoch: 1417
[ Wed Apr 25 11:02:12 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:02:12 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:02:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:12 2018 ] Training epoch: 1418
[ Wed Apr 25 11:02:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:02:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:02:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:16 2018 ] Training epoch: 1419
[ Wed Apr 25 11:02:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:02:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:02:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:20 2018 ] Training epoch: 1420
[ Wed Apr 25 11:02:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:02:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:02:24 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:02:24 2018 ] Eval epoch: 1420
[ Wed Apr 25 11:02:27 2018 ] 	Mean test loss of 1 batches: 0.20493100583553314.
[ Wed Apr 25 11:02:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:02:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:02:27 2018 ] Training epoch: 1421
[ Wed Apr 25 11:02:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:02:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:02:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:31 2018 ] Training epoch: 1422
[ Wed Apr 25 11:02:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:02:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:02:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:35 2018 ] Training epoch: 1423
[ Wed Apr 25 11:02:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:02:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:02:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:39 2018 ] Training epoch: 1424
[ Wed Apr 25 11:02:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:02:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:02:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:43 2018 ] Training epoch: 1425
[ Wed Apr 25 11:02:47 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 11:02:47 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 11:02:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:47 2018 ] Eval epoch: 1425
[ Wed Apr 25 11:02:50 2018 ] 	Mean test loss of 1 batches: 0.18575039505958557.
[ Wed Apr 25 11:02:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:02:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:02:50 2018 ] Training epoch: 1426
[ Wed Apr 25 11:02:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:02:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:02:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:54 2018 ] Training epoch: 1427
[ Wed Apr 25 11:02:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:02:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:02:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:02:58 2018 ] Training epoch: 1428
[ Wed Apr 25 11:03:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:03:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:03:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:02 2018 ] Training epoch: 1429
[ Wed Apr 25 11:03:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:03:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:03:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:06 2018 ] Training epoch: 1430
[ Wed Apr 25 11:03:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:03:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:03:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:10 2018 ] Eval epoch: 1430
[ Wed Apr 25 11:03:13 2018 ] 	Mean test loss of 1 batches: 0.18852268159389496.
[ Wed Apr 25 11:03:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:03:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:03:13 2018 ] Training epoch: 1431
[ Wed Apr 25 11:03:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:03:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:03:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:17 2018 ] Training epoch: 1432
[ Wed Apr 25 11:03:21 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:03:21 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:03:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:21 2018 ] Training epoch: 1433
[ Wed Apr 25 11:03:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:03:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:03:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:25 2018 ] Training epoch: 1434
[ Wed Apr 25 11:03:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:03:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:03:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:29 2018 ] Training epoch: 1435
[ Wed Apr 25 11:03:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:03:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:03:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:33 2018 ] Eval epoch: 1435
[ Wed Apr 25 11:03:36 2018 ] 	Mean test loss of 1 batches: 0.2030056267976761.
[ Wed Apr 25 11:03:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:03:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:03:36 2018 ] Training epoch: 1436
[ Wed Apr 25 11:03:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:03:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:03:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:40 2018 ] Training epoch: 1437
[ Wed Apr 25 11:03:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:03:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:03:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:44 2018 ] Training epoch: 1438
[ Wed Apr 25 11:03:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:03:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:03:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:48 2018 ] Training epoch: 1439
[ Wed Apr 25 11:03:52 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:03:52 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:03:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:03:52 2018 ] Training epoch: 1440
[ Wed Apr 25 11:03:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:03:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:03:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:03:57 2018 ] Eval epoch: 1440
[ Wed Apr 25 11:03:59 2018 ] 	Mean test loss of 1 batches: 0.19946636259555817.
[ Wed Apr 25 11:03:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:04:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:04:00 2018 ] Training epoch: 1441
[ Wed Apr 25 11:04:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:04:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:04:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:03 2018 ] Training epoch: 1442
[ Wed Apr 25 11:04:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:04:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:04:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:08 2018 ] Training epoch: 1443
[ Wed Apr 25 11:04:12 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:04:12 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:04:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:12 2018 ] Training epoch: 1444
[ Wed Apr 25 11:04:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:04:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:04:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:16 2018 ] Training epoch: 1445
[ Wed Apr 25 11:04:20 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:04:20 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:04:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:20 2018 ] Eval epoch: 1445
[ Wed Apr 25 11:04:22 2018 ] 	Mean test loss of 1 batches: 0.21424809098243713.
[ Wed Apr 25 11:04:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:04:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:04:22 2018 ] Training epoch: 1446
[ Wed Apr 25 11:04:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:04:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:04:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:26 2018 ] Training epoch: 1447
[ Wed Apr 25 11:04:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:04:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:04:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:31 2018 ] Training epoch: 1448
[ Wed Apr 25 11:04:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:04:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:04:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:35 2018 ] Training epoch: 1449
[ Wed Apr 25 11:04:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:04:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:04:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:39 2018 ] Training epoch: 1450
[ Wed Apr 25 11:04:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:04:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:04:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:43 2018 ] Eval epoch: 1450
[ Wed Apr 25 11:04:46 2018 ] 	Mean test loss of 1 batches: 0.22515328228473663.
[ Wed Apr 25 11:04:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:04:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:04:46 2018 ] Training epoch: 1451
[ Wed Apr 25 11:04:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:04:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:04:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:50 2018 ] Training epoch: 1452
[ Wed Apr 25 11:04:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:04:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:04:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:54 2018 ] Training epoch: 1453
[ Wed Apr 25 11:04:58 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:04:58 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:04:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:04:58 2018 ] Training epoch: 1454
[ Wed Apr 25 11:05:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:05:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:05:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:02 2018 ] Training epoch: 1455
[ Wed Apr 25 11:05:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:05:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:05:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:06 2018 ] Eval epoch: 1455
[ Wed Apr 25 11:05:09 2018 ] 	Mean test loss of 1 batches: 0.23618468642234802.
[ Wed Apr 25 11:05:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:05:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:05:09 2018 ] Training epoch: 1456
[ Wed Apr 25 11:05:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:05:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:05:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:13 2018 ] Training epoch: 1457
[ Wed Apr 25 11:05:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:05:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:05:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:17 2018 ] Training epoch: 1458
[ Wed Apr 25 11:05:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:05:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:05:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:21 2018 ] Training epoch: 1459
[ Wed Apr 25 11:05:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:05:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:05:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:25 2018 ] Training epoch: 1460
[ Wed Apr 25 11:05:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:05:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:05:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:29 2018 ] Eval epoch: 1460
[ Wed Apr 25 11:05:32 2018 ] 	Mean test loss of 1 batches: 0.23227296769618988.
[ Wed Apr 25 11:05:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:05:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:05:32 2018 ] Training epoch: 1461
[ Wed Apr 25 11:05:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:05:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:05:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:36 2018 ] Training epoch: 1462
[ Wed Apr 25 11:05:40 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:05:40 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:05:40 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:05:40 2018 ] Training epoch: 1463
[ Wed Apr 25 11:05:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:05:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:05:44 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:05:44 2018 ] Training epoch: 1464
[ Wed Apr 25 11:05:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:05:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:05:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:05:48 2018 ] Training epoch: 1465
[ Wed Apr 25 11:05:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:05:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:05:53 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:05:53 2018 ] Eval epoch: 1465
[ Wed Apr 25 11:05:56 2018 ] 	Mean test loss of 1 batches: 0.2380092591047287.
[ Wed Apr 25 11:05:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:05:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:05:56 2018 ] Training epoch: 1466
[ Wed Apr 25 11:06:00 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:06:00 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:06:00 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:06:00 2018 ] Training epoch: 1467
[ Wed Apr 25 11:06:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:06:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:06:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:04 2018 ] Training epoch: 1468
[ Wed Apr 25 11:06:08 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:06:08 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:06:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:08 2018 ] Training epoch: 1469
[ Wed Apr 25 11:06:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:06:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:06:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:12 2018 ] Training epoch: 1470
[ Wed Apr 25 11:06:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:06:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:06:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:16 2018 ] Eval epoch: 1470
[ Wed Apr 25 11:06:19 2018 ] 	Mean test loss of 1 batches: 0.2563877999782562.
[ Wed Apr 25 11:06:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:06:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:06:19 2018 ] Training epoch: 1471
[ Wed Apr 25 11:06:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:06:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:06:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:23 2018 ] Training epoch: 1472
[ Wed Apr 25 11:06:27 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:06:27 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:06:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:27 2018 ] Training epoch: 1473
[ Wed Apr 25 11:06:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:06:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:06:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:31 2018 ] Training epoch: 1474
[ Wed Apr 25 11:06:35 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:06:35 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:06:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:35 2018 ] Training epoch: 1475
[ Wed Apr 25 11:06:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:06:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:06:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:39 2018 ] Eval epoch: 1475
[ Wed Apr 25 11:06:42 2018 ] 	Mean test loss of 1 batches: 0.2553160488605499.
[ Wed Apr 25 11:06:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:06:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:06:42 2018 ] Training epoch: 1476
[ Wed Apr 25 11:06:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:06:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:06:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:46 2018 ] Training epoch: 1477
[ Wed Apr 25 11:06:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:06:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:06:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:50 2018 ] Training epoch: 1478
[ Wed Apr 25 11:06:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:06:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:06:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:06:54 2018 ] Training epoch: 1479
[ Wed Apr 25 11:06:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:06:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:06:58 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:06:58 2018 ] Training epoch: 1480
[ Wed Apr 25 11:07:02 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:07:02 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:07:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:02 2018 ] Eval epoch: 1480
[ Wed Apr 25 11:07:05 2018 ] 	Mean test loss of 1 batches: 0.25581929087638855.
[ Wed Apr 25 11:07:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:07:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:07:05 2018 ] Training epoch: 1481
[ Wed Apr 25 11:07:09 2018 ] 	Batch(0/1) done. Loss: 0.0018  lr:0.100000
[ Wed Apr 25 11:07:09 2018 ] 	Mean training loss: 0.0018.
[ Wed Apr 25 11:07:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:09 2018 ] Training epoch: 1482
[ Wed Apr 25 11:07:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:07:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:07:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:07:13 2018 ] Training epoch: 1483
[ Wed Apr 25 11:07:17 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:07:17 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:07:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:17 2018 ] Training epoch: 1484
[ Wed Apr 25 11:07:21 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:07:21 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:07:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:21 2018 ] Training epoch: 1485
[ Wed Apr 25 11:07:25 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:07:25 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:07:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:25 2018 ] Eval epoch: 1485
[ Wed Apr 25 11:07:28 2018 ] 	Mean test loss of 1 batches: 0.1900678426027298.
[ Wed Apr 25 11:07:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:07:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:07:28 2018 ] Training epoch: 1486
[ Wed Apr 25 11:07:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:07:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:07:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:32 2018 ] Training epoch: 1487
[ Wed Apr 25 11:07:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:07:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:07:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:36 2018 ] Training epoch: 1488
[ Wed Apr 25 11:07:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:07:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:07:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:40 2018 ] Training epoch: 1489
[ Wed Apr 25 11:07:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:07:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:07:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:44 2018 ] Training epoch: 1490
[ Wed Apr 25 11:07:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:07:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:07:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:48 2018 ] Eval epoch: 1490
[ Wed Apr 25 11:07:51 2018 ] 	Mean test loss of 1 batches: 0.16515414416790009.
[ Wed Apr 25 11:07:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:07:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:07:51 2018 ] Training epoch: 1491
[ Wed Apr 25 11:07:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:07:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:07:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:55 2018 ] Training epoch: 1492
[ Wed Apr 25 11:07:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:07:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:07:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:07:59 2018 ] Training epoch: 1493
[ Wed Apr 25 11:08:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:03 2018 ] Training epoch: 1494
[ Wed Apr 25 11:08:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:08:07 2018 ] Training epoch: 1495
[ Wed Apr 25 11:08:11 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 11:08:11 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 11:08:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:11 2018 ] Eval epoch: 1495
[ Wed Apr 25 11:08:14 2018 ] 	Mean test loss of 1 batches: 0.16707570850849152.
[ Wed Apr 25 11:08:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:08:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:08:14 2018 ] Training epoch: 1496
[ Wed Apr 25 11:08:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:18 2018 ] Training epoch: 1497
[ Wed Apr 25 11:08:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:22 2018 ] Training epoch: 1498
[ Wed Apr 25 11:08:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:08:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:08:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:26 2018 ] Training epoch: 1499
[ Wed Apr 25 11:08:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:08:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:08:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:30 2018 ] Training epoch: 1500
[ Wed Apr 25 11:08:34 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:08:34 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:08:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:34 2018 ] Eval epoch: 1500
[ Wed Apr 25 11:08:37 2018 ] 	Mean test loss of 1 batches: 0.18633584678173065.
[ Wed Apr 25 11:08:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:08:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:08:37 2018 ] Training epoch: 1501
[ Wed Apr 25 11:08:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:41 2018 ] Training epoch: 1502
[ Wed Apr 25 11:08:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:45 2018 ] Training epoch: 1503
[ Wed Apr 25 11:08:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:08:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:08:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:49 2018 ] Training epoch: 1504
[ Wed Apr 25 11:08:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:08:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:08:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:53 2018 ] Training epoch: 1505
[ Wed Apr 25 11:08:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:08:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:08:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:08:57 2018 ] Eval epoch: 1505
[ Wed Apr 25 11:09:00 2018 ] 	Mean test loss of 1 batches: 0.1811649650335312.
[ Wed Apr 25 11:09:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:09:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:09:00 2018 ] Training epoch: 1506
[ Wed Apr 25 11:09:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:09:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:09:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:04 2018 ] Training epoch: 1507
[ Wed Apr 25 11:09:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:09:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:09:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:08 2018 ] Training epoch: 1508
[ Wed Apr 25 11:09:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:09:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:09:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:12 2018 ] Training epoch: 1509
[ Wed Apr 25 11:09:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:09:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:09:16 2018 ] 	Time consumption: [Data]78%, [Network]21%
[ Wed Apr 25 11:09:16 2018 ] Training epoch: 1510
[ Wed Apr 25 11:09:20 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:09:20 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:09:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:20 2018 ] Eval epoch: 1510
[ Wed Apr 25 11:09:23 2018 ] 	Mean test loss of 1 batches: 0.18287380039691925.
[ Wed Apr 25 11:09:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:09:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:09:23 2018 ] Training epoch: 1511
[ Wed Apr 25 11:09:27 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:09:27 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:09:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:27 2018 ] Training epoch: 1512
[ Wed Apr 25 11:09:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:09:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:09:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:31 2018 ] Training epoch: 1513
[ Wed Apr 25 11:09:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:09:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:09:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:35 2018 ] Training epoch: 1514
[ Wed Apr 25 11:09:39 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:09:39 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:09:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:39 2018 ] Training epoch: 1515
[ Wed Apr 25 11:09:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:09:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:09:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:43 2018 ] Eval epoch: 1515
[ Wed Apr 25 11:09:46 2018 ] 	Mean test loss of 1 batches: 0.192499041557312.
[ Wed Apr 25 11:09:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:09:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:09:46 2018 ] Training epoch: 1516
[ Wed Apr 25 11:09:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:09:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:09:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:50 2018 ] Training epoch: 1517
[ Wed Apr 25 11:09:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:09:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:09:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:54 2018 ] Training epoch: 1518
[ Wed Apr 25 11:09:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:09:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:09:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:09:58 2018 ] Training epoch: 1519
[ Wed Apr 25 11:10:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:10:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:10:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:02 2018 ] Training epoch: 1520
[ Wed Apr 25 11:10:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:10:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:10:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:06 2018 ] Eval epoch: 1520
[ Wed Apr 25 11:10:09 2018 ] 	Mean test loss of 1 batches: 0.19844159483909607.
[ Wed Apr 25 11:10:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:10:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:10:09 2018 ] Training epoch: 1521
[ Wed Apr 25 11:10:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:10:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:10:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:10:13 2018 ] Training epoch: 1522
[ Wed Apr 25 11:10:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:10:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:10:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:17 2018 ] Training epoch: 1523
[ Wed Apr 25 11:10:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:10:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:10:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:21 2018 ] Training epoch: 1524
[ Wed Apr 25 11:10:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:10:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:10:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:25 2018 ] Training epoch: 1525
[ Wed Apr 25 11:10:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:10:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:10:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:29 2018 ] Eval epoch: 1525
[ Wed Apr 25 11:10:32 2018 ] 	Mean test loss of 1 batches: 0.2132875621318817.
[ Wed Apr 25 11:10:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:10:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:10:32 2018 ] Training epoch: 1526
[ Wed Apr 25 11:10:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:10:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:10:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:36 2018 ] Training epoch: 1527
[ Wed Apr 25 11:10:40 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:10:40 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:10:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:40 2018 ] Training epoch: 1528
[ Wed Apr 25 11:10:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:10:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:10:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:44 2018 ] Training epoch: 1529
[ Wed Apr 25 11:10:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:10:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:10:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:48 2018 ] Training epoch: 1530
[ Wed Apr 25 11:10:52 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:10:52 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:10:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:52 2018 ] Eval epoch: 1530
[ Wed Apr 25 11:10:55 2018 ] 	Mean test loss of 1 batches: 0.21578070521354675.
[ Wed Apr 25 11:10:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:10:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:10:55 2018 ] Training epoch: 1531
[ Wed Apr 25 11:10:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:10:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:10:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:10:59 2018 ] Training epoch: 1532
[ Wed Apr 25 11:11:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:11:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:11:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:03 2018 ] Training epoch: 1533
[ Wed Apr 25 11:11:07 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:11:07 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:11:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:07 2018 ] Training epoch: 1534
[ Wed Apr 25 11:11:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:11:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:11:11 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:11:11 2018 ] Training epoch: 1535
[ Wed Apr 25 11:11:15 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:11:15 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:11:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:15 2018 ] Eval epoch: 1535
[ Wed Apr 25 11:11:18 2018 ] 	Mean test loss of 1 batches: 0.2212209552526474.
[ Wed Apr 25 11:11:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:11:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:11:18 2018 ] Training epoch: 1536
[ Wed Apr 25 11:11:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:11:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:11:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:22 2018 ] Training epoch: 1537
[ Wed Apr 25 11:11:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:11:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:11:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:26 2018 ] Training epoch: 1538
[ Wed Apr 25 11:11:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:11:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:11:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:30 2018 ] Training epoch: 1539
[ Wed Apr 25 11:11:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:11:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:11:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:34 2018 ] Training epoch: 1540
[ Wed Apr 25 11:11:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:11:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:11:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:38 2018 ] Eval epoch: 1540
[ Wed Apr 25 11:11:41 2018 ] 	Mean test loss of 1 batches: 0.2279583215713501.
[ Wed Apr 25 11:11:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:11:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:11:41 2018 ] Training epoch: 1541
[ Wed Apr 25 11:11:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:11:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:11:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:45 2018 ] Training epoch: 1542
[ Wed Apr 25 11:11:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:11:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:11:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:49 2018 ] Training epoch: 1543
[ Wed Apr 25 11:11:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:11:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:11:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:11:53 2018 ] Training epoch: 1544
[ Wed Apr 25 11:11:57 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:11:57 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:11:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:11:57 2018 ] Training epoch: 1545
[ Wed Apr 25 11:12:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:12:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:12:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:01 2018 ] Eval epoch: 1545
[ Wed Apr 25 11:12:04 2018 ] 	Mean test loss of 1 batches: 0.22738859057426453.
[ Wed Apr 25 11:12:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:12:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:12:04 2018 ] Training epoch: 1546
[ Wed Apr 25 11:12:08 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:12:08 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:12:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:08 2018 ] Training epoch: 1547
[ Wed Apr 25 11:12:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:12:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:12:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:12 2018 ] Training epoch: 1548
[ Wed Apr 25 11:12:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:12:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:12:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:16 2018 ] Training epoch: 1549
[ Wed Apr 25 11:12:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:12:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:12:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:20 2018 ] Training epoch: 1550
[ Wed Apr 25 11:12:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:12:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:12:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:24 2018 ] Eval epoch: 1550
[ Wed Apr 25 11:12:27 2018 ] 	Mean test loss of 1 batches: 0.23591938614845276.
[ Wed Apr 25 11:12:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:12:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:12:27 2018 ] Training epoch: 1551
[ Wed Apr 25 11:12:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:12:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:12:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:31 2018 ] Training epoch: 1552
[ Wed Apr 25 11:12:35 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:12:35 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:12:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:35 2018 ] Training epoch: 1553
[ Wed Apr 25 11:12:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:12:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:12:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:39 2018 ] Training epoch: 1554
[ Wed Apr 25 11:12:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:12:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:12:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:43 2018 ] Training epoch: 1555
[ Wed Apr 25 11:12:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:12:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:12:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:47 2018 ] Eval epoch: 1555
[ Wed Apr 25 11:12:50 2018 ] 	Mean test loss of 1 batches: 0.23384468257427216.
[ Wed Apr 25 11:12:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:12:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:12:50 2018 ] Training epoch: 1556
[ Wed Apr 25 11:12:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:12:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:12:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:54 2018 ] Training epoch: 1557
[ Wed Apr 25 11:12:58 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:12:58 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:12:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:12:58 2018 ] Training epoch: 1558
[ Wed Apr 25 11:13:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:13:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:13:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:02 2018 ] Training epoch: 1559
[ Wed Apr 25 11:13:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:13:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:13:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:06 2018 ] Training epoch: 1560
[ Wed Apr 25 11:13:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:13:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:13:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:10 2018 ] Eval epoch: 1560
[ Wed Apr 25 11:13:13 2018 ] 	Mean test loss of 1 batches: 0.2329135686159134.
[ Wed Apr 25 11:13:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:13:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:13:13 2018 ] Training epoch: 1561
[ Wed Apr 25 11:13:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:13:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:13:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:17 2018 ] Training epoch: 1562
[ Wed Apr 25 11:13:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:13:21 2018 ] Training epoch: 1563
[ Wed Apr 25 11:13:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:26 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:13:26 2018 ] Training epoch: 1564
[ Wed Apr 25 11:13:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:30 2018 ] Training epoch: 1565
[ Wed Apr 25 11:13:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:34 2018 ] Eval epoch: 1565
[ Wed Apr 25 11:13:37 2018 ] 	Mean test loss of 1 batches: 0.23117387294769287.
[ Wed Apr 25 11:13:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:13:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:13:37 2018 ] Training epoch: 1566
[ Wed Apr 25 11:13:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:13:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:13:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:41 2018 ] Training epoch: 1567
[ Wed Apr 25 11:13:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:45 2018 ] Training epoch: 1568
[ Wed Apr 25 11:13:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:13:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:13:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:49 2018 ] Training epoch: 1569
[ Wed Apr 25 11:13:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:13:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:13:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:53 2018 ] Training epoch: 1570
[ Wed Apr 25 11:13:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:13:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:13:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:13:57 2018 ] Eval epoch: 1570
[ Wed Apr 25 11:14:00 2018 ] 	Mean test loss of 1 batches: 0.2325991690158844.
[ Wed Apr 25 11:14:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:14:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:14:00 2018 ] Training epoch: 1571
[ Wed Apr 25 11:14:05 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:14:05 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:14:05 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:14:05 2018 ] Training epoch: 1572
[ Wed Apr 25 11:14:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:14:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:14:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:09 2018 ] Training epoch: 1573
[ Wed Apr 25 11:14:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:13 2018 ] Training epoch: 1574
[ Wed Apr 25 11:14:17 2018 ] 	Batch(0/1) done. Loss: 0.0016  lr:0.100000
[ Wed Apr 25 11:14:17 2018 ] 	Mean training loss: 0.0016.
[ Wed Apr 25 11:14:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:17 2018 ] Training epoch: 1575
[ Wed Apr 25 11:14:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:21 2018 ] Eval epoch: 1575
[ Wed Apr 25 11:14:24 2018 ] 	Mean test loss of 1 batches: 0.22273264825344086.
[ Wed Apr 25 11:14:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:14:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:14:24 2018 ] Training epoch: 1576
[ Wed Apr 25 11:14:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:14:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:14:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:28 2018 ] Training epoch: 1577
[ Wed Apr 25 11:14:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:14:32 2018 ] Training epoch: 1578
[ Wed Apr 25 11:14:36 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 11:14:36 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 11:14:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:36 2018 ] Training epoch: 1579
[ Wed Apr 25 11:14:40 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:14:40 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:14:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:40 2018 ] Training epoch: 1580
[ Wed Apr 25 11:14:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:44 2018 ] Eval epoch: 1580
[ Wed Apr 25 11:14:47 2018 ] 	Mean test loss of 1 batches: 0.2122102677822113.
[ Wed Apr 25 11:14:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:14:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:14:47 2018 ] Training epoch: 1581
[ Wed Apr 25 11:14:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:51 2018 ] Training epoch: 1582
[ Wed Apr 25 11:14:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:14:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:14:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:55 2018 ] Training epoch: 1583
[ Wed Apr 25 11:14:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:14:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:14:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:14:59 2018 ] Training epoch: 1584
[ Wed Apr 25 11:15:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:15:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:15:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:03 2018 ] Training epoch: 1585
[ Wed Apr 25 11:15:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:15:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:15:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:07 2018 ] Eval epoch: 1585
[ Wed Apr 25 11:15:10 2018 ] 	Mean test loss of 1 batches: 0.2089986652135849.
[ Wed Apr 25 11:15:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:15:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:15:10 2018 ] Training epoch: 1586
[ Wed Apr 25 11:15:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:15:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:15:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:14 2018 ] Training epoch: 1587
[ Wed Apr 25 11:15:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:15:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:15:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:18 2018 ] Training epoch: 1588
[ Wed Apr 25 11:15:22 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:15:22 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:15:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:22 2018 ] Training epoch: 1589
[ Wed Apr 25 11:15:26 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:15:26 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:15:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:26 2018 ] Training epoch: 1590
[ Wed Apr 25 11:15:31 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:15:31 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:15:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:15:31 2018 ] Eval epoch: 1590
[ Wed Apr 25 11:15:34 2018 ] 	Mean test loss of 1 batches: 0.21093234419822693.
[ Wed Apr 25 11:15:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:15:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:15:34 2018 ] Training epoch: 1591
[ Wed Apr 25 11:15:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:15:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:15:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:38 2018 ] Training epoch: 1592
[ Wed Apr 25 11:15:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:15:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:15:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:42 2018 ] Training epoch: 1593
[ Wed Apr 25 11:15:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:15:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:15:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:46 2018 ] Training epoch: 1594
[ Wed Apr 25 11:15:50 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:15:50 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:15:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:50 2018 ] Training epoch: 1595
[ Wed Apr 25 11:15:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:15:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:15:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:15:54 2018 ] Eval epoch: 1595
[ Wed Apr 25 11:15:57 2018 ] 	Mean test loss of 1 batches: 0.21662834286689758.
[ Wed Apr 25 11:15:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:15:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:15:57 2018 ] Training epoch: 1596
[ Wed Apr 25 11:16:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:16:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:16:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:01 2018 ] Training epoch: 1597
[ Wed Apr 25 11:16:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:16:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:16:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:05 2018 ] Training epoch: 1598
[ Wed Apr 25 11:16:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:16:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:16:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:09 2018 ] Training epoch: 1599
[ Wed Apr 25 11:16:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:16:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:16:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:13 2018 ] Training epoch: 1600
[ Wed Apr 25 11:16:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:16:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:16:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:17 2018 ] Eval epoch: 1600
[ Wed Apr 25 11:16:20 2018 ] 	Mean test loss of 1 batches: 0.22723552584648132.
[ Wed Apr 25 11:16:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:16:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:16:20 2018 ] Training epoch: 1601
[ Wed Apr 25 11:16:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:16:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:16:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:24 2018 ] Training epoch: 1602
[ Wed Apr 25 11:16:28 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:16:28 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:16:28 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 11:16:28 2018 ] Training epoch: 1603
[ Wed Apr 25 11:16:32 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:16:32 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:16:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:32 2018 ] Training epoch: 1604
[ Wed Apr 25 11:16:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:16:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:16:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:36 2018 ] Training epoch: 1605
[ Wed Apr 25 11:16:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:16:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:16:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:40 2018 ] Eval epoch: 1605
[ Wed Apr 25 11:16:43 2018 ] 	Mean test loss of 1 batches: 0.20929227769374847.
[ Wed Apr 25 11:16:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:16:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:16:43 2018 ] Training epoch: 1606
[ Wed Apr 25 11:16:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:16:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:16:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:47 2018 ] Training epoch: 1607
[ Wed Apr 25 11:16:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:16:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:16:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:51 2018 ] Training epoch: 1608
[ Wed Apr 25 11:16:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:16:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:16:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:55 2018 ] Training epoch: 1609
[ Wed Apr 25 11:16:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:16:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:16:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:16:59 2018 ] Training epoch: 1610
[ Wed Apr 25 11:17:03 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:17:03 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:17:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:03 2018 ] Eval epoch: 1610
[ Wed Apr 25 11:17:06 2018 ] 	Mean test loss of 1 batches: 0.19738556444644928.
[ Wed Apr 25 11:17:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:17:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:17:06 2018 ] Training epoch: 1611
[ Wed Apr 25 11:17:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:17:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:17:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:10 2018 ] Training epoch: 1612
[ Wed Apr 25 11:17:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:17:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:17:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:14 2018 ] Training epoch: 1613
[ Wed Apr 25 11:17:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:17:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:17:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:18 2018 ] Training epoch: 1614
[ Wed Apr 25 11:17:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:17:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:17:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:22 2018 ] Training epoch: 1615
[ Wed Apr 25 11:17:26 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:17:26 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:17:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:26 2018 ] Eval epoch: 1615
[ Wed Apr 25 11:17:29 2018 ] 	Mean test loss of 1 batches: 0.19317473471164703.
[ Wed Apr 25 11:17:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:17:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:17:29 2018 ] Training epoch: 1616
[ Wed Apr 25 11:17:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:17:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:17:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:33 2018 ] Training epoch: 1617
[ Wed Apr 25 11:17:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:17:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:17:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:37 2018 ] Training epoch: 1618
[ Wed Apr 25 11:17:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:17:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:17:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:41 2018 ] Training epoch: 1619
[ Wed Apr 25 11:17:45 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:17:45 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:17:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:45 2018 ] Training epoch: 1620
[ Wed Apr 25 11:17:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:17:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:17:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:49 2018 ] Eval epoch: 1620
[ Wed Apr 25 11:17:52 2018 ] 	Mean test loss of 1 batches: 0.2084629237651825.
[ Wed Apr 25 11:17:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:17:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:17:52 2018 ] Training epoch: 1621
[ Wed Apr 25 11:17:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:17:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:17:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:17:56 2018 ] Training epoch: 1622
[ Wed Apr 25 11:18:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:00 2018 ] Training epoch: 1623
[ Wed Apr 25 11:18:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:18:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:18:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:04 2018 ] Training epoch: 1624
[ Wed Apr 25 11:18:08 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:18:08 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:18:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:18:08 2018 ] Training epoch: 1625
[ Wed Apr 25 11:18:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:12 2018 ] Eval epoch: 1625
[ Wed Apr 25 11:18:14 2018 ] 	Mean test loss of 1 batches: 0.2126704454421997.
[ Wed Apr 25 11:18:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:18:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:18:14 2018 ] Training epoch: 1626
[ Wed Apr 25 11:18:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:18:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:18:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:18 2018 ] Training epoch: 1627
[ Wed Apr 25 11:18:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:18:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:18:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:22 2018 ] Training epoch: 1628
[ Wed Apr 25 11:18:26 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:18:26 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:18:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:26 2018 ] Training epoch: 1629
[ Wed Apr 25 11:18:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:30 2018 ] Training epoch: 1630
[ Wed Apr 25 11:18:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:18:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:18:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:34 2018 ] Eval epoch: 1630
[ Wed Apr 25 11:18:37 2018 ] 	Mean test loss of 1 batches: 0.20417596399784088.
[ Wed Apr 25 11:18:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:18:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:18:37 2018 ] Training epoch: 1631
[ Wed Apr 25 11:18:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:41 2018 ] Training epoch: 1632
[ Wed Apr 25 11:18:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:18:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:18:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:45 2018 ] Training epoch: 1633
[ Wed Apr 25 11:18:49 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:18:49 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:18:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:49 2018 ] Training epoch: 1634
[ Wed Apr 25 11:18:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:53 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:18:53 2018 ] Training epoch: 1635
[ Wed Apr 25 11:18:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:18:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:18:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:18:57 2018 ] Eval epoch: 1635
[ Wed Apr 25 11:19:00 2018 ] 	Mean test loss of 1 batches: 0.2121334820985794.
[ Wed Apr 25 11:19:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:19:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:19:00 2018 ] Training epoch: 1636
[ Wed Apr 25 11:19:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:19:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:19:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:19:04 2018 ] Training epoch: 1637
[ Wed Apr 25 11:19:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:19:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:19:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:08 2018 ] Training epoch: 1638
[ Wed Apr 25 11:19:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:19:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:19:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:12 2018 ] Training epoch: 1639
[ Wed Apr 25 11:19:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:19:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:19:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:16 2018 ] Training epoch: 1640
[ Wed Apr 25 11:19:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:19:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:19:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:20 2018 ] Eval epoch: 1640
[ Wed Apr 25 11:19:23 2018 ] 	Mean test loss of 1 batches: 0.22039391100406647.
[ Wed Apr 25 11:19:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:19:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:19:23 2018 ] Training epoch: 1641
[ Wed Apr 25 11:19:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:19:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:19:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:27 2018 ] Training epoch: 1642
[ Wed Apr 25 11:19:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:19:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:19:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:31 2018 ] Training epoch: 1643
[ Wed Apr 25 11:19:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:19:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:19:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:35 2018 ] Training epoch: 1644
[ Wed Apr 25 11:19:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:19:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:19:39 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:19:39 2018 ] Training epoch: 1645
[ Wed Apr 25 11:19:43 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:19:43 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:19:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:43 2018 ] Eval epoch: 1645
[ Wed Apr 25 11:19:46 2018 ] 	Mean test loss of 1 batches: 0.23730112612247467.
[ Wed Apr 25 11:19:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:19:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:19:46 2018 ] Training epoch: 1646
[ Wed Apr 25 11:19:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:19:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:19:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:50 2018 ] Training epoch: 1647
[ Wed Apr 25 11:19:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:19:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:19:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:54 2018 ] Training epoch: 1648
[ Wed Apr 25 11:19:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:19:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:19:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:19:59 2018 ] Training epoch: 1649
[ Wed Apr 25 11:20:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:20:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:20:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:03 2018 ] Training epoch: 1650
[ Wed Apr 25 11:20:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:06 2018 ] Eval epoch: 1650
[ Wed Apr 25 11:20:09 2018 ] 	Mean test loss of 1 batches: 0.22408732771873474.
[ Wed Apr 25 11:20:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:20:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:20:09 2018 ] Training epoch: 1651
[ Wed Apr 25 11:20:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:20:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:20:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:13 2018 ] Training epoch: 1652
[ Wed Apr 25 11:20:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:20:17 2018 ] Training epoch: 1653
[ Wed Apr 25 11:20:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:20:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:20:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:21 2018 ] Training epoch: 1654
[ Wed Apr 25 11:20:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:25 2018 ] Training epoch: 1655
[ Wed Apr 25 11:20:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:20:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:20:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:30 2018 ] Eval epoch: 1655
[ Wed Apr 25 11:20:32 2018 ] 	Mean test loss of 1 batches: 0.22040823101997375.
[ Wed Apr 25 11:20:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:20:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:20:32 2018 ] Training epoch: 1656
[ Wed Apr 25 11:20:36 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:20:36 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:20:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:36 2018 ] Training epoch: 1657
[ Wed Apr 25 11:20:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:40 2018 ] Training epoch: 1658
[ Wed Apr 25 11:20:44 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:20:44 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:20:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:44 2018 ] Training epoch: 1659
[ Wed Apr 25 11:20:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:48 2018 ] Training epoch: 1660
[ Wed Apr 25 11:20:52 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:20:52 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:20:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:20:52 2018 ] Eval epoch: 1660
[ Wed Apr 25 11:20:55 2018 ] 	Mean test loss of 1 batches: 0.21461617946624756.
[ Wed Apr 25 11:20:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:20:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:20:55 2018 ] Training epoch: 1661
[ Wed Apr 25 11:20:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:20:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:20:59 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:20:59 2018 ] Training epoch: 1662
[ Wed Apr 25 11:21:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:03 2018 ] Training epoch: 1663
[ Wed Apr 25 11:21:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:21:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:21:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:07 2018 ] Training epoch: 1664
[ Wed Apr 25 11:21:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:11 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:21:11 2018 ] Training epoch: 1665
[ Wed Apr 25 11:21:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:21:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:21:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:15 2018 ] Eval epoch: 1665
[ Wed Apr 25 11:21:18 2018 ] 	Mean test loss of 1 batches: 0.21335887908935547.
[ Wed Apr 25 11:21:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:21:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:21:18 2018 ] Training epoch: 1666
[ Wed Apr 25 11:21:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:21:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:21:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:21:22 2018 ] Training epoch: 1667
[ Wed Apr 25 11:21:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:26 2018 ] Training epoch: 1668
[ Wed Apr 25 11:21:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:30 2018 ] Training epoch: 1669
[ Wed Apr 25 11:21:34 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:21:34 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:21:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:34 2018 ] Training epoch: 1670
[ Wed Apr 25 11:21:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:38 2018 ] Eval epoch: 1670
[ Wed Apr 25 11:21:41 2018 ] 	Mean test loss of 1 batches: 0.21763154864311218.
[ Wed Apr 25 11:21:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:21:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:21:41 2018 ] Training epoch: 1671
[ Wed Apr 25 11:21:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:45 2018 ] Training epoch: 1672
[ Wed Apr 25 11:21:49 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 11:21:49 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 11:21:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:49 2018 ] Training epoch: 1673
[ Wed Apr 25 11:21:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:21:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:21:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:21:53 2018 ] Training epoch: 1674
[ Wed Apr 25 11:21:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:21:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:21:57 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:21:57 2018 ] Training epoch: 1675
[ Wed Apr 25 11:22:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:22:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:22:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:01 2018 ] Eval epoch: 1675
[ Wed Apr 25 11:22:04 2018 ] 	Mean test loss of 1 batches: 0.24267442524433136.
[ Wed Apr 25 11:22:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:22:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:22:04 2018 ] Training epoch: 1676
[ Wed Apr 25 11:22:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:22:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:22:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:08 2018 ] Training epoch: 1677
[ Wed Apr 25 11:22:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:12 2018 ] Training epoch: 1678
[ Wed Apr 25 11:22:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:16 2018 ] Training epoch: 1679
[ Wed Apr 25 11:22:20 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:22:20 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:22:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:20 2018 ] Training epoch: 1680
[ Wed Apr 25 11:22:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:24 2018 ] Eval epoch: 1680
[ Wed Apr 25 11:22:27 2018 ] 	Mean test loss of 1 batches: 0.2042994499206543.
[ Wed Apr 25 11:22:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:22:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:22:27 2018 ] Training epoch: 1681
[ Wed Apr 25 11:22:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:31 2018 ] Training epoch: 1682
[ Wed Apr 25 11:22:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:22:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:22:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:35 2018 ] Training epoch: 1683
[ Wed Apr 25 11:22:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:39 2018 ] Training epoch: 1684
[ Wed Apr 25 11:22:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:22:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:22:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:43 2018 ] Training epoch: 1685
[ Wed Apr 25 11:22:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:47 2018 ] Eval epoch: 1685
[ Wed Apr 25 11:22:50 2018 ] 	Mean test loss of 1 batches: 0.18817922472953796.
[ Wed Apr 25 11:22:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:22:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:22:50 2018 ] Training epoch: 1686
[ Wed Apr 25 11:22:54 2018 ] 	Batch(0/1) done. Loss: 0.0045  lr:0.100000
[ Wed Apr 25 11:22:54 2018 ] 	Mean training loss: 0.0045.
[ Wed Apr 25 11:22:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:54 2018 ] Training epoch: 1687
[ Wed Apr 25 11:22:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:22:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:22:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:22:58 2018 ] Training epoch: 1688
[ Wed Apr 25 11:23:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:23:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:23:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:02 2018 ] Training epoch: 1689
[ Wed Apr 25 11:23:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:23:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:23:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:06 2018 ] Training epoch: 1690
[ Wed Apr 25 11:23:10 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 11:23:10 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 11:23:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:10 2018 ] Eval epoch: 1690
[ Wed Apr 25 11:23:13 2018 ] 	Mean test loss of 1 batches: 0.2002701759338379.
[ Wed Apr 25 11:23:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:23:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:23:13 2018 ] Training epoch: 1691
[ Wed Apr 25 11:23:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:23:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:23:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:17 2018 ] Training epoch: 1692
[ Wed Apr 25 11:23:21 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:23:21 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:23:21 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 11:23:21 2018 ] Training epoch: 1693
[ Wed Apr 25 11:23:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:23:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:23:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:26 2018 ] Training epoch: 1694
[ Wed Apr 25 11:23:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:23:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:23:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:30 2018 ] Training epoch: 1695
[ Wed Apr 25 11:23:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:23:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:23:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:34 2018 ] Eval epoch: 1695
[ Wed Apr 25 11:23:37 2018 ] 	Mean test loss of 1 batches: 0.21221686899662018.
[ Wed Apr 25 11:23:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:23:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:23:37 2018 ] Training epoch: 1696
[ Wed Apr 25 11:23:41 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.100000
[ Wed Apr 25 11:23:41 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 11:23:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:23:41 2018 ] Training epoch: 1697
[ Wed Apr 25 11:23:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:23:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:23:45 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:23:45 2018 ] Training epoch: 1698
[ Wed Apr 25 11:23:49 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:23:49 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:23:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:49 2018 ] Training epoch: 1699
[ Wed Apr 25 11:23:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:23:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:23:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:23:53 2018 ] Training epoch: 1700
[ Wed Apr 25 11:23:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:23:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:23:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:23:57 2018 ] Eval epoch: 1700
[ Wed Apr 25 11:24:00 2018 ] 	Mean test loss of 1 batches: 0.23430299758911133.
[ Wed Apr 25 11:24:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:24:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:24:00 2018 ] Training epoch: 1701
[ Wed Apr 25 11:24:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:24:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:24:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:04 2018 ] Training epoch: 1702
[ Wed Apr 25 11:24:08 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:24:08 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:24:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:08 2018 ] Training epoch: 1703
[ Wed Apr 25 11:24:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:12 2018 ] Training epoch: 1704
[ Wed Apr 25 11:24:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:16 2018 ] Training epoch: 1705
[ Wed Apr 25 11:24:20 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.100000
[ Wed Apr 25 11:24:20 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 11:24:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:20 2018 ] Eval epoch: 1705
[ Wed Apr 25 11:24:23 2018 ] 	Mean test loss of 1 batches: 0.2225002944469452.
[ Wed Apr 25 11:24:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:24:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:24:23 2018 ] Training epoch: 1706
[ Wed Apr 25 11:24:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:27 2018 ] Training epoch: 1707
[ Wed Apr 25 11:24:31 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:24:31 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:24:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:31 2018 ] Training epoch: 1708
[ Wed Apr 25 11:24:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:24:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:24:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:35 2018 ] Training epoch: 1709
[ Wed Apr 25 11:24:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:39 2018 ] Training epoch: 1710
[ Wed Apr 25 11:24:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:24:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:24:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:43 2018 ] Eval epoch: 1710
[ Wed Apr 25 11:24:46 2018 ] 	Mean test loss of 1 batches: 0.18019188940525055.
[ Wed Apr 25 11:24:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:24:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:24:46 2018 ] Training epoch: 1711
[ Wed Apr 25 11:24:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:50 2018 ] Training epoch: 1712
[ Wed Apr 25 11:24:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:24:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:24:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:54 2018 ] Training epoch: 1713
[ Wed Apr 25 11:24:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:24:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:24:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:24:58 2018 ] Training epoch: 1714
[ Wed Apr 25 11:25:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:25:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:25:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:02 2018 ] Training epoch: 1715
[ Wed Apr 25 11:25:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:25:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:25:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:06 2018 ] Eval epoch: 1715
[ Wed Apr 25 11:25:09 2018 ] 	Mean test loss of 1 batches: 0.1617760807275772.
[ Wed Apr 25 11:25:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:25:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:25:09 2018 ] Training epoch: 1716
[ Wed Apr 25 11:25:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:25:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:25:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:13 2018 ] Training epoch: 1717
[ Wed Apr 25 11:25:18 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:25:18 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:25:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:18 2018 ] Training epoch: 1718
[ Wed Apr 25 11:25:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:25:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:25:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:25:22 2018 ] Training epoch: 1719
[ Wed Apr 25 11:25:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:25:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:25:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:26 2018 ] Training epoch: 1720
[ Wed Apr 25 11:25:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:25:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:25:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:30 2018 ] Eval epoch: 1720
[ Wed Apr 25 11:25:33 2018 ] 	Mean test loss of 1 batches: 0.14961767196655273.
[ Wed Apr 25 11:25:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:25:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:25:33 2018 ] Training epoch: 1721
[ Wed Apr 25 11:25:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:25:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:25:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:37 2018 ] Training epoch: 1722
[ Wed Apr 25 11:25:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:25:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:25:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:41 2018 ] Training epoch: 1723
[ Wed Apr 25 11:25:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:25:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:25:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:45 2018 ] Training epoch: 1724
[ Wed Apr 25 11:25:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:25:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:25:49 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 11:25:49 2018 ] Training epoch: 1725
[ Wed Apr 25 11:25:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:25:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:25:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:25:53 2018 ] Eval epoch: 1725
[ Wed Apr 25 11:25:56 2018 ] 	Mean test loss of 1 batches: 0.1641145646572113.
[ Wed Apr 25 11:25:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:25:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:25:56 2018 ] Training epoch: 1726
[ Wed Apr 25 11:26:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:26:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:26:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:00 2018 ] Training epoch: 1727
[ Wed Apr 25 11:26:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:26:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:26:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:04 2018 ] Training epoch: 1728
[ Wed Apr 25 11:26:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:26:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:26:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:26:09 2018 ] Training epoch: 1729
[ Wed Apr 25 11:26:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:26:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:26:13 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:26:13 2018 ] Training epoch: 1730
[ Wed Apr 25 11:26:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:26:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:26:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:17 2018 ] Eval epoch: 1730
[ Wed Apr 25 11:26:21 2018 ] 	Mean test loss of 1 batches: 0.16137661039829254.
[ Wed Apr 25 11:26:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:26:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:26:21 2018 ] Training epoch: 1731
[ Wed Apr 25 11:26:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:26:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:26:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:25 2018 ] Training epoch: 1732
[ Wed Apr 25 11:26:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:26:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:26:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:29 2018 ] Training epoch: 1733
[ Wed Apr 25 11:26:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:26:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:26:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:33 2018 ] Training epoch: 1734
[ Wed Apr 25 11:26:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:26:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:26:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:37 2018 ] Training epoch: 1735
[ Wed Apr 25 11:26:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:26:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:26:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:41 2018 ] Eval epoch: 1735
[ Wed Apr 25 11:26:44 2018 ] 	Mean test loss of 1 batches: 0.17857500910758972.
[ Wed Apr 25 11:26:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:26:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:26:44 2018 ] Training epoch: 1736
[ Wed Apr 25 11:26:48 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:26:48 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:26:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:48 2018 ] Training epoch: 1737
[ Wed Apr 25 11:26:52 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:26:52 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:26:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:52 2018 ] Training epoch: 1738
[ Wed Apr 25 11:26:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:26:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:26:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:26:56 2018 ] Training epoch: 1739
[ Wed Apr 25 11:27:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:27:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:27:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:00 2018 ] Training epoch: 1740
[ Wed Apr 25 11:27:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:27:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:27:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:04 2018 ] Eval epoch: 1740
[ Wed Apr 25 11:27:07 2018 ] 	Mean test loss of 1 batches: 0.1808013617992401.
[ Wed Apr 25 11:27:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:27:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:27:07 2018 ] Training epoch: 1741
[ Wed Apr 25 11:27:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:27:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:27:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:11 2018 ] Training epoch: 1742
[ Wed Apr 25 11:27:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:27:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:27:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:15 2018 ] Training epoch: 1743
[ Wed Apr 25 11:27:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:27:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:27:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:19 2018 ] Training epoch: 1744
[ Wed Apr 25 11:27:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:27:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:27:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:23 2018 ] Training epoch: 1745
[ Wed Apr 25 11:27:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:27:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:27:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:27 2018 ] Eval epoch: 1745
[ Wed Apr 25 11:27:30 2018 ] 	Mean test loss of 1 batches: 0.18468207120895386.
[ Wed Apr 25 11:27:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:27:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:27:30 2018 ] Training epoch: 1746
[ Wed Apr 25 11:27:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:27:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:27:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:34 2018 ] Training epoch: 1747
[ Wed Apr 25 11:27:38 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:27:38 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:27:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:38 2018 ] Training epoch: 1748
[ Wed Apr 25 11:27:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:27:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:27:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:42 2018 ] Training epoch: 1749
[ Wed Apr 25 11:27:46 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:27:46 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:27:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:46 2018 ] Training epoch: 1750
[ Wed Apr 25 11:27:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:27:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:27:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:50 2018 ] Eval epoch: 1750
[ Wed Apr 25 11:27:53 2018 ] 	Mean test loss of 1 batches: 0.1851784586906433.
[ Wed Apr 25 11:27:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:27:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:27:53 2018 ] Training epoch: 1751
[ Wed Apr 25 11:27:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:27:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:27:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:27:57 2018 ] Training epoch: 1752
[ Wed Apr 25 11:28:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:28:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:28:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:01 2018 ] Training epoch: 1753
[ Wed Apr 25 11:28:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:28:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:28:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:05 2018 ] Training epoch: 1754
[ Wed Apr 25 11:28:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:28:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:28:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:09 2018 ] Training epoch: 1755
[ Wed Apr 25 11:28:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:28:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:28:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:28:13 2018 ] Eval epoch: 1755
[ Wed Apr 25 11:28:16 2018 ] 	Mean test loss of 1 batches: 0.1856851875782013.
[ Wed Apr 25 11:28:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:28:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:28:16 2018 ] Training epoch: 1756
[ Wed Apr 25 11:28:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:28:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:28:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:20 2018 ] Training epoch: 1757
[ Wed Apr 25 11:28:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:28:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:28:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:24 2018 ] Training epoch: 1758
[ Wed Apr 25 11:28:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:28:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:28:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:28 2018 ] Training epoch: 1759
[ Wed Apr 25 11:28:33 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:28:33 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:28:33 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:28:33 2018 ] Training epoch: 1760
[ Wed Apr 25 11:28:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:28:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:28:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:37 2018 ] Eval epoch: 1760
[ Wed Apr 25 11:28:39 2018 ] 	Mean test loss of 1 batches: 0.19590845704078674.
[ Wed Apr 25 11:28:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:28:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:28:39 2018 ] Training epoch: 1761
[ Wed Apr 25 11:28:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:28:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:28:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:44 2018 ] Training epoch: 1762
[ Wed Apr 25 11:28:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:28:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:28:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:48 2018 ] Training epoch: 1763
[ Wed Apr 25 11:28:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:28:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:28:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:28:52 2018 ] Training epoch: 1764
[ Wed Apr 25 11:28:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:28:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:28:56 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:28:56 2018 ] Training epoch: 1765
[ Wed Apr 25 11:29:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:29:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:29:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:00 2018 ] Eval epoch: 1765
[ Wed Apr 25 11:29:03 2018 ] 	Mean test loss of 1 batches: 0.20021994411945343.
[ Wed Apr 25 11:29:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:29:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:29:03 2018 ] Training epoch: 1766
[ Wed Apr 25 11:29:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:29:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:29:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:07 2018 ] Training epoch: 1767
[ Wed Apr 25 11:29:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:29:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:29:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:11 2018 ] Training epoch: 1768
[ Wed Apr 25 11:29:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:29:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:29:15 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:29:15 2018 ] Training epoch: 1769
[ Wed Apr 25 11:29:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:29:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:29:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:19 2018 ] Training epoch: 1770
[ Wed Apr 25 11:29:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:29:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:29:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:23 2018 ] Eval epoch: 1770
[ Wed Apr 25 11:29:26 2018 ] 	Mean test loss of 1 batches: 0.20817527174949646.
[ Wed Apr 25 11:29:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:29:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:29:26 2018 ] Training epoch: 1771
[ Wed Apr 25 11:29:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:29:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:29:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:30 2018 ] Training epoch: 1772
[ Wed Apr 25 11:29:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:29:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:29:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:34 2018 ] Training epoch: 1773
[ Wed Apr 25 11:29:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:29:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:29:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:38 2018 ] Training epoch: 1774
[ Wed Apr 25 11:29:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:29:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:29:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:42 2018 ] Training epoch: 1775
[ Wed Apr 25 11:29:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:29:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:29:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:29:46 2018 ] Eval epoch: 1775
[ Wed Apr 25 11:29:49 2018 ] 	Mean test loss of 1 batches: 0.2011784315109253.
[ Wed Apr 25 11:29:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:29:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:29:49 2018 ] Training epoch: 1776
[ Wed Apr 25 11:29:53 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:29:53 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:29:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:53 2018 ] Training epoch: 1777
[ Wed Apr 25 11:29:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:29:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:29:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:29:57 2018 ] Training epoch: 1778
[ Wed Apr 25 11:30:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:30:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:30:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:01 2018 ] Training epoch: 1779
[ Wed Apr 25 11:30:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:30:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:30:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:05 2018 ] Training epoch: 1780
[ Wed Apr 25 11:30:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:09 2018 ] Eval epoch: 1780
[ Wed Apr 25 11:30:12 2018 ] 	Mean test loss of 1 batches: 0.21695464849472046.
[ Wed Apr 25 11:30:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:30:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:30:12 2018 ] Training epoch: 1781
[ Wed Apr 25 11:30:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:30:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:30:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:16 2018 ] Training epoch: 1782
[ Wed Apr 25 11:30:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:30:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:30:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:20 2018 ] Training epoch: 1783
[ Wed Apr 25 11:30:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:24 2018 ] Training epoch: 1784
[ Wed Apr 25 11:30:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:30:28 2018 ] Training epoch: 1785
[ Wed Apr 25 11:30:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:32 2018 ] Eval epoch: 1785
[ Wed Apr 25 11:30:34 2018 ] 	Mean test loss of 1 batches: 0.186912402510643.
[ Wed Apr 25 11:30:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:30:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:30:34 2018 ] Training epoch: 1786
[ Wed Apr 25 11:30:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:39 2018 ] Training epoch: 1787
[ Wed Apr 25 11:30:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:30:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:30:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:43 2018 ] Training epoch: 1788
[ Wed Apr 25 11:30:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:30:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:30:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:47 2018 ] Training epoch: 1789
[ Wed Apr 25 11:30:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:30:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:30:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:51 2018 ] Training epoch: 1790
[ Wed Apr 25 11:30:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:30:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:30:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:30:55 2018 ] Eval epoch: 1790
[ Wed Apr 25 11:30:58 2018 ] 	Mean test loss of 1 batches: 0.1835319846868515.
[ Wed Apr 25 11:30:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:30:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:30:58 2018 ] Training epoch: 1791
[ Wed Apr 25 11:31:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:31:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:31:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:02 2018 ] Training epoch: 1792
[ Wed Apr 25 11:31:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:31:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:31:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:06 2018 ] Training epoch: 1793
[ Wed Apr 25 11:31:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:31:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:31:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:10 2018 ] Training epoch: 1794
[ Wed Apr 25 11:31:14 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:31:14 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:31:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:14 2018 ] Training epoch: 1795
[ Wed Apr 25 11:31:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:31:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:31:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:18 2018 ] Eval epoch: 1795
[ Wed Apr 25 11:31:21 2018 ] 	Mean test loss of 1 batches: 0.194901242852211.
[ Wed Apr 25 11:31:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:31:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:31:21 2018 ] Training epoch: 1796
[ Wed Apr 25 11:31:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:31:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:31:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:25 2018 ] Training epoch: 1797
[ Wed Apr 25 11:31:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:31:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:31:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:29 2018 ] Training epoch: 1798
[ Wed Apr 25 11:31:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:31:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:31:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:33 2018 ] Training epoch: 1799
[ Wed Apr 25 11:31:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:31:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:31:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:37 2018 ] Training epoch: 1800
[ Wed Apr 25 11:31:41 2018 ] 	Batch(0/1) done. Loss: 0.0014  lr:0.100000
[ Wed Apr 25 11:31:41 2018 ] 	Mean training loss: 0.0014.
[ Wed Apr 25 11:31:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:31:41 2018 ] Eval epoch: 1800
[ Wed Apr 25 11:31:44 2018 ] 	Mean test loss of 1 batches: 0.18650883436203003.
[ Wed Apr 25 11:31:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:31:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:31:44 2018 ] Training epoch: 1801
[ Wed Apr 25 11:31:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:31:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:31:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:48 2018 ] Training epoch: 1802
[ Wed Apr 25 11:31:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:31:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:31:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:52 2018 ] Training epoch: 1803
[ Wed Apr 25 11:31:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:31:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:31:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:31:56 2018 ] Training epoch: 1804
[ Wed Apr 25 11:32:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:32:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:32:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:00 2018 ] Training epoch: 1805
[ Wed Apr 25 11:32:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:32:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:32:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:04 2018 ] Eval epoch: 1805
[ Wed Apr 25 11:32:07 2018 ] 	Mean test loss of 1 batches: 0.19008813798427582.
[ Wed Apr 25 11:32:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:32:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:32:07 2018 ] Training epoch: 1806
[ Wed Apr 25 11:32:11 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:32:11 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:32:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:11 2018 ] Training epoch: 1807
[ Wed Apr 25 11:32:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:32:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:32:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:15 2018 ] Training epoch: 1808
[ Wed Apr 25 11:32:19 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 11:32:19 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 11:32:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:19 2018 ] Training epoch: 1809
[ Wed Apr 25 11:32:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:32:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:32:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:23 2018 ] Training epoch: 1810
[ Wed Apr 25 11:32:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:32:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:32:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:27 2018 ] Eval epoch: 1810
[ Wed Apr 25 11:32:30 2018 ] 	Mean test loss of 1 batches: 0.20272380113601685.
[ Wed Apr 25 11:32:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:32:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:32:30 2018 ] Training epoch: 1811
[ Wed Apr 25 11:32:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:32:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:32:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:34 2018 ] Training epoch: 1812
[ Wed Apr 25 11:32:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:32:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:32:38 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:32:38 2018 ] Training epoch: 1813
[ Wed Apr 25 11:32:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:32:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:32:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:42 2018 ] Training epoch: 1814
[ Wed Apr 25 11:32:46 2018 ] 	Batch(0/1) done. Loss: 0.0011  lr:0.100000
[ Wed Apr 25 11:32:46 2018 ] 	Mean training loss: 0.0011.
[ Wed Apr 25 11:32:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:46 2018 ] Training epoch: 1815
[ Wed Apr 25 11:32:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:32:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:32:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:50 2018 ] Eval epoch: 1815
[ Wed Apr 25 11:32:53 2018 ] 	Mean test loss of 1 batches: 0.19803616404533386.
[ Wed Apr 25 11:32:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:32:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:32:53 2018 ] Training epoch: 1816
[ Wed Apr 25 11:32:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:32:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:32:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:32:57 2018 ] Training epoch: 1817
[ Wed Apr 25 11:33:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:33:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:33:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:01 2018 ] Training epoch: 1818
[ Wed Apr 25 11:33:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:33:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:33:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:05 2018 ] Training epoch: 1819
[ Wed Apr 25 11:33:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:33:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:33:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:09 2018 ] Training epoch: 1820
[ Wed Apr 25 11:33:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:33:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:33:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:13 2018 ] Eval epoch: 1820
[ Wed Apr 25 11:33:16 2018 ] 	Mean test loss of 1 batches: 0.20474904775619507.
[ Wed Apr 25 11:33:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:33:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:33:16 2018 ] Training epoch: 1821
[ Wed Apr 25 11:33:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:33:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:33:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:20 2018 ] Training epoch: 1822
[ Wed Apr 25 11:33:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:33:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:33:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:24 2018 ] Training epoch: 1823
[ Wed Apr 25 11:33:28 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:33:28 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:33:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:28 2018 ] Training epoch: 1824
[ Wed Apr 25 11:33:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:33:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:33:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:32 2018 ] Training epoch: 1825
[ Wed Apr 25 11:33:36 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:33:36 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:33:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:36 2018 ] Eval epoch: 1825
[ Wed Apr 25 11:33:39 2018 ] 	Mean test loss of 1 batches: 0.2064560502767563.
[ Wed Apr 25 11:33:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:33:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:33:39 2018 ] Training epoch: 1826
[ Wed Apr 25 11:33:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:33:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:33:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:43 2018 ] Training epoch: 1827
[ Wed Apr 25 11:33:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:33:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:33:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:47 2018 ] Training epoch: 1828
[ Wed Apr 25 11:33:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:33:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:33:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:51 2018 ] Training epoch: 1829
[ Wed Apr 25 11:33:55 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:33:55 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:33:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:55 2018 ] Training epoch: 1830
[ Wed Apr 25 11:33:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:33:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:33:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:33:59 2018 ] Eval epoch: 1830
[ Wed Apr 25 11:34:02 2018 ] 	Mean test loss of 1 batches: 0.21782729029655457.
[ Wed Apr 25 11:34:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:34:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:34:02 2018 ] Training epoch: 1831
[ Wed Apr 25 11:34:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:34:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:34:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:06 2018 ] Training epoch: 1832
[ Wed Apr 25 11:34:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:34:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:34:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:10 2018 ] Training epoch: 1833
[ Wed Apr 25 11:34:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:34:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:34:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:14 2018 ] Training epoch: 1834
[ Wed Apr 25 11:34:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:34:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:34:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:18 2018 ] Training epoch: 1835
[ Wed Apr 25 11:34:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:34:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:34:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:22 2018 ] Eval epoch: 1835
[ Wed Apr 25 11:34:25 2018 ] 	Mean test loss of 1 batches: 0.21393775939941406.
[ Wed Apr 25 11:34:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:34:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:34:25 2018 ] Training epoch: 1836
[ Wed Apr 25 11:34:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:34:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:34:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:29 2018 ] Training epoch: 1837
[ Wed Apr 25 11:34:33 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:34:33 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:34:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:33 2018 ] Training epoch: 1838
[ Wed Apr 25 11:34:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:34:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:34:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:37 2018 ] Training epoch: 1839
[ Wed Apr 25 11:34:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:34:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:34:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:41 2018 ] Training epoch: 1840
[ Wed Apr 25 11:34:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:34:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:34:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:45 2018 ] Eval epoch: 1840
[ Wed Apr 25 11:34:48 2018 ] 	Mean test loss of 1 batches: 0.19994309544563293.
[ Wed Apr 25 11:34:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:34:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:34:48 2018 ] Training epoch: 1841
[ Wed Apr 25 11:34:52 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:34:52 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:34:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:52 2018 ] Training epoch: 1842
[ Wed Apr 25 11:34:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:34:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:34:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:34:56 2018 ] Training epoch: 1843
[ Wed Apr 25 11:35:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:35:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:35:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:00 2018 ] Training epoch: 1844
[ Wed Apr 25 11:35:04 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.100000
[ Wed Apr 25 11:35:04 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 11:35:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:04 2018 ] Training epoch: 1845
[ Wed Apr 25 11:35:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:08 2018 ] Eval epoch: 1845
[ Wed Apr 25 11:35:11 2018 ] 	Mean test loss of 1 batches: 0.17181071639060974.
[ Wed Apr 25 11:35:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:35:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:35:11 2018 ] Training epoch: 1846
[ Wed Apr 25 11:35:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:15 2018 ] Training epoch: 1847
[ Wed Apr 25 11:35:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:19 2018 ] Training epoch: 1848
[ Wed Apr 25 11:35:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:23 2018 ] Training epoch: 1849
[ Wed Apr 25 11:35:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:35:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:35:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:27 2018 ] Training epoch: 1850
[ Wed Apr 25 11:35:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:35:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:35:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:31 2018 ] Eval epoch: 1850
[ Wed Apr 25 11:35:34 2018 ] 	Mean test loss of 1 batches: 0.1722724288702011.
[ Wed Apr 25 11:35:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:35:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:35:34 2018 ] Training epoch: 1851
[ Wed Apr 25 11:35:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:38 2018 ] Training epoch: 1852
[ Wed Apr 25 11:35:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:35:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:35:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:42 2018 ] Training epoch: 1853
[ Wed Apr 25 11:35:46 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:35:46 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:35:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:46 2018 ] Training epoch: 1854
[ Wed Apr 25 11:35:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:35:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:35:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:50 2018 ] Training epoch: 1855
[ Wed Apr 25 11:35:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:35:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:35:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:35:54 2018 ] Eval epoch: 1855
[ Wed Apr 25 11:35:57 2018 ] 	Mean test loss of 1 batches: 0.17361457645893097.
[ Wed Apr 25 11:35:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:35:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:35:57 2018 ] Training epoch: 1856
[ Wed Apr 25 11:36:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:01 2018 ] Training epoch: 1857
[ Wed Apr 25 11:36:05 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.100000
[ Wed Apr 25 11:36:05 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 11:36:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:05 2018 ] Training epoch: 1858
[ Wed Apr 25 11:36:09 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:36:09 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:36:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:09 2018 ] Training epoch: 1859
[ Wed Apr 25 11:36:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:36:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:36:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:13 2018 ] Training epoch: 1860
[ Wed Apr 25 11:36:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:18 2018 ] Eval epoch: 1860
[ Wed Apr 25 11:36:20 2018 ] 	Mean test loss of 1 batches: 0.16760890185832977.
[ Wed Apr 25 11:36:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:36:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:36:21 2018 ] Training epoch: 1861
[ Wed Apr 25 11:36:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:36:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:36:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:36:24 2018 ] Training epoch: 1862
[ Wed Apr 25 11:36:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:36:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:36:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:28 2018 ] Training epoch: 1863
[ Wed Apr 25 11:36:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:36:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:36:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:32 2018 ] Training epoch: 1864
[ Wed Apr 25 11:36:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:36 2018 ] Training epoch: 1865
[ Wed Apr 25 11:36:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:41 2018 ] Eval epoch: 1865
[ Wed Apr 25 11:36:44 2018 ] 	Mean test loss of 1 batches: 0.1723799854516983.
[ Wed Apr 25 11:36:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:36:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:36:44 2018 ] Training epoch: 1866
[ Wed Apr 25 11:36:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:48 2018 ] Training epoch: 1867
[ Wed Apr 25 11:36:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:36:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:36:52 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 11:36:52 2018 ] Training epoch: 1868
[ Wed Apr 25 11:36:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:36:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:36:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:36:56 2018 ] Training epoch: 1869
[ Wed Apr 25 11:37:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:37:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:37:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:00 2018 ] Training epoch: 1870
[ Wed Apr 25 11:37:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:04 2018 ] Eval epoch: 1870
[ Wed Apr 25 11:37:07 2018 ] 	Mean test loss of 1 batches: 0.19430819153785706.
[ Wed Apr 25 11:37:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:37:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:37:07 2018 ] Training epoch: 1871
[ Wed Apr 25 11:37:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:37:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:37:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:11 2018 ] Training epoch: 1872
[ Wed Apr 25 11:37:15 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:37:15 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:37:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:15 2018 ] Training epoch: 1873
[ Wed Apr 25 11:37:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:37:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:37:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:19 2018 ] Training epoch: 1874
[ Wed Apr 25 11:37:23 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:37:23 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:37:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:23 2018 ] Training epoch: 1875
[ Wed Apr 25 11:37:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:27 2018 ] Eval epoch: 1875
[ Wed Apr 25 11:37:30 2018 ] 	Mean test loss of 1 batches: 0.20392760634422302.
[ Wed Apr 25 11:37:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:37:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:37:30 2018 ] Training epoch: 1876
[ Wed Apr 25 11:37:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:34 2018 ] Training epoch: 1877
[ Wed Apr 25 11:37:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:37:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:37:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:38 2018 ] Training epoch: 1878
[ Wed Apr 25 11:37:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:42 2018 ] Training epoch: 1879
[ Wed Apr 25 11:37:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:37:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:37:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:46 2018 ] Training epoch: 1880
[ Wed Apr 25 11:37:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:51 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:37:51 2018 ] Eval epoch: 1880
[ Wed Apr 25 11:37:53 2018 ] 	Mean test loss of 1 batches: 0.2055661529302597.
[ Wed Apr 25 11:37:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:37:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:37:53 2018 ] Training epoch: 1881
[ Wed Apr 25 11:37:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:37:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:37:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:37:58 2018 ] Training epoch: 1882
[ Wed Apr 25 11:38:02 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:38:02 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:38:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:38:02 2018 ] Training epoch: 1883
[ Wed Apr 25 11:38:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:38:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:38:06 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:38:06 2018 ] Training epoch: 1884
[ Wed Apr 25 11:38:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:38:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:38:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:10 2018 ] Training epoch: 1885
[ Wed Apr 25 11:38:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:38:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:38:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:14 2018 ] Eval epoch: 1885
[ Wed Apr 25 11:38:17 2018 ] 	Mean test loss of 1 batches: 0.18430784344673157.
[ Wed Apr 25 11:38:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:38:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:38:17 2018 ] Training epoch: 1886
[ Wed Apr 25 11:38:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:21 2018 ] Training epoch: 1887
[ Wed Apr 25 11:38:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:25 2018 ] Training epoch: 1888
[ Wed Apr 25 11:38:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:29 2018 ] Training epoch: 1889
[ Wed Apr 25 11:38:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:33 2018 ] Training epoch: 1890
[ Wed Apr 25 11:38:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:37 2018 ] Eval epoch: 1890
[ Wed Apr 25 11:38:40 2018 ] 	Mean test loss of 1 batches: 0.1816968321800232.
[ Wed Apr 25 11:38:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:38:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:38:40 2018 ] Training epoch: 1891
[ Wed Apr 25 11:38:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:44 2018 ] Training epoch: 1892
[ Wed Apr 25 11:38:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:48 2018 ] Training epoch: 1893
[ Wed Apr 25 11:38:52 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:38:52 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:38:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:38:52 2018 ] Training epoch: 1894
[ Wed Apr 25 11:38:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:38:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:38:56 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:38:56 2018 ] Training epoch: 1895
[ Wed Apr 25 11:39:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:00 2018 ] Eval epoch: 1895
[ Wed Apr 25 11:39:03 2018 ] 	Mean test loss of 1 batches: 0.19071391224861145.
[ Wed Apr 25 11:39:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:39:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:39:03 2018 ] Training epoch: 1896
[ Wed Apr 25 11:39:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:07 2018 ] Training epoch: 1897
[ Wed Apr 25 11:39:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:11 2018 ] Training epoch: 1898
[ Wed Apr 25 11:39:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:15 2018 ] Training epoch: 1899
[ Wed Apr 25 11:39:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:39:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:39:19 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:39:19 2018 ] Training epoch: 1900
[ Wed Apr 25 11:39:23 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.100000
[ Wed Apr 25 11:39:23 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:39:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:23 2018 ] Eval epoch: 1900
[ Wed Apr 25 11:39:26 2018 ] 	Mean test loss of 1 batches: 0.20595072209835052.
[ Wed Apr 25 11:39:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:39:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:39:26 2018 ] Training epoch: 1901
[ Wed Apr 25 11:39:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:39:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:39:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:30 2018 ] Training epoch: 1902
[ Wed Apr 25 11:39:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:39:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:39:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:34 2018 ] Training epoch: 1903
[ Wed Apr 25 11:39:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:38 2018 ] Training epoch: 1904
[ Wed Apr 25 11:39:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:39:42 2018 ] Training epoch: 1905
[ Wed Apr 25 11:39:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:39:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:39:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:46 2018 ] Eval epoch: 1905
[ Wed Apr 25 11:39:49 2018 ] 	Mean test loss of 1 batches: 0.21419355273246765.
[ Wed Apr 25 11:39:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:39:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:39:49 2018 ] Training epoch: 1906
[ Wed Apr 25 11:39:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:39:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:39:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:53 2018 ] Training epoch: 1907
[ Wed Apr 25 11:39:57 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:39:57 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:39:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:39:57 2018 ] Training epoch: 1908
[ Wed Apr 25 11:40:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:40:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:40:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:01 2018 ] Training epoch: 1909
[ Wed Apr 25 11:40:05 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.100000
[ Wed Apr 25 11:40:05 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:40:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:05 2018 ] Training epoch: 1910
[ Wed Apr 25 11:40:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:40:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:40:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:09 2018 ] Eval epoch: 1910
[ Wed Apr 25 11:40:12 2018 ] 	Mean test loss of 1 batches: 0.21773777902126312.
[ Wed Apr 25 11:40:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:40:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:40:12 2018 ] Training epoch: 1911
[ Wed Apr 25 11:40:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:40:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:40:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:16 2018 ] Training epoch: 1912
[ Wed Apr 25 11:40:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:40:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:40:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:20 2018 ] Training epoch: 1913
[ Wed Apr 25 11:40:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:40:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:40:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:24 2018 ] Training epoch: 1914
[ Wed Apr 25 11:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:40:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:40:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:28 2018 ] Training epoch: 1915
[ Wed Apr 25 11:40:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:40:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:40:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:32 2018 ] Eval epoch: 1915
[ Wed Apr 25 11:40:34 2018 ] 	Mean test loss of 1 batches: 0.224530428647995.
[ Wed Apr 25 11:40:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:40:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:40:34 2018 ] Training epoch: 1916
[ Wed Apr 25 11:40:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:40:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:40:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:38 2018 ] Training epoch: 1917
[ Wed Apr 25 11:40:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:40:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:40:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:42 2018 ] Training epoch: 1918
[ Wed Apr 25 11:40:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:40:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:40:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:46 2018 ] Training epoch: 1919
[ Wed Apr 25 11:40:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:40:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:40:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:50 2018 ] Training epoch: 1920
[ Wed Apr 25 11:40:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:40:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:40:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:40:54 2018 ] Eval epoch: 1920
[ Wed Apr 25 11:40:57 2018 ] 	Mean test loss of 1 batches: 0.23944930732250214.
[ Wed Apr 25 11:40:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:40:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:40:57 2018 ] Training epoch: 1921
[ Wed Apr 25 11:41:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:01 2018 ] Training epoch: 1922
[ Wed Apr 25 11:41:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:05 2018 ] Training epoch: 1923
[ Wed Apr 25 11:41:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:09 2018 ] Training epoch: 1924
[ Wed Apr 25 11:41:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:41:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:41:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:13 2018 ] Training epoch: 1925
[ Wed Apr 25 11:41:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:41:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:41:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:17 2018 ] Eval epoch: 1925
[ Wed Apr 25 11:41:20 2018 ] 	Mean test loss of 1 batches: 0.24006539583206177.
[ Wed Apr 25 11:41:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:41:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:41:20 2018 ] Training epoch: 1926
[ Wed Apr 25 11:41:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:24 2018 ] Training epoch: 1927
[ Wed Apr 25 11:41:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:28 2018 ] Training epoch: 1928
[ Wed Apr 25 11:41:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:32 2018 ] Training epoch: 1929
[ Wed Apr 25 11:41:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:41:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:41:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:36 2018 ] Training epoch: 1930
[ Wed Apr 25 11:41:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:41:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:41:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:40 2018 ] Eval epoch: 1930
[ Wed Apr 25 11:41:43 2018 ] 	Mean test loss of 1 batches: 0.2315661460161209.
[ Wed Apr 25 11:41:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:41:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:41:43 2018 ] Training epoch: 1931
[ Wed Apr 25 11:41:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:47 2018 ] Training epoch: 1932
[ Wed Apr 25 11:41:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:41:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:41:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:51 2018 ] Training epoch: 1933
[ Wed Apr 25 11:41:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:55 2018 ] Training epoch: 1934
[ Wed Apr 25 11:41:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:41:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:41:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:41:59 2018 ] Training epoch: 1935
[ Wed Apr 25 11:42:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:42:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:42:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:03 2018 ] Eval epoch: 1935
[ Wed Apr 25 11:42:06 2018 ] 	Mean test loss of 1 batches: 0.23444677889347076.
[ Wed Apr 25 11:42:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:42:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:42:06 2018 ] Training epoch: 1936
[ Wed Apr 25 11:42:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:42:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:42:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:10 2018 ] Training epoch: 1937
[ Wed Apr 25 11:42:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:42:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:42:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:14 2018 ] Training epoch: 1938
[ Wed Apr 25 11:42:18 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.100000
[ Wed Apr 25 11:42:18 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:42:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:18 2018 ] Training epoch: 1939
[ Wed Apr 25 11:42:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:42:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:42:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:22 2018 ] Training epoch: 1940
[ Wed Apr 25 11:42:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:42:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:42:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:26 2018 ] Eval epoch: 1940
[ Wed Apr 25 11:42:29 2018 ] 	Mean test loss of 1 batches: 0.1912420243024826.
[ Wed Apr 25 11:42:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:42:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:42:29 2018 ] Training epoch: 1941
[ Wed Apr 25 11:42:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:42:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:42:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:33 2018 ] Training epoch: 1942
[ Wed Apr 25 11:42:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:42:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:42:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:37 2018 ] Training epoch: 1943
[ Wed Apr 25 11:42:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:42:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:42:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:41 2018 ] Training epoch: 1944
[ Wed Apr 25 11:42:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:42:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:42:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:45 2018 ] Training epoch: 1945
[ Wed Apr 25 11:42:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:42:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:42:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:42:49 2018 ] Eval epoch: 1945
[ Wed Apr 25 11:42:52 2018 ] 	Mean test loss of 1 batches: 0.1831829845905304.
[ Wed Apr 25 11:42:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:42:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:42:52 2018 ] Training epoch: 1946
[ Wed Apr 25 11:42:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:42:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:42:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:42:56 2018 ] Training epoch: 1947
[ Wed Apr 25 11:43:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:43:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:43:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:00 2018 ] Training epoch: 1948
[ Wed Apr 25 11:43:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:04 2018 ] Training epoch: 1949
[ Wed Apr 25 11:43:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:08 2018 ] Training epoch: 1950
[ Wed Apr 25 11:43:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:43:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:43:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:12 2018 ] Eval epoch: 1950
[ Wed Apr 25 11:43:14 2018 ] 	Mean test loss of 1 batches: 0.17286144196987152.
[ Wed Apr 25 11:43:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:43:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:43:14 2018 ] Training epoch: 1951
[ Wed Apr 25 11:43:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:43:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:43:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:18 2018 ] Training epoch: 1952
[ Wed Apr 25 11:43:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:23 2018 ] Training epoch: 1953
[ Wed Apr 25 11:43:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:43:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:43:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:43:26 2018 ] Training epoch: 1954
[ Wed Apr 25 11:43:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:43:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:43:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:31 2018 ] Training epoch: 1955
[ Wed Apr 25 11:43:34 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:34 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:43:34 2018 ] Eval epoch: 1955
[ Wed Apr 25 11:43:37 2018 ] 	Mean test loss of 1 batches: 0.1822795569896698.
[ Wed Apr 25 11:43:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:43:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:43:37 2018 ] Training epoch: 1956
[ Wed Apr 25 11:43:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:43:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:43:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:41 2018 ] Training epoch: 1957
[ Wed Apr 25 11:43:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:43:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:43:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:45 2018 ] Training epoch: 1958
[ Wed Apr 25 11:43:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:43:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:43:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:50 2018 ] Training epoch: 1959
[ Wed Apr 25 11:43:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:43:54 2018 ] Training epoch: 1960
[ Wed Apr 25 11:43:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:43:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:43:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:43:58 2018 ] Eval epoch: 1960
[ Wed Apr 25 11:44:01 2018 ] 	Mean test loss of 1 batches: 0.19152820110321045.
[ Wed Apr 25 11:44:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:44:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:44:01 2018 ] Training epoch: 1961
[ Wed Apr 25 11:44:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:44:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:44:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:05 2018 ] Training epoch: 1962
[ Wed Apr 25 11:44:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:09 2018 ] Training epoch: 1963
[ Wed Apr 25 11:44:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:44:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:44:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:13 2018 ] Training epoch: 1964
[ Wed Apr 25 11:44:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:17 2018 ] Training epoch: 1965
[ Wed Apr 25 11:44:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:21 2018 ] Eval epoch: 1965
[ Wed Apr 25 11:44:24 2018 ] 	Mean test loss of 1 batches: 0.19712069630622864.
[ Wed Apr 25 11:44:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:44:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:44:24 2018 ] Training epoch: 1966
[ Wed Apr 25 11:44:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:28 2018 ] Training epoch: 1967
[ Wed Apr 25 11:44:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:32 2018 ] Training epoch: 1968
[ Wed Apr 25 11:44:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:44:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:44:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:36 2018 ] Training epoch: 1969
[ Wed Apr 25 11:44:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:40 2018 ] Training epoch: 1970
[ Wed Apr 25 11:44:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:44 2018 ] Eval epoch: 1970
[ Wed Apr 25 11:44:47 2018 ] 	Mean test loss of 1 batches: 0.20222514867782593.
[ Wed Apr 25 11:44:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:44:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:44:47 2018 ] Training epoch: 1971
[ Wed Apr 25 11:44:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:44:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:44:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:51 2018 ] Training epoch: 1972
[ Wed Apr 25 11:44:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:55 2018 ] Training epoch: 1973
[ Wed Apr 25 11:44:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:44:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:44:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:44:59 2018 ] Training epoch: 1974
[ Wed Apr 25 11:45:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:45:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:45:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:03 2018 ] Training epoch: 1975
[ Wed Apr 25 11:45:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:45:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:45:07 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 11:45:07 2018 ] Eval epoch: 1975
[ Wed Apr 25 11:45:10 2018 ] 	Mean test loss of 1 batches: 0.20901134610176086.
[ Wed Apr 25 11:45:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:45:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:45:10 2018 ] Training epoch: 1976
[ Wed Apr 25 11:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:45:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:14 2018 ] Training epoch: 1977
[ Wed Apr 25 11:45:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:45:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:45:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:18 2018 ] Training epoch: 1978
[ Wed Apr 25 11:45:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:45:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:45:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:45:22 2018 ] Training epoch: 1979
[ Wed Apr 25 11:45:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:45:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:45:26 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:45:26 2018 ] Training epoch: 1980
[ Wed Apr 25 11:45:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:45:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:45:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:45:31 2018 ] Eval epoch: 1980
[ Wed Apr 25 11:45:34 2018 ] 	Mean test loss of 1 batches: 0.20201513171195984.
[ Wed Apr 25 11:45:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:45:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:45:34 2018 ] Training epoch: 1981
[ Wed Apr 25 11:45:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:45:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:45:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:38 2018 ] Training epoch: 1982
[ Wed Apr 25 11:45:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:45:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:45:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:45:42 2018 ] Training epoch: 1983
[ Wed Apr 25 11:45:46 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:45:46 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:45:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:45:46 2018 ] Training epoch: 1984
[ Wed Apr 25 11:45:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:45:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:45:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:50 2018 ] Training epoch: 1985
[ Wed Apr 25 11:45:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:45:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:45:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:45:54 2018 ] Eval epoch: 1985
[ Wed Apr 25 11:45:57 2018 ] 	Mean test loss of 1 batches: 0.20645684003829956.
[ Wed Apr 25 11:45:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:45:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:45:57 2018 ] Training epoch: 1986
[ Wed Apr 25 11:46:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:46:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:46:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:01 2018 ] Training epoch: 1987
[ Wed Apr 25 11:46:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:46:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:46:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:05 2018 ] Training epoch: 1988
[ Wed Apr 25 11:46:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:09 2018 ] Training epoch: 1989
[ Wed Apr 25 11:46:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:46:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:46:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:13 2018 ] Training epoch: 1990
[ Wed Apr 25 11:46:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:46:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:46:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:17 2018 ] Eval epoch: 1990
[ Wed Apr 25 11:46:20 2018 ] 	Mean test loss of 1 batches: 0.21766531467437744.
[ Wed Apr 25 11:46:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:46:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:46:20 2018 ] Training epoch: 1991
[ Wed Apr 25 11:46:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:24 2018 ] Training epoch: 1992
[ Wed Apr 25 11:46:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:28 2018 ] Training epoch: 1993
[ Wed Apr 25 11:46:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:46:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:46:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:32 2018 ] Training epoch: 1994
[ Wed Apr 25 11:46:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:36 2018 ] Training epoch: 1995
[ Wed Apr 25 11:46:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.100000
[ Wed Apr 25 11:46:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:46:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:40 2018 ] Eval epoch: 1995
[ Wed Apr 25 11:46:43 2018 ] 	Mean test loss of 1 batches: 0.22302259504795074.
[ Wed Apr 25 11:46:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:46:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:46:43 2018 ] Training epoch: 1996
[ Wed Apr 25 11:46:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:47 2018 ] Training epoch: 1997
[ Wed Apr 25 11:46:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:51 2018 ] Training epoch: 1998
[ Wed Apr 25 11:46:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.100000
[ Wed Apr 25 11:46:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:46:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:55 2018 ] Training epoch: 1999
[ Wed Apr 25 11:46:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.100000
[ Wed Apr 25 11:46:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:46:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:46:59 2018 ] Training epoch: 2000
[ Wed Apr 25 11:47:03 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.100000
[ Wed Apr 25 11:47:03 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:47:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:03 2018 ] Eval epoch: 2000
[ Wed Apr 25 11:47:06 2018 ] 	Mean test loss of 1 batches: 0.21879588067531586.
[ Wed Apr 25 11:47:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:47:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:47:06 2018 ] Training epoch: 2001
[ Wed Apr 25 11:47:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:47:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:47:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:10 2018 ] Training epoch: 2002
[ Wed Apr 25 11:47:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:47:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:47:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:14 2018 ] Training epoch: 2003
[ Wed Apr 25 11:47:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:47:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:47:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:18 2018 ] Training epoch: 2004
[ Wed Apr 25 11:47:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:47:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:47:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:47:22 2018 ] Training epoch: 2005
[ Wed Apr 25 11:47:26 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:47:26 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:47:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:26 2018 ] Eval epoch: 2005
[ Wed Apr 25 11:47:29 2018 ] 	Mean test loss of 1 batches: 0.22772270441055298.
[ Wed Apr 25 11:47:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:47:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:47:29 2018 ] Training epoch: 2006
[ Wed Apr 25 11:47:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:47:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:47:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:33 2018 ] Training epoch: 2007
[ Wed Apr 25 11:47:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:47:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:47:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:47:38 2018 ] Training epoch: 2008
[ Wed Apr 25 11:47:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:47:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:47:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:42 2018 ] Training epoch: 2009
[ Wed Apr 25 11:47:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:47:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:47:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:46 2018 ] Training epoch: 2010
[ Wed Apr 25 11:47:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:47:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:47:50 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:47:50 2018 ] Eval epoch: 2010
[ Wed Apr 25 11:47:53 2018 ] 	Mean test loss of 1 batches: 0.21879346668720245.
[ Wed Apr 25 11:47:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:47:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:47:53 2018 ] Training epoch: 2011
[ Wed Apr 25 11:47:57 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:47:57 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:47:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:47:57 2018 ] Training epoch: 2012
[ Wed Apr 25 11:48:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:01 2018 ] Training epoch: 2013
[ Wed Apr 25 11:48:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:48:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:48:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:05 2018 ] Training epoch: 2014
[ Wed Apr 25 11:48:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:48:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:48:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:09 2018 ] Training epoch: 2015
[ Wed Apr 25 11:48:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:13 2018 ] Eval epoch: 2015
[ Wed Apr 25 11:48:16 2018 ] 	Mean test loss of 1 batches: 0.21442225575447083.
[ Wed Apr 25 11:48:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:48:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:48:16 2018 ] Training epoch: 2016
[ Wed Apr 25 11:48:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:48:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:48:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:48:20 2018 ] Training epoch: 2017
[ Wed Apr 25 11:48:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:24 2018 ] Training epoch: 2018
[ Wed Apr 25 11:48:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:28 2018 ] Training epoch: 2019
[ Wed Apr 25 11:48:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:32 2018 ] Training epoch: 2020
[ Wed Apr 25 11:48:36 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:48:36 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:48:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:36 2018 ] Eval epoch: 2020
[ Wed Apr 25 11:48:39 2018 ] 	Mean test loss of 1 batches: 0.21710576117038727.
[ Wed Apr 25 11:48:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:48:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:48:39 2018 ] Training epoch: 2021
[ Wed Apr 25 11:48:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:48:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:48:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:43 2018 ] Training epoch: 2022
[ Wed Apr 25 11:48:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:48:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:48:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:47 2018 ] Training epoch: 2023
[ Wed Apr 25 11:48:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:48:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:48:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:51 2018 ] Training epoch: 2024
[ Wed Apr 25 11:48:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:48:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:48:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:55 2018 ] Training epoch: 2025
[ Wed Apr 25 11:48:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:48:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:48:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:48:59 2018 ] Eval epoch: 2025
[ Wed Apr 25 11:49:02 2018 ] 	Mean test loss of 1 batches: 0.2257152497768402.
[ Wed Apr 25 11:49:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:49:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:49:02 2018 ] Training epoch: 2026
[ Wed Apr 25 11:49:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:49:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:49:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:06 2018 ] Training epoch: 2027
[ Wed Apr 25 11:49:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:49:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:49:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:10 2018 ] Training epoch: 2028
[ Wed Apr 25 11:49:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:49:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:49:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:14 2018 ] Training epoch: 2029
[ Wed Apr 25 11:49:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:49:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:49:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:18 2018 ] Training epoch: 2030
[ Wed Apr 25 11:49:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:49:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:49:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:22 2018 ] Eval epoch: 2030
[ Wed Apr 25 11:49:25 2018 ] 	Mean test loss of 1 batches: 0.22673532366752625.
[ Wed Apr 25 11:49:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:49:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:49:25 2018 ] Training epoch: 2031
[ Wed Apr 25 11:49:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:49:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:49:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:29 2018 ] Training epoch: 2032
[ Wed Apr 25 11:49:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:49:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:49:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:33 2018 ] Training epoch: 2033
[ Wed Apr 25 11:49:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:49:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:49:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:37 2018 ] Training epoch: 2034
[ Wed Apr 25 11:49:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:49:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:49:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:41 2018 ] Training epoch: 2035
[ Wed Apr 25 11:49:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:49:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:49:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:45 2018 ] Eval epoch: 2035
[ Wed Apr 25 11:49:48 2018 ] 	Mean test loss of 1 batches: 0.22015149891376495.
[ Wed Apr 25 11:49:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:49:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:49:48 2018 ] Training epoch: 2036
[ Wed Apr 25 11:49:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:49:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:49:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:52 2018 ] Training epoch: 2037
[ Wed Apr 25 11:49:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:49:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:49:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:49:56 2018 ] Training epoch: 2038
[ Wed Apr 25 11:50:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:00 2018 ] Training epoch: 2039
[ Wed Apr 25 11:50:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:50:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:50:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:04 2018 ] Training epoch: 2040
[ Wed Apr 25 11:50:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:08 2018 ] Eval epoch: 2040
[ Wed Apr 25 11:50:11 2018 ] 	Mean test loss of 1 batches: 0.2292616218328476.
[ Wed Apr 25 11:50:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:50:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:50:11 2018 ] Training epoch: 2041
[ Wed Apr 25 11:50:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:50:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:50:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:15 2018 ] Training epoch: 2042
[ Wed Apr 25 11:50:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:19 2018 ] Training epoch: 2043
[ Wed Apr 25 11:50:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:23 2018 ] Training epoch: 2044
[ Wed Apr 25 11:50:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:50:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:50:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:50:27 2018 ] Training epoch: 2045
[ Wed Apr 25 11:50:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:50:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:50:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:50:31 2018 ] Eval epoch: 2045
[ Wed Apr 25 11:50:34 2018 ] 	Mean test loss of 1 batches: 0.22288471460342407.
[ Wed Apr 25 11:50:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:50:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:50:34 2018 ] Training epoch: 2046
[ Wed Apr 25 11:50:38 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.010000
[ Wed Apr 25 11:50:38 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 11:50:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:50:38 2018 ] Training epoch: 2047
[ Wed Apr 25 11:50:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:42 2018 ] Training epoch: 2048
[ Wed Apr 25 11:50:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:50:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:50:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:46 2018 ] Training epoch: 2049
[ Wed Apr 25 11:50:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:50:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:50:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:50 2018 ] Training epoch: 2050
[ Wed Apr 25 11:50:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:50:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:50:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:50:54 2018 ] Eval epoch: 2050
[ Wed Apr 25 11:50:57 2018 ] 	Mean test loss of 1 batches: 0.21776826679706573.
[ Wed Apr 25 11:50:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:50:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:50:57 2018 ] Training epoch: 2051
[ Wed Apr 25 11:51:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:01 2018 ] Training epoch: 2052
[ Wed Apr 25 11:51:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:05 2018 ] Training epoch: 2053
[ Wed Apr 25 11:51:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:09 2018 ] Training epoch: 2054
[ Wed Apr 25 11:51:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:51:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:51:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:13 2018 ] Training epoch: 2055
[ Wed Apr 25 11:51:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:17 2018 ] Eval epoch: 2055
[ Wed Apr 25 11:51:20 2018 ] 	Mean test loss of 1 batches: 0.22372816503047943.
[ Wed Apr 25 11:51:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:51:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:51:20 2018 ] Training epoch: 2056
[ Wed Apr 25 11:51:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:51:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:51:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:24 2018 ] Training epoch: 2057
[ Wed Apr 25 11:51:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:28 2018 ] Training epoch: 2058
[ Wed Apr 25 11:51:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:32 2018 ] Training epoch: 2059
[ Wed Apr 25 11:51:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:51:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:51:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:36 2018 ] Training epoch: 2060
[ Wed Apr 25 11:51:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:51:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:51:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:40 2018 ] Eval epoch: 2060
[ Wed Apr 25 11:51:43 2018 ] 	Mean test loss of 1 batches: 0.22789505124092102.
[ Wed Apr 25 11:51:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:51:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:51:43 2018 ] Training epoch: 2061
[ Wed Apr 25 11:51:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:47 2018 ] Training epoch: 2062
[ Wed Apr 25 11:51:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:51:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:51:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:51:51 2018 ] Training epoch: 2063
[ Wed Apr 25 11:51:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:51:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:51:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:51:55 2018 ] Training epoch: 2064
[ Wed Apr 25 11:51:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:51:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:51:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:51:59 2018 ] Training epoch: 2065
[ Wed Apr 25 11:52:03 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:52:03 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:52:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:03 2018 ] Eval epoch: 2065
[ Wed Apr 25 11:52:06 2018 ] 	Mean test loss of 1 batches: 0.23457157611846924.
[ Wed Apr 25 11:52:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:52:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:52:06 2018 ] Training epoch: 2066
[ Wed Apr 25 11:52:10 2018 ] 	Batch(0/1) done. Loss: 0.0073  lr:0.010000
[ Wed Apr 25 11:52:10 2018 ] 	Mean training loss: 0.0073.
[ Wed Apr 25 11:52:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:10 2018 ] Training epoch: 2067
[ Wed Apr 25 11:52:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:52:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:52:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:14 2018 ] Training epoch: 2068
[ Wed Apr 25 11:52:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:18 2018 ] Training epoch: 2069
[ Wed Apr 25 11:52:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:22 2018 ] Training epoch: 2070
[ Wed Apr 25 11:52:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:26 2018 ] Eval epoch: 2070
[ Wed Apr 25 11:52:29 2018 ] 	Mean test loss of 1 batches: 0.24170126020908356.
[ Wed Apr 25 11:52:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:52:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:52:29 2018 ] Training epoch: 2071
[ Wed Apr 25 11:52:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:33 2018 ] Training epoch: 2072
[ Wed Apr 25 11:52:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:52:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:52:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:37 2018 ] Training epoch: 2073
[ Wed Apr 25 11:52:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:41 2018 ] Training epoch: 2074
[ Wed Apr 25 11:52:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:52:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:52:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:45 2018 ] Training epoch: 2075
[ Wed Apr 25 11:52:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:52:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:52:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:49 2018 ] Eval epoch: 2075
[ Wed Apr 25 11:52:52 2018 ] 	Mean test loss of 1 batches: 0.23983792960643768.
[ Wed Apr 25 11:52:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:52:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:52:52 2018 ] Training epoch: 2076
[ Wed Apr 25 11:52:56 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:52:56 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:52:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:52:56 2018 ] Training epoch: 2077
[ Wed Apr 25 11:53:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:00 2018 ] Training epoch: 2078
[ Wed Apr 25 11:53:04 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:53:04 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:53:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:04 2018 ] Training epoch: 2079
[ Wed Apr 25 11:53:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:08 2018 ] Training epoch: 2080
[ Wed Apr 25 11:53:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:12 2018 ] Eval epoch: 2080
[ Wed Apr 25 11:53:15 2018 ] 	Mean test loss of 1 batches: 0.24569982290267944.
[ Wed Apr 25 11:53:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:53:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:53:15 2018 ] Training epoch: 2081
[ Wed Apr 25 11:53:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:19 2018 ] Training epoch: 2082
[ Wed Apr 25 11:53:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:23 2018 ] Training epoch: 2083
[ Wed Apr 25 11:53:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:27 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 11:53:27 2018 ] Training epoch: 2084
[ Wed Apr 25 11:53:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:31 2018 ] Training epoch: 2085
[ Wed Apr 25 11:53:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:35 2018 ] Eval epoch: 2085
[ Wed Apr 25 11:53:38 2018 ] 	Mean test loss of 1 batches: 0.24386103451251984.
[ Wed Apr 25 11:53:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:53:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:53:38 2018 ] Training epoch: 2086
[ Wed Apr 25 11:53:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:53:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:53:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:42 2018 ] Training epoch: 2087
[ Wed Apr 25 11:53:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:53:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:53:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:53:46 2018 ] Training epoch: 2088
[ Wed Apr 25 11:53:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:53:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:53:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:50 2018 ] Training epoch: 2089
[ Wed Apr 25 11:53:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:53:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:53:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:53:54 2018 ] Training epoch: 2090
[ Wed Apr 25 11:53:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:53:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:53:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:53:58 2018 ] Eval epoch: 2090
[ Wed Apr 25 11:54:01 2018 ] 	Mean test loss of 1 batches: 0.24639655649662018.
[ Wed Apr 25 11:54:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:54:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:54:01 2018 ] Training epoch: 2091
[ Wed Apr 25 11:54:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:54:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:54:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:05 2018 ] Training epoch: 2092
[ Wed Apr 25 11:54:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:54:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:54:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:09 2018 ] Training epoch: 2093
[ Wed Apr 25 11:54:13 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.010000
[ Wed Apr 25 11:54:13 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 11:54:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:13 2018 ] Training epoch: 2094
[ Wed Apr 25 11:54:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:54:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:54:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:17 2018 ] Training epoch: 2095
[ Wed Apr 25 11:54:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:54:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:54:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:21 2018 ] Eval epoch: 2095
[ Wed Apr 25 11:54:24 2018 ] 	Mean test loss of 1 batches: 0.23370416462421417.
[ Wed Apr 25 11:54:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:54:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:54:24 2018 ] Training epoch: 2096
[ Wed Apr 25 11:54:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:54:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:54:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:28 2018 ] Training epoch: 2097
[ Wed Apr 25 11:54:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:54:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:54:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:32 2018 ] Training epoch: 2098
[ Wed Apr 25 11:54:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:54:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:54:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:36 2018 ] Training epoch: 2099
[ Wed Apr 25 11:54:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:54:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:54:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:40 2018 ] Training epoch: 2100
[ Wed Apr 25 11:54:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:54:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:54:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:44 2018 ] Eval epoch: 2100
[ Wed Apr 25 11:54:47 2018 ] 	Mean test loss of 1 batches: 0.2370194047689438.
[ Wed Apr 25 11:54:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:54:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:54:47 2018 ] Training epoch: 2101
[ Wed Apr 25 11:54:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:54:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:54:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:51 2018 ] Training epoch: 2102
[ Wed Apr 25 11:54:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:54:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:54:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:55 2018 ] Training epoch: 2103
[ Wed Apr 25 11:54:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:54:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:54:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:54:59 2018 ] Training epoch: 2104
[ Wed Apr 25 11:55:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:55:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:55:04 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 11:55:04 2018 ] Training epoch: 2105
[ Wed Apr 25 11:55:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:55:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:55:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:08 2018 ] Eval epoch: 2105
[ Wed Apr 25 11:55:11 2018 ] 	Mean test loss of 1 batches: 0.23728656768798828.
[ Wed Apr 25 11:55:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:55:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:55:11 2018 ] Training epoch: 2106
[ Wed Apr 25 11:55:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:55:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:55:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:15 2018 ] Training epoch: 2107
[ Wed Apr 25 11:55:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:55:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:55:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:19 2018 ] Training epoch: 2108
[ Wed Apr 25 11:55:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:55:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:55:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:23 2018 ] Training epoch: 2109
[ Wed Apr 25 11:55:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:55:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:55:28 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 11:55:28 2018 ] Training epoch: 2110
[ Wed Apr 25 11:55:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:55:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:55:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:32 2018 ] Eval epoch: 2110
[ Wed Apr 25 11:55:35 2018 ] 	Mean test loss of 1 batches: 0.24078865349292755.
[ Wed Apr 25 11:55:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:55:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:55:35 2018 ] Training epoch: 2111
[ Wed Apr 25 11:55:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:55:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:55:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:39 2018 ] Training epoch: 2112
[ Wed Apr 25 11:55:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:55:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:55:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:43 2018 ] Training epoch: 2113
[ Wed Apr 25 11:55:47 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 11:55:47 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 11:55:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:47 2018 ] Training epoch: 2114
[ Wed Apr 25 11:55:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:55:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:55:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:51 2018 ] Training epoch: 2115
[ Wed Apr 25 11:55:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:55:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:55:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:55:55 2018 ] Eval epoch: 2115
[ Wed Apr 25 11:55:58 2018 ] 	Mean test loss of 1 batches: 0.2316194474697113.
[ Wed Apr 25 11:55:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:55:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:55:58 2018 ] Training epoch: 2116
[ Wed Apr 25 11:56:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:56:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:56:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:02 2018 ] Training epoch: 2117
[ Wed Apr 25 11:56:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:06 2018 ] Training epoch: 2118
[ Wed Apr 25 11:56:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:56:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:56:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:10 2018 ] Training epoch: 2119
[ Wed Apr 25 11:56:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:56:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:56:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:14 2018 ] Training epoch: 2120
[ Wed Apr 25 11:56:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:18 2018 ] Eval epoch: 2120
[ Wed Apr 25 11:56:21 2018 ] 	Mean test loss of 1 batches: 0.22451181709766388.
[ Wed Apr 25 11:56:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:56:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:56:21 2018 ] Training epoch: 2121
[ Wed Apr 25 11:56:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:25 2018 ] Training epoch: 2122
[ Wed Apr 25 11:56:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:56:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:56:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:29 2018 ] Training epoch: 2123
[ Wed Apr 25 11:56:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:33 2018 ] Training epoch: 2124
[ Wed Apr 25 11:56:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:56:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:56:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:37 2018 ] Training epoch: 2125
[ Wed Apr 25 11:56:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:41 2018 ] Eval epoch: 2125
[ Wed Apr 25 11:56:44 2018 ] 	Mean test loss of 1 batches: 0.22676022350788116.
[ Wed Apr 25 11:56:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:56:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:56:44 2018 ] Training epoch: 2126
[ Wed Apr 25 11:56:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:56:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:56:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:48 2018 ] Training epoch: 2127
[ Wed Apr 25 11:56:52 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:56:52 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:56:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:52 2018 ] Training epoch: 2128
[ Wed Apr 25 11:56:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:56:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:56:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:56:56 2018 ] Training epoch: 2129
[ Wed Apr 25 11:57:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:57:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:57:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:00 2018 ] Training epoch: 2130
[ Wed Apr 25 11:57:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:57:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:57:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:04 2018 ] Eval epoch: 2130
[ Wed Apr 25 11:57:07 2018 ] 	Mean test loss of 1 batches: 0.22492006421089172.
[ Wed Apr 25 11:57:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:57:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:57:07 2018 ] Training epoch: 2131
[ Wed Apr 25 11:57:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:11 2018 ] Training epoch: 2132
[ Wed Apr 25 11:57:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:57:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:57:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:15 2018 ] Training epoch: 2133
[ Wed Apr 25 11:57:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:57:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:57:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:19 2018 ] Training epoch: 2134
[ Wed Apr 25 11:57:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:23 2018 ] Training epoch: 2135
[ Wed Apr 25 11:57:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:27 2018 ] Eval epoch: 2135
[ Wed Apr 25 11:57:30 2018 ] 	Mean test loss of 1 batches: 0.22824831306934357.
[ Wed Apr 25 11:57:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:57:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:57:30 2018 ] Training epoch: 2136
[ Wed Apr 25 11:57:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:57:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:57:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:34 2018 ] Training epoch: 2137
[ Wed Apr 25 11:57:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:57:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:57:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:38 2018 ] Training epoch: 2138
[ Wed Apr 25 11:57:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:42 2018 ] Training epoch: 2139
[ Wed Apr 25 11:57:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:46 2018 ] Training epoch: 2140
[ Wed Apr 25 11:57:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:57:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:57:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:50 2018 ] Eval epoch: 2140
[ Wed Apr 25 11:57:53 2018 ] 	Mean test loss of 1 batches: 0.22371427714824677.
[ Wed Apr 25 11:57:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:57:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:57:53 2018 ] Training epoch: 2141
[ Wed Apr 25 11:57:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:57:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:57:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:57:57 2018 ] Training epoch: 2142
[ Wed Apr 25 11:58:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:58:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:58:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:01 2018 ] Training epoch: 2143
[ Wed Apr 25 11:58:05 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:58:05 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:58:05 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:58:05 2018 ] Training epoch: 2144
[ Wed Apr 25 11:58:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:58:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:58:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:09 2018 ] Training epoch: 2145
[ Wed Apr 25 11:58:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:58:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:58:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:14 2018 ] Eval epoch: 2145
[ Wed Apr 25 11:58:16 2018 ] 	Mean test loss of 1 batches: 0.22256402671337128.
[ Wed Apr 25 11:58:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:58:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:58:16 2018 ] Training epoch: 2146
[ Wed Apr 25 11:58:20 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:58:20 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:58:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:20 2018 ] Training epoch: 2147
[ Wed Apr 25 11:58:24 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:58:24 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:58:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:24 2018 ] Training epoch: 2148
[ Wed Apr 25 11:58:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:58:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:58:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:29 2018 ] Training epoch: 2149
[ Wed Apr 25 11:58:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:58:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:58:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:33 2018 ] Training epoch: 2150
[ Wed Apr 25 11:58:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 11:58:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 11:58:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:58:37 2018 ] Eval epoch: 2150
[ Wed Apr 25 11:58:40 2018 ] 	Mean test loss of 1 batches: 0.22134441137313843.
[ Wed Apr 25 11:58:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:58:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:58:40 2018 ] Training epoch: 2151
[ Wed Apr 25 11:58:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:58:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:58:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:44 2018 ] Training epoch: 2152
[ Wed Apr 25 11:58:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:58:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:58:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:48 2018 ] Training epoch: 2153
[ Wed Apr 25 11:58:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:58:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:58:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:52 2018 ] Training epoch: 2154
[ Wed Apr 25 11:58:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:58:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:58:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:58:56 2018 ] Training epoch: 2155
[ Wed Apr 25 11:59:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:00 2018 ] Eval epoch: 2155
[ Wed Apr 25 11:59:03 2018 ] 	Mean test loss of 1 batches: 0.22238638997077942.
[ Wed Apr 25 11:59:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:59:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:59:03 2018 ] Training epoch: 2156
[ Wed Apr 25 11:59:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 11:59:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 11:59:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:07 2018 ] Training epoch: 2157
[ Wed Apr 25 11:59:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:11 2018 ] Training epoch: 2158
[ Wed Apr 25 11:59:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:15 2018 ] Training epoch: 2159
[ Wed Apr 25 11:59:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:59:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:59:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:19 2018 ] Training epoch: 2160
[ Wed Apr 25 11:59:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:23 2018 ] Eval epoch: 2160
[ Wed Apr 25 11:59:26 2018 ] 	Mean test loss of 1 batches: 0.22644451260566711.
[ Wed Apr 25 11:59:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:59:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:59:26 2018 ] Training epoch: 2161
[ Wed Apr 25 11:59:30 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:59:30 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:59:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:30 2018 ] Training epoch: 2162
[ Wed Apr 25 11:59:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 11:59:34 2018 ] Training epoch: 2163
[ Wed Apr 25 11:59:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:59:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:59:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:38 2018 ] Training epoch: 2164
[ Wed Apr 25 11:59:42 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 11:59:42 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 11:59:42 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 11:59:42 2018 ] Training epoch: 2165
[ Wed Apr 25 11:59:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 11:59:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 11:59:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:46 2018 ] Eval epoch: 2165
[ Wed Apr 25 11:59:49 2018 ] 	Mean test loss of 1 batches: 0.23461773991584778.
[ Wed Apr 25 11:59:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 11:59:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 11:59:49 2018 ] Training epoch: 2166
[ Wed Apr 25 11:59:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:59:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:59:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:53 2018 ] Training epoch: 2167
[ Wed Apr 25 11:59:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 11:59:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 11:59:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 11:59:57 2018 ] Training epoch: 2168
[ Wed Apr 25 12:00:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:01 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:00:01 2018 ] Training epoch: 2169
[ Wed Apr 25 12:00:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:00:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:00:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:05 2018 ] Training epoch: 2170
[ Wed Apr 25 12:00:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:10 2018 ] Eval epoch: 2170
[ Wed Apr 25 12:00:13 2018 ] 	Mean test loss of 1 batches: 0.22889110445976257.
[ Wed Apr 25 12:00:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:00:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:00:13 2018 ] Training epoch: 2171
[ Wed Apr 25 12:00:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:00:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:00:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:00:17 2018 ] Training epoch: 2172
[ Wed Apr 25 12:00:21 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:00:21 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:00:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:21 2018 ] Training epoch: 2173
[ Wed Apr 25 12:00:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:00:25 2018 ] Training epoch: 2174
[ Wed Apr 25 12:00:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:29 2018 ] Training epoch: 2175
[ Wed Apr 25 12:00:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:00:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:00:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:33 2018 ] Eval epoch: 2175
[ Wed Apr 25 12:00:36 2018 ] 	Mean test loss of 1 batches: 0.2360547035932541.
[ Wed Apr 25 12:00:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:00:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:00:36 2018 ] Training epoch: 2176
[ Wed Apr 25 12:00:40 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 12:00:40 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 12:00:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:40 2018 ] Training epoch: 2177
[ Wed Apr 25 12:00:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:00:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:00:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:44 2018 ] Training epoch: 2178
[ Wed Apr 25 12:00:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:48 2018 ] Training epoch: 2179
[ Wed Apr 25 12:00:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:00:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:00:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:52 2018 ] Training epoch: 2180
[ Wed Apr 25 12:00:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:00:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:00:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:00:56 2018 ] Eval epoch: 2180
[ Wed Apr 25 12:00:59 2018 ] 	Mean test loss of 1 batches: 0.23436839878559113.
[ Wed Apr 25 12:00:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:00:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:00:59 2018 ] Training epoch: 2181
[ Wed Apr 25 12:01:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:01:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:01:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:03 2018 ] Training epoch: 2182
[ Wed Apr 25 12:01:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:01:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:01:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:07 2018 ] Training epoch: 2183
[ Wed Apr 25 12:01:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:01:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:01:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:11 2018 ] Training epoch: 2184
[ Wed Apr 25 12:01:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:01:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:01:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:15 2018 ] Training epoch: 2185
[ Wed Apr 25 12:01:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:01:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:01:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:19 2018 ] Eval epoch: 2185
[ Wed Apr 25 12:01:22 2018 ] 	Mean test loss of 1 batches: 0.2330281287431717.
[ Wed Apr 25 12:01:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:01:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:01:22 2018 ] Training epoch: 2186
[ Wed Apr 25 12:01:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:01:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:01:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:26 2018 ] Training epoch: 2187
[ Wed Apr 25 12:01:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:01:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:01:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:30 2018 ] Training epoch: 2188
[ Wed Apr 25 12:01:34 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:01:34 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:01:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:34 2018 ] Training epoch: 2189
[ Wed Apr 25 12:01:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:01:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:01:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:38 2018 ] Training epoch: 2190
[ Wed Apr 25 12:01:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:01:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:01:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:42 2018 ] Eval epoch: 2190
[ Wed Apr 25 12:01:45 2018 ] 	Mean test loss of 1 batches: 0.23800012469291687.
[ Wed Apr 25 12:01:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:01:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:01:45 2018 ] Training epoch: 2191
[ Wed Apr 25 12:01:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:01:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:01:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:49 2018 ] Training epoch: 2192
[ Wed Apr 25 12:01:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:01:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:01:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:53 2018 ] Training epoch: 2193
[ Wed Apr 25 12:01:57 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:01:57 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:01:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:01:57 2018 ] Training epoch: 2194
[ Wed Apr 25 12:02:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:02:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:02:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:01 2018 ] Training epoch: 2195
[ Wed Apr 25 12:02:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:02:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:02:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:05 2018 ] Eval epoch: 2195
[ Wed Apr 25 12:02:08 2018 ] 	Mean test loss of 1 batches: 0.2370326817035675.
[ Wed Apr 25 12:02:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:02:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:02:08 2018 ] Training epoch: 2196
[ Wed Apr 25 12:02:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:02:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:02:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:12 2018 ] Training epoch: 2197
[ Wed Apr 25 12:02:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:02:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:02:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:16 2018 ] Training epoch: 2198
[ Wed Apr 25 12:02:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:02:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:02:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:20 2018 ] Training epoch: 2199
[ Wed Apr 25 12:02:24 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:02:24 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:02:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:24 2018 ] Training epoch: 2200
[ Wed Apr 25 12:02:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:02:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:02:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:28 2018 ] Eval epoch: 2200
[ Wed Apr 25 12:02:31 2018 ] 	Mean test loss of 1 batches: 0.23433542251586914.
[ Wed Apr 25 12:02:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:02:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:02:31 2018 ] Training epoch: 2201
[ Wed Apr 25 12:02:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:02:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:02:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:35 2018 ] Training epoch: 2202
[ Wed Apr 25 12:02:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:02:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:02:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:39 2018 ] Training epoch: 2203
[ Wed Apr 25 12:02:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:02:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:02:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:43 2018 ] Training epoch: 2204
[ Wed Apr 25 12:02:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:02:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:02:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:47 2018 ] Training epoch: 2205
[ Wed Apr 25 12:02:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:02:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:02:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:51 2018 ] Eval epoch: 2205
[ Wed Apr 25 12:02:54 2018 ] 	Mean test loss of 1 batches: 0.23265373706817627.
[ Wed Apr 25 12:02:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:02:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:02:54 2018 ] Training epoch: 2206
[ Wed Apr 25 12:02:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:02:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:02:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:02:58 2018 ] Training epoch: 2207
[ Wed Apr 25 12:03:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:02 2018 ] Training epoch: 2208
[ Wed Apr 25 12:03:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:06 2018 ] Training epoch: 2209
[ Wed Apr 25 12:03:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:03:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:03:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:10 2018 ] Training epoch: 2210
[ Wed Apr 25 12:03:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:14 2018 ] Eval epoch: 2210
[ Wed Apr 25 12:03:17 2018 ] 	Mean test loss of 1 batches: 0.2332981675863266.
[ Wed Apr 25 12:03:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:03:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:03:17 2018 ] Training epoch: 2211
[ Wed Apr 25 12:03:21 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:03:21 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:03:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:21 2018 ] Training epoch: 2212
[ Wed Apr 25 12:03:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:25 2018 ] Training epoch: 2213
[ Wed Apr 25 12:03:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:03:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:03:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:29 2018 ] Training epoch: 2214
[ Wed Apr 25 12:03:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:33 2018 ] Training epoch: 2215
[ Wed Apr 25 12:03:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:03:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:03:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:37 2018 ] Eval epoch: 2215
[ Wed Apr 25 12:03:40 2018 ] 	Mean test loss of 1 batches: 0.23262731730937958.
[ Wed Apr 25 12:03:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:03:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:03:40 2018 ] Training epoch: 2216
[ Wed Apr 25 12:03:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:03:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:03:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:44 2018 ] Training epoch: 2217
[ Wed Apr 25 12:03:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:03:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:03:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:03:48 2018 ] Training epoch: 2218
[ Wed Apr 25 12:03:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:03:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:03:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:52 2018 ] Training epoch: 2219
[ Wed Apr 25 12:03:56 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:03:56 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:03:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:03:56 2018 ] Training epoch: 2220
[ Wed Apr 25 12:04:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:00 2018 ] Eval epoch: 2220
[ Wed Apr 25 12:04:03 2018 ] 	Mean test loss of 1 batches: 0.22647058963775635.
[ Wed Apr 25 12:04:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:04:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:04:03 2018 ] Training epoch: 2221
[ Wed Apr 25 12:04:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:07 2018 ] Training epoch: 2222
[ Wed Apr 25 12:04:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:04:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:04:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:11 2018 ] Training epoch: 2223
[ Wed Apr 25 12:04:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:04:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:04:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:15 2018 ] Training epoch: 2224
[ Wed Apr 25 12:04:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:19 2018 ] Training epoch: 2225
[ Wed Apr 25 12:04:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:04:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:04:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:23 2018 ] Eval epoch: 2225
[ Wed Apr 25 12:04:26 2018 ] 	Mean test loss of 1 batches: 0.22423134744167328.
[ Wed Apr 25 12:04:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:04:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:04:26 2018 ] Training epoch: 2226
[ Wed Apr 25 12:04:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:30 2018 ] Training epoch: 2227
[ Wed Apr 25 12:04:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:34 2018 ] Training epoch: 2228
[ Wed Apr 25 12:04:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:04:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:04:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:38 2018 ] Training epoch: 2229
[ Wed Apr 25 12:04:42 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 12:04:42 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 12:04:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:42 2018 ] Training epoch: 2230
[ Wed Apr 25 12:04:46 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:04:46 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:04:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:46 2018 ] Eval epoch: 2230
[ Wed Apr 25 12:04:49 2018 ] 	Mean test loss of 1 batches: 0.2296561598777771.
[ Wed Apr 25 12:04:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:04:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:04:49 2018 ] Training epoch: 2231
[ Wed Apr 25 12:04:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:04:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:04:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:53 2018 ] Training epoch: 2232
[ Wed Apr 25 12:04:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:04:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:04:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:04:57 2018 ] Training epoch: 2233
[ Wed Apr 25 12:05:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:01 2018 ] Training epoch: 2234
[ Wed Apr 25 12:05:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:05:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:05:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:05:05 2018 ] Training epoch: 2235
[ Wed Apr 25 12:05:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:09 2018 ] Eval epoch: 2235
[ Wed Apr 25 12:05:12 2018 ] 	Mean test loss of 1 batches: 0.22733303904533386.
[ Wed Apr 25 12:05:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:05:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:05:12 2018 ] Training epoch: 2236
[ Wed Apr 25 12:05:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:05:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:05:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:16 2018 ] Training epoch: 2237
[ Wed Apr 25 12:05:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:05:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:05:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:20 2018 ] Training epoch: 2238
[ Wed Apr 25 12:05:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:24 2018 ] Training epoch: 2239
[ Wed Apr 25 12:05:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:05:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:05:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:28 2018 ] Training epoch: 2240
[ Wed Apr 25 12:05:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:32 2018 ] Eval epoch: 2240
[ Wed Apr 25 12:05:35 2018 ] 	Mean test loss of 1 batches: 0.23240907490253448.
[ Wed Apr 25 12:05:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:05:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:05:35 2018 ] Training epoch: 2241
[ Wed Apr 25 12:05:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:05:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:05:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:05:38 2018 ] Training epoch: 2242
[ Wed Apr 25 12:05:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:43 2018 ] Training epoch: 2243
[ Wed Apr 25 12:05:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:05:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:05:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:47 2018 ] Training epoch: 2244
[ Wed Apr 25 12:05:51 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:05:51 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:05:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:51 2018 ] Training epoch: 2245
[ Wed Apr 25 12:05:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:05:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:05:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:05:55 2018 ] Eval epoch: 2245
[ Wed Apr 25 12:05:58 2018 ] 	Mean test loss of 1 batches: 0.24498790502548218.
[ Wed Apr 25 12:05:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:05:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:05:58 2018 ] Training epoch: 2246
[ Wed Apr 25 12:06:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:02 2018 ] Training epoch: 2247
[ Wed Apr 25 12:06:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:06:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:06:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:06 2018 ] Training epoch: 2248
[ Wed Apr 25 12:06:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:10 2018 ] Training epoch: 2249
[ Wed Apr 25 12:06:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:14 2018 ] Training epoch: 2250
[ Wed Apr 25 12:06:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:06:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:06:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:18 2018 ] Eval epoch: 2250
[ Wed Apr 25 12:06:21 2018 ] 	Mean test loss of 1 batches: 0.24255616962909698.
[ Wed Apr 25 12:06:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:06:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:06:21 2018 ] Training epoch: 2251
[ Wed Apr 25 12:06:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:06:25 2018 ] Training epoch: 2252
[ Wed Apr 25 12:06:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:06:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:06:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:29 2018 ] Training epoch: 2253
[ Wed Apr 25 12:06:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:33 2018 ] Training epoch: 2254
[ Wed Apr 25 12:06:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:37 2018 ] Training epoch: 2255
[ Wed Apr 25 12:06:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:06:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:06:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:41 2018 ] Eval epoch: 2255
[ Wed Apr 25 12:06:44 2018 ] 	Mean test loss of 1 batches: 0.2424243539571762.
[ Wed Apr 25 12:06:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:06:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:06:44 2018 ] Training epoch: 2256
[ Wed Apr 25 12:06:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:06:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:06:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:06:48 2018 ] Training epoch: 2257
[ Wed Apr 25 12:06:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:06:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:06:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:52 2018 ] Training epoch: 2258
[ Wed Apr 25 12:06:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:06:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:06:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:06:56 2018 ] Training epoch: 2259
[ Wed Apr 25 12:07:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:07:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:07:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:00 2018 ] Training epoch: 2260
[ Wed Apr 25 12:07:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:07:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:07:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:04 2018 ] Eval epoch: 2260
[ Wed Apr 25 12:07:07 2018 ] 	Mean test loss of 1 batches: 0.2333296835422516.
[ Wed Apr 25 12:07:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:07:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:07:07 2018 ] Training epoch: 2261
[ Wed Apr 25 12:07:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:07:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:07:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:11 2018 ] Training epoch: 2262
[ Wed Apr 25 12:07:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:07:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:07:15 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 12:07:15 2018 ] Training epoch: 2263
[ Wed Apr 25 12:07:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:07:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:07:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:19 2018 ] Training epoch: 2264
[ Wed Apr 25 12:07:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:07:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:07:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:23 2018 ] Training epoch: 2265
[ Wed Apr 25 12:07:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:07:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:07:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:27 2018 ] Eval epoch: 2265
[ Wed Apr 25 12:07:30 2018 ] 	Mean test loss of 1 batches: 0.22955875098705292.
[ Wed Apr 25 12:07:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:07:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:07:30 2018 ] Training epoch: 2266
[ Wed Apr 25 12:07:34 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:07:34 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:07:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:34 2018 ] Training epoch: 2267
[ Wed Apr 25 12:07:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:07:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:07:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:38 2018 ] Training epoch: 2268
[ Wed Apr 25 12:07:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:07:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:07:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:42 2018 ] Training epoch: 2269
[ Wed Apr 25 12:07:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:07:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:07:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:46 2018 ] Training epoch: 2270
[ Wed Apr 25 12:07:50 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 12:07:50 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 12:07:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:50 2018 ] Eval epoch: 2270
[ Wed Apr 25 12:07:53 2018 ] 	Mean test loss of 1 batches: 0.23865880072116852.
[ Wed Apr 25 12:07:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:07:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:07:53 2018 ] Training epoch: 2271
[ Wed Apr 25 12:07:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:07:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:07:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:07:57 2018 ] Training epoch: 2272
[ Wed Apr 25 12:08:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:01 2018 ] Training epoch: 2273
[ Wed Apr 25 12:08:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:05 2018 ] Training epoch: 2274
[ Wed Apr 25 12:08:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:09 2018 ] Training epoch: 2275
[ Wed Apr 25 12:08:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:13 2018 ] Eval epoch: 2275
[ Wed Apr 25 12:08:16 2018 ] 	Mean test loss of 1 batches: 0.23521019518375397.
[ Wed Apr 25 12:08:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:08:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:08:16 2018 ] Training epoch: 2276
[ Wed Apr 25 12:08:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:08:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:08:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:20 2018 ] Training epoch: 2277
[ Wed Apr 25 12:08:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:08:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:08:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:24 2018 ] Training epoch: 2278
[ Wed Apr 25 12:08:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:08:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:08:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:28 2018 ] Training epoch: 2279
[ Wed Apr 25 12:08:32 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:08:32 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:08:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:32 2018 ] Training epoch: 2280
[ Wed Apr 25 12:08:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:36 2018 ] Eval epoch: 2280
[ Wed Apr 25 12:08:39 2018 ] 	Mean test loss of 1 batches: 0.21942682564258575.
[ Wed Apr 25 12:08:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:08:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:08:39 2018 ] Training epoch: 2281
[ Wed Apr 25 12:08:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:08:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:08:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:43 2018 ] Training epoch: 2282
[ Wed Apr 25 12:08:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:47 2018 ] Training epoch: 2283
[ Wed Apr 25 12:08:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:08:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:08:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:51 2018 ] Training epoch: 2284
[ Wed Apr 25 12:08:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:08:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:08:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:55 2018 ] Training epoch: 2285
[ Wed Apr 25 12:08:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:08:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:08:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:08:59 2018 ] Eval epoch: 2285
[ Wed Apr 25 12:09:02 2018 ] 	Mean test loss of 1 batches: 0.223423570394516.
[ Wed Apr 25 12:09:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:09:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:09:02 2018 ] Training epoch: 2286
[ Wed Apr 25 12:09:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:09:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:09:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:06 2018 ] Training epoch: 2287
[ Wed Apr 25 12:09:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:09:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:09:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:10 2018 ] Training epoch: 2288
[ Wed Apr 25 12:09:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:09:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:09:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:14 2018 ] Training epoch: 2289
[ Wed Apr 25 12:09:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:09:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:09:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:18 2018 ] Training epoch: 2290
[ Wed Apr 25 12:09:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:09:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:09:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:22 2018 ] Eval epoch: 2290
[ Wed Apr 25 12:09:25 2018 ] 	Mean test loss of 1 batches: 0.22302912175655365.
[ Wed Apr 25 12:09:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:09:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:09:25 2018 ] Training epoch: 2291
[ Wed Apr 25 12:09:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:09:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:09:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:29 2018 ] Training epoch: 2292
[ Wed Apr 25 12:09:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:09:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:09:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:33 2018 ] Training epoch: 2293
[ Wed Apr 25 12:09:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:09:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:09:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:37 2018 ] Training epoch: 2294
[ Wed Apr 25 12:09:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:09:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:09:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:41 2018 ] Training epoch: 2295
[ Wed Apr 25 12:09:45 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 12:09:45 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 12:09:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:45 2018 ] Eval epoch: 2295
[ Wed Apr 25 12:09:48 2018 ] 	Mean test loss of 1 batches: 0.22547827661037445.
[ Wed Apr 25 12:09:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:09:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:09:48 2018 ] Training epoch: 2296
[ Wed Apr 25 12:09:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:09:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:09:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:09:52 2018 ] Training epoch: 2297
[ Wed Apr 25 12:09:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:09:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:09:56 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:09:56 2018 ] Training epoch: 2298
[ Wed Apr 25 12:10:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:00 2018 ] Training epoch: 2299
[ Wed Apr 25 12:10:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:10:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:10:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:04 2018 ] Training epoch: 2300
[ Wed Apr 25 12:10:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:08 2018 ] Eval epoch: 2300
[ Wed Apr 25 12:10:11 2018 ] 	Mean test loss of 1 batches: 0.23053006827831268.
[ Wed Apr 25 12:10:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:10:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:10:11 2018 ] Training epoch: 2301
[ Wed Apr 25 12:10:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:10:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:10:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:15 2018 ] Training epoch: 2302
[ Wed Apr 25 12:10:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:10:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:10:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:19 2018 ] Training epoch: 2303
[ Wed Apr 25 12:10:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:23 2018 ] Training epoch: 2304
[ Wed Apr 25 12:10:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:28 2018 ] Training epoch: 2305
[ Wed Apr 25 12:10:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:31 2018 ] Eval epoch: 2305
[ Wed Apr 25 12:10:34 2018 ] 	Mean test loss of 1 batches: 0.245171457529068.
[ Wed Apr 25 12:10:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:10:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:10:34 2018 ] Training epoch: 2306
[ Wed Apr 25 12:10:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:38 2018 ] Training epoch: 2307
[ Wed Apr 25 12:10:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:42 2018 ] Training epoch: 2308
[ Wed Apr 25 12:10:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:46 2018 ] Training epoch: 2309
[ Wed Apr 25 12:10:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:10:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:10:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:51 2018 ] Training epoch: 2310
[ Wed Apr 25 12:10:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:10:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:10:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:10:55 2018 ] Eval epoch: 2310
[ Wed Apr 25 12:10:57 2018 ] 	Mean test loss of 1 batches: 0.23397225141525269.
[ Wed Apr 25 12:10:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:10:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:10:57 2018 ] Training epoch: 2311
[ Wed Apr 25 12:11:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:11:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:11:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:01 2018 ] Training epoch: 2312
[ Wed Apr 25 12:11:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:11:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:11:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:11:05 2018 ] Training epoch: 2313
[ Wed Apr 25 12:11:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:11:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:11:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:09 2018 ] Training epoch: 2314
[ Wed Apr 25 12:11:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:11:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:11:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:13 2018 ] Training epoch: 2315
[ Wed Apr 25 12:11:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:11:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:11:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:17 2018 ] Eval epoch: 2315
[ Wed Apr 25 12:11:20 2018 ] 	Mean test loss of 1 batches: 0.23598425090312958.
[ Wed Apr 25 12:11:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:11:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:11:20 2018 ] Training epoch: 2316
[ Wed Apr 25 12:11:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:11:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:11:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:24 2018 ] Training epoch: 2317
[ Wed Apr 25 12:11:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:11:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:11:29 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:11:29 2018 ] Training epoch: 2318
[ Wed Apr 25 12:11:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:11:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:11:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:33 2018 ] Training epoch: 2319
[ Wed Apr 25 12:11:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:11:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:11:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:11:37 2018 ] Training epoch: 2320
[ Wed Apr 25 12:11:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:11:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:11:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:11:41 2018 ] Eval epoch: 2320
[ Wed Apr 25 12:11:44 2018 ] 	Mean test loss of 1 batches: 0.23734310269355774.
[ Wed Apr 25 12:11:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:11:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:11:44 2018 ] Training epoch: 2321
[ Wed Apr 25 12:11:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:11:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:11:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:48 2018 ] Training epoch: 2322
[ Wed Apr 25 12:11:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:11:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:11:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:52 2018 ] Training epoch: 2323
[ Wed Apr 25 12:11:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:11:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:11:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:11:56 2018 ] Training epoch: 2324
[ Wed Apr 25 12:12:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:00 2018 ] Training epoch: 2325
[ Wed Apr 25 12:12:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:12:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:12:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:04 2018 ] Eval epoch: 2325
[ Wed Apr 25 12:12:07 2018 ] 	Mean test loss of 1 batches: 0.2336706966161728.
[ Wed Apr 25 12:12:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:12:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:12:07 2018 ] Training epoch: 2326
[ Wed Apr 25 12:12:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:12:11 2018 ] Training epoch: 2327
[ Wed Apr 25 12:12:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:12:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:12:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:15 2018 ] Training epoch: 2328
[ Wed Apr 25 12:12:19 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.010000
[ Wed Apr 25 12:12:19 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 12:12:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:19 2018 ] Training epoch: 2329
[ Wed Apr 25 12:12:23 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:12:23 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:12:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:23 2018 ] Training epoch: 2330
[ Wed Apr 25 12:12:27 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:12:27 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:12:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:27 2018 ] Eval epoch: 2330
[ Wed Apr 25 12:12:30 2018 ] 	Mean test loss of 1 batches: 0.2366148680448532.
[ Wed Apr 25 12:12:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:12:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:12:30 2018 ] Training epoch: 2331
[ Wed Apr 25 12:12:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:34 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:12:34 2018 ] Training epoch: 2332
[ Wed Apr 25 12:12:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:38 2018 ] Training epoch: 2333
[ Wed Apr 25 12:12:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:12:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:12:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:42 2018 ] Training epoch: 2334
[ Wed Apr 25 12:12:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:46 2018 ] Training epoch: 2335
[ Wed Apr 25 12:12:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:12:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:12:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:50 2018 ] Eval epoch: 2335
[ Wed Apr 25 12:12:53 2018 ] 	Mean test loss of 1 batches: 0.22947828471660614.
[ Wed Apr 25 12:12:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:12:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:12:53 2018 ] Training epoch: 2336
[ Wed Apr 25 12:12:57 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:12:57 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:12:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:12:57 2018 ] Training epoch: 2337
[ Wed Apr 25 12:13:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:01 2018 ] Training epoch: 2338
[ Wed Apr 25 12:13:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:13:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:13:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:05 2018 ] Training epoch: 2339
[ Wed Apr 25 12:13:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:13:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:13:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:09 2018 ] Training epoch: 2340
[ Wed Apr 25 12:13:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:13 2018 ] Eval epoch: 2340
[ Wed Apr 25 12:13:16 2018 ] 	Mean test loss of 1 batches: 0.23104412853717804.
[ Wed Apr 25 12:13:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:13:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:13:16 2018 ] Training epoch: 2341
[ Wed Apr 25 12:13:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:13:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:13:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:20 2018 ] Training epoch: 2342
[ Wed Apr 25 12:13:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:24 2018 ] Training epoch: 2343
[ Wed Apr 25 12:13:28 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.010000
[ Wed Apr 25 12:13:28 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 12:13:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:28 2018 ] Training epoch: 2344
[ Wed Apr 25 12:13:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:13:32 2018 ] Training epoch: 2345
[ Wed Apr 25 12:13:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:36 2018 ] Eval epoch: 2345
[ Wed Apr 25 12:13:39 2018 ] 	Mean test loss of 1 batches: 0.22148513793945312.
[ Wed Apr 25 12:13:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:13:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:13:39 2018 ] Training epoch: 2346
[ Wed Apr 25 12:13:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:13:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:13:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:43 2018 ] Training epoch: 2347
[ Wed Apr 25 12:13:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:13:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:13:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:47 2018 ] Training epoch: 2348
[ Wed Apr 25 12:13:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:13:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:13:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:51 2018 ] Training epoch: 2349
[ Wed Apr 25 12:13:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:55 2018 ] Training epoch: 2350
[ Wed Apr 25 12:13:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:13:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:13:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:13:59 2018 ] Eval epoch: 2350
[ Wed Apr 25 12:14:02 2018 ] 	Mean test loss of 1 batches: 0.226756289601326.
[ Wed Apr 25 12:14:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:14:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:14:02 2018 ] Training epoch: 2351
[ Wed Apr 25 12:14:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:14:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:14:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:06 2018 ] Training epoch: 2352
[ Wed Apr 25 12:14:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:14:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:14:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:10 2018 ] Training epoch: 2353
[ Wed Apr 25 12:14:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:14:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:14:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:14 2018 ] Training epoch: 2354
[ Wed Apr 25 12:14:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:14:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:14:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:18 2018 ] Training epoch: 2355
[ Wed Apr 25 12:14:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:14:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:14:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:22 2018 ] Eval epoch: 2355
[ Wed Apr 25 12:14:24 2018 ] 	Mean test loss of 1 batches: 0.2162753939628601.
[ Wed Apr 25 12:14:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:14:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:14:24 2018 ] Training epoch: 2356
[ Wed Apr 25 12:14:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:14:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:14:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:28 2018 ] Training epoch: 2357
[ Wed Apr 25 12:14:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:14:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:14:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:32 2018 ] Training epoch: 2358
[ Wed Apr 25 12:14:36 2018 ] 	Batch(0/1) done. Loss: 0.0025  lr:0.010000
[ Wed Apr 25 12:14:36 2018 ] 	Mean training loss: 0.0025.
[ Wed Apr 25 12:14:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:36 2018 ] Training epoch: 2359
[ Wed Apr 25 12:14:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:14:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:14:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:40 2018 ] Training epoch: 2360
[ Wed Apr 25 12:14:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:14:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:14:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:44 2018 ] Eval epoch: 2360
[ Wed Apr 25 12:14:47 2018 ] 	Mean test loss of 1 batches: 0.20890970528125763.
[ Wed Apr 25 12:14:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:14:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:14:47 2018 ] Training epoch: 2361
[ Wed Apr 25 12:14:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:14:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:14:51 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:14:51 2018 ] Training epoch: 2362
[ Wed Apr 25 12:14:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:14:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:14:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:55 2018 ] Training epoch: 2363
[ Wed Apr 25 12:14:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:14:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:14:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:14:59 2018 ] Training epoch: 2364
[ Wed Apr 25 12:15:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:15:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:15:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:03 2018 ] Training epoch: 2365
[ Wed Apr 25 12:15:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:15:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:15:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:07 2018 ] Eval epoch: 2365
[ Wed Apr 25 12:15:10 2018 ] 	Mean test loss of 1 batches: 0.21452197432518005.
[ Wed Apr 25 12:15:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:15:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:15:10 2018 ] Training epoch: 2366
[ Wed Apr 25 12:15:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:15:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:15:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:14 2018 ] Training epoch: 2367
[ Wed Apr 25 12:15:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:15:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:15:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:18 2018 ] Training epoch: 2368
[ Wed Apr 25 12:15:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:15:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:15:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:22 2018 ] Training epoch: 2369
[ Wed Apr 25 12:15:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:15:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:15:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:26 2018 ] Training epoch: 2370
[ Wed Apr 25 12:15:30 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:15:30 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:15:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:30 2018 ] Eval epoch: 2370
[ Wed Apr 25 12:15:33 2018 ] 	Mean test loss of 1 batches: 0.21404369175434113.
[ Wed Apr 25 12:15:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:15:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:15:33 2018 ] Training epoch: 2371
[ Wed Apr 25 12:15:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:15:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:15:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:37 2018 ] Training epoch: 2372
[ Wed Apr 25 12:15:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:15:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:15:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:41 2018 ] Training epoch: 2373
[ Wed Apr 25 12:15:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:15:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:15:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:45 2018 ] Training epoch: 2374
[ Wed Apr 25 12:15:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:15:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:15:49 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:15:49 2018 ] Training epoch: 2375
[ Wed Apr 25 12:15:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:15:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:15:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:15:53 2018 ] Eval epoch: 2375
[ Wed Apr 25 12:15:56 2018 ] 	Mean test loss of 1 batches: 0.21305030584335327.
[ Wed Apr 25 12:15:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:15:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:15:56 2018 ] Training epoch: 2376
[ Wed Apr 25 12:16:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:00 2018 ] Training epoch: 2377
[ Wed Apr 25 12:16:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:04 2018 ] Training epoch: 2378
[ Wed Apr 25 12:16:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:08 2018 ] Training epoch: 2379
[ Wed Apr 25 12:16:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:12 2018 ] Training epoch: 2380
[ Wed Apr 25 12:16:16 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:16:16 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:16:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:16:16 2018 ] Eval epoch: 2380
[ Wed Apr 25 12:16:19 2018 ] 	Mean test loss of 1 batches: 0.20743468403816223.
[ Wed Apr 25 12:16:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:16:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:16:19 2018 ] Training epoch: 2381
[ Wed Apr 25 12:16:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:23 2018 ] Training epoch: 2382
[ Wed Apr 25 12:16:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:16:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:16:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:27 2018 ] Training epoch: 2383
[ Wed Apr 25 12:16:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:16:31 2018 ] Training epoch: 2384
[ Wed Apr 25 12:16:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:36 2018 ] Training epoch: 2385
[ Wed Apr 25 12:16:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:40 2018 ] Eval epoch: 2385
[ Wed Apr 25 12:16:43 2018 ] 	Mean test loss of 1 batches: 0.21393531560897827.
[ Wed Apr 25 12:16:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:16:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:16:43 2018 ] Training epoch: 2386
[ Wed Apr 25 12:16:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:47 2018 ] 	Time consumption: [Data]78%, [Network]21%
[ Wed Apr 25 12:16:47 2018 ] Training epoch: 2387
[ Wed Apr 25 12:16:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:51 2018 ] Training epoch: 2388
[ Wed Apr 25 12:16:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:16:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:16:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:16:55 2018 ] Training epoch: 2389
[ Wed Apr 25 12:16:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:16:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:16:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:16:59 2018 ] Training epoch: 2390
[ Wed Apr 25 12:17:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:17:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:17:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:03 2018 ] Eval epoch: 2390
[ Wed Apr 25 12:17:06 2018 ] 	Mean test loss of 1 batches: 0.21818511188030243.
[ Wed Apr 25 12:17:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:17:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:17:06 2018 ] Training epoch: 2391
[ Wed Apr 25 12:17:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:10 2018 ] Training epoch: 2392
[ Wed Apr 25 12:17:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:14 2018 ] Training epoch: 2393
[ Wed Apr 25 12:17:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:18 2018 ] Training epoch: 2394
[ Wed Apr 25 12:17:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:22 2018 ] Training epoch: 2395
[ Wed Apr 25 12:17:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:26 2018 ] Eval epoch: 2395
[ Wed Apr 25 12:17:29 2018 ] 	Mean test loss of 1 batches: 0.22864314913749695.
[ Wed Apr 25 12:17:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:17:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:17:29 2018 ] Training epoch: 2396
[ Wed Apr 25 12:17:33 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:17:33 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:17:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:33 2018 ] Training epoch: 2397
[ Wed Apr 25 12:17:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:17:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:17:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:37 2018 ] Training epoch: 2398
[ Wed Apr 25 12:17:41 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:17:41 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:17:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:41 2018 ] Training epoch: 2399
[ Wed Apr 25 12:17:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:17:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:17:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:45 2018 ] Training epoch: 2400
[ Wed Apr 25 12:17:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:17:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:17:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:50 2018 ] Eval epoch: 2400
[ Wed Apr 25 12:17:52 2018 ] 	Mean test loss of 1 batches: 0.23212923109531403.
[ Wed Apr 25 12:17:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:17:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:17:52 2018 ] Training epoch: 2401
[ Wed Apr 25 12:17:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:17:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:17:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:17:56 2018 ] Training epoch: 2402
[ Wed Apr 25 12:18:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:18:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:18:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:00 2018 ] Training epoch: 2403
[ Wed Apr 25 12:18:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:18:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:18:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:04 2018 ] Training epoch: 2404
[ Wed Apr 25 12:18:09 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:18:09 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:18:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:09 2018 ] Training epoch: 2405
[ Wed Apr 25 12:18:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:13 2018 ] Eval epoch: 2405
[ Wed Apr 25 12:18:15 2018 ] 	Mean test loss of 1 batches: 0.22030365467071533.
[ Wed Apr 25 12:18:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:18:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:18:15 2018 ] Training epoch: 2406
[ Wed Apr 25 12:18:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:18:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:18:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:19 2018 ] Training epoch: 2407
[ Wed Apr 25 12:18:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:23 2018 ] Training epoch: 2408
[ Wed Apr 25 12:18:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:28 2018 ] Training epoch: 2409
[ Wed Apr 25 12:18:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:32 2018 ] Training epoch: 2410
[ Wed Apr 25 12:18:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:18:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:18:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:36 2018 ] Eval epoch: 2410
[ Wed Apr 25 12:18:38 2018 ] 	Mean test loss of 1 batches: 0.22022177278995514.
[ Wed Apr 25 12:18:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:18:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:18:38 2018 ] Training epoch: 2411
[ Wed Apr 25 12:18:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:42 2018 ] Training epoch: 2412
[ Wed Apr 25 12:18:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:18:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:18:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:46 2018 ] Training epoch: 2413
[ Wed Apr 25 12:18:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:18:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:18:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:51 2018 ] Training epoch: 2414
[ Wed Apr 25 12:18:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:18:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:18:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:55 2018 ] Training epoch: 2415
[ Wed Apr 25 12:18:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:18:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:18:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:18:59 2018 ] Eval epoch: 2415
[ Wed Apr 25 12:19:01 2018 ] 	Mean test loss of 1 batches: 0.22009751200675964.
[ Wed Apr 25 12:19:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:19:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:19:01 2018 ] Training epoch: 2416
[ Wed Apr 25 12:19:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:05 2018 ] Training epoch: 2417
[ Wed Apr 25 12:19:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:10 2018 ] Training epoch: 2418
[ Wed Apr 25 12:19:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:14 2018 ] Training epoch: 2419
[ Wed Apr 25 12:19:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:18 2018 ] Training epoch: 2420
[ Wed Apr 25 12:19:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:22 2018 ] Eval epoch: 2420
[ Wed Apr 25 12:19:25 2018 ] 	Mean test loss of 1 batches: 0.2228083461523056.
[ Wed Apr 25 12:19:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:19:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:19:25 2018 ] Training epoch: 2421
[ Wed Apr 25 12:19:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:29 2018 ] Training epoch: 2422
[ Wed Apr 25 12:19:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:19:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:19:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:33 2018 ] Training epoch: 2423
[ Wed Apr 25 12:19:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:19:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:19:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:37 2018 ] Training epoch: 2424
[ Wed Apr 25 12:19:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:19:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:19:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:41 2018 ] Training epoch: 2425
[ Wed Apr 25 12:19:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:19:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:19:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:45 2018 ] Eval epoch: 2425
[ Wed Apr 25 12:19:48 2018 ] 	Mean test loss of 1 batches: 0.22149764001369476.
[ Wed Apr 25 12:19:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:19:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:19:48 2018 ] Training epoch: 2426
[ Wed Apr 25 12:19:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:19:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:19:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:52 2018 ] Training epoch: 2427
[ Wed Apr 25 12:19:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:19:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:19:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:19:56 2018 ] Training epoch: 2428
[ Wed Apr 25 12:20:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:00 2018 ] Training epoch: 2429
[ Wed Apr 25 12:20:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:20:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:20:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:04 2018 ] Training epoch: 2430
[ Wed Apr 25 12:20:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:08 2018 ] Eval epoch: 2430
[ Wed Apr 25 12:20:11 2018 ] 	Mean test loss of 1 batches: 0.23789256811141968.
[ Wed Apr 25 12:20:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:20:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:20:11 2018 ] Training epoch: 2431
[ Wed Apr 25 12:20:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:20:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:20:15 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:20:15 2018 ] Training epoch: 2432
[ Wed Apr 25 12:20:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:19 2018 ] Training epoch: 2433
[ Wed Apr 25 12:20:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:20:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:20:24 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:20:24 2018 ] Training epoch: 2434
[ Wed Apr 25 12:20:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:20:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:20:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:28 2018 ] Training epoch: 2435
[ Wed Apr 25 12:20:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:32 2018 ] Eval epoch: 2435
[ Wed Apr 25 12:20:35 2018 ] 	Mean test loss of 1 batches: 0.23241673409938812.
[ Wed Apr 25 12:20:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:20:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:20:35 2018 ] Training epoch: 2436
[ Wed Apr 25 12:20:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:39 2018 ] Training epoch: 2437
[ Wed Apr 25 12:20:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:20:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:20:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:43 2018 ] Training epoch: 2438
[ Wed Apr 25 12:20:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:20:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:20:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:47 2018 ] Training epoch: 2439
[ Wed Apr 25 12:20:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:20:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:20:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:51 2018 ] Training epoch: 2440
[ Wed Apr 25 12:20:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:20:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:20:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:20:55 2018 ] Eval epoch: 2440
[ Wed Apr 25 12:20:58 2018 ] 	Mean test loss of 1 batches: 0.23631544411182404.
[ Wed Apr 25 12:20:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:20:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:20:58 2018 ] Training epoch: 2441
[ Wed Apr 25 12:21:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:21:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:21:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:02 2018 ] Training epoch: 2442
[ Wed Apr 25 12:21:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:21:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:21:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:06 2018 ] Training epoch: 2443
[ Wed Apr 25 12:21:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:10 2018 ] Training epoch: 2444
[ Wed Apr 25 12:21:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:21:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:21:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:14 2018 ] Training epoch: 2445
[ Wed Apr 25 12:21:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:18 2018 ] Eval epoch: 2445
[ Wed Apr 25 12:21:21 2018 ] 	Mean test loss of 1 batches: 0.21745061874389648.
[ Wed Apr 25 12:21:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:21:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:21:21 2018 ] Training epoch: 2446
[ Wed Apr 25 12:21:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:21:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:21:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:25 2018 ] Training epoch: 2447
[ Wed Apr 25 12:21:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:29 2018 ] Training epoch: 2448
[ Wed Apr 25 12:21:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:33 2018 ] Training epoch: 2449
[ Wed Apr 25 12:21:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:21:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:21:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:37 2018 ] Training epoch: 2450
[ Wed Apr 25 12:21:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:21:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:21:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:41 2018 ] Eval epoch: 2450
[ Wed Apr 25 12:21:44 2018 ] 	Mean test loss of 1 batches: 0.2233407199382782.
[ Wed Apr 25 12:21:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:21:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:21:44 2018 ] Training epoch: 2451
[ Wed Apr 25 12:21:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:49 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:21:49 2018 ] Training epoch: 2452
[ Wed Apr 25 12:21:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:53 2018 ] Training epoch: 2453
[ Wed Apr 25 12:21:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:21:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:21:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:21:57 2018 ] Training epoch: 2454
[ Wed Apr 25 12:22:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:22:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:22:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:01 2018 ] Training epoch: 2455
[ Wed Apr 25 12:22:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:22:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:22:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:05 2018 ] Eval epoch: 2455
[ Wed Apr 25 12:22:08 2018 ] 	Mean test loss of 1 batches: 0.2321970909833908.
[ Wed Apr 25 12:22:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:22:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:22:08 2018 ] Training epoch: 2456
[ Wed Apr 25 12:22:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:22:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:22:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:12 2018 ] Training epoch: 2457
[ Wed Apr 25 12:22:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:16 2018 ] Training epoch: 2458
[ Wed Apr 25 12:22:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:22:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:22:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:20 2018 ] Training epoch: 2459
[ Wed Apr 25 12:22:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:24 2018 ] Training epoch: 2460
[ Wed Apr 25 12:22:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:28 2018 ] Eval epoch: 2460
[ Wed Apr 25 12:22:31 2018 ] 	Mean test loss of 1 batches: 0.22328302264213562.
[ Wed Apr 25 12:22:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:22:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:22:31 2018 ] Training epoch: 2461
[ Wed Apr 25 12:22:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:35 2018 ] Training epoch: 2462
[ Wed Apr 25 12:22:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:22:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:22:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:39 2018 ] Training epoch: 2463
[ Wed Apr 25 12:22:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:43 2018 ] Training epoch: 2464
[ Wed Apr 25 12:22:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:22:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:22:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:47 2018 ] Training epoch: 2465
[ Wed Apr 25 12:22:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:22:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:22:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:51 2018 ] Eval epoch: 2465
[ Wed Apr 25 12:22:54 2018 ] 	Mean test loss of 1 batches: 0.22755199670791626.
[ Wed Apr 25 12:22:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:22:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:22:54 2018 ] Training epoch: 2466
[ Wed Apr 25 12:22:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:22:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:22:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:22:58 2018 ] Training epoch: 2467
[ Wed Apr 25 12:23:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:02 2018 ] Training epoch: 2468
[ Wed Apr 25 12:23:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:06 2018 ] Training epoch: 2469
[ Wed Apr 25 12:23:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:23:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:23:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:10 2018 ] Training epoch: 2470
[ Wed Apr 25 12:23:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:23:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:23:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:14 2018 ] Eval epoch: 2470
[ Wed Apr 25 12:23:16 2018 ] 	Mean test loss of 1 batches: 0.22900374233722687.
[ Wed Apr 25 12:23:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:23:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:23:16 2018 ] Training epoch: 2471
[ Wed Apr 25 12:23:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:20 2018 ] Training epoch: 2472
[ Wed Apr 25 12:23:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:23:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:23:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:24 2018 ] Training epoch: 2473
[ Wed Apr 25 12:23:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:28 2018 ] Training epoch: 2474
[ Wed Apr 25 12:23:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:23:32 2018 ] Training epoch: 2475
[ Wed Apr 25 12:23:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:36 2018 ] Eval epoch: 2475
[ Wed Apr 25 12:23:39 2018 ] 	Mean test loss of 1 batches: 0.22268924117088318.
[ Wed Apr 25 12:23:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:23:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:23:39 2018 ] Training epoch: 2476
[ Wed Apr 25 12:23:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:43 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:23:43 2018 ] Training epoch: 2477
[ Wed Apr 25 12:23:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:23:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:23:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:47 2018 ] Training epoch: 2478
[ Wed Apr 25 12:23:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:23:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:23:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:51 2018 ] Training epoch: 2479
[ Wed Apr 25 12:23:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:23:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:23:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:55 2018 ] Training epoch: 2480
[ Wed Apr 25 12:23:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:23:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:23:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:23:59 2018 ] Eval epoch: 2480
[ Wed Apr 25 12:24:02 2018 ] 	Mean test loss of 1 batches: 0.23323914408683777.
[ Wed Apr 25 12:24:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:24:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:24:02 2018 ] Training epoch: 2481
[ Wed Apr 25 12:24:06 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:24:06 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:24:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:06 2018 ] Training epoch: 2482
[ Wed Apr 25 12:24:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:24:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:24:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:10 2018 ] Training epoch: 2483
[ Wed Apr 25 12:24:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:24:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:24:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:14 2018 ] Training epoch: 2484
[ Wed Apr 25 12:24:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:24:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:24:18 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:24:18 2018 ] Training epoch: 2485
[ Wed Apr 25 12:24:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:24:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:24:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:22 2018 ] Eval epoch: 2485
[ Wed Apr 25 12:24:25 2018 ] 	Mean test loss of 1 batches: 0.23109294474124908.
[ Wed Apr 25 12:24:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:24:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:24:25 2018 ] Training epoch: 2486
[ Wed Apr 25 12:24:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:24:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:24:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:29 2018 ] Training epoch: 2487
[ Wed Apr 25 12:24:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:24:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:24:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:33 2018 ] Training epoch: 2488
[ Wed Apr 25 12:24:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:24:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:24:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:37 2018 ] Training epoch: 2489
[ Wed Apr 25 12:24:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:24:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:24:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:41 2018 ] Training epoch: 2490
[ Wed Apr 25 12:24:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:24:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:24:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:45 2018 ] Eval epoch: 2490
[ Wed Apr 25 12:24:48 2018 ] 	Mean test loss of 1 batches: 0.22968727350234985.
[ Wed Apr 25 12:24:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:24:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:24:48 2018 ] Training epoch: 2491
[ Wed Apr 25 12:24:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:24:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:24:52 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:24:52 2018 ] Training epoch: 2492
[ Wed Apr 25 12:24:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:24:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:24:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:24:56 2018 ] Training epoch: 2493
[ Wed Apr 25 12:25:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:25:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:25:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:00 2018 ] Training epoch: 2494
[ Wed Apr 25 12:25:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:25:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:25:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:04 2018 ] Training epoch: 2495
[ Wed Apr 25 12:25:08 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:25:08 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:25:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:08 2018 ] Eval epoch: 2495
[ Wed Apr 25 12:25:11 2018 ] 	Mean test loss of 1 batches: 0.2169126570224762.
[ Wed Apr 25 12:25:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:25:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:25:11 2018 ] Training epoch: 2496
[ Wed Apr 25 12:25:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:25:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:25:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:15 2018 ] Training epoch: 2497
[ Wed Apr 25 12:25:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:25:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:25:19 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:25:19 2018 ] Training epoch: 2498
[ Wed Apr 25 12:25:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:25:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:25:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:23 2018 ] Training epoch: 2499
[ Wed Apr 25 12:25:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:25:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:25:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:27 2018 ] Training epoch: 2500
[ Wed Apr 25 12:25:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:25:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:25:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:25:31 2018 ] Eval epoch: 2500
[ Wed Apr 25 12:25:34 2018 ] 	Mean test loss of 1 batches: 0.214942067861557.
[ Wed Apr 25 12:25:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:25:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:25:34 2018 ] Training epoch: 2501
[ Wed Apr 25 12:25:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:25:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:25:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:38 2018 ] Training epoch: 2502
[ Wed Apr 25 12:25:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:25:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:25:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:25:42 2018 ] Training epoch: 2503
[ Wed Apr 25 12:25:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:25:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:25:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:46 2018 ] Training epoch: 2504
[ Wed Apr 25 12:25:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:25:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:25:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:50 2018 ] Training epoch: 2505
[ Wed Apr 25 12:25:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:25:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:25:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:25:54 2018 ] Eval epoch: 2505
[ Wed Apr 25 12:25:57 2018 ] 	Mean test loss of 1 batches: 0.219635471701622.
[ Wed Apr 25 12:25:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:25:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:25:57 2018 ] Training epoch: 2506
[ Wed Apr 25 12:26:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:26:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:26:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:01 2018 ] Training epoch: 2507
[ Wed Apr 25 12:26:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:26:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:26:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:05 2018 ] Training epoch: 2508
[ Wed Apr 25 12:26:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:26:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:26:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:26:10 2018 ] Training epoch: 2509
[ Wed Apr 25 12:26:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:26:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:26:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:14 2018 ] Training epoch: 2510
[ Wed Apr 25 12:26:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:26:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:26:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:18 2018 ] Eval epoch: 2510
[ Wed Apr 25 12:26:21 2018 ] 	Mean test loss of 1 batches: 0.21688556671142578.
[ Wed Apr 25 12:26:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:26:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:26:21 2018 ] Training epoch: 2511
[ Wed Apr 25 12:26:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:26:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:26:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:25 2018 ] Training epoch: 2512
[ Wed Apr 25 12:26:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:26:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:26:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:29 2018 ] Training epoch: 2513
[ Wed Apr 25 12:26:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:26:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:26:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:33 2018 ] Training epoch: 2514
[ Wed Apr 25 12:26:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:26:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:26:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:26:37 2018 ] Training epoch: 2515
[ Wed Apr 25 12:26:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:26:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:26:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:41 2018 ] Eval epoch: 2515
[ Wed Apr 25 12:26:44 2018 ] 	Mean test loss of 1 batches: 0.23764504492282867.
[ Wed Apr 25 12:26:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:26:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:26:44 2018 ] Training epoch: 2516
[ Wed Apr 25 12:26:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:26:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:26:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:48 2018 ] Training epoch: 2517
[ Wed Apr 25 12:26:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:26:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:26:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:52 2018 ] Training epoch: 2518
[ Wed Apr 25 12:26:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:26:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:26:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:26:56 2018 ] Training epoch: 2519
[ Wed Apr 25 12:27:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:27:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:27:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:00 2018 ] Training epoch: 2520
[ Wed Apr 25 12:27:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:27:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:27:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:04 2018 ] Eval epoch: 2520
[ Wed Apr 25 12:27:07 2018 ] 	Mean test loss of 1 batches: 0.2290278673171997.
[ Wed Apr 25 12:27:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:27:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:27:07 2018 ] Training epoch: 2521
[ Wed Apr 25 12:27:11 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:27:11 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:27:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:11 2018 ] Training epoch: 2522
[ Wed Apr 25 12:27:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:27:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:27:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:15 2018 ] Training epoch: 2523
[ Wed Apr 25 12:27:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:27:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:27:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:19 2018 ] Training epoch: 2524
[ Wed Apr 25 12:27:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:27:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:27:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:23 2018 ] Training epoch: 2525
[ Wed Apr 25 12:27:27 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:27:27 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:27:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:27:27 2018 ] Eval epoch: 2525
[ Wed Apr 25 12:27:30 2018 ] 	Mean test loss of 1 batches: 0.23399469256401062.
[ Wed Apr 25 12:27:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:27:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:27:30 2018 ] Training epoch: 2526
[ Wed Apr 25 12:27:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:27:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:27:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:34 2018 ] Training epoch: 2527
[ Wed Apr 25 12:27:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:27:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:27:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:27:38 2018 ] Training epoch: 2528
[ Wed Apr 25 12:27:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:27:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:27:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:42 2018 ] Training epoch: 2529
[ Wed Apr 25 12:27:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:27:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:27:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:46 2018 ] Training epoch: 2530
[ Wed Apr 25 12:27:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:27:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:27:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:51 2018 ] Eval epoch: 2530
[ Wed Apr 25 12:27:53 2018 ] 	Mean test loss of 1 batches: 0.23414601385593414.
[ Wed Apr 25 12:27:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:27:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:27:53 2018 ] Training epoch: 2531
[ Wed Apr 25 12:27:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:27:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:27:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:27:57 2018 ] Training epoch: 2532
[ Wed Apr 25 12:28:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:28:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:28:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:01 2018 ] Training epoch: 2533
[ Wed Apr 25 12:28:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:28:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:28:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:05 2018 ] Training epoch: 2534
[ Wed Apr 25 12:28:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:28:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:28:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:09 2018 ] Training epoch: 2535
[ Wed Apr 25 12:28:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:28:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:28:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:14 2018 ] Eval epoch: 2535
[ Wed Apr 25 12:28:17 2018 ] 	Mean test loss of 1 batches: 0.2295096218585968.
[ Wed Apr 25 12:28:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:28:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:28:17 2018 ] Training epoch: 2536
[ Wed Apr 25 12:28:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:28:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:28:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:21 2018 ] Training epoch: 2537
[ Wed Apr 25 12:28:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:28:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:28:25 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 12:28:25 2018 ] Training epoch: 2538
[ Wed Apr 25 12:28:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:28:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:28:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:29 2018 ] Training epoch: 2539
[ Wed Apr 25 12:28:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:28:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:28:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:33 2018 ] Training epoch: 2540
[ Wed Apr 25 12:28:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:28:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:28:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:37 2018 ] Eval epoch: 2540
[ Wed Apr 25 12:28:40 2018 ] 	Mean test loss of 1 batches: 0.23034273087978363.
[ Wed Apr 25 12:28:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:28:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:28:40 2018 ] Training epoch: 2541
[ Wed Apr 25 12:28:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:28:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:28:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:44 2018 ] Training epoch: 2542
[ Wed Apr 25 12:28:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:28:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:28:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:48 2018 ] Training epoch: 2543
[ Wed Apr 25 12:28:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:28:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:28:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:52 2018 ] Training epoch: 2544
[ Wed Apr 25 12:28:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:28:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:28:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:28:56 2018 ] Training epoch: 2545
[ Wed Apr 25 12:29:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:29:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:29:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:00 2018 ] Eval epoch: 2545
[ Wed Apr 25 12:29:03 2018 ] 	Mean test loss of 1 batches: 0.23236125707626343.
[ Wed Apr 25 12:29:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:29:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:29:03 2018 ] Training epoch: 2546
[ Wed Apr 25 12:29:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:07 2018 ] Training epoch: 2547
[ Wed Apr 25 12:29:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:11 2018 ] Training epoch: 2548
[ Wed Apr 25 12:29:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:29:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:29:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:15 2018 ] Training epoch: 2549
[ Wed Apr 25 12:29:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:19 2018 ] Training epoch: 2550
[ Wed Apr 25 12:29:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:23 2018 ] Eval epoch: 2550
[ Wed Apr 25 12:29:26 2018 ] 	Mean test loss of 1 batches: 0.2351696640253067.
[ Wed Apr 25 12:29:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:29:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:29:26 2018 ] Training epoch: 2551
[ Wed Apr 25 12:29:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:29:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:29:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:30 2018 ] Training epoch: 2552
[ Wed Apr 25 12:29:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:34 2018 ] Training epoch: 2553
[ Wed Apr 25 12:29:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:29:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:29:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:38 2018 ] Training epoch: 2554
[ Wed Apr 25 12:29:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:29:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:29:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:42 2018 ] Training epoch: 2555
[ Wed Apr 25 12:29:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:29:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:29:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:46 2018 ] Eval epoch: 2555
[ Wed Apr 25 12:29:49 2018 ] 	Mean test loss of 1 batches: 0.2242293655872345.
[ Wed Apr 25 12:29:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:29:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:29:49 2018 ] Training epoch: 2556
[ Wed Apr 25 12:29:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:29:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:29:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:29:53 2018 ] Training epoch: 2557
[ Wed Apr 25 12:29:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:29:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:29:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:29:57 2018 ] Training epoch: 2558
[ Wed Apr 25 12:30:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:01 2018 ] Training epoch: 2559
[ Wed Apr 25 12:30:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:05 2018 ] Training epoch: 2560
[ Wed Apr 25 12:30:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:09 2018 ] Eval epoch: 2560
[ Wed Apr 25 12:30:12 2018 ] 	Mean test loss of 1 batches: 0.21984688937664032.
[ Wed Apr 25 12:30:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:30:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:30:12 2018 ] Training epoch: 2561
[ Wed Apr 25 12:30:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:16 2018 ] Training epoch: 2562
[ Wed Apr 25 12:30:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:30:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:30:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:21 2018 ] Training epoch: 2563
[ Wed Apr 25 12:30:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:30:25 2018 ] Training epoch: 2564
[ Wed Apr 25 12:30:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:29 2018 ] Training epoch: 2565
[ Wed Apr 25 12:30:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:33 2018 ] Eval epoch: 2565
[ Wed Apr 25 12:30:36 2018 ] 	Mean test loss of 1 batches: 0.22505906224250793.
[ Wed Apr 25 12:30:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:30:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:30:36 2018 ] Training epoch: 2566
[ Wed Apr 25 12:30:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:40 2018 ] Training epoch: 2567
[ Wed Apr 25 12:30:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:44 2018 ] Training epoch: 2568
[ Wed Apr 25 12:30:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:30:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:30:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:48 2018 ] Training epoch: 2569
[ Wed Apr 25 12:30:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:30:52 2018 ] Training epoch: 2570
[ Wed Apr 25 12:30:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:30:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:30:56 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:30:56 2018 ] Eval epoch: 2570
[ Wed Apr 25 12:30:59 2018 ] 	Mean test loss of 1 batches: 0.22400538623332977.
[ Wed Apr 25 12:30:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:30:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:30:59 2018 ] Training epoch: 2571
[ Wed Apr 25 12:31:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:31:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:31:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:03 2018 ] Training epoch: 2572
[ Wed Apr 25 12:31:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:07 2018 ] Training epoch: 2573
[ Wed Apr 25 12:31:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:11 2018 ] Training epoch: 2574
[ Wed Apr 25 12:31:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:15 2018 ] Training epoch: 2575
[ Wed Apr 25 12:31:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:31:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:31:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:19 2018 ] Eval epoch: 2575
[ Wed Apr 25 12:31:22 2018 ] 	Mean test loss of 1 batches: 0.21803484857082367.
[ Wed Apr 25 12:31:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:31:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:31:22 2018 ] Training epoch: 2576
[ Wed Apr 25 12:31:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:31:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:31:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:26 2018 ] Training epoch: 2577
[ Wed Apr 25 12:31:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:31:31 2018 ] Training epoch: 2578
[ Wed Apr 25 12:31:35 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.010000
[ Wed Apr 25 12:31:35 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 12:31:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:35 2018 ] Training epoch: 2579
[ Wed Apr 25 12:31:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:31:39 2018 ] Training epoch: 2580
[ Wed Apr 25 12:31:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:31:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:31:43 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:31:43 2018 ] Eval epoch: 2580
[ Wed Apr 25 12:31:46 2018 ] 	Mean test loss of 1 batches: 0.2294260412454605.
[ Wed Apr 25 12:31:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:31:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:31:46 2018 ] Training epoch: 2581
[ Wed Apr 25 12:31:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:50 2018 ] Training epoch: 2582
[ Wed Apr 25 12:31:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:31:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:31:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:31:54 2018 ] Training epoch: 2583
[ Wed Apr 25 12:31:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:31:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:31:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:31:58 2018 ] Training epoch: 2584
[ Wed Apr 25 12:32:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:03 2018 ] Training epoch: 2585
[ Wed Apr 25 12:32:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:32:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:32:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:07 2018 ] Eval epoch: 2585
[ Wed Apr 25 12:32:10 2018 ] 	Mean test loss of 1 batches: 0.216337651014328.
[ Wed Apr 25 12:32:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:32:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:32:10 2018 ] Training epoch: 2586
[ Wed Apr 25 12:32:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:14 2018 ] Training epoch: 2587
[ Wed Apr 25 12:32:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:18 2018 ] Training epoch: 2588
[ Wed Apr 25 12:32:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:32:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:32:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:22 2018 ] Training epoch: 2589
[ Wed Apr 25 12:32:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:26 2018 ] Training epoch: 2590
[ Wed Apr 25 12:32:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:30 2018 ] Eval epoch: 2590
[ Wed Apr 25 12:32:33 2018 ] 	Mean test loss of 1 batches: 0.22220025956630707.
[ Wed Apr 25 12:32:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:32:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:32:33 2018 ] Training epoch: 2591
[ Wed Apr 25 12:32:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:32:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:32:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:37 2018 ] Training epoch: 2592
[ Wed Apr 25 12:32:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:32:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:32:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:41 2018 ] Training epoch: 2593
[ Wed Apr 25 12:32:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:45 2018 ] Training epoch: 2594
[ Wed Apr 25 12:32:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:32:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:32:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:49 2018 ] Training epoch: 2595
[ Wed Apr 25 12:32:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:32:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:32:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:32:53 2018 ] Eval epoch: 2595
[ Wed Apr 25 12:32:56 2018 ] 	Mean test loss of 1 batches: 0.2190919816493988.
[ Wed Apr 25 12:32:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:32:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:32:56 2018 ] Training epoch: 2596
[ Wed Apr 25 12:33:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:33:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:33:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:00 2018 ] Training epoch: 2597
[ Wed Apr 25 12:33:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:33:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:33:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:04 2018 ] Training epoch: 2598
[ Wed Apr 25 12:33:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:33:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:33:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:08 2018 ] Training epoch: 2599
[ Wed Apr 25 12:33:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:33:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:33:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:12 2018 ] Training epoch: 2600
[ Wed Apr 25 12:33:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:16 2018 ] Eval epoch: 2600
[ Wed Apr 25 12:33:19 2018 ] 	Mean test loss of 1 batches: 0.21571050584316254.
[ Wed Apr 25 12:33:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:33:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:33:19 2018 ] Training epoch: 2601
[ Wed Apr 25 12:33:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:23 2018 ] Training epoch: 2602
[ Wed Apr 25 12:33:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:33:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:33:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:27 2018 ] Training epoch: 2603
[ Wed Apr 25 12:33:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:31 2018 ] Training epoch: 2604
[ Wed Apr 25 12:33:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:35 2018 ] Training epoch: 2605
[ Wed Apr 25 12:33:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:33:39 2018 ] Eval epoch: 2605
[ Wed Apr 25 12:33:42 2018 ] 	Mean test loss of 1 batches: 0.22017452120780945.
[ Wed Apr 25 12:33:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:33:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:33:42 2018 ] Training epoch: 2606
[ Wed Apr 25 12:33:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:46 2018 ] Training epoch: 2607
[ Wed Apr 25 12:33:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:50 2018 ] Training epoch: 2608
[ Wed Apr 25 12:33:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:33:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:33:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:33:54 2018 ] Training epoch: 2609
[ Wed Apr 25 12:33:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:33:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:33:58 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:33:58 2018 ] Training epoch: 2610
[ Wed Apr 25 12:34:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:02 2018 ] Eval epoch: 2610
[ Wed Apr 25 12:34:05 2018 ] 	Mean test loss of 1 batches: 0.22677898406982422.
[ Wed Apr 25 12:34:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:34:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:34:05 2018 ] Training epoch: 2611
[ Wed Apr 25 12:34:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:09 2018 ] Training epoch: 2612
[ Wed Apr 25 12:34:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:13 2018 ] Training epoch: 2613
[ Wed Apr 25 12:34:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:17 2018 ] Training epoch: 2614
[ Wed Apr 25 12:34:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:21 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:34:21 2018 ] Training epoch: 2615
[ Wed Apr 25 12:34:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:25 2018 ] Eval epoch: 2615
[ Wed Apr 25 12:34:28 2018 ] 	Mean test loss of 1 batches: 0.227943554520607.
[ Wed Apr 25 12:34:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:34:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:34:28 2018 ] Training epoch: 2616
[ Wed Apr 25 12:34:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:32 2018 ] Training epoch: 2617
[ Wed Apr 25 12:34:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:36 2018 ] Training epoch: 2618
[ Wed Apr 25 12:34:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:40 2018 ] Training epoch: 2619
[ Wed Apr 25 12:34:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:44 2018 ] Training epoch: 2620
[ Wed Apr 25 12:34:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:49 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:34:49 2018 ] Eval epoch: 2620
[ Wed Apr 25 12:34:51 2018 ] 	Mean test loss of 1 batches: 0.2305435985326767.
[ Wed Apr 25 12:34:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:34:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:34:51 2018 ] Training epoch: 2621
[ Wed Apr 25 12:34:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:34:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:34:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:55 2018 ] Training epoch: 2622
[ Wed Apr 25 12:34:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:34:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:34:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:34:59 2018 ] Training epoch: 2623
[ Wed Apr 25 12:35:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:35:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:35:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:03 2018 ] Training epoch: 2624
[ Wed Apr 25 12:35:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:35:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:35:07 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:35:07 2018 ] Training epoch: 2625
[ Wed Apr 25 12:35:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:35:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:35:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:11 2018 ] Eval epoch: 2625
[ Wed Apr 25 12:35:14 2018 ] 	Mean test loss of 1 batches: 0.23276939988136292.
[ Wed Apr 25 12:35:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:35:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:35:14 2018 ] Training epoch: 2626
[ Wed Apr 25 12:35:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:18 2018 ] Training epoch: 2627
[ Wed Apr 25 12:35:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:22 2018 ] Training epoch: 2628
[ Wed Apr 25 12:35:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:26 2018 ] Training epoch: 2629
[ Wed Apr 25 12:35:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:30 2018 ] Training epoch: 2630
[ Wed Apr 25 12:35:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:34 2018 ] Eval epoch: 2630
[ Wed Apr 25 12:35:37 2018 ] 	Mean test loss of 1 batches: 0.2270912230014801.
[ Wed Apr 25 12:35:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:35:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:35:37 2018 ] Training epoch: 2631
[ Wed Apr 25 12:35:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:35:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:35:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:41 2018 ] Training epoch: 2632
[ Wed Apr 25 12:35:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:35:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:35:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:45 2018 ] Training epoch: 2633
[ Wed Apr 25 12:35:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:35:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:35:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:49 2018 ] Training epoch: 2634
[ Wed Apr 25 12:35:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:35:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:35:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:53 2018 ] Training epoch: 2635
[ Wed Apr 25 12:35:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:35:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:35:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:35:57 2018 ] Eval epoch: 2635
[ Wed Apr 25 12:36:00 2018 ] 	Mean test loss of 1 batches: 0.23912756145000458.
[ Wed Apr 25 12:36:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:36:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:36:00 2018 ] Training epoch: 2636
[ Wed Apr 25 12:36:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:04 2018 ] Training epoch: 2637
[ Wed Apr 25 12:36:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:09 2018 ] Training epoch: 2638
[ Wed Apr 25 12:36:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:36:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:36:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:13 2018 ] Training epoch: 2639
[ Wed Apr 25 12:36:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:17 2018 ] Training epoch: 2640
[ Wed Apr 25 12:36:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:21 2018 ] Eval epoch: 2640
[ Wed Apr 25 12:36:23 2018 ] 	Mean test loss of 1 batches: 0.2293255627155304.
[ Wed Apr 25 12:36:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:36:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:36:23 2018 ] Training epoch: 2641
[ Wed Apr 25 12:36:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:28 2018 ] Training epoch: 2642
[ Wed Apr 25 12:36:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:36:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:36:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:36:32 2018 ] Training epoch: 2643
[ Wed Apr 25 12:36:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:36 2018 ] Training epoch: 2644
[ Wed Apr 25 12:36:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:36:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:36:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:40 2018 ] Training epoch: 2645
[ Wed Apr 25 12:36:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:36:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:36:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:44 2018 ] Eval epoch: 2645
[ Wed Apr 25 12:36:47 2018 ] 	Mean test loss of 1 batches: 0.22489331662654877.
[ Wed Apr 25 12:36:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:36:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:36:47 2018 ] Training epoch: 2646
[ Wed Apr 25 12:36:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:36:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:36:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:51 2018 ] Training epoch: 2647
[ Wed Apr 25 12:36:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:36:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:36:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:55 2018 ] Training epoch: 2648
[ Wed Apr 25 12:36:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:36:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:36:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:36:59 2018 ] Training epoch: 2649
[ Wed Apr 25 12:37:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:37:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:37:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:03 2018 ] Training epoch: 2650
[ Wed Apr 25 12:37:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:37:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:37:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:37:07 2018 ] Eval epoch: 2650
[ Wed Apr 25 12:37:10 2018 ] 	Mean test loss of 1 batches: 0.22825194895267487.
[ Wed Apr 25 12:37:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:37:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:37:10 2018 ] Training epoch: 2651
[ Wed Apr 25 12:37:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:37:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:37:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:14 2018 ] Training epoch: 2652
[ Wed Apr 25 12:37:18 2018 ] 	Batch(0/1) done. Loss: 0.0000  lr:0.010000
[ Wed Apr 25 12:37:18 2018 ] 	Mean training loss: 0.0000.
[ Wed Apr 25 12:37:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:18 2018 ] Training epoch: 2653
[ Wed Apr 25 12:37:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:37:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:37:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:22 2018 ] Training epoch: 2654
[ Wed Apr 25 12:37:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:37:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:37:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:26 2018 ] Training epoch: 2655
[ Wed Apr 25 12:37:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:37:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:37:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:30 2018 ] Eval epoch: 2655
[ Wed Apr 25 12:37:33 2018 ] 	Mean test loss of 1 batches: 0.21988724172115326.
[ Wed Apr 25 12:37:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:37:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:37:33 2018 ] Training epoch: 2656
[ Wed Apr 25 12:37:37 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.010000
[ Wed Apr 25 12:37:37 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 12:37:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:37 2018 ] Training epoch: 2657
[ Wed Apr 25 12:37:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:37:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:37:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:41 2018 ] Training epoch: 2658
[ Wed Apr 25 12:37:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:37:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:37:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:37:45 2018 ] Training epoch: 2659
[ Wed Apr 25 12:37:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:37:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:37:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:49 2018 ] Training epoch: 2660
[ Wed Apr 25 12:37:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:37:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:37:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:37:53 2018 ] Eval epoch: 2660
[ Wed Apr 25 12:37:56 2018 ] 	Mean test loss of 1 batches: 0.2257288545370102.
[ Wed Apr 25 12:37:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:37:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:37:56 2018 ] Training epoch: 2661
[ Wed Apr 25 12:38:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:00 2018 ] Training epoch: 2662
[ Wed Apr 25 12:38:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:38:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:38:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:04 2018 ] Training epoch: 2663
[ Wed Apr 25 12:38:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:38:09 2018 ] Training epoch: 2664
[ Wed Apr 25 12:38:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:13 2018 ] Training epoch: 2665
[ Wed Apr 25 12:38:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:38:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:38:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:17 2018 ] Eval epoch: 2665
[ Wed Apr 25 12:38:19 2018 ] 	Mean test loss of 1 batches: 0.22458332777023315.
[ Wed Apr 25 12:38:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:38:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:38:19 2018 ] Training epoch: 2666
[ Wed Apr 25 12:38:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:38:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:38:24 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:38:24 2018 ] Training epoch: 2667
[ Wed Apr 25 12:38:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:38:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:38:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:28 2018 ] Training epoch: 2668
[ Wed Apr 25 12:38:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:32 2018 ] Training epoch: 2669
[ Wed Apr 25 12:38:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:36 2018 ] Training epoch: 2670
[ Wed Apr 25 12:38:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:40 2018 ] Eval epoch: 2670
[ Wed Apr 25 12:38:43 2018 ] 	Mean test loss of 1 batches: 0.23336079716682434.
[ Wed Apr 25 12:38:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:38:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:38:43 2018 ] Training epoch: 2671
[ Wed Apr 25 12:38:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:38:47 2018 ] Training epoch: 2672
[ Wed Apr 25 12:38:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:51 2018 ] Training epoch: 2673
[ Wed Apr 25 12:38:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:38:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:38:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:55 2018 ] Training epoch: 2674
[ Wed Apr 25 12:38:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:38:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:38:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:38:59 2018 ] Training epoch: 2675
[ Wed Apr 25 12:39:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:03 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:39:03 2018 ] Eval epoch: 2675
[ Wed Apr 25 12:39:06 2018 ] 	Mean test loss of 1 batches: 0.22773128747940063.
[ Wed Apr 25 12:39:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:39:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:39:06 2018 ] Training epoch: 2676
[ Wed Apr 25 12:39:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:10 2018 ] Training epoch: 2677
[ Wed Apr 25 12:39:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:14 2018 ] Training epoch: 2678
[ Wed Apr 25 12:39:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:39:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:39:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:18 2018 ] Training epoch: 2679
[ Wed Apr 25 12:39:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:39:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:39:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:22 2018 ] Training epoch: 2680
[ Wed Apr 25 12:39:26 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.010000
[ Wed Apr 25 12:39:26 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 12:39:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:26 2018 ] Eval epoch: 2680
[ Wed Apr 25 12:39:29 2018 ] 	Mean test loss of 1 batches: 0.232186958193779.
[ Wed Apr 25 12:39:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:39:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:39:29 2018 ] Training epoch: 2681
[ Wed Apr 25 12:39:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:33 2018 ] Training epoch: 2682
[ Wed Apr 25 12:39:37 2018 ] 	Batch(0/1) done. Loss: 0.0044  lr:0.010000
[ Wed Apr 25 12:39:37 2018 ] 	Mean training loss: 0.0044.
[ Wed Apr 25 12:39:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:37 2018 ] Training epoch: 2683
[ Wed Apr 25 12:39:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:39:42 2018 ] Training epoch: 2684
[ Wed Apr 25 12:39:46 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.010000
[ Wed Apr 25 12:39:46 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 12:39:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:46 2018 ] Training epoch: 2685
[ Wed Apr 25 12:39:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:39:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:39:50 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:39:50 2018 ] Eval epoch: 2685
[ Wed Apr 25 12:39:53 2018 ] 	Mean test loss of 1 batches: 0.2295297235250473.
[ Wed Apr 25 12:39:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:39:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:39:53 2018 ] Training epoch: 2686
[ Wed Apr 25 12:39:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:39:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:39:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:39:57 2018 ] Training epoch: 2687
[ Wed Apr 25 12:40:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:01 2018 ] Training epoch: 2688
[ Wed Apr 25 12:40:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:40:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:40:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:05 2018 ] Training epoch: 2689
[ Wed Apr 25 12:40:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:40:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:40:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:09 2018 ] Training epoch: 2690
[ Wed Apr 25 12:40:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:40:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:40:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:13 2018 ] Eval epoch: 2690
[ Wed Apr 25 12:40:16 2018 ] 	Mean test loss of 1 batches: 0.23964379727840424.
[ Wed Apr 25 12:40:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:40:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:40:16 2018 ] Training epoch: 2691
[ Wed Apr 25 12:40:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:40:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:40:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:20 2018 ] Training epoch: 2692
[ Wed Apr 25 12:40:24 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:40:24 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:40:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:24 2018 ] Training epoch: 2693
[ Wed Apr 25 12:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:28 2018 ] Training epoch: 2694
[ Wed Apr 25 12:40:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:40:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:40:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:32 2018 ] Training epoch: 2695
[ Wed Apr 25 12:40:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:36 2018 ] Eval epoch: 2695
[ Wed Apr 25 12:40:39 2018 ] 	Mean test loss of 1 batches: 0.23509778082370758.
[ Wed Apr 25 12:40:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:40:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:40:39 2018 ] Training epoch: 2696
[ Wed Apr 25 12:40:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:40:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:40:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:43 2018 ] Training epoch: 2697
[ Wed Apr 25 12:40:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:40:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:40:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:47 2018 ] Training epoch: 2698
[ Wed Apr 25 12:40:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:51 2018 ] Training epoch: 2699
[ Wed Apr 25 12:40:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:55 2018 ] Training epoch: 2700
[ Wed Apr 25 12:40:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:40:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:40:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:40:59 2018 ] Eval epoch: 2700
[ Wed Apr 25 12:41:02 2018 ] 	Mean test loss of 1 batches: 0.22577445209026337.
[ Wed Apr 25 12:41:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:41:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:41:02 2018 ] Training epoch: 2701
[ Wed Apr 25 12:41:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:41:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:41:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:06 2018 ] Training epoch: 2702
[ Wed Apr 25 12:41:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:41:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:41:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:10 2018 ] Training epoch: 2703
[ Wed Apr 25 12:41:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:41:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:41:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:14 2018 ] Training epoch: 2704
[ Wed Apr 25 12:41:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:41:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:41:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:18 2018 ] Training epoch: 2705
[ Wed Apr 25 12:41:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:41:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:41:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:22 2018 ] Eval epoch: 2705
[ Wed Apr 25 12:41:25 2018 ] 	Mean test loss of 1 batches: 0.22160714864730835.
[ Wed Apr 25 12:41:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:41:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:41:25 2018 ] Training epoch: 2706
[ Wed Apr 25 12:41:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:41:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:41:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:29 2018 ] Training epoch: 2707
[ Wed Apr 25 12:41:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:41:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:41:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:34 2018 ] Training epoch: 2708
[ Wed Apr 25 12:41:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:41:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:41:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:38 2018 ] Training epoch: 2709
[ Wed Apr 25 12:41:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:41:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:41:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:42 2018 ] Training epoch: 2710
[ Wed Apr 25 12:41:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:41:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:41:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:46 2018 ] Eval epoch: 2710
[ Wed Apr 25 12:41:49 2018 ] 	Mean test loss of 1 batches: 0.21094416081905365.
[ Wed Apr 25 12:41:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:41:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:41:49 2018 ] Training epoch: 2711
[ Wed Apr 25 12:41:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:41:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:41:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:41:53 2018 ] Training epoch: 2712
[ Wed Apr 25 12:41:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:41:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:41:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:41:57 2018 ] Training epoch: 2713
[ Wed Apr 25 12:42:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:42:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:42:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:01 2018 ] Training epoch: 2714
[ Wed Apr 25 12:42:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:42:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:42:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:05 2018 ] Training epoch: 2715
[ Wed Apr 25 12:42:09 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:42:09 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:42:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:09 2018 ] Eval epoch: 2715
[ Wed Apr 25 12:42:12 2018 ] 	Mean test loss of 1 batches: 0.2223125696182251.
[ Wed Apr 25 12:42:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:42:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:42:12 2018 ] Training epoch: 2716
[ Wed Apr 25 12:42:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:42:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:42:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:16 2018 ] Training epoch: 2717
[ Wed Apr 25 12:42:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:42:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:42:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:20 2018 ] Training epoch: 2718
[ Wed Apr 25 12:42:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:42:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:42:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:24 2018 ] Training epoch: 2719
[ Wed Apr 25 12:42:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:42:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:42:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:28 2018 ] Training epoch: 2720
[ Wed Apr 25 12:42:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:42:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:42:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:32 2018 ] Eval epoch: 2720
[ Wed Apr 25 12:42:35 2018 ] 	Mean test loss of 1 batches: 0.21419757604599.
[ Wed Apr 25 12:42:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:42:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:42:35 2018 ] Training epoch: 2721
[ Wed Apr 25 12:42:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:42:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:42:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:42:39 2018 ] Training epoch: 2722
[ Wed Apr 25 12:42:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:42:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:42:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:43 2018 ] Training epoch: 2723
[ Wed Apr 25 12:42:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:42:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:42:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:47 2018 ] Training epoch: 2724
[ Wed Apr 25 12:42:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:42:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:42:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:51 2018 ] Training epoch: 2725
[ Wed Apr 25 12:42:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:42:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:42:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:42:55 2018 ] Eval epoch: 2725
[ Wed Apr 25 12:42:58 2018 ] 	Mean test loss of 1 batches: 0.21216563880443573.
[ Wed Apr 25 12:42:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:42:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:42:58 2018 ] Training epoch: 2726
[ Wed Apr 25 12:43:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:02 2018 ] Training epoch: 2727
[ Wed Apr 25 12:43:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:43:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:43:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:06 2018 ] Training epoch: 2728
[ Wed Apr 25 12:43:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:43:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:43:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:10 2018 ] Training epoch: 2729
[ Wed Apr 25 12:43:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:43:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:43:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:14 2018 ] Training epoch: 2730
[ Wed Apr 25 12:43:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:19 2018 ] Eval epoch: 2730
[ Wed Apr 25 12:43:21 2018 ] 	Mean test loss of 1 batches: 0.22030048072338104.
[ Wed Apr 25 12:43:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:43:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:43:21 2018 ] Training epoch: 2731
[ Wed Apr 25 12:43:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:25 2018 ] Training epoch: 2732
[ Wed Apr 25 12:43:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:43:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:43:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:30 2018 ] Training epoch: 2733
[ Wed Apr 25 12:43:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:43:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:43:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:34 2018 ] Training epoch: 2734
[ Wed Apr 25 12:43:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:38 2018 ] Training epoch: 2735
[ Wed Apr 25 12:43:42 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:43:42 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:43:42 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:43:42 2018 ] Eval epoch: 2735
[ Wed Apr 25 12:43:45 2018 ] 	Mean test loss of 1 batches: 0.236017644405365.
[ Wed Apr 25 12:43:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:43:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:43:45 2018 ] Training epoch: 2736
[ Wed Apr 25 12:43:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:43:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:43:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:49 2018 ] Training epoch: 2737
[ Wed Apr 25 12:43:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:53 2018 ] Training epoch: 2738
[ Wed Apr 25 12:43:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:43:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:43:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:43:57 2018 ] Training epoch: 2739
[ Wed Apr 25 12:44:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:01 2018 ] Training epoch: 2740
[ Wed Apr 25 12:44:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:44:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:44:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:05 2018 ] Eval epoch: 2740
[ Wed Apr 25 12:44:08 2018 ] 	Mean test loss of 1 batches: 0.22241954505443573.
[ Wed Apr 25 12:44:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:44:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:44:08 2018 ] Training epoch: 2741
[ Wed Apr 25 12:44:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:12 2018 ] Training epoch: 2742
[ Wed Apr 25 12:44:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:44:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:44:16 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:44:16 2018 ] Training epoch: 2743
[ Wed Apr 25 12:44:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:44:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:44:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:20 2018 ] Training epoch: 2744
[ Wed Apr 25 12:44:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:44:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:44:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:24 2018 ] Training epoch: 2745
[ Wed Apr 25 12:44:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:28 2018 ] Eval epoch: 2745
[ Wed Apr 25 12:44:31 2018 ] 	Mean test loss of 1 batches: 0.22667577862739563.
[ Wed Apr 25 12:44:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:44:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:44:31 2018 ] Training epoch: 2746
[ Wed Apr 25 12:44:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:35 2018 ] Training epoch: 2747
[ Wed Apr 25 12:44:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:39 2018 ] Training epoch: 2748
[ Wed Apr 25 12:44:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:44:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:44:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:43 2018 ] Training epoch: 2749
[ Wed Apr 25 12:44:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:44:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:44:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:47 2018 ] Training epoch: 2750
[ Wed Apr 25 12:44:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:44:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:44:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:51 2018 ] Eval epoch: 2750
[ Wed Apr 25 12:44:54 2018 ] 	Mean test loss of 1 batches: 0.23283135890960693.
[ Wed Apr 25 12:44:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:44:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:44:54 2018 ] Training epoch: 2751
[ Wed Apr 25 12:44:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:44:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:44:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:44:58 2018 ] Training epoch: 2752
[ Wed Apr 25 12:45:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:45:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:45:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:02 2018 ] Training epoch: 2753
[ Wed Apr 25 12:45:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:45:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:45:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:06 2018 ] Training epoch: 2754
[ Wed Apr 25 12:45:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:45:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:45:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:10 2018 ] Training epoch: 2755
[ Wed Apr 25 12:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:45:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:14 2018 ] Eval epoch: 2755
[ Wed Apr 25 12:45:17 2018 ] 	Mean test loss of 1 batches: 0.22441861033439636.
[ Wed Apr 25 12:45:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:45:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:45:17 2018 ] Training epoch: 2756
[ Wed Apr 25 12:45:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:45:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:45:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:21 2018 ] Training epoch: 2757
[ Wed Apr 25 12:45:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:45:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:45:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:25 2018 ] Training epoch: 2758
[ Wed Apr 25 12:45:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:45:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:45:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:29 2018 ] Training epoch: 2759
[ Wed Apr 25 12:45:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:45:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:45:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:33 2018 ] Training epoch: 2760
[ Wed Apr 25 12:45:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:45:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:45:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:37 2018 ] Eval epoch: 2760
[ Wed Apr 25 12:45:40 2018 ] 	Mean test loss of 1 batches: 0.21641139686107635.
[ Wed Apr 25 12:45:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:45:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:45:40 2018 ] Training epoch: 2761
[ Wed Apr 25 12:45:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:45:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:45:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:44 2018 ] Training epoch: 2762
[ Wed Apr 25 12:45:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:45:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:45:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:45:48 2018 ] Training epoch: 2763
[ Wed Apr 25 12:45:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:45:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:45:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:45:52 2018 ] Training epoch: 2764
[ Wed Apr 25 12:45:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:45:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:45:56 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:45:56 2018 ] Training epoch: 2765
[ Wed Apr 25 12:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:46:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:46:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:00 2018 ] Eval epoch: 2765
[ Wed Apr 25 12:46:03 2018 ] 	Mean test loss of 1 batches: 0.2299201637506485.
[ Wed Apr 25 12:46:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:46:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:46:03 2018 ] Training epoch: 2766
[ Wed Apr 25 12:46:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:46:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:46:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:07 2018 ] Training epoch: 2767
[ Wed Apr 25 12:46:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:46:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:46:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:11 2018 ] Training epoch: 2768
[ Wed Apr 25 12:46:15 2018 ] 	Batch(0/1) done. Loss: 0.0023  lr:0.010000
[ Wed Apr 25 12:46:15 2018 ] 	Mean training loss: 0.0023.
[ Wed Apr 25 12:46:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:15 2018 ] Training epoch: 2769
[ Wed Apr 25 12:46:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:46:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:46:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:19 2018 ] Training epoch: 2770
[ Wed Apr 25 12:46:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:46:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:46:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:23 2018 ] Eval epoch: 2770
[ Wed Apr 25 12:46:26 2018 ] 	Mean test loss of 1 batches: 0.22767165303230286.
[ Wed Apr 25 12:46:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:46:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:46:26 2018 ] Training epoch: 2771
[ Wed Apr 25 12:46:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:46:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:46:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:30 2018 ] Training epoch: 2772
[ Wed Apr 25 12:46:34 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:46:34 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:46:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:34 2018 ] Training epoch: 2773
[ Wed Apr 25 12:46:38 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:46:38 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:46:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:38 2018 ] Training epoch: 2774
[ Wed Apr 25 12:46:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:46:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:46:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:42 2018 ] Training epoch: 2775
[ Wed Apr 25 12:46:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:46:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:46:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:46 2018 ] Eval epoch: 2775
[ Wed Apr 25 12:46:49 2018 ] 	Mean test loss of 1 batches: 0.23522335290908813.
[ Wed Apr 25 12:46:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:46:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:46:49 2018 ] Training epoch: 2776
[ Wed Apr 25 12:46:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:46:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:46:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:53 2018 ] Training epoch: 2777
[ Wed Apr 25 12:46:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:46:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:46:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:46:57 2018 ] Training epoch: 2778
[ Wed Apr 25 12:47:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:47:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:47:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:47:01 2018 ] Training epoch: 2779
[ Wed Apr 25 12:47:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:47:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:47:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:05 2018 ] Training epoch: 2780
[ Wed Apr 25 12:47:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:47:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:47:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:09 2018 ] Eval epoch: 2780
[ Wed Apr 25 12:47:12 2018 ] 	Mean test loss of 1 batches: 0.2206568419933319.
[ Wed Apr 25 12:47:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:47:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:47:12 2018 ] Training epoch: 2781
[ Wed Apr 25 12:47:16 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:47:16 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:47:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:16 2018 ] Training epoch: 2782
[ Wed Apr 25 12:47:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:47:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:47:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:20 2018 ] Training epoch: 2783
[ Wed Apr 25 12:47:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:47:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:47:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:24 2018 ] Training epoch: 2784
[ Wed Apr 25 12:47:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:47:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:47:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:28 2018 ] Training epoch: 2785
[ Wed Apr 25 12:47:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:47:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:47:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:32 2018 ] Eval epoch: 2785
[ Wed Apr 25 12:47:35 2018 ] 	Mean test loss of 1 batches: 0.22666813433170319.
[ Wed Apr 25 12:47:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:47:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:47:35 2018 ] Training epoch: 2786
[ Wed Apr 25 12:47:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:47:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:47:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:39 2018 ] Training epoch: 2787
[ Wed Apr 25 12:47:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:47:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:47:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:47:43 2018 ] Training epoch: 2788
[ Wed Apr 25 12:47:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:47:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:47:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:47 2018 ] Training epoch: 2789
[ Wed Apr 25 12:47:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:47:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:47:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:51 2018 ] Training epoch: 2790
[ Wed Apr 25 12:47:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:47:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:47:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:47:55 2018 ] Eval epoch: 2790
[ Wed Apr 25 12:47:58 2018 ] 	Mean test loss of 1 batches: 0.23200219869613647.
[ Wed Apr 25 12:47:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:47:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:47:58 2018 ] Training epoch: 2791
[ Wed Apr 25 12:48:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:02 2018 ] Training epoch: 2792
[ Wed Apr 25 12:48:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:48:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:48:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:06 2018 ] Training epoch: 2793
[ Wed Apr 25 12:48:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:10 2018 ] Training epoch: 2794
[ Wed Apr 25 12:48:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:14 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:48:14 2018 ] Training epoch: 2795
[ Wed Apr 25 12:48:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:18 2018 ] Eval epoch: 2795
[ Wed Apr 25 12:48:21 2018 ] 	Mean test loss of 1 batches: 0.22943055629730225.
[ Wed Apr 25 12:48:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:48:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:48:21 2018 ] Training epoch: 2796
[ Wed Apr 25 12:48:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:25 2018 ] Training epoch: 2797
[ Wed Apr 25 12:48:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:48:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:48:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:29 2018 ] Training epoch: 2798
[ Wed Apr 25 12:48:33 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:48:33 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:48:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:33 2018 ] Training epoch: 2799
[ Wed Apr 25 12:48:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:37 2018 ] Training epoch: 2800
[ Wed Apr 25 12:48:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:48:42 2018 ] Eval epoch: 2800
[ Wed Apr 25 12:48:45 2018 ] 	Mean test loss of 1 batches: 0.22004181146621704.
[ Wed Apr 25 12:48:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:48:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:48:45 2018 ] Training epoch: 2801
[ Wed Apr 25 12:48:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:49 2018 ] Training epoch: 2802
[ Wed Apr 25 12:48:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:48:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:48:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:53 2018 ] Training epoch: 2803
[ Wed Apr 25 12:48:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:48:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:48:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:48:57 2018 ] Training epoch: 2804
[ Wed Apr 25 12:49:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:01 2018 ] Training epoch: 2805
[ Wed Apr 25 12:49:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:49:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:49:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:05 2018 ] Eval epoch: 2805
[ Wed Apr 25 12:49:08 2018 ] 	Mean test loss of 1 batches: 0.23781967163085938.
[ Wed Apr 25 12:49:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:49:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:49:08 2018 ] Training epoch: 2806
[ Wed Apr 25 12:49:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:12 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:49:12 2018 ] Training epoch: 2807
[ Wed Apr 25 12:49:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:16 2018 ] Training epoch: 2808
[ Wed Apr 25 12:49:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:20 2018 ] Training epoch: 2809
[ Wed Apr 25 12:49:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:24 2018 ] Training epoch: 2810
[ Wed Apr 25 12:49:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:49:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:49:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:28 2018 ] Eval epoch: 2810
[ Wed Apr 25 12:49:31 2018 ] 	Mean test loss of 1 batches: 0.2343747317790985.
[ Wed Apr 25 12:49:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:49:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:49:31 2018 ] Training epoch: 2811
[ Wed Apr 25 12:49:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:49:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:49:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:35 2018 ] Training epoch: 2812
[ Wed Apr 25 12:49:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:39 2018 ] Training epoch: 2813
[ Wed Apr 25 12:49:43 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:49:43 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:49:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:43 2018 ] Training epoch: 2814
[ Wed Apr 25 12:49:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:49:47 2018 ] Training epoch: 2815
[ Wed Apr 25 12:49:51 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:49:51 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:49:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:51 2018 ] Eval epoch: 2815
[ Wed Apr 25 12:49:54 2018 ] 	Mean test loss of 1 batches: 0.23509937524795532.
[ Wed Apr 25 12:49:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:49:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:49:54 2018 ] Training epoch: 2816
[ Wed Apr 25 12:49:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:49:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:49:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:49:58 2018 ] Training epoch: 2817
[ Wed Apr 25 12:50:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:50:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:50:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:02 2018 ] Training epoch: 2818
[ Wed Apr 25 12:50:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:50:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:50:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:06 2018 ] Training epoch: 2819
[ Wed Apr 25 12:50:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:50:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:50:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:10 2018 ] Training epoch: 2820
[ Wed Apr 25 12:50:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:50:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:50:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:14 2018 ] Eval epoch: 2820
[ Wed Apr 25 12:50:17 2018 ] 	Mean test loss of 1 batches: 0.2331119328737259.
[ Wed Apr 25 12:50:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:50:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:50:17 2018 ] Training epoch: 2821
[ Wed Apr 25 12:50:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:50:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:50:21 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 12:50:21 2018 ] Training epoch: 2822
[ Wed Apr 25 12:50:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:50:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:50:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:26 2018 ] Training epoch: 2823
[ Wed Apr 25 12:50:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:50:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:50:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:30 2018 ] Training epoch: 2824
[ Wed Apr 25 12:50:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:50:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:50:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:34 2018 ] Training epoch: 2825
[ Wed Apr 25 12:50:38 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:50:38 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:50:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:38 2018 ] Eval epoch: 2825
[ Wed Apr 25 12:50:41 2018 ] 	Mean test loss of 1 batches: 0.2351314276456833.
[ Wed Apr 25 12:50:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:50:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:50:41 2018 ] Training epoch: 2826
[ Wed Apr 25 12:50:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:50:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:50:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:45 2018 ] Training epoch: 2827
[ Wed Apr 25 12:50:49 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:50:49 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:50:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:50:49 2018 ] Training epoch: 2828
[ Wed Apr 25 12:50:53 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:50:53 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:50:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:50:53 2018 ] Training epoch: 2829
[ Wed Apr 25 12:50:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:50:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:50:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:50:57 2018 ] Training epoch: 2830
[ Wed Apr 25 12:51:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:01 2018 ] Eval epoch: 2830
[ Wed Apr 25 12:51:04 2018 ] 	Mean test loss of 1 batches: 0.23463135957717896.
[ Wed Apr 25 12:51:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:51:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:51:04 2018 ] Training epoch: 2831
[ Wed Apr 25 12:51:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:08 2018 ] Training epoch: 2832
[ Wed Apr 25 12:51:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:12 2018 ] Training epoch: 2833
[ Wed Apr 25 12:51:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:16 2018 ] Training epoch: 2834
[ Wed Apr 25 12:51:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:51:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:51:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:20 2018 ] Training epoch: 2835
[ Wed Apr 25 12:51:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:51:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:51:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:24 2018 ] Eval epoch: 2835
[ Wed Apr 25 12:51:27 2018 ] 	Mean test loss of 1 batches: 0.24012821912765503.
[ Wed Apr 25 12:51:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:51:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:51:27 2018 ] Training epoch: 2836
[ Wed Apr 25 12:51:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:31 2018 ] Training epoch: 2837
[ Wed Apr 25 12:51:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:35 2018 ] Training epoch: 2838
[ Wed Apr 25 12:51:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:39 2018 ] Training epoch: 2839
[ Wed Apr 25 12:51:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:51:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:51:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:43 2018 ] Training epoch: 2840
[ Wed Apr 25 12:51:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:51:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:51:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:47 2018 ] Eval epoch: 2840
[ Wed Apr 25 12:51:50 2018 ] 	Mean test loss of 1 batches: 0.23179662227630615.
[ Wed Apr 25 12:51:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:51:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:51:50 2018 ] Training epoch: 2841
[ Wed Apr 25 12:51:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:51:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:51:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:54 2018 ] Training epoch: 2842
[ Wed Apr 25 12:51:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:51:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:51:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:51:58 2018 ] Training epoch: 2843
[ Wed Apr 25 12:52:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:02 2018 ] Training epoch: 2844
[ Wed Apr 25 12:52:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:52:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:52:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:06 2018 ] Training epoch: 2845
[ Wed Apr 25 12:52:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:10 2018 ] Eval epoch: 2845
[ Wed Apr 25 12:52:13 2018 ] 	Mean test loss of 1 batches: 0.22346928715705872.
[ Wed Apr 25 12:52:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:52:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:52:13 2018 ] Training epoch: 2846
[ Wed Apr 25 12:52:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:17 2018 ] Training epoch: 2847
[ Wed Apr 25 12:52:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:52:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:52:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:21 2018 ] Training epoch: 2848
[ Wed Apr 25 12:52:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:52:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:52:25 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:52:25 2018 ] Training epoch: 2849
[ Wed Apr 25 12:52:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:52:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:52:30 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:52:30 2018 ] Training epoch: 2850
[ Wed Apr 25 12:52:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:34 2018 ] Eval epoch: 2850
[ Wed Apr 25 12:52:37 2018 ] 	Mean test loss of 1 batches: 0.22921419143676758.
[ Wed Apr 25 12:52:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:52:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:52:37 2018 ] Training epoch: 2851
[ Wed Apr 25 12:52:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:52:41 2018 ] Training epoch: 2852
[ Wed Apr 25 12:52:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:45 2018 ] Training epoch: 2853
[ Wed Apr 25 12:52:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:52:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:52:49 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:52:49 2018 ] Training epoch: 2854
[ Wed Apr 25 12:52:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:52:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:52:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:53 2018 ] Training epoch: 2855
[ Wed Apr 25 12:52:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:52:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:52:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:52:57 2018 ] Eval epoch: 2855
[ Wed Apr 25 12:53:00 2018 ] 	Mean test loss of 1 batches: 0.23404580354690552.
[ Wed Apr 25 12:53:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:53:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:53:00 2018 ] Training epoch: 2856
[ Wed Apr 25 12:53:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:53:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:53:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:04 2018 ] Training epoch: 2857
[ Wed Apr 25 12:53:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:53:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:53:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:08 2018 ] Training epoch: 2858
[ Wed Apr 25 12:53:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:53:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:53:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:12 2018 ] Training epoch: 2859
[ Wed Apr 25 12:53:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:53:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:53:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:16 2018 ] Training epoch: 2860
[ Wed Apr 25 12:53:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:21 2018 ] Eval epoch: 2860
[ Wed Apr 25 12:53:24 2018 ] 	Mean test loss of 1 batches: 0.2311098724603653.
[ Wed Apr 25 12:53:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:53:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:53:24 2018 ] Training epoch: 2861
[ Wed Apr 25 12:53:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:28 2018 ] Training epoch: 2862
[ Wed Apr 25 12:53:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:32 2018 ] Training epoch: 2863
[ Wed Apr 25 12:53:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:36 2018 ] Training epoch: 2864
[ Wed Apr 25 12:53:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:40 2018 ] Training epoch: 2865
[ Wed Apr 25 12:53:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:53:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:53:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:44 2018 ] Eval epoch: 2865
[ Wed Apr 25 12:53:47 2018 ] 	Mean test loss of 1 batches: 0.22989118099212646.
[ Wed Apr 25 12:53:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:53:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:53:47 2018 ] Training epoch: 2866
[ Wed Apr 25 12:53:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:53:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:53:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:51 2018 ] Training epoch: 2867
[ Wed Apr 25 12:53:55 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:53:55 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:53:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:55 2018 ] Training epoch: 2868
[ Wed Apr 25 12:53:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:53:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:53:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:53:59 2018 ] Training epoch: 2869
[ Wed Apr 25 12:54:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:54:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:54:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:03 2018 ] Training epoch: 2870
[ Wed Apr 25 12:54:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:54:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:54:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:07 2018 ] Eval epoch: 2870
[ Wed Apr 25 12:54:10 2018 ] 	Mean test loss of 1 batches: 0.23688246309757233.
[ Wed Apr 25 12:54:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:54:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:54:10 2018 ] Training epoch: 2871
[ Wed Apr 25 12:54:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:54:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:54:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:14 2018 ] Training epoch: 2872
[ Wed Apr 25 12:54:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:54:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:54:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:18 2018 ] Training epoch: 2873
[ Wed Apr 25 12:54:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:54:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:54:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:54:22 2018 ] Training epoch: 2874
[ Wed Apr 25 12:54:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:54:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:54:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:26 2018 ] Training epoch: 2875
[ Wed Apr 25 12:54:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:54:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:54:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:30 2018 ] Eval epoch: 2875
[ Wed Apr 25 12:54:33 2018 ] 	Mean test loss of 1 batches: 0.23633958399295807.
[ Wed Apr 25 12:54:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:54:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:54:33 2018 ] Training epoch: 2876
[ Wed Apr 25 12:54:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:54:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:54:37 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:54:37 2018 ] Training epoch: 2877
[ Wed Apr 25 12:54:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:54:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:54:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:41 2018 ] Training epoch: 2878
[ Wed Apr 25 12:54:45 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:54:45 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:54:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:45 2018 ] Training epoch: 2879
[ Wed Apr 25 12:54:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:54:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:54:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:49 2018 ] Training epoch: 2880
[ Wed Apr 25 12:54:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:54:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:54:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:54:53 2018 ] Eval epoch: 2880
[ Wed Apr 25 12:54:56 2018 ] 	Mean test loss of 1 batches: 0.22781549394130707.
[ Wed Apr 25 12:54:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:54:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:54:56 2018 ] Training epoch: 2881
[ Wed Apr 25 12:55:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:00 2018 ] Training epoch: 2882
[ Wed Apr 25 12:55:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:55:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:55:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:04 2018 ] Training epoch: 2883
[ Wed Apr 25 12:55:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:55:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:55:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:08 2018 ] Training epoch: 2884
[ Wed Apr 25 12:55:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:55:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:55:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:12 2018 ] Training epoch: 2885
[ Wed Apr 25 12:55:16 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 12:55:16 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 12:55:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:16 2018 ] Eval epoch: 2885
[ Wed Apr 25 12:55:19 2018 ] 	Mean test loss of 1 batches: 0.2342999428510666.
[ Wed Apr 25 12:55:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:55:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:55:19 2018 ] Training epoch: 2886
[ Wed Apr 25 12:55:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:55:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:55:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:23 2018 ] Training epoch: 2887
[ Wed Apr 25 12:55:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:55:27 2018 ] Training epoch: 2888
[ Wed Apr 25 12:55:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:32 2018 ] Training epoch: 2889
[ Wed Apr 25 12:55:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:36 2018 ] Training epoch: 2890
[ Wed Apr 25 12:55:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:55:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:55:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:40 2018 ] Eval epoch: 2890
[ Wed Apr 25 12:55:43 2018 ] 	Mean test loss of 1 batches: 0.2300158143043518.
[ Wed Apr 25 12:55:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:55:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:55:43 2018 ] Training epoch: 2891
[ Wed Apr 25 12:55:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:55:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:55:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:47 2018 ] Training epoch: 2892
[ Wed Apr 25 12:55:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:51 2018 ] Training epoch: 2893
[ Wed Apr 25 12:55:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:55:55 2018 ] Training epoch: 2894
[ Wed Apr 25 12:55:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:55:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:55:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:55:59 2018 ] Training epoch: 2895
[ Wed Apr 25 12:56:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:03 2018 ] Eval epoch: 2895
[ Wed Apr 25 12:56:06 2018 ] 	Mean test loss of 1 batches: 0.23664148151874542.
[ Wed Apr 25 12:56:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:56:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:56:06 2018 ] Training epoch: 2896
[ Wed Apr 25 12:56:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:56:10 2018 ] Training epoch: 2897
[ Wed Apr 25 12:56:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:56:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:56:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:14 2018 ] Training epoch: 2898
[ Wed Apr 25 12:56:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:18 2018 ] Training epoch: 2899
[ Wed Apr 25 12:56:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:56:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:56:22 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 12:56:22 2018 ] Training epoch: 2900
[ Wed Apr 25 12:56:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:56:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:56:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:26 2018 ] Eval epoch: 2900
[ Wed Apr 25 12:56:29 2018 ] 	Mean test loss of 1 batches: 0.21960054337978363.
[ Wed Apr 25 12:56:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:56:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:56:29 2018 ] Training epoch: 2901
[ Wed Apr 25 12:56:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:56:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:56:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:33 2018 ] Training epoch: 2902
[ Wed Apr 25 12:56:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:37 2018 ] Training epoch: 2903
[ Wed Apr 25 12:56:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:56:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:56:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:41 2018 ] Training epoch: 2904
[ Wed Apr 25 12:56:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:56:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:56:45 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 12:56:45 2018 ] Training epoch: 2905
[ Wed Apr 25 12:56:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:49 2018 ] Eval epoch: 2905
[ Wed Apr 25 12:56:52 2018 ] 	Mean test loss of 1 batches: 0.21175698935985565.
[ Wed Apr 25 12:56:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:56:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:56:52 2018 ] Training epoch: 2906
[ Wed Apr 25 12:56:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:56:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:56:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:56:56 2018 ] Training epoch: 2907
[ Wed Apr 25 12:57:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:57:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:57:00 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:57:00 2018 ] Training epoch: 2908
[ Wed Apr 25 12:57:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:57:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:57:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:04 2018 ] Training epoch: 2909
[ Wed Apr 25 12:57:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:57:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:57:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:08 2018 ] Training epoch: 2910
[ Wed Apr 25 12:57:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:57:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:57:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:12 2018 ] Eval epoch: 2910
[ Wed Apr 25 12:57:15 2018 ] 	Mean test loss of 1 batches: 0.21214105188846588.
[ Wed Apr 25 12:57:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:57:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:57:15 2018 ] Training epoch: 2911
[ Wed Apr 25 12:57:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:57:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:57:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:19 2018 ] Training epoch: 2912
[ Wed Apr 25 12:57:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:57:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:57:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:23 2018 ] Training epoch: 2913
[ Wed Apr 25 12:57:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:57:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:57:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:27 2018 ] Training epoch: 2914
[ Wed Apr 25 12:57:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:57:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:57:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:57:31 2018 ] Training epoch: 2915
[ Wed Apr 25 12:57:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:57:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:57:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:35 2018 ] Eval epoch: 2915
[ Wed Apr 25 12:57:38 2018 ] 	Mean test loss of 1 batches: 0.21805980801582336.
[ Wed Apr 25 12:57:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:57:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:57:38 2018 ] Training epoch: 2916
[ Wed Apr 25 12:57:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:57:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:57:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:42 2018 ] Training epoch: 2917
[ Wed Apr 25 12:57:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:57:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:57:46 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 12:57:46 2018 ] Training epoch: 2918
[ Wed Apr 25 12:57:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:57:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:57:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:50 2018 ] Training epoch: 2919
[ Wed Apr 25 12:57:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:57:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:57:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:54 2018 ] Training epoch: 2920
[ Wed Apr 25 12:57:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:57:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:57:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:57:58 2018 ] Eval epoch: 2920
[ Wed Apr 25 12:58:01 2018 ] 	Mean test loss of 1 batches: 0.22123076021671295.
[ Wed Apr 25 12:58:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:58:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:58:01 2018 ] Training epoch: 2921
[ Wed Apr 25 12:58:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.010000
[ Wed Apr 25 12:58:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 12:58:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:05 2018 ] Training epoch: 2922
[ Wed Apr 25 12:58:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:09 2018 ] Training epoch: 2923
[ Wed Apr 25 12:58:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:58:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:58:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:13 2018 ] Training epoch: 2924
[ Wed Apr 25 12:58:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:17 2018 ] Training epoch: 2925
[ Wed Apr 25 12:58:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:21 2018 ] Eval epoch: 2925
[ Wed Apr 25 12:58:24 2018 ] 	Mean test loss of 1 batches: 0.21450021862983704.
[ Wed Apr 25 12:58:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:58:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:58:24 2018 ] Training epoch: 2926
[ Wed Apr 25 12:58:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:28 2018 ] Training epoch: 2927
[ Wed Apr 25 12:58:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:32 2018 ] Training epoch: 2928
[ Wed Apr 25 12:58:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:36 2018 ] Training epoch: 2929
[ Wed Apr 25 12:58:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:58:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:58:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:40 2018 ] Training epoch: 2930
[ Wed Apr 25 12:58:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:58:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:58:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:44 2018 ] Eval epoch: 2930
[ Wed Apr 25 12:58:47 2018 ] 	Mean test loss of 1 batches: 0.207351952791214.
[ Wed Apr 25 12:58:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:58:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:58:47 2018 ] Training epoch: 2931
[ Wed Apr 25 12:58:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:58:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:58:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:51 2018 ] Training epoch: 2932
[ Wed Apr 25 12:58:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:58:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:58:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:55 2018 ] Training epoch: 2933
[ Wed Apr 25 12:58:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:58:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:58:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:58:59 2018 ] Training epoch: 2934
[ Wed Apr 25 12:59:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:59:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:59:03 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:59:03 2018 ] Training epoch: 2935
[ Wed Apr 25 12:59:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:59:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:59:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:07 2018 ] Eval epoch: 2935
[ Wed Apr 25 12:59:10 2018 ] 	Mean test loss of 1 batches: 0.21853682398796082.
[ Wed Apr 25 12:59:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:59:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:59:10 2018 ] Training epoch: 2936
[ Wed Apr 25 12:59:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:59:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:59:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:14 2018 ] Training epoch: 2937
[ Wed Apr 25 12:59:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:59:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:59:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:18 2018 ] Training epoch: 2938
[ Wed Apr 25 12:59:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:59:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:59:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:22 2018 ] Training epoch: 2939
[ Wed Apr 25 12:59:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:59:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:59:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:59:26 2018 ] Training epoch: 2940
[ Wed Apr 25 12:59:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 12:59:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 12:59:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:30 2018 ] Eval epoch: 2940
[ Wed Apr 25 12:59:33 2018 ] 	Mean test loss of 1 batches: 0.23013676702976227.
[ Wed Apr 25 12:59:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:59:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:59:33 2018 ] Training epoch: 2941
[ Wed Apr 25 12:59:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:59:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:59:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:37 2018 ] Training epoch: 2942
[ Wed Apr 25 12:59:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:59:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:59:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:41 2018 ] Training epoch: 2943
[ Wed Apr 25 12:59:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:59:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:59:45 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 12:59:45 2018 ] Training epoch: 2944
[ Wed Apr 25 12:59:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 12:59:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 12:59:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:50 2018 ] Training epoch: 2945
[ Wed Apr 25 12:59:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 12:59:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 12:59:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 12:59:54 2018 ] Eval epoch: 2945
[ Wed Apr 25 12:59:57 2018 ] 	Mean test loss of 1 batches: 0.21819037199020386.
[ Wed Apr 25 12:59:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 12:59:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 12:59:57 2018 ] Training epoch: 2946
[ Wed Apr 25 13:00:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:00:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:00:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:01 2018 ] Training epoch: 2947
[ Wed Apr 25 13:00:05 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 13:00:05 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:00:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:05 2018 ] Training epoch: 2948
[ Wed Apr 25 13:00:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:09 2018 ] Training epoch: 2949
[ Wed Apr 25 13:00:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:13 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:00:13 2018 ] Training epoch: 2950
[ Wed Apr 25 13:00:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:17 2018 ] Eval epoch: 2950
[ Wed Apr 25 13:00:20 2018 ] 	Mean test loss of 1 batches: 0.21334896981716156.
[ Wed Apr 25 13:00:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:00:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:00:20 2018 ] Training epoch: 2951
[ Wed Apr 25 13:00:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:00:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:00:25 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:00:25 2018 ] Training epoch: 2952
[ Wed Apr 25 13:00:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:29 2018 ] Training epoch: 2953
[ Wed Apr 25 13:00:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:00:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:00:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:33 2018 ] Training epoch: 2954
[ Wed Apr 25 13:00:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:37 2018 ] Training epoch: 2955
[ Wed Apr 25 13:00:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:00:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:00:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:41 2018 ] Eval epoch: 2955
[ Wed Apr 25 13:00:44 2018 ] 	Mean test loss of 1 batches: 0.2201623022556305.
[ Wed Apr 25 13:00:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:00:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:00:44 2018 ] Training epoch: 2956
[ Wed Apr 25 13:00:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:00:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:00:48 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:00:48 2018 ] Training epoch: 2957
[ Wed Apr 25 13:00:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:00:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:00:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:00:52 2018 ] Training epoch: 2958
[ Wed Apr 25 13:00:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:00:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:00:56 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:00:56 2018 ] Training epoch: 2959
[ Wed Apr 25 13:01:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:01 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:01:01 2018 ] Training epoch: 2960
[ Wed Apr 25 13:01:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:01:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:01:05 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:01:05 2018 ] Eval epoch: 2960
[ Wed Apr 25 13:01:08 2018 ] 	Mean test loss of 1 batches: 0.21482041478157043.
[ Wed Apr 25 13:01:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:01:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:01:08 2018 ] Training epoch: 2961
[ Wed Apr 25 13:01:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:01:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:01:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:12 2018 ] Training epoch: 2962
[ Wed Apr 25 13:01:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:01:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:01:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:16 2018 ] Training epoch: 2963
[ Wed Apr 25 13:01:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:20 2018 ] Training epoch: 2964
[ Wed Apr 25 13:01:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:24 2018 ] Training epoch: 2965
[ Wed Apr 25 13:01:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:01:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:01:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:28 2018 ] Eval epoch: 2965
[ Wed Apr 25 13:01:31 2018 ] 	Mean test loss of 1 batches: 0.2242916226387024.
[ Wed Apr 25 13:01:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:01:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:01:31 2018 ] Training epoch: 2966
[ Wed Apr 25 13:01:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:35 2018 ] Training epoch: 2967
[ Wed Apr 25 13:01:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:01:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:01:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:39 2018 ] Training epoch: 2968
[ Wed Apr 25 13:01:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:43 2018 ] Training epoch: 2969
[ Wed Apr 25 13:01:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:01:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:01:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:47 2018 ] Training epoch: 2970
[ Wed Apr 25 13:01:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:01:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:01:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:51 2018 ] Eval epoch: 2970
[ Wed Apr 25 13:01:54 2018 ] 	Mean test loss of 1 batches: 0.2294866442680359.
[ Wed Apr 25 13:01:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:01:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:01:54 2018 ] Training epoch: 2971
[ Wed Apr 25 13:01:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:01:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:01:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:01:58 2018 ] Training epoch: 2972
[ Wed Apr 25 13:02:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:02 2018 ] Training epoch: 2973
[ Wed Apr 25 13:02:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:06 2018 ] Training epoch: 2974
[ Wed Apr 25 13:02:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:11 2018 ] Training epoch: 2975
[ Wed Apr 25 13:02:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:02:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:02:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:15 2018 ] Eval epoch: 2975
[ Wed Apr 25 13:02:18 2018 ] 	Mean test loss of 1 batches: 0.2148400992155075.
[ Wed Apr 25 13:02:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:02:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:02:18 2018 ] Training epoch: 2976
[ Wed Apr 25 13:02:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:22 2018 ] Training epoch: 2977
[ Wed Apr 25 13:02:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:02:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:02:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:26 2018 ] Training epoch: 2978
[ Wed Apr 25 13:02:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:02:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:02:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:30 2018 ] Training epoch: 2979
[ Wed Apr 25 13:02:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:34 2018 ] Training epoch: 2980
[ Wed Apr 25 13:02:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:02:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:02:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:38 2018 ] Eval epoch: 2980
[ Wed Apr 25 13:02:41 2018 ] 	Mean test loss of 1 batches: 0.21525093913078308.
[ Wed Apr 25 13:02:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:02:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:02:41 2018 ] Training epoch: 2981
[ Wed Apr 25 13:02:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:02:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:02:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:45 2018 ] Training epoch: 2982
[ Wed Apr 25 13:02:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:02:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:02:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:49 2018 ] Training epoch: 2983
[ Wed Apr 25 13:02:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:02:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:02:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:02:53 2018 ] Training epoch: 2984
[ Wed Apr 25 13:02:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:02:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:02:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:02:57 2018 ] Training epoch: 2985
[ Wed Apr 25 13:03:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:03:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:03:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:01 2018 ] Eval epoch: 2985
[ Wed Apr 25 13:03:04 2018 ] 	Mean test loss of 1 batches: 0.20789124071598053.
[ Wed Apr 25 13:03:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:03:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:03:04 2018 ] Training epoch: 2986
[ Wed Apr 25 13:03:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:03:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:03:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:08 2018 ] Training epoch: 2987
[ Wed Apr 25 13:03:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:03:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:03:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:12 2018 ] Training epoch: 2988
[ Wed Apr 25 13:03:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:03:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:03:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:16 2018 ] Training epoch: 2989
[ Wed Apr 25 13:03:20 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.010000
[ Wed Apr 25 13:03:20 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 13:03:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:20 2018 ] Training epoch: 2990
[ Wed Apr 25 13:03:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:03:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:03:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:24 2018 ] Eval epoch: 2990
[ Wed Apr 25 13:03:27 2018 ] 	Mean test loss of 1 batches: 0.21157656610012054.
[ Wed Apr 25 13:03:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:03:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:03:27 2018 ] Training epoch: 2991
[ Wed Apr 25 13:03:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:03:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:03:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:31 2018 ] Training epoch: 2992
[ Wed Apr 25 13:03:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:03:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:03:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:35 2018 ] Training epoch: 2993
[ Wed Apr 25 13:03:39 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.010000
[ Wed Apr 25 13:03:39 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:03:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:39 2018 ] Training epoch: 2994
[ Wed Apr 25 13:03:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:03:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:03:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:43 2018 ] Training epoch: 2995
[ Wed Apr 25 13:03:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:03:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:03:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:47 2018 ] Eval epoch: 2995
[ Wed Apr 25 13:03:50 2018 ] 	Mean test loss of 1 batches: 0.22422026097774506.
[ Wed Apr 25 13:03:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:03:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:03:50 2018 ] Training epoch: 2996
[ Wed Apr 25 13:03:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:03:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:03:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:54 2018 ] Training epoch: 2997
[ Wed Apr 25 13:03:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.010000
[ Wed Apr 25 13:03:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:03:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:03:58 2018 ] Training epoch: 2998
[ Wed Apr 25 13:04:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.010000
[ Wed Apr 25 13:04:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:04:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:02 2018 ] Training epoch: 2999
[ Wed Apr 25 13:04:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:04:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:04:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:06 2018 ] Training epoch: 3000
[ Wed Apr 25 13:04:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.010000
[ Wed Apr 25 13:04:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:04:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:10 2018 ] Eval epoch: 3000
[ Wed Apr 25 13:04:13 2018 ] 	Mean test loss of 1 batches: 0.2282344549894333.
[ Wed Apr 25 13:04:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:04:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:04:13 2018 ] Training epoch: 3001
[ Wed Apr 25 13:04:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:04:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:04:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:17 2018 ] Training epoch: 3002
[ Wed Apr 25 13:04:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:04:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:04:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:21 2018 ] Training epoch: 3003
[ Wed Apr 25 13:04:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:04:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:04:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:25 2018 ] Training epoch: 3004
[ Wed Apr 25 13:04:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:04:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:04:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:29 2018 ] Training epoch: 3005
[ Wed Apr 25 13:04:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:04:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:04:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:33 2018 ] Eval epoch: 3005
[ Wed Apr 25 13:04:36 2018 ] 	Mean test loss of 1 batches: 0.21349090337753296.
[ Wed Apr 25 13:04:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:04:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:04:36 2018 ] Training epoch: 3006
[ Wed Apr 25 13:04:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:04:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:04:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:40 2018 ] Training epoch: 3007
[ Wed Apr 25 13:04:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:04:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:04:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:44 2018 ] Training epoch: 3008
[ Wed Apr 25 13:04:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:04:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:04:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:48 2018 ] Training epoch: 3009
[ Wed Apr 25 13:04:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:04:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:04:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:52 2018 ] Training epoch: 3010
[ Wed Apr 25 13:04:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:04:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:04:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:04:56 2018 ] Eval epoch: 3010
[ Wed Apr 25 13:04:59 2018 ] 	Mean test loss of 1 batches: 0.2285420447587967.
[ Wed Apr 25 13:04:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:04:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:04:59 2018 ] Training epoch: 3011
[ Wed Apr 25 13:05:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:03 2018 ] Training epoch: 3012
[ Wed Apr 25 13:05:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:05:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:05:08 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:05:08 2018 ] Training epoch: 3013
[ Wed Apr 25 13:05:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:05:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:05:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:12 2018 ] Training epoch: 3014
[ Wed Apr 25 13:05:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:16 2018 ] Training epoch: 3015
[ Wed Apr 25 13:05:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:05:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:05:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:20 2018 ] Eval epoch: 3015
[ Wed Apr 25 13:05:23 2018 ] 	Mean test loss of 1 batches: 0.21373380720615387.
[ Wed Apr 25 13:05:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:05:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:05:23 2018 ] Training epoch: 3016
[ Wed Apr 25 13:05:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:05:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:05:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:27 2018 ] Training epoch: 3017
[ Wed Apr 25 13:05:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:31 2018 ] Training epoch: 3018
[ Wed Apr 25 13:05:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:35 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:05:35 2018 ] Training epoch: 3019
[ Wed Apr 25 13:05:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:39 2018 ] Training epoch: 3020
[ Wed Apr 25 13:05:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:05:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:05:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:43 2018 ] Eval epoch: 3020
[ Wed Apr 25 13:05:46 2018 ] 	Mean test loss of 1 batches: 0.21074330806732178.
[ Wed Apr 25 13:05:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:05:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:05:46 2018 ] Training epoch: 3021
[ Wed Apr 25 13:05:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:50 2018 ] Training epoch: 3022
[ Wed Apr 25 13:05:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:05:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:05:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:05:54 2018 ] Training epoch: 3023
[ Wed Apr 25 13:05:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:05:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:05:58 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:05:58 2018 ] Training epoch: 3024
[ Wed Apr 25 13:06:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:06:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:06:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:02 2018 ] Training epoch: 3025
[ Wed Apr 25 13:06:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:06:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:06:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:06 2018 ] Eval epoch: 3025
[ Wed Apr 25 13:06:09 2018 ] 	Mean test loss of 1 batches: 0.21779954433441162.
[ Wed Apr 25 13:06:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:06:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:06:09 2018 ] Training epoch: 3026
[ Wed Apr 25 13:06:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:13 2018 ] Training epoch: 3027
[ Wed Apr 25 13:06:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:17 2018 ] Training epoch: 3028
[ Wed Apr 25 13:06:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:06:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:06:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:21 2018 ] Training epoch: 3029
[ Wed Apr 25 13:06:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:25 2018 ] Training epoch: 3030
[ Wed Apr 25 13:06:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:06:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:06:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:29 2018 ] Eval epoch: 3030
[ Wed Apr 25 13:06:32 2018 ] 	Mean test loss of 1 batches: 0.2146892249584198.
[ Wed Apr 25 13:06:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:06:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:06:32 2018 ] Training epoch: 3031
[ Wed Apr 25 13:06:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:06:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:06:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:36 2018 ] Training epoch: 3032
[ Wed Apr 25 13:06:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:06:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:06:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:40 2018 ] Training epoch: 3033
[ Wed Apr 25 13:06:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:44 2018 ] Training epoch: 3034
[ Wed Apr 25 13:06:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:06:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:06:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:48 2018 ] Training epoch: 3035
[ Wed Apr 25 13:06:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:52 2018 ] Eval epoch: 3035
[ Wed Apr 25 13:06:55 2018 ] 	Mean test loss of 1 batches: 0.21439716219902039.
[ Wed Apr 25 13:06:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:06:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:06:55 2018 ] Training epoch: 3036
[ Wed Apr 25 13:06:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:06:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:06:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:06:59 2018 ] Training epoch: 3037
[ Wed Apr 25 13:07:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:03 2018 ] Training epoch: 3038
[ Wed Apr 25 13:07:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:07 2018 ] Training epoch: 3039
[ Wed Apr 25 13:07:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:07:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:07:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:11 2018 ] Training epoch: 3040
[ Wed Apr 25 13:07:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:15 2018 ] Eval epoch: 3040
[ Wed Apr 25 13:07:18 2018 ] 	Mean test loss of 1 batches: 0.21099135279655457.
[ Wed Apr 25 13:07:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:07:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:07:18 2018 ] Training epoch: 3041
[ Wed Apr 25 13:07:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:22 2018 ] Training epoch: 3042
[ Wed Apr 25 13:07:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:26 2018 ] Training epoch: 3043
[ Wed Apr 25 13:07:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:30 2018 ] Training epoch: 3044
[ Wed Apr 25 13:07:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:34 2018 ] Training epoch: 3045
[ Wed Apr 25 13:07:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:38 2018 ] Eval epoch: 3045
[ Wed Apr 25 13:07:41 2018 ] 	Mean test loss of 1 batches: 0.2146175652742386.
[ Wed Apr 25 13:07:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:07:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:07:41 2018 ] Training epoch: 3046
[ Wed Apr 25 13:07:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:45 2018 ] Training epoch: 3047
[ Wed Apr 25 13:07:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:49 2018 ] Training epoch: 3048
[ Wed Apr 25 13:07:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:07:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:07:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:07:53 2018 ] Training epoch: 3049
[ Wed Apr 25 13:07:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:07:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:07:57 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:07:57 2018 ] Training epoch: 3050
[ Wed Apr 25 13:08:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:01 2018 ] Eval epoch: 3050
[ Wed Apr 25 13:08:04 2018 ] 	Mean test loss of 1 batches: 0.21004199981689453.
[ Wed Apr 25 13:08:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:08:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:08:04 2018 ] Training epoch: 3051
[ Wed Apr 25 13:08:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:08:09 2018 ] Training epoch: 3052
[ Wed Apr 25 13:08:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:13 2018 ] Training epoch: 3053
[ Wed Apr 25 13:08:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:17 2018 ] Training epoch: 3054
[ Wed Apr 25 13:08:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:21 2018 ] Training epoch: 3055
[ Wed Apr 25 13:08:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:08:25 2018 ] Eval epoch: 3055
[ Wed Apr 25 13:08:28 2018 ] 	Mean test loss of 1 batches: 0.22320431470870972.
[ Wed Apr 25 13:08:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:08:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:08:28 2018 ] Training epoch: 3056
[ Wed Apr 25 13:08:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:32 2018 ] Training epoch: 3057
[ Wed Apr 25 13:08:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:36 2018 ] Training epoch: 3058
[ Wed Apr 25 13:08:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:40 2018 ] Training epoch: 3059
[ Wed Apr 25 13:08:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:44 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:08:44 2018 ] Training epoch: 3060
[ Wed Apr 25 13:08:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:08:48 2018 ] Eval epoch: 3060
[ Wed Apr 25 13:08:51 2018 ] 	Mean test loss of 1 batches: 0.2207779735326767.
[ Wed Apr 25 13:08:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:08:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:08:51 2018 ] Training epoch: 3061
[ Wed Apr 25 13:08:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:08:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:08:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:08:55 2018 ] Training epoch: 3062
[ Wed Apr 25 13:08:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:08:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:08:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:08:59 2018 ] Training epoch: 3063
[ Wed Apr 25 13:09:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:09:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:09:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:03 2018 ] Training epoch: 3064
[ Wed Apr 25 13:09:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:07 2018 ] Training epoch: 3065
[ Wed Apr 25 13:09:12 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:09:12 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:09:12 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:09:12 2018 ] Eval epoch: 3065
[ Wed Apr 25 13:09:14 2018 ] 	Mean test loss of 1 batches: 0.23183496296405792.
[ Wed Apr 25 13:09:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:09:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:09:14 2018 ] Training epoch: 3066
[ Wed Apr 25 13:09:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:18 2018 ] Training epoch: 3067
[ Wed Apr 25 13:09:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:22 2018 ] Training epoch: 3068
[ Wed Apr 25 13:09:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:26 2018 ] Training epoch: 3069
[ Wed Apr 25 13:09:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:30 2018 ] Training epoch: 3070
[ Wed Apr 25 13:09:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:09:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:09:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:35 2018 ] Eval epoch: 3070
[ Wed Apr 25 13:09:37 2018 ] 	Mean test loss of 1 batches: 0.2195506989955902.
[ Wed Apr 25 13:09:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:09:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:09:37 2018 ] Training epoch: 3071
[ Wed Apr 25 13:09:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:09:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:09:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:41 2018 ] Training epoch: 3072
[ Wed Apr 25 13:09:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:09:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:09:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:46 2018 ] Training epoch: 3073
[ Wed Apr 25 13:09:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:50 2018 ] Training epoch: 3074
[ Wed Apr 25 13:09:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:09:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:09:54 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:09:54 2018 ] Training epoch: 3075
[ Wed Apr 25 13:09:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:09:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:09:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:09:58 2018 ] Eval epoch: 3075
[ Wed Apr 25 13:10:01 2018 ] 	Mean test loss of 1 batches: 0.2152564972639084.
[ Wed Apr 25 13:10:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:10:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:10:01 2018 ] Training epoch: 3076
[ Wed Apr 25 13:10:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:10:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:10:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:05 2018 ] Training epoch: 3077
[ Wed Apr 25 13:10:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:10:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:10:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:09 2018 ] Training epoch: 3078
[ Wed Apr 25 13:10:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:10:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:10:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:13 2018 ] Training epoch: 3079
[ Wed Apr 25 13:10:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:10:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:10:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:17 2018 ] Training epoch: 3080
[ Wed Apr 25 13:10:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:10:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:10:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:10:21 2018 ] Eval epoch: 3080
[ Wed Apr 25 13:10:24 2018 ] 	Mean test loss of 1 batches: 0.21766340732574463.
[ Wed Apr 25 13:10:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:10:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:10:24 2018 ] Training epoch: 3081
[ Wed Apr 25 13:10:28 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:10:28 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:10:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:10:28 2018 ] Training epoch: 3082
[ Wed Apr 25 13:10:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:10:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:10:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:32 2018 ] Training epoch: 3083
[ Wed Apr 25 13:10:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:10:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:10:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:36 2018 ] Training epoch: 3084
[ Wed Apr 25 13:10:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:10:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:10:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:40 2018 ] Training epoch: 3085
[ Wed Apr 25 13:10:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:10:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:10:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:44 2018 ] Eval epoch: 3085
[ Wed Apr 25 13:10:47 2018 ] 	Mean test loss of 1 batches: 0.21734198927879333.
[ Wed Apr 25 13:10:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:10:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:10:47 2018 ] Training epoch: 3086
[ Wed Apr 25 13:10:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:10:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:10:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:51 2018 ] Training epoch: 3087
[ Wed Apr 25 13:10:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:10:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:10:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:55 2018 ] Training epoch: 3088
[ Wed Apr 25 13:10:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:10:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:10:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:10:59 2018 ] Training epoch: 3089
[ Wed Apr 25 13:11:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:03 2018 ] Training epoch: 3090
[ Wed Apr 25 13:11:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:11:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:11:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:07 2018 ] Eval epoch: 3090
[ Wed Apr 25 13:11:10 2018 ] 	Mean test loss of 1 batches: 0.21353760361671448.
[ Wed Apr 25 13:11:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:11:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:11:10 2018 ] Training epoch: 3091
[ Wed Apr 25 13:11:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:14 2018 ] Training epoch: 3092
[ Wed Apr 25 13:11:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:18 2018 ] Training epoch: 3093
[ Wed Apr 25 13:11:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:22 2018 ] Training epoch: 3094
[ Wed Apr 25 13:11:26 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.001000
[ Wed Apr 25 13:11:26 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 13:11:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:26 2018 ] Training epoch: 3095
[ Wed Apr 25 13:11:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:11:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:11:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:30 2018 ] Eval epoch: 3095
[ Wed Apr 25 13:11:33 2018 ] 	Mean test loss of 1 batches: 0.21499894559383392.
[ Wed Apr 25 13:11:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:11:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:11:33 2018 ] Training epoch: 3096
[ Wed Apr 25 13:11:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:37 2018 ] Training epoch: 3097
[ Wed Apr 25 13:11:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:11:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:11:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:41 2018 ] Training epoch: 3098
[ Wed Apr 25 13:11:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:45 2018 ] Training epoch: 3099
[ Wed Apr 25 13:11:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:11:49 2018 ] Training epoch: 3100
[ Wed Apr 25 13:11:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:11:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:11:53 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:11:53 2018 ] Eval epoch: 3100
[ Wed Apr 25 13:11:56 2018 ] 	Mean test loss of 1 batches: 0.21889135241508484.
[ Wed Apr 25 13:11:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:11:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:11:56 2018 ] Training epoch: 3101
[ Wed Apr 25 13:12:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:12:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:12:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:00 2018 ] Training epoch: 3102
[ Wed Apr 25 13:12:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:12:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:12:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:04 2018 ] Training epoch: 3103
[ Wed Apr 25 13:12:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:08 2018 ] Training epoch: 3104
[ Wed Apr 25 13:12:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:12 2018 ] Training epoch: 3105
[ Wed Apr 25 13:12:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:12:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:12:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:16 2018 ] Eval epoch: 3105
[ Wed Apr 25 13:12:19 2018 ] 	Mean test loss of 1 batches: 0.20381861925125122.
[ Wed Apr 25 13:12:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:12:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:12:19 2018 ] Training epoch: 3106
[ Wed Apr 25 13:12:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:23 2018 ] Training epoch: 3107
[ Wed Apr 25 13:12:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:12:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:12:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:12:27 2018 ] Training epoch: 3108
[ Wed Apr 25 13:12:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:32 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:12:32 2018 ] Training epoch: 3109
[ Wed Apr 25 13:12:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:12:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:12:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:36 2018 ] Training epoch: 3110
[ Wed Apr 25 13:12:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:40 2018 ] Eval epoch: 3110
[ Wed Apr 25 13:12:43 2018 ] 	Mean test loss of 1 batches: 0.2033248245716095.
[ Wed Apr 25 13:12:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:12:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:12:43 2018 ] Training epoch: 3111
[ Wed Apr 25 13:12:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:12:47 2018 ] Training epoch: 3112
[ Wed Apr 25 13:12:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:12:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:12:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:51 2018 ] Training epoch: 3113
[ Wed Apr 25 13:12:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:12:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:12:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:12:55 2018 ] Training epoch: 3114
[ Wed Apr 25 13:13:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:13:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:13:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:00 2018 ] Training epoch: 3115
[ Wed Apr 25 13:13:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:04 2018 ] Eval epoch: 3115
[ Wed Apr 25 13:13:07 2018 ] 	Mean test loss of 1 batches: 0.21664810180664062.
[ Wed Apr 25 13:13:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:13:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:13:07 2018 ] Training epoch: 3116
[ Wed Apr 25 13:13:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:13:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:13:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:13:11 2018 ] Training epoch: 3117
[ Wed Apr 25 13:13:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:15 2018 ] Training epoch: 3118
[ Wed Apr 25 13:13:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:13:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:13:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:19 2018 ] Training epoch: 3119
[ Wed Apr 25 13:13:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:23 2018 ] Training epoch: 3120
[ Wed Apr 25 13:13:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:27 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:13:27 2018 ] Eval epoch: 3120
[ Wed Apr 25 13:13:30 2018 ] 	Mean test loss of 1 batches: 0.22220508754253387.
[ Wed Apr 25 13:13:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:13:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:13:30 2018 ] Training epoch: 3121
[ Wed Apr 25 13:13:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:34 2018 ] Training epoch: 3122
[ Wed Apr 25 13:13:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:38 2018 ] Training epoch: 3123
[ Wed Apr 25 13:13:43 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.001000
[ Wed Apr 25 13:13:43 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 13:13:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:13:43 2018 ] Training epoch: 3124
[ Wed Apr 25 13:13:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:13:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:13:47 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:13:47 2018 ] Training epoch: 3125
[ Wed Apr 25 13:13:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:13:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:13:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:51 2018 ] Eval epoch: 3125
[ Wed Apr 25 13:13:54 2018 ] 	Mean test loss of 1 batches: 0.22310608625411987.
[ Wed Apr 25 13:13:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:13:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:13:54 2018 ] Training epoch: 3126
[ Wed Apr 25 13:13:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:13:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:13:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:13:58 2018 ] Training epoch: 3127
[ Wed Apr 25 13:14:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:02 2018 ] Training epoch: 3128
[ Wed Apr 25 13:14:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:14:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:14:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:14:06 2018 ] Training epoch: 3129
[ Wed Apr 25 13:14:10 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:14:10 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:14:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:10 2018 ] Training epoch: 3130
[ Wed Apr 25 13:14:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:14 2018 ] Eval epoch: 3130
[ Wed Apr 25 13:14:17 2018 ] 	Mean test loss of 1 batches: 0.22042033076286316.
[ Wed Apr 25 13:14:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:14:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:14:17 2018 ] Training epoch: 3131
[ Wed Apr 25 13:14:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:22 2018 ] Training epoch: 3132
[ Wed Apr 25 13:14:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:14:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:14:26 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 13:14:26 2018 ] Training epoch: 3133
[ Wed Apr 25 13:14:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:30 2018 ] Training epoch: 3134
[ Wed Apr 25 13:14:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:34 2018 ] Training epoch: 3135
[ Wed Apr 25 13:14:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:39 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:14:39 2018 ] Eval epoch: 3135
[ Wed Apr 25 13:14:42 2018 ] 	Mean test loss of 1 batches: 0.21036502718925476.
[ Wed Apr 25 13:14:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:14:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:14:42 2018 ] Training epoch: 3136
[ Wed Apr 25 13:14:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:46 2018 ] Training epoch: 3137
[ Wed Apr 25 13:14:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:14:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:14:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:50 2018 ] Training epoch: 3138
[ Wed Apr 25 13:14:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:14:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:14:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:54 2018 ] Training epoch: 3139
[ Wed Apr 25 13:14:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:14:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:14:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:14:58 2018 ] Training epoch: 3140
[ Wed Apr 25 13:15:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:02 2018 ] Eval epoch: 3140
[ Wed Apr 25 13:15:05 2018 ] 	Mean test loss of 1 batches: 0.21045082807540894.
[ Wed Apr 25 13:15:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:15:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:15:05 2018 ] Training epoch: 3141
[ Wed Apr 25 13:15:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:15:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:15:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:09 2018 ] Training epoch: 3142
[ Wed Apr 25 13:15:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:15:13 2018 ] Training epoch: 3143
[ Wed Apr 25 13:15:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:17 2018 ] Training epoch: 3144
[ Wed Apr 25 13:15:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:21 2018 ] Training epoch: 3145
[ Wed Apr 25 13:15:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:15:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:15:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:25 2018 ] Eval epoch: 3145
[ Wed Apr 25 13:15:28 2018 ] 	Mean test loss of 1 batches: 0.20383840799331665.
[ Wed Apr 25 13:15:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:15:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:15:28 2018 ] Training epoch: 3146
[ Wed Apr 25 13:15:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:15:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:15:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:32 2018 ] Training epoch: 3147
[ Wed Apr 25 13:15:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:36 2018 ] Training epoch: 3148
[ Wed Apr 25 13:15:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:40 2018 ] Training epoch: 3149
[ Wed Apr 25 13:15:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:15:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:15:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:44 2018 ] Training epoch: 3150
[ Wed Apr 25 13:15:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:15:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:15:48 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:15:48 2018 ] Eval epoch: 3150
[ Wed Apr 25 13:15:51 2018 ] 	Mean test loss of 1 batches: 0.21094799041748047.
[ Wed Apr 25 13:15:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:15:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:15:51 2018 ] Training epoch: 3151
[ Wed Apr 25 13:15:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:15:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:15:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:55 2018 ] Training epoch: 3152
[ Wed Apr 25 13:15:59 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:15:59 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:15:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:15:59 2018 ] Training epoch: 3153
[ Wed Apr 25 13:16:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:03 2018 ] Training epoch: 3154
[ Wed Apr 25 13:16:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:07 2018 ] Training epoch: 3155
[ Wed Apr 25 13:16:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:11 2018 ] Eval epoch: 3155
[ Wed Apr 25 13:16:14 2018 ] 	Mean test loss of 1 batches: 0.21211369335651398.
[ Wed Apr 25 13:16:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:16:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:16:14 2018 ] Training epoch: 3156
[ Wed Apr 25 13:16:18 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:16:18 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:16:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:18 2018 ] Training epoch: 3157
[ Wed Apr 25 13:16:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:22 2018 ] Training epoch: 3158
[ Wed Apr 25 13:16:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:16:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:16:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:26 2018 ] Training epoch: 3159
[ Wed Apr 25 13:16:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:16:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:16:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:30 2018 ] Training epoch: 3160
[ Wed Apr 25 13:16:34 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:16:34 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:16:34 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 13:16:34 2018 ] Eval epoch: 3160
[ Wed Apr 25 13:16:37 2018 ] 	Mean test loss of 1 batches: 0.22341163456439972.
[ Wed Apr 25 13:16:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:16:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:16:37 2018 ] Training epoch: 3161
[ Wed Apr 25 13:16:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:16:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:16:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:41 2018 ] Training epoch: 3162
[ Wed Apr 25 13:16:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:45 2018 ] Training epoch: 3163
[ Wed Apr 25 13:16:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:49 2018 ] Training epoch: 3164
[ Wed Apr 25 13:16:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:16:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:16:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:53 2018 ] Training epoch: 3165
[ Wed Apr 25 13:16:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:16:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:16:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:16:57 2018 ] Eval epoch: 3165
[ Wed Apr 25 13:17:00 2018 ] 	Mean test loss of 1 batches: 0.22039759159088135.
[ Wed Apr 25 13:17:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:17:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:17:00 2018 ] Training epoch: 3166
[ Wed Apr 25 13:17:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:04 2018 ] Training epoch: 3167
[ Wed Apr 25 13:17:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:17:09 2018 ] Training epoch: 3168
[ Wed Apr 25 13:17:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:17:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:17:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:13 2018 ] Training epoch: 3169
[ Wed Apr 25 13:17:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:17:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:17:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:17 2018 ] Training epoch: 3170
[ Wed Apr 25 13:17:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:17:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:17:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:21 2018 ] Eval epoch: 3170
[ Wed Apr 25 13:17:24 2018 ] 	Mean test loss of 1 batches: 0.22821129858493805.
[ Wed Apr 25 13:17:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:17:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:17:24 2018 ] Training epoch: 3171
[ Wed Apr 25 13:17:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:28 2018 ] Training epoch: 3172
[ Wed Apr 25 13:17:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:32 2018 ] Training epoch: 3173
[ Wed Apr 25 13:17:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:36 2018 ] Training epoch: 3174
[ Wed Apr 25 13:17:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:40 2018 ] Training epoch: 3175
[ Wed Apr 25 13:17:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:44 2018 ] Eval epoch: 3175
[ Wed Apr 25 13:17:46 2018 ] 	Mean test loss of 1 batches: 0.2178700566291809.
[ Wed Apr 25 13:17:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:17:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:17:46 2018 ] Training epoch: 3176
[ Wed Apr 25 13:17:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:17:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:17:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:50 2018 ] Training epoch: 3177
[ Wed Apr 25 13:17:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:17:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:17:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:54 2018 ] Training epoch: 3178
[ Wed Apr 25 13:17:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:17:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:17:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:17:58 2018 ] Training epoch: 3179
[ Wed Apr 25 13:18:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:18:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:18:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:02 2018 ] Training epoch: 3180
[ Wed Apr 25 13:18:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:18:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:18:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:06 2018 ] Eval epoch: 3180
[ Wed Apr 25 13:18:09 2018 ] 	Mean test loss of 1 batches: 0.21456459164619446.
[ Wed Apr 25 13:18:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:18:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:18:09 2018 ] Training epoch: 3181
[ Wed Apr 25 13:18:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:18:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:18:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:13 2018 ] Training epoch: 3182
[ Wed Apr 25 13:18:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:18:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:18:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:17 2018 ] Training epoch: 3183
[ Wed Apr 25 13:18:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:18:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:18:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:21 2018 ] Training epoch: 3184
[ Wed Apr 25 13:18:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:18:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:18:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:25 2018 ] Training epoch: 3185
[ Wed Apr 25 13:18:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:18:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:18:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:29 2018 ] Eval epoch: 3185
[ Wed Apr 25 13:18:32 2018 ] 	Mean test loss of 1 batches: 0.2153625637292862.
[ Wed Apr 25 13:18:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:18:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:18:32 2018 ] Training epoch: 3186
[ Wed Apr 25 13:18:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:18:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:18:37 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:18:37 2018 ] Training epoch: 3187
[ Wed Apr 25 13:18:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:18:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:18:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:41 2018 ] Training epoch: 3188
[ Wed Apr 25 13:18:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:18:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:18:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:45 2018 ] Training epoch: 3189
[ Wed Apr 25 13:18:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:18:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:18:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:49 2018 ] Training epoch: 3190
[ Wed Apr 25 13:18:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:18:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:18:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:18:53 2018 ] Eval epoch: 3190
[ Wed Apr 25 13:18:56 2018 ] 	Mean test loss of 1 batches: 0.2220289260149002.
[ Wed Apr 25 13:18:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:18:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:18:56 2018 ] Training epoch: 3191
[ Wed Apr 25 13:19:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:19:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:19:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:00 2018 ] Training epoch: 3192
[ Wed Apr 25 13:19:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:19:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:19:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:19:04 2018 ] Training epoch: 3193
[ Wed Apr 25 13:19:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:19:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:19:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:08 2018 ] Training epoch: 3194
[ Wed Apr 25 13:19:12 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.001000
[ Wed Apr 25 13:19:12 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 13:19:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:12 2018 ] Training epoch: 3195
[ Wed Apr 25 13:19:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:19:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:19:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:16 2018 ] Eval epoch: 3195
[ Wed Apr 25 13:19:19 2018 ] 	Mean test loss of 1 batches: 0.2156379520893097.
[ Wed Apr 25 13:19:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:19:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:19:19 2018 ] Training epoch: 3196
[ Wed Apr 25 13:19:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:19:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:19:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:23 2018 ] Training epoch: 3197
[ Wed Apr 25 13:19:27 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:19:27 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:19:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:27 2018 ] Training epoch: 3198
[ Wed Apr 25 13:19:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:19:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:19:31 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:19:31 2018 ] Training epoch: 3199
[ Wed Apr 25 13:19:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:35 2018 ] Training epoch: 3200
[ Wed Apr 25 13:19:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:19:39 2018 ] Eval epoch: 3200
[ Wed Apr 25 13:19:42 2018 ] 	Mean test loss of 1 batches: 0.22536884248256683.
[ Wed Apr 25 13:19:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:19:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:19:42 2018 ] Training epoch: 3201
[ Wed Apr 25 13:19:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:46 2018 ] Training epoch: 3202
[ Wed Apr 25 13:19:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:50 2018 ] Training epoch: 3203
[ Wed Apr 25 13:19:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:54 2018 ] Training epoch: 3204
[ Wed Apr 25 13:19:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:19:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:19:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:19:58 2018 ] Training epoch: 3205
[ Wed Apr 25 13:20:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:20:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:20:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:02 2018 ] Eval epoch: 3205
[ Wed Apr 25 13:20:05 2018 ] 	Mean test loss of 1 batches: 0.23425643146038055.
[ Wed Apr 25 13:20:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:20:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:20:05 2018 ] Training epoch: 3206
[ Wed Apr 25 13:20:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:09 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:20:09 2018 ] Training epoch: 3207
[ Wed Apr 25 13:20:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:20:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:20:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:14 2018 ] Training epoch: 3208
[ Wed Apr 25 13:20:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:20:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:20:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:18 2018 ] Training epoch: 3209
[ Wed Apr 25 13:20:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:22 2018 ] Training epoch: 3210
[ Wed Apr 25 13:20:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:26 2018 ] Eval epoch: 3210
[ Wed Apr 25 13:20:29 2018 ] 	Mean test loss of 1 batches: 0.22811080515384674.
[ Wed Apr 25 13:20:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:20:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:20:29 2018 ] Training epoch: 3211
[ Wed Apr 25 13:20:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:33 2018 ] Training epoch: 3212
[ Wed Apr 25 13:20:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:20:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:20:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:37 2018 ] Training epoch: 3213
[ Wed Apr 25 13:20:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:20:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:20:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:41 2018 ] Training epoch: 3214
[ Wed Apr 25 13:20:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:45 2018 ] Training epoch: 3215
[ Wed Apr 25 13:20:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:20:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:20:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:49 2018 ] Eval epoch: 3215
[ Wed Apr 25 13:20:52 2018 ] 	Mean test loss of 1 batches: 0.2232205718755722.
[ Wed Apr 25 13:20:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:20:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:20:52 2018 ] Training epoch: 3216
[ Wed Apr 25 13:20:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:20:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:20:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:20:56 2018 ] Training epoch: 3217
[ Wed Apr 25 13:21:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:21:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:21:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:00 2018 ] Training epoch: 3218
[ Wed Apr 25 13:21:04 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:21:04 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:21:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:04 2018 ] Training epoch: 3219
[ Wed Apr 25 13:21:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:21:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:21:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:08 2018 ] Training epoch: 3220
[ Wed Apr 25 13:21:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:21:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:21:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:12 2018 ] Eval epoch: 3220
[ Wed Apr 25 13:21:15 2018 ] 	Mean test loss of 1 batches: 0.2159581184387207.
[ Wed Apr 25 13:21:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:21:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:21:15 2018 ] Training epoch: 3221
[ Wed Apr 25 13:21:19 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:21:19 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:21:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:19 2018 ] Training epoch: 3222
[ Wed Apr 25 13:21:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:21:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:21:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:23 2018 ] Training epoch: 3223
[ Wed Apr 25 13:21:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:21:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:21:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:27 2018 ] Training epoch: 3224
[ Wed Apr 25 13:21:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:21:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:21:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:31 2018 ] Training epoch: 3225
[ Wed Apr 25 13:21:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:21:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:21:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:35 2018 ] Eval epoch: 3225
[ Wed Apr 25 13:21:38 2018 ] 	Mean test loss of 1 batches: 0.22008536756038666.
[ Wed Apr 25 13:21:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:21:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:21:38 2018 ] Training epoch: 3226
[ Wed Apr 25 13:21:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:21:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:21:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:42 2018 ] Training epoch: 3227
[ Wed Apr 25 13:21:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:21:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:21:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:46 2018 ] Training epoch: 3228
[ Wed Apr 25 13:21:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:21:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:21:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:50 2018 ] Training epoch: 3229
[ Wed Apr 25 13:21:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:21:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:21:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:54 2018 ] Training epoch: 3230
[ Wed Apr 25 13:21:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:21:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:21:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:21:58 2018 ] Eval epoch: 3230
[ Wed Apr 25 13:22:01 2018 ] 	Mean test loss of 1 batches: 0.22137434780597687.
[ Wed Apr 25 13:22:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:22:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:22:01 2018 ] Training epoch: 3231
[ Wed Apr 25 13:22:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:05 2018 ] Training epoch: 3232
[ Wed Apr 25 13:22:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:10 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:22:10 2018 ] Training epoch: 3233
[ Wed Apr 25 13:22:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:22:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:22:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:14 2018 ] Training epoch: 3234
[ Wed Apr 25 13:22:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:18 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:22:18 2018 ] Training epoch: 3235
[ Wed Apr 25 13:22:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:22 2018 ] Eval epoch: 3235
[ Wed Apr 25 13:22:25 2018 ] 	Mean test loss of 1 batches: 0.23622195422649384.
[ Wed Apr 25 13:22:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:22:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:22:25 2018 ] Training epoch: 3236
[ Wed Apr 25 13:22:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:29 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:22:29 2018 ] Training epoch: 3237
[ Wed Apr 25 13:22:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:22:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:22:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:33 2018 ] Training epoch: 3238
[ Wed Apr 25 13:22:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:22:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:22:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:37 2018 ] Training epoch: 3239
[ Wed Apr 25 13:22:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:22:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:22:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:41 2018 ] Training epoch: 3240
[ Wed Apr 25 13:22:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:22:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:22:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:45 2018 ] Eval epoch: 3240
[ Wed Apr 25 13:22:48 2018 ] 	Mean test loss of 1 batches: 0.23004987835884094.
[ Wed Apr 25 13:22:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:22:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:22:48 2018 ] Training epoch: 3241
[ Wed Apr 25 13:22:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:22:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:22:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:52 2018 ] Training epoch: 3242
[ Wed Apr 25 13:22:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:22:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:22:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:22:56 2018 ] Training epoch: 3243
[ Wed Apr 25 13:23:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:23:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:23:00 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:23:00 2018 ] Training epoch: 3244
[ Wed Apr 25 13:23:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:23:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:23:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:04 2018 ] Training epoch: 3245
[ Wed Apr 25 13:23:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:08 2018 ] Eval epoch: 3245
[ Wed Apr 25 13:23:11 2018 ] 	Mean test loss of 1 batches: 0.22791340947151184.
[ Wed Apr 25 13:23:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:23:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:23:11 2018 ] Training epoch: 3246
[ Wed Apr 25 13:23:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:23:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:23:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:15 2018 ] Training epoch: 3247
[ Wed Apr 25 13:23:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:19 2018 ] Training epoch: 3248
[ Wed Apr 25 13:23:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:23:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:23:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:23 2018 ] Training epoch: 3249
[ Wed Apr 25 13:23:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:27 2018 ] Training epoch: 3250
[ Wed Apr 25 13:23:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:23:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:23:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:31 2018 ] Eval epoch: 3250
[ Wed Apr 25 13:23:34 2018 ] 	Mean test loss of 1 batches: 0.22584867477416992.
[ Wed Apr 25 13:23:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:23:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:23:34 2018 ] Training epoch: 3251
[ Wed Apr 25 13:23:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:38 2018 ] Training epoch: 3252
[ Wed Apr 25 13:23:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:42 2018 ] Training epoch: 3253
[ Wed Apr 25 13:23:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:46 2018 ] Training epoch: 3254
[ Wed Apr 25 13:23:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:23:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:23:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:51 2018 ] Training epoch: 3255
[ Wed Apr 25 13:23:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:23:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:23:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:23:55 2018 ] Eval epoch: 3255
[ Wed Apr 25 13:23:58 2018 ] 	Mean test loss of 1 batches: 0.22632449865341187.
[ Wed Apr 25 13:23:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:23:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:23:58 2018 ] Training epoch: 3256
[ Wed Apr 25 13:24:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:02 2018 ] Training epoch: 3257
[ Wed Apr 25 13:24:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:24:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:24:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:06 2018 ] Training epoch: 3258
[ Wed Apr 25 13:24:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:24:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:24:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:10 2018 ] Training epoch: 3259
[ Wed Apr 25 13:24:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:14 2018 ] Training epoch: 3260
[ Wed Apr 25 13:24:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:24:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:24:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:18 2018 ] Eval epoch: 3260
[ Wed Apr 25 13:24:21 2018 ] 	Mean test loss of 1 batches: 0.2201467901468277.
[ Wed Apr 25 13:24:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:24:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:24:21 2018 ] Training epoch: 3261
[ Wed Apr 25 13:24:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:24:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:24:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:25 2018 ] Training epoch: 3262
[ Wed Apr 25 13:24:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:24:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:24:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:29 2018 ] Training epoch: 3263
[ Wed Apr 25 13:24:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:33 2018 ] Training epoch: 3264
[ Wed Apr 25 13:24:37 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:24:37 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:24:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:37 2018 ] Training epoch: 3265
[ Wed Apr 25 13:24:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:41 2018 ] Eval epoch: 3265
[ Wed Apr 25 13:24:44 2018 ] 	Mean test loss of 1 batches: 0.21405991911888123.
[ Wed Apr 25 13:24:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:24:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:24:44 2018 ] Training epoch: 3266
[ Wed Apr 25 13:24:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:48 2018 ] Training epoch: 3267
[ Wed Apr 25 13:24:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:52 2018 ] Training epoch: 3268
[ Wed Apr 25 13:24:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:24:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:24:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:24:56 2018 ] Training epoch: 3269
[ Wed Apr 25 13:25:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:25:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:25:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:00 2018 ] Training epoch: 3270
[ Wed Apr 25 13:25:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:25:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:25:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:05 2018 ] Eval epoch: 3270
[ Wed Apr 25 13:25:07 2018 ] 	Mean test loss of 1 batches: 0.21968965232372284.
[ Wed Apr 25 13:25:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:25:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:25:07 2018 ] Training epoch: 3271
[ Wed Apr 25 13:25:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:25:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:25:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:12 2018 ] Training epoch: 3272
[ Wed Apr 25 13:25:16 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:25:16 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:25:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:16 2018 ] Training epoch: 3273
[ Wed Apr 25 13:25:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:25:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:25:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:20 2018 ] Training epoch: 3274
[ Wed Apr 25 13:25:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:25:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:25:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:24 2018 ] Training epoch: 3275
[ Wed Apr 25 13:25:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:25:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:25:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:28 2018 ] Eval epoch: 3275
[ Wed Apr 25 13:25:31 2018 ] 	Mean test loss of 1 batches: 0.21771161258220673.
[ Wed Apr 25 13:25:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:25:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:25:31 2018 ] Training epoch: 3276
[ Wed Apr 25 13:25:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:25:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:25:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:35 2018 ] Training epoch: 3277
[ Wed Apr 25 13:25:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:25:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:25:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:39 2018 ] Training epoch: 3278
[ Wed Apr 25 13:25:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:25:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:25:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:43 2018 ] Training epoch: 3279
[ Wed Apr 25 13:25:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:25:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:25:47 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:25:47 2018 ] Training epoch: 3280
[ Wed Apr 25 13:25:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:25:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:25:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:51 2018 ] Eval epoch: 3280
[ Wed Apr 25 13:25:54 2018 ] 	Mean test loss of 1 batches: 0.22330686450004578.
[ Wed Apr 25 13:25:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:25:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:25:54 2018 ] Training epoch: 3281
[ Wed Apr 25 13:25:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:25:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:25:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:25:58 2018 ] Training epoch: 3282
[ Wed Apr 25 13:26:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:26:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:26:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:02 2018 ] Training epoch: 3283
[ Wed Apr 25 13:26:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:26:06 2018 ] Training epoch: 3284
[ Wed Apr 25 13:26:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:26:11 2018 ] Training epoch: 3285
[ Wed Apr 25 13:26:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:15 2018 ] Eval epoch: 3285
[ Wed Apr 25 13:26:18 2018 ] 	Mean test loss of 1 batches: 0.22131016850471497.
[ Wed Apr 25 13:26:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:26:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:26:18 2018 ] Training epoch: 3286
[ Wed Apr 25 13:26:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:26:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:26:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:26:22 2018 ] Training epoch: 3287
[ Wed Apr 25 13:26:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:26 2018 ] Training epoch: 3288
[ Wed Apr 25 13:26:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:26:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:26:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:30 2018 ] Training epoch: 3289
[ Wed Apr 25 13:26:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:34 2018 ] Training epoch: 3290
[ Wed Apr 25 13:26:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:26:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:26:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:38 2018 ] Eval epoch: 3290
[ Wed Apr 25 13:26:41 2018 ] 	Mean test loss of 1 batches: 0.22092854976654053.
[ Wed Apr 25 13:26:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:26:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:26:41 2018 ] Training epoch: 3291
[ Wed Apr 25 13:26:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:26:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:26:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:45 2018 ] Training epoch: 3292
[ Wed Apr 25 13:26:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:26:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:26:50 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:26:50 2018 ] Training epoch: 3293
[ Wed Apr 25 13:26:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:26:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:26:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:54 2018 ] Training epoch: 3294
[ Wed Apr 25 13:26:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:26:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:26:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:26:58 2018 ] Training epoch: 3295
[ Wed Apr 25 13:27:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:27:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:27:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:02 2018 ] Eval epoch: 3295
[ Wed Apr 25 13:27:05 2018 ] 	Mean test loss of 1 batches: 0.2264823317527771.
[ Wed Apr 25 13:27:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:27:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:27:05 2018 ] Training epoch: 3296
[ Wed Apr 25 13:27:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:09 2018 ] Training epoch: 3297
[ Wed Apr 25 13:27:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:13 2018 ] Training epoch: 3298
[ Wed Apr 25 13:27:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:17 2018 ] Training epoch: 3299
[ Wed Apr 25 13:27:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:27:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:27:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:21 2018 ] Training epoch: 3300
[ Wed Apr 25 13:27:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:27:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:27:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:25 2018 ] Eval epoch: 3300
[ Wed Apr 25 13:27:28 2018 ] 	Mean test loss of 1 batches: 0.22771169245243073.
[ Wed Apr 25 13:27:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:27:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:27:28 2018 ] Training epoch: 3301
[ Wed Apr 25 13:27:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:32 2018 ] Training epoch: 3302
[ Wed Apr 25 13:27:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:27:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:27:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:36 2018 ] Training epoch: 3303
[ Wed Apr 25 13:27:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:40 2018 ] Training epoch: 3304
[ Wed Apr 25 13:27:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:44 2018 ] Training epoch: 3305
[ Wed Apr 25 13:27:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:27:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:27:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:48 2018 ] Eval epoch: 3305
[ Wed Apr 25 13:27:51 2018 ] 	Mean test loss of 1 batches: 0.222566619515419.
[ Wed Apr 25 13:27:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:27:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:27:51 2018 ] Training epoch: 3306
[ Wed Apr 25 13:27:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:55 2018 ] Training epoch: 3307
[ Wed Apr 25 13:27:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:27:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:27:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:27:59 2018 ] Training epoch: 3308
[ Wed Apr 25 13:28:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:28:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:28:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:03 2018 ] Training epoch: 3309
[ Wed Apr 25 13:28:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:28:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:28:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:07 2018 ] Training epoch: 3310
[ Wed Apr 25 13:28:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:11 2018 ] Eval epoch: 3310
[ Wed Apr 25 13:28:14 2018 ] 	Mean test loss of 1 batches: 0.21881835162639618.
[ Wed Apr 25 13:28:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:28:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:28:14 2018 ] Training epoch: 3311
[ Wed Apr 25 13:28:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:18 2018 ] Training epoch: 3312
[ Wed Apr 25 13:28:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:22 2018 ] Training epoch: 3313
[ Wed Apr 25 13:28:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:26 2018 ] Training epoch: 3314
[ Wed Apr 25 13:28:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:28:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:28:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:30 2018 ] Training epoch: 3315
[ Wed Apr 25 13:28:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:28:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:28:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:28:34 2018 ] Eval epoch: 3315
[ Wed Apr 25 13:28:37 2018 ] 	Mean test loss of 1 batches: 0.21298860013484955.
[ Wed Apr 25 13:28:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:28:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:28:37 2018 ] Training epoch: 3316
[ Wed Apr 25 13:28:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:28:41 2018 ] Training epoch: 3317
[ Wed Apr 25 13:28:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:28:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:28:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:45 2018 ] Training epoch: 3318
[ Wed Apr 25 13:28:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:49 2018 ] Training epoch: 3319
[ Wed Apr 25 13:28:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:28:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:28:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:53 2018 ] Training epoch: 3320
[ Wed Apr 25 13:28:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:28:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:28:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:28:57 2018 ] Eval epoch: 3320
[ Wed Apr 25 13:29:00 2018 ] 	Mean test loss of 1 batches: 0.21537135541439056.
[ Wed Apr 25 13:29:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:29:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:29:00 2018 ] Training epoch: 3321
[ Wed Apr 25 13:29:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:04 2018 ] Training epoch: 3322
[ Wed Apr 25 13:29:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:08 2018 ] Training epoch: 3323
[ Wed Apr 25 13:29:12 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:29:12 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:29:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:12 2018 ] Training epoch: 3324
[ Wed Apr 25 13:29:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:16 2018 ] Training epoch: 3325
[ Wed Apr 25 13:29:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:20 2018 ] Eval epoch: 3325
[ Wed Apr 25 13:29:23 2018 ] 	Mean test loss of 1 batches: 0.21800369024276733.
[ Wed Apr 25 13:29:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:29:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:29:23 2018 ] Training epoch: 3326
[ Wed Apr 25 13:29:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:29:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:29:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:29:27 2018 ] Training epoch: 3327
[ Wed Apr 25 13:29:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:29:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:29:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:31 2018 ] Training epoch: 3328
[ Wed Apr 25 13:29:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:35 2018 ] Training epoch: 3329
[ Wed Apr 25 13:29:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:29:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:29:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:39 2018 ] Training epoch: 3330
[ Wed Apr 25 13:29:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:43 2018 ] Eval epoch: 3330
[ Wed Apr 25 13:29:46 2018 ] 	Mean test loss of 1 batches: 0.21744520962238312.
[ Wed Apr 25 13:29:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:29:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:29:46 2018 ] Training epoch: 3331
[ Wed Apr 25 13:29:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:50 2018 ] Training epoch: 3332
[ Wed Apr 25 13:29:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:29:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:29:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:54 2018 ] Training epoch: 3333
[ Wed Apr 25 13:29:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:29:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:29:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:29:58 2018 ] Training epoch: 3334
[ Wed Apr 25 13:30:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:02 2018 ] Training epoch: 3335
[ Wed Apr 25 13:30:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:07 2018 ] Eval epoch: 3335
[ Wed Apr 25 13:30:09 2018 ] 	Mean test loss of 1 batches: 0.2208511382341385.
[ Wed Apr 25 13:30:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:30:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:30:09 2018 ] Training epoch: 3336
[ Wed Apr 25 13:30:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:30:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:30:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:13 2018 ] Training epoch: 3337
[ Wed Apr 25 13:30:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:18 2018 ] Training epoch: 3338
[ Wed Apr 25 13:30:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:30:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:30:21 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:30:21 2018 ] Training epoch: 3339
[ Wed Apr 25 13:30:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:25 2018 ] Training epoch: 3340
[ Wed Apr 25 13:30:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:29 2018 ] Eval epoch: 3340
[ Wed Apr 25 13:30:32 2018 ] 	Mean test loss of 1 batches: 0.21458852291107178.
[ Wed Apr 25 13:30:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:30:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:30:32 2018 ] Training epoch: 3341
[ Wed Apr 25 13:30:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:30:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:30:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:36 2018 ] Training epoch: 3342
[ Wed Apr 25 13:30:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:30:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:30:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:40 2018 ] Training epoch: 3343
[ Wed Apr 25 13:30:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:30:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:30:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:44 2018 ] Training epoch: 3344
[ Wed Apr 25 13:30:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:30:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:30:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:48 2018 ] Training epoch: 3345
[ Wed Apr 25 13:30:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:30:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:30:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:52 2018 ] Eval epoch: 3345
[ Wed Apr 25 13:30:55 2018 ] 	Mean test loss of 1 batches: 0.20768533647060394.
[ Wed Apr 25 13:30:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:30:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:30:55 2018 ] Training epoch: 3346
[ Wed Apr 25 13:30:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:30:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:30:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:30:59 2018 ] Training epoch: 3347
[ Wed Apr 25 13:31:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:03 2018 ] Training epoch: 3348
[ Wed Apr 25 13:31:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:07 2018 ] Training epoch: 3349
[ Wed Apr 25 13:31:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:11 2018 ] Training epoch: 3350
[ Wed Apr 25 13:31:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:31:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:31:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:15 2018 ] Eval epoch: 3350
[ Wed Apr 25 13:31:18 2018 ] 	Mean test loss of 1 batches: 0.21151883900165558.
[ Wed Apr 25 13:31:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:31:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:31:18 2018 ] Training epoch: 3351
[ Wed Apr 25 13:31:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:31:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:31:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:22 2018 ] Training epoch: 3352
[ Wed Apr 25 13:31:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:31:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:31:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:26 2018 ] Training epoch: 3353
[ Wed Apr 25 13:31:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:30 2018 ] Training epoch: 3354
[ Wed Apr 25 13:31:34 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.001000
[ Wed Apr 25 13:31:34 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 13:31:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:34 2018 ] Training epoch: 3355
[ Wed Apr 25 13:31:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:38 2018 ] Eval epoch: 3355
[ Wed Apr 25 13:31:41 2018 ] 	Mean test loss of 1 batches: 0.21538658440113068.
[ Wed Apr 25 13:31:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:31:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:31:41 2018 ] Training epoch: 3356
[ Wed Apr 25 13:31:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:45 2018 ] Training epoch: 3357
[ Wed Apr 25 13:31:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:31:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:31:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:49 2018 ] Training epoch: 3358
[ Wed Apr 25 13:31:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:31:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:31:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:53 2018 ] Training epoch: 3359
[ Wed Apr 25 13:31:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:31:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:31:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:31:57 2018 ] Training epoch: 3360
[ Wed Apr 25 13:32:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:01 2018 ] Eval epoch: 3360
[ Wed Apr 25 13:32:04 2018 ] 	Mean test loss of 1 batches: 0.21800464391708374.
[ Wed Apr 25 13:32:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:32:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:32:04 2018 ] Training epoch: 3361
[ Wed Apr 25 13:32:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:08 2018 ] Training epoch: 3362
[ Wed Apr 25 13:32:12 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:32:12 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:32:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:12 2018 ] Training epoch: 3363
[ Wed Apr 25 13:32:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:32:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:32:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:16 2018 ] Training epoch: 3364
[ Wed Apr 25 13:32:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:20 2018 ] Training epoch: 3365
[ Wed Apr 25 13:32:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:24 2018 ] Eval epoch: 3365
[ Wed Apr 25 13:32:27 2018 ] 	Mean test loss of 1 batches: 0.2302122265100479.
[ Wed Apr 25 13:32:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:32:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:32:27 2018 ] Training epoch: 3366
[ Wed Apr 25 13:32:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:31 2018 ] Training epoch: 3367
[ Wed Apr 25 13:32:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:32:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:32:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:35 2018 ] Training epoch: 3368
[ Wed Apr 25 13:32:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:32:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:32:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:39 2018 ] Training epoch: 3369
[ Wed Apr 25 13:32:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:32:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:32:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:43 2018 ] Training epoch: 3370
[ Wed Apr 25 13:32:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:47 2018 ] Eval epoch: 3370
[ Wed Apr 25 13:32:50 2018 ] 	Mean test loss of 1 batches: 0.22670824825763702.
[ Wed Apr 25 13:32:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:32:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:32:50 2018 ] Training epoch: 3371
[ Wed Apr 25 13:32:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:32:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:32:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:54 2018 ] Training epoch: 3372
[ Wed Apr 25 13:32:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:32:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:32:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:32:58 2018 ] Training epoch: 3373
[ Wed Apr 25 13:33:02 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:33:02 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:33:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:02 2018 ] Training epoch: 3374
[ Wed Apr 25 13:33:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:33:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:33:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:06 2018 ] Training epoch: 3375
[ Wed Apr 25 13:33:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:33:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:33:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:10 2018 ] Eval epoch: 3375
[ Wed Apr 25 13:33:13 2018 ] 	Mean test loss of 1 batches: 0.2246430665254593.
[ Wed Apr 25 13:33:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:33:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:33:13 2018 ] Training epoch: 3376
[ Wed Apr 25 13:33:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:33:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:33:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:17 2018 ] Training epoch: 3377
[ Wed Apr 25 13:33:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:33:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:33:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:21 2018 ] Training epoch: 3378
[ Wed Apr 25 13:33:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:33:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:33:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:25 2018 ] Training epoch: 3379
[ Wed Apr 25 13:33:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:33:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:33:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:29 2018 ] Training epoch: 3380
[ Wed Apr 25 13:33:33 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:33:33 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:33:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:33 2018 ] Eval epoch: 3380
[ Wed Apr 25 13:33:36 2018 ] 	Mean test loss of 1 batches: 0.2303331196308136.
[ Wed Apr 25 13:33:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:33:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:33:36 2018 ] Training epoch: 3381
[ Wed Apr 25 13:33:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:33:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:33:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:40 2018 ] Training epoch: 3382
[ Wed Apr 25 13:33:44 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:33:44 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:33:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:44 2018 ] Training epoch: 3383
[ Wed Apr 25 13:33:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:33:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:33:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:48 2018 ] Training epoch: 3384
[ Wed Apr 25 13:33:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:33:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:33:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:52 2018 ] Training epoch: 3385
[ Wed Apr 25 13:33:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:33:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:33:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:33:56 2018 ] Eval epoch: 3385
[ Wed Apr 25 13:33:59 2018 ] 	Mean test loss of 1 batches: 0.22243840992450714.
[ Wed Apr 25 13:33:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:33:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:33:59 2018 ] Training epoch: 3386
[ Wed Apr 25 13:34:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:03 2018 ] Training epoch: 3387
[ Wed Apr 25 13:34:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:34:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:34:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:07 2018 ] Training epoch: 3388
[ Wed Apr 25 13:34:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:11 2018 ] Training epoch: 3389
[ Wed Apr 25 13:34:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:15 2018 ] Training epoch: 3390
[ Wed Apr 25 13:34:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:19 2018 ] Eval epoch: 3390
[ Wed Apr 25 13:34:22 2018 ] 	Mean test loss of 1 batches: 0.2308487743139267.
[ Wed Apr 25 13:34:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:34:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:34:22 2018 ] Training epoch: 3391
[ Wed Apr 25 13:34:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:34:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:34:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:26 2018 ] Training epoch: 3392
[ Wed Apr 25 13:34:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:34:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:34:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:30 2018 ] Training epoch: 3393
[ Wed Apr 25 13:34:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:34 2018 ] Training epoch: 3394
[ Wed Apr 25 13:34:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:34:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:34:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:38 2018 ] Training epoch: 3395
[ Wed Apr 25 13:34:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:34:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:34:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:43 2018 ] Eval epoch: 3395
[ Wed Apr 25 13:34:45 2018 ] 	Mean test loss of 1 batches: 0.23075315356254578.
[ Wed Apr 25 13:34:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:34:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:34:45 2018 ] Training epoch: 3396
[ Wed Apr 25 13:34:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:34:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:34:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:34:49 2018 ] Training epoch: 3397
[ Wed Apr 25 13:34:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:34:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:34:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:53 2018 ] Training epoch: 3398
[ Wed Apr 25 13:34:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:34:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:34:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:34:57 2018 ] Training epoch: 3399
[ Wed Apr 25 13:35:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:01 2018 ] Training epoch: 3400
[ Wed Apr 25 13:35:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:35:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:35:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:06 2018 ] Eval epoch: 3400
[ Wed Apr 25 13:35:08 2018 ] 	Mean test loss of 1 batches: 0.23024389147758484.
[ Wed Apr 25 13:35:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:35:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:35:08 2018 ] Training epoch: 3401
[ Wed Apr 25 13:35:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:12 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:35:12 2018 ] Training epoch: 3402
[ Wed Apr 25 13:35:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:16 2018 ] Training epoch: 3403
[ Wed Apr 25 13:35:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:35:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:35:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:21 2018 ] Training epoch: 3404
[ Wed Apr 25 13:35:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:25 2018 ] Training epoch: 3405
[ Wed Apr 25 13:35:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:29 2018 ] Eval epoch: 3405
[ Wed Apr 25 13:35:31 2018 ] 	Mean test loss of 1 batches: 0.21980701386928558.
[ Wed Apr 25 13:35:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:35:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:35:31 2018 ] Training epoch: 3406
[ Wed Apr 25 13:35:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:35:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:35:36 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 13:35:36 2018 ] Training epoch: 3407
[ Wed Apr 25 13:35:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:40 2018 ] Training epoch: 3408
[ Wed Apr 25 13:35:44 2018 ] 	Batch(0/1) done. Loss: 0.0041  lr:0.001000
[ Wed Apr 25 13:35:44 2018 ] 	Mean training loss: 0.0041.
[ Wed Apr 25 13:35:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:44 2018 ] Training epoch: 3409
[ Wed Apr 25 13:35:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:35:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:35:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:48 2018 ] Training epoch: 3410
[ Wed Apr 25 13:35:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:35:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:35:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:52 2018 ] Eval epoch: 3410
[ Wed Apr 25 13:35:55 2018 ] 	Mean test loss of 1 batches: 0.21693097054958344.
[ Wed Apr 25 13:35:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:35:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:35:55 2018 ] Training epoch: 3411
[ Wed Apr 25 13:35:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:35:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:35:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:35:59 2018 ] Training epoch: 3412
[ Wed Apr 25 13:36:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:03 2018 ] Training epoch: 3413
[ Wed Apr 25 13:36:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:07 2018 ] Training epoch: 3414
[ Wed Apr 25 13:36:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:11 2018 ] Training epoch: 3415
[ Wed Apr 25 13:36:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:15 2018 ] Eval epoch: 3415
[ Wed Apr 25 13:36:18 2018 ] 	Mean test loss of 1 batches: 0.22895000874996185.
[ Wed Apr 25 13:36:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:36:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:36:18 2018 ] Training epoch: 3416
[ Wed Apr 25 13:36:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:36:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:36:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:22 2018 ] Training epoch: 3417
[ Wed Apr 25 13:36:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:36:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:36:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:26 2018 ] Training epoch: 3418
[ Wed Apr 25 13:36:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:36:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:36:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:30 2018 ] Training epoch: 3419
[ Wed Apr 25 13:36:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:34 2018 ] Training epoch: 3420
[ Wed Apr 25 13:36:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:36:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:36:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:38 2018 ] Eval epoch: 3420
[ Wed Apr 25 13:36:41 2018 ] 	Mean test loss of 1 batches: 0.2315981090068817.
[ Wed Apr 25 13:36:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:36:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:36:41 2018 ] Training epoch: 3421
[ Wed Apr 25 13:36:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:36:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:36:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:45 2018 ] Training epoch: 3422
[ Wed Apr 25 13:36:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:36:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:36:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:49 2018 ] Training epoch: 3423
[ Wed Apr 25 13:36:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:36:53 2018 ] Training epoch: 3424
[ Wed Apr 25 13:36:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:36:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:36:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:36:57 2018 ] Training epoch: 3425
[ Wed Apr 25 13:37:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:37:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:37:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:01 2018 ] Eval epoch: 3425
[ Wed Apr 25 13:37:04 2018 ] 	Mean test loss of 1 batches: 0.22369225323200226.
[ Wed Apr 25 13:37:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:37:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:37:04 2018 ] Training epoch: 3426
[ Wed Apr 25 13:37:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:37:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:37:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:08 2018 ] Training epoch: 3427
[ Wed Apr 25 13:37:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:37:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:37:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:12 2018 ] Training epoch: 3428
[ Wed Apr 25 13:37:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:37:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:37:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:16 2018 ] Training epoch: 3429
[ Wed Apr 25 13:37:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:20 2018 ] Training epoch: 3430
[ Wed Apr 25 13:37:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:37:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:37:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:24 2018 ] Eval epoch: 3430
[ Wed Apr 25 13:37:27 2018 ] 	Mean test loss of 1 batches: 0.23590046167373657.
[ Wed Apr 25 13:37:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:37:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:37:27 2018 ] Training epoch: 3431
[ Wed Apr 25 13:37:31 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.001000
[ Wed Apr 25 13:37:31 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 13:37:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:31 2018 ] Training epoch: 3432
[ Wed Apr 25 13:37:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:35 2018 ] Training epoch: 3433
[ Wed Apr 25 13:37:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:40 2018 ] Training epoch: 3434
[ Wed Apr 25 13:37:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:44 2018 ] Training epoch: 3435
[ Wed Apr 25 13:37:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:37:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:37:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:48 2018 ] Eval epoch: 3435
[ Wed Apr 25 13:37:50 2018 ] 	Mean test loss of 1 batches: 0.22537843883037567.
[ Wed Apr 25 13:37:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:37:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:37:50 2018 ] Training epoch: 3436
[ Wed Apr 25 13:37:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:55 2018 ] Training epoch: 3437
[ Wed Apr 25 13:37:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:37:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:37:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:37:59 2018 ] Training epoch: 3438
[ Wed Apr 25 13:38:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:38:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:38:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:03 2018 ] Training epoch: 3439
[ Wed Apr 25 13:38:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:38:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:38:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:38:07 2018 ] Training epoch: 3440
[ Wed Apr 25 13:38:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:38:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:38:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:38:10 2018 ] Eval epoch: 3440
[ Wed Apr 25 13:38:13 2018 ] 	Mean test loss of 1 batches: 0.22445297241210938.
[ Wed Apr 25 13:38:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:38:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:38:13 2018 ] Training epoch: 3441
[ Wed Apr 25 13:38:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:38:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:38:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:17 2018 ] Training epoch: 3442
[ Wed Apr 25 13:38:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:38:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:38:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:21 2018 ] Training epoch: 3443
[ Wed Apr 25 13:38:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:38:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:38:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:25 2018 ] Training epoch: 3444
[ Wed Apr 25 13:38:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:38:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:38:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:30 2018 ] Training epoch: 3445
[ Wed Apr 25 13:38:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:38:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:38:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:34 2018 ] Eval epoch: 3445
[ Wed Apr 25 13:38:36 2018 ] 	Mean test loss of 1 batches: 0.2236035019159317.
[ Wed Apr 25 13:38:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:38:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:38:36 2018 ] Training epoch: 3446
[ Wed Apr 25 13:38:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:38:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:38:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:40 2018 ] Training epoch: 3447
[ Wed Apr 25 13:38:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:38:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:38:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:44 2018 ] Training epoch: 3448
[ Wed Apr 25 13:38:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:38:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:38:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:48 2018 ] Training epoch: 3449
[ Wed Apr 25 13:38:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:38:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:38:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:53 2018 ] Training epoch: 3450
[ Wed Apr 25 13:38:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:38:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:38:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:38:57 2018 ] Eval epoch: 3450
[ Wed Apr 25 13:38:59 2018 ] 	Mean test loss of 1 batches: 0.21827678382396698.
[ Wed Apr 25 13:38:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:38:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:38:59 2018 ] Training epoch: 3451
[ Wed Apr 25 13:39:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:39:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:39:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:03 2018 ] Training epoch: 3452
[ Wed Apr 25 13:39:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:07 2018 ] Training epoch: 3453
[ Wed Apr 25 13:39:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:11 2018 ] Training epoch: 3454
[ Wed Apr 25 13:39:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:39:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:39:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:16 2018 ] Training epoch: 3455
[ Wed Apr 25 13:39:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:20 2018 ] Eval epoch: 3455
[ Wed Apr 25 13:39:22 2018 ] 	Mean test loss of 1 batches: 0.21836505830287933.
[ Wed Apr 25 13:39:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:39:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:39:22 2018 ] Training epoch: 3456
[ Wed Apr 25 13:39:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:26 2018 ] Training epoch: 3457
[ Wed Apr 25 13:39:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:30 2018 ] Training epoch: 3458
[ Wed Apr 25 13:39:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:39:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:39:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:34 2018 ] Training epoch: 3459
[ Wed Apr 25 13:39:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:38 2018 ] Training epoch: 3460
[ Wed Apr 25 13:39:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:42 2018 ] Eval epoch: 3460
[ Wed Apr 25 13:39:45 2018 ] 	Mean test loss of 1 batches: 0.22483721375465393.
[ Wed Apr 25 13:39:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:39:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:39:45 2018 ] Training epoch: 3461
[ Wed Apr 25 13:39:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:39:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:39:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:49 2018 ] Training epoch: 3462
[ Wed Apr 25 13:39:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:53 2018 ] Training epoch: 3463
[ Wed Apr 25 13:39:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:39:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:39:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:39:57 2018 ] Training epoch: 3464
[ Wed Apr 25 13:40:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:01 2018 ] Training epoch: 3465
[ Wed Apr 25 13:40:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:05 2018 ] Eval epoch: 3465
[ Wed Apr 25 13:40:08 2018 ] 	Mean test loss of 1 batches: 0.21922558546066284.
[ Wed Apr 25 13:40:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:40:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:40:08 2018 ] Training epoch: 3466
[ Wed Apr 25 13:40:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:12 2018 ] Training epoch: 3467
[ Wed Apr 25 13:40:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:16 2018 ] Training epoch: 3468
[ Wed Apr 25 13:40:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:20 2018 ] Training epoch: 3469
[ Wed Apr 25 13:40:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:24 2018 ] Training epoch: 3470
[ Wed Apr 25 13:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:40:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:40:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:28 2018 ] Eval epoch: 3470
[ Wed Apr 25 13:40:31 2018 ] 	Mean test loss of 1 batches: 0.21891623735427856.
[ Wed Apr 25 13:40:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:40:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:40:31 2018 ] Training epoch: 3471
[ Wed Apr 25 13:40:35 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:40:35 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:40:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:35 2018 ] Training epoch: 3472
[ Wed Apr 25 13:40:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:39 2018 ] Training epoch: 3473
[ Wed Apr 25 13:40:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:40:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:40:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:43 2018 ] Training epoch: 3474
[ Wed Apr 25 13:40:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:40:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:40:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:47 2018 ] Training epoch: 3475
[ Wed Apr 25 13:40:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:51 2018 ] Eval epoch: 3475
[ Wed Apr 25 13:40:54 2018 ] 	Mean test loss of 1 batches: 0.22470305860042572.
[ Wed Apr 25 13:40:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:40:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:40:54 2018 ] Training epoch: 3476
[ Wed Apr 25 13:40:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:40:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:40:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:40:58 2018 ] Training epoch: 3477
[ Wed Apr 25 13:41:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:41:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:41:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:41:02 2018 ] Training epoch: 3478
[ Wed Apr 25 13:41:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:41:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:41:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:06 2018 ] Training epoch: 3479
[ Wed Apr 25 13:41:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:10 2018 ] Training epoch: 3480
[ Wed Apr 25 13:41:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:14 2018 ] Eval epoch: 3480
[ Wed Apr 25 13:41:17 2018 ] 	Mean test loss of 1 batches: 0.2215331792831421.
[ Wed Apr 25 13:41:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:41:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:41:17 2018 ] Training epoch: 3481
[ Wed Apr 25 13:41:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:21 2018 ] Training epoch: 3482
[ Wed Apr 25 13:41:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:41:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:41:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:25 2018 ] Training epoch: 3483
[ Wed Apr 25 13:41:29 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.001000
[ Wed Apr 25 13:41:29 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 13:41:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:29 2018 ] Training epoch: 3484
[ Wed Apr 25 13:41:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:33 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:41:33 2018 ] Training epoch: 3485
[ Wed Apr 25 13:41:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:37 2018 ] Eval epoch: 3485
[ Wed Apr 25 13:41:40 2018 ] 	Mean test loss of 1 batches: 0.21803678572177887.
[ Wed Apr 25 13:41:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:41:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:41:40 2018 ] Training epoch: 3486
[ Wed Apr 25 13:41:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:44 2018 ] Training epoch: 3487
[ Wed Apr 25 13:41:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:41:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:41:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:48 2018 ] Training epoch: 3488
[ Wed Apr 25 13:41:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:41:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:41:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:52 2018 ] Training epoch: 3489
[ Wed Apr 25 13:41:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:41:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:41:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:41:56 2018 ] Training epoch: 3490
[ Wed Apr 25 13:42:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:42:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:42:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:00 2018 ] Eval epoch: 3490
[ Wed Apr 25 13:42:03 2018 ] 	Mean test loss of 1 batches: 0.21468980610370636.
[ Wed Apr 25 13:42:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:42:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:42:03 2018 ] Training epoch: 3491
[ Wed Apr 25 13:42:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:42:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:42:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:07 2018 ] Training epoch: 3492
[ Wed Apr 25 13:42:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:11 2018 ] Training epoch: 3493
[ Wed Apr 25 13:42:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:42:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:42:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:15 2018 ] Training epoch: 3494
[ Wed Apr 25 13:42:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:19 2018 ] Training epoch: 3495
[ Wed Apr 25 13:42:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:42:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:42:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:23 2018 ] Eval epoch: 3495
[ Wed Apr 25 13:42:26 2018 ] 	Mean test loss of 1 batches: 0.2046283781528473.
[ Wed Apr 25 13:42:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:42:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:42:26 2018 ] Training epoch: 3496
[ Wed Apr 25 13:42:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:30 2018 ] Training epoch: 3497
[ Wed Apr 25 13:42:34 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:42:34 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:42:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:34 2018 ] Training epoch: 3498
[ Wed Apr 25 13:42:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:42:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:42:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:38 2018 ] Training epoch: 3499
[ Wed Apr 25 13:42:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:42 2018 ] Training epoch: 3500
[ Wed Apr 25 13:42:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:46 2018 ] Eval epoch: 3500
[ Wed Apr 25 13:42:49 2018 ] 	Mean test loss of 1 batches: 0.20647312700748444.
[ Wed Apr 25 13:42:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:42:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:42:49 2018 ] Training epoch: 3501
[ Wed Apr 25 13:42:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:53 2018 ] Training epoch: 3502
[ Wed Apr 25 13:42:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:42:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:42:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:42:57 2018 ] Training epoch: 3503
[ Wed Apr 25 13:43:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:43:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:43:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:01 2018 ] Training epoch: 3504
[ Wed Apr 25 13:43:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:43:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:43:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:05 2018 ] Training epoch: 3505
[ Wed Apr 25 13:43:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:09 2018 ] Eval epoch: 3505
[ Wed Apr 25 13:43:12 2018 ] 	Mean test loss of 1 batches: 0.2144794464111328.
[ Wed Apr 25 13:43:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:43:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:43:12 2018 ] Training epoch: 3506
[ Wed Apr 25 13:43:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:16 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:43:16 2018 ] Training epoch: 3507
[ Wed Apr 25 13:43:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:43:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:43:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:20 2018 ] Training epoch: 3508
[ Wed Apr 25 13:43:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:43:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:43:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:24 2018 ] Training epoch: 3509
[ Wed Apr 25 13:43:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:43:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:43:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:28 2018 ] Training epoch: 3510
[ Wed Apr 25 13:43:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:32 2018 ] Eval epoch: 3510
[ Wed Apr 25 13:43:35 2018 ] 	Mean test loss of 1 batches: 0.2166176736354828.
[ Wed Apr 25 13:43:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:43:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:43:35 2018 ] Training epoch: 3511
[ Wed Apr 25 13:43:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:43:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:43:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:39 2018 ] Training epoch: 3512
[ Wed Apr 25 13:43:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:43:43 2018 ] Training epoch: 3513
[ Wed Apr 25 13:43:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:48 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:43:48 2018 ] Training epoch: 3514
[ Wed Apr 25 13:43:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:43:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:43:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:52 2018 ] Training epoch: 3515
[ Wed Apr 25 13:43:56 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:43:56 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:43:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:43:56 2018 ] Eval epoch: 3515
[ Wed Apr 25 13:43:59 2018 ] 	Mean test loss of 1 batches: 0.21844850480556488.
[ Wed Apr 25 13:43:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:43:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:43:59 2018 ] Training epoch: 3516
[ Wed Apr 25 13:44:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:44:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:44:03 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:44:03 2018 ] Training epoch: 3517
[ Wed Apr 25 13:44:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:44:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:44:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:07 2018 ] Training epoch: 3518
[ Wed Apr 25 13:44:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:44:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:44:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:11 2018 ] Training epoch: 3519
[ Wed Apr 25 13:44:16 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:44:16 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:44:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:16 2018 ] Training epoch: 3520
[ Wed Apr 25 13:44:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:44:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:44:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:20 2018 ] Eval epoch: 3520
[ Wed Apr 25 13:44:22 2018 ] 	Mean test loss of 1 batches: 0.2165970504283905.
[ Wed Apr 25 13:44:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:44:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:44:22 2018 ] Training epoch: 3521
[ Wed Apr 25 13:44:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:44:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:44:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:26 2018 ] Training epoch: 3522
[ Wed Apr 25 13:44:31 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.001000
[ Wed Apr 25 13:44:31 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 13:44:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:31 2018 ] Training epoch: 3523
[ Wed Apr 25 13:44:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:44:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:44:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:35 2018 ] Training epoch: 3524
[ Wed Apr 25 13:44:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:44:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:44:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:39 2018 ] Training epoch: 3525
[ Wed Apr 25 13:44:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:44:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:44:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:43 2018 ] Eval epoch: 3525
[ Wed Apr 25 13:44:46 2018 ] 	Mean test loss of 1 batches: 0.2174992710351944.
[ Wed Apr 25 13:44:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:44:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:44:46 2018 ] Training epoch: 3526
[ Wed Apr 25 13:44:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:44:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:44:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:50 2018 ] Training epoch: 3527
[ Wed Apr 25 13:44:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:44:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:44:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:54 2018 ] Training epoch: 3528
[ Wed Apr 25 13:44:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:44:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:44:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:44:58 2018 ] Training epoch: 3529
[ Wed Apr 25 13:45:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:45:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:45:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:02 2018 ] Training epoch: 3530
[ Wed Apr 25 13:45:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:45:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:45:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:06 2018 ] Eval epoch: 3530
[ Wed Apr 25 13:45:09 2018 ] 	Mean test loss of 1 batches: 0.20896397531032562.
[ Wed Apr 25 13:45:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:45:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:45:09 2018 ] Training epoch: 3531
[ Wed Apr 25 13:45:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:45:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:45:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:13 2018 ] Training epoch: 3532
[ Wed Apr 25 13:45:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:45:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:45:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:17 2018 ] Training epoch: 3533
[ Wed Apr 25 13:45:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:45:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:45:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:21 2018 ] Training epoch: 3534
[ Wed Apr 25 13:45:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:45:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:45:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:25 2018 ] Training epoch: 3535
[ Wed Apr 25 13:45:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:45:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:45:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:29 2018 ] Eval epoch: 3535
[ Wed Apr 25 13:45:32 2018 ] 	Mean test loss of 1 batches: 0.20895260572433472.
[ Wed Apr 25 13:45:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:45:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:45:32 2018 ] Training epoch: 3536
[ Wed Apr 25 13:45:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:45:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:45:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:36 2018 ] Training epoch: 3537
[ Wed Apr 25 13:45:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:45:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:45:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:40 2018 ] Training epoch: 3538
[ Wed Apr 25 13:45:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:45:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:45:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:44 2018 ] Training epoch: 3539
[ Wed Apr 25 13:45:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:45:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:45:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:48 2018 ] Training epoch: 3540
[ Wed Apr 25 13:45:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:45:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:45:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:52 2018 ] Eval epoch: 3540
[ Wed Apr 25 13:45:55 2018 ] 	Mean test loss of 1 batches: 0.21254479885101318.
[ Wed Apr 25 13:45:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:45:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:45:55 2018 ] Training epoch: 3541
[ Wed Apr 25 13:45:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:45:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:45:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:45:59 2018 ] Training epoch: 3542
[ Wed Apr 25 13:46:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:46:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:46:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:03 2018 ] Training epoch: 3543
[ Wed Apr 25 13:46:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:07 2018 ] Training epoch: 3544
[ Wed Apr 25 13:46:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:11 2018 ] Training epoch: 3545
[ Wed Apr 25 13:46:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:15 2018 ] Eval epoch: 3545
[ Wed Apr 25 13:46:18 2018 ] 	Mean test loss of 1 batches: 0.20745648443698883.
[ Wed Apr 25 13:46:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:46:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:46:18 2018 ] Training epoch: 3546
[ Wed Apr 25 13:46:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:22 2018 ] Training epoch: 3547
[ Wed Apr 25 13:46:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:46:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:46:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:26 2018 ] Training epoch: 3548
[ Wed Apr 25 13:46:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:46:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:46:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:30 2018 ] Training epoch: 3549
[ Wed Apr 25 13:46:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:34 2018 ] Training epoch: 3550
[ Wed Apr 25 13:46:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:46:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:46:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:38 2018 ] Eval epoch: 3550
[ Wed Apr 25 13:46:41 2018 ] 	Mean test loss of 1 batches: 0.20859000086784363.
[ Wed Apr 25 13:46:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:46:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:46:41 2018 ] Training epoch: 3551
[ Wed Apr 25 13:46:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:45 2018 ] Training epoch: 3552
[ Wed Apr 25 13:46:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:46:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:46:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:49 2018 ] Training epoch: 3553
[ Wed Apr 25 13:46:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:46:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:46:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:53 2018 ] Training epoch: 3554
[ Wed Apr 25 13:46:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:46:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:46:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:46:57 2018 ] Training epoch: 3555
[ Wed Apr 25 13:47:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:47:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:47:01 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 13:47:01 2018 ] Eval epoch: 3555
[ Wed Apr 25 13:47:04 2018 ] 	Mean test loss of 1 batches: 0.20215104520320892.
[ Wed Apr 25 13:47:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:47:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:47:04 2018 ] Training epoch: 3556
[ Wed Apr 25 13:47:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:47:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:47:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:08 2018 ] Training epoch: 3557
[ Wed Apr 25 13:47:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:12 2018 ] Training epoch: 3558
[ Wed Apr 25 13:47:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:47:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:47:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:16 2018 ] Training epoch: 3559
[ Wed Apr 25 13:47:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:47:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:47:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:20 2018 ] Training epoch: 3560
[ Wed Apr 25 13:47:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:25 2018 ] Eval epoch: 3560
[ Wed Apr 25 13:47:27 2018 ] 	Mean test loss of 1 batches: 0.20279939472675323.
[ Wed Apr 25 13:47:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:47:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:47:27 2018 ] Training epoch: 3561
[ Wed Apr 25 13:47:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:31 2018 ] Training epoch: 3562
[ Wed Apr 25 13:47:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:35 2018 ] Training epoch: 3563
[ Wed Apr 25 13:47:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:40 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:47:40 2018 ] Training epoch: 3564
[ Wed Apr 25 13:47:44 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.001000
[ Wed Apr 25 13:47:44 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 13:47:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:44 2018 ] Training epoch: 3565
[ Wed Apr 25 13:47:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:48 2018 ] Eval epoch: 3565
[ Wed Apr 25 13:47:51 2018 ] 	Mean test loss of 1 batches: 0.2105584293603897.
[ Wed Apr 25 13:47:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:47:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:47:51 2018 ] Training epoch: 3566
[ Wed Apr 25 13:47:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:55 2018 ] Training epoch: 3567
[ Wed Apr 25 13:47:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:47:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:47:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:47:59 2018 ] Training epoch: 3568
[ Wed Apr 25 13:48:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:48:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:48:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:03 2018 ] Training epoch: 3569
[ Wed Apr 25 13:48:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:48:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:48:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:07 2018 ] Training epoch: 3570
[ Wed Apr 25 13:48:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:48:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:48:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:11 2018 ] Eval epoch: 3570
[ Wed Apr 25 13:48:14 2018 ] 	Mean test loss of 1 batches: 0.21481643617153168.
[ Wed Apr 25 13:48:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:48:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:48:14 2018 ] Training epoch: 3571
[ Wed Apr 25 13:48:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:48:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:48:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:19 2018 ] Training epoch: 3572
[ Wed Apr 25 13:48:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:48:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:48:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:23 2018 ] Training epoch: 3573
[ Wed Apr 25 13:48:27 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:48:27 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:48:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:48:27 2018 ] Training epoch: 3574
[ Wed Apr 25 13:48:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:48:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:48:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:31 2018 ] Training epoch: 3575
[ Wed Apr 25 13:48:35 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:48:35 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:48:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:35 2018 ] Eval epoch: 3575
[ Wed Apr 25 13:48:38 2018 ] 	Mean test loss of 1 batches: 0.22921933233737946.
[ Wed Apr 25 13:48:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:48:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:48:38 2018 ] Training epoch: 3576
[ Wed Apr 25 13:48:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:48:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:48:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:42 2018 ] Training epoch: 3577
[ Wed Apr 25 13:48:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:48:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:48:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:46 2018 ] Training epoch: 3578
[ Wed Apr 25 13:48:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:48:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:48:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:50 2018 ] Training epoch: 3579
[ Wed Apr 25 13:48:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:48:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:48:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:54 2018 ] Training epoch: 3580
[ Wed Apr 25 13:48:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:48:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:48:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:48:58 2018 ] Eval epoch: 3580
[ Wed Apr 25 13:49:01 2018 ] 	Mean test loss of 1 batches: 0.22235314548015594.
[ Wed Apr 25 13:49:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:49:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:49:01 2018 ] Training epoch: 3581
[ Wed Apr 25 13:49:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:49:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:49:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:05 2018 ] Training epoch: 3582
[ Wed Apr 25 13:49:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:09 2018 ] Training epoch: 3583
[ Wed Apr 25 13:49:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:13 2018 ] Training epoch: 3584
[ Wed Apr 25 13:49:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:49:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:49:18 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:49:18 2018 ] Training epoch: 3585
[ Wed Apr 25 13:49:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:22 2018 ] Eval epoch: 3585
[ Wed Apr 25 13:49:24 2018 ] 	Mean test loss of 1 batches: 0.2247101217508316.
[ Wed Apr 25 13:49:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:49:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:49:24 2018 ] Training epoch: 3586
[ Wed Apr 25 13:49:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:28 2018 ] Training epoch: 3587
[ Wed Apr 25 13:49:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:49:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:49:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:33 2018 ] Training epoch: 3588
[ Wed Apr 25 13:49:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:37 2018 ] Training epoch: 3589
[ Wed Apr 25 13:49:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:49:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:49:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:40 2018 ] Training epoch: 3590
[ Wed Apr 25 13:49:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:45 2018 ] Eval epoch: 3590
[ Wed Apr 25 13:49:47 2018 ] 	Mean test loss of 1 batches: 0.22466342151165009.
[ Wed Apr 25 13:49:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:49:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:49:47 2018 ] Training epoch: 3591
[ Wed Apr 25 13:49:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:49:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:49:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:51 2018 ] Training epoch: 3592
[ Wed Apr 25 13:49:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:55 2018 ] Training epoch: 3593
[ Wed Apr 25 13:49:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:49:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:49:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:49:59 2018 ] Training epoch: 3594
[ Wed Apr 25 13:50:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:03 2018 ] Training epoch: 3595
[ Wed Apr 25 13:50:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:07 2018 ] Eval epoch: 3595
[ Wed Apr 25 13:50:10 2018 ] 	Mean test loss of 1 batches: 0.21618781983852386.
[ Wed Apr 25 13:50:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:50:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:50:10 2018 ] Training epoch: 3596
[ Wed Apr 25 13:50:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:14 2018 ] Training epoch: 3597
[ Wed Apr 25 13:50:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:18 2018 ] Training epoch: 3598
[ Wed Apr 25 13:50:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:50:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:50:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:22 2018 ] Training epoch: 3599
[ Wed Apr 25 13:50:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:50:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:50:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:26 2018 ] Training epoch: 3600
[ Wed Apr 25 13:50:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:30 2018 ] Eval epoch: 3600
[ Wed Apr 25 13:50:33 2018 ] 	Mean test loss of 1 batches: 0.22419606149196625.
[ Wed Apr 25 13:50:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:50:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:50:33 2018 ] Training epoch: 3601
[ Wed Apr 25 13:50:37 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:50:37 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:50:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:37 2018 ] Training epoch: 3602
[ Wed Apr 25 13:50:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:41 2018 ] Training epoch: 3603
[ Wed Apr 25 13:50:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:45 2018 ] Training epoch: 3604
[ Wed Apr 25 13:50:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:49 2018 ] Training epoch: 3605
[ Wed Apr 25 13:50:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:50:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:50:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:50:53 2018 ] Eval epoch: 3605
[ Wed Apr 25 13:50:56 2018 ] 	Mean test loss of 1 batches: 0.21419933438301086.
[ Wed Apr 25 13:50:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:50:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:50:56 2018 ] Training epoch: 3606
[ Wed Apr 25 13:51:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:51:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:51:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:00 2018 ] Training epoch: 3607
[ Wed Apr 25 13:51:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:04 2018 ] Training epoch: 3608
[ Wed Apr 25 13:51:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:08 2018 ] Training epoch: 3609
[ Wed Apr 25 13:51:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:51:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:51:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:12 2018 ] Training epoch: 3610
[ Wed Apr 25 13:51:16 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.001000
[ Wed Apr 25 13:51:16 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 13:51:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:16 2018 ] Eval epoch: 3610
[ Wed Apr 25 13:51:19 2018 ] 	Mean test loss of 1 batches: 0.2172272652387619.
[ Wed Apr 25 13:51:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:51:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:51:19 2018 ] Training epoch: 3611
[ Wed Apr 25 13:51:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:51:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:51:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:23 2018 ] Training epoch: 3612
[ Wed Apr 25 13:51:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:27 2018 ] Training epoch: 3613
[ Wed Apr 25 13:51:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:31 2018 ] Training epoch: 3614
[ Wed Apr 25 13:51:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:35 2018 ] Training epoch: 3615
[ Wed Apr 25 13:51:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:39 2018 ] Eval epoch: 3615
[ Wed Apr 25 13:51:42 2018 ] 	Mean test loss of 1 batches: 0.22379547357559204.
[ Wed Apr 25 13:51:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:51:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:51:42 2018 ] Training epoch: 3616
[ Wed Apr 25 13:51:46 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:51:46 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:51:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:46 2018 ] Training epoch: 3617
[ Wed Apr 25 13:51:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:51:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:51:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:50 2018 ] Training epoch: 3618
[ Wed Apr 25 13:51:54 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:51:54 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:51:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:54 2018 ] Training epoch: 3619
[ Wed Apr 25 13:51:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:51:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:51:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:51:58 2018 ] Training epoch: 3620
[ Wed Apr 25 13:52:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:52:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:52:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:02 2018 ] Eval epoch: 3620
[ Wed Apr 25 13:52:05 2018 ] 	Mean test loss of 1 batches: 0.22340764105319977.
[ Wed Apr 25 13:52:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:52:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:52:05 2018 ] Training epoch: 3621
[ Wed Apr 25 13:52:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:09 2018 ] Training epoch: 3622
[ Wed Apr 25 13:52:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:13 2018 ] Training epoch: 3623
[ Wed Apr 25 13:52:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:52:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:52:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:17 2018 ] Training epoch: 3624
[ Wed Apr 25 13:52:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:21 2018 ] Training epoch: 3625
[ Wed Apr 25 13:52:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:25 2018 ] Eval epoch: 3625
[ Wed Apr 25 13:52:28 2018 ] 	Mean test loss of 1 batches: 0.21566730737686157.
[ Wed Apr 25 13:52:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:52:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:52:28 2018 ] Training epoch: 3626
[ Wed Apr 25 13:52:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:52:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:52:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:32 2018 ] Training epoch: 3627
[ Wed Apr 25 13:52:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:36 2018 ] Training epoch: 3628
[ Wed Apr 25 13:52:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:52:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:52:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:40 2018 ] Training epoch: 3629
[ Wed Apr 25 13:52:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:52:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:52:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:44 2018 ] Training epoch: 3630
[ Wed Apr 25 13:52:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:52:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:52:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:48 2018 ] Eval epoch: 3630
[ Wed Apr 25 13:52:51 2018 ] 	Mean test loss of 1 batches: 0.1994563788175583.
[ Wed Apr 25 13:52:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:52:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:52:51 2018 ] Training epoch: 3631
[ Wed Apr 25 13:52:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:52:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:52:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:55 2018 ] Training epoch: 3632
[ Wed Apr 25 13:52:59 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 13:52:59 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 13:52:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:52:59 2018 ] Training epoch: 3633
[ Wed Apr 25 13:53:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:03 2018 ] Training epoch: 3634
[ Wed Apr 25 13:53:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:53:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:53:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:07 2018 ] Training epoch: 3635
[ Wed Apr 25 13:53:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:53:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:53:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:11 2018 ] Eval epoch: 3635
[ Wed Apr 25 13:53:14 2018 ] 	Mean test loss of 1 batches: 0.2090245932340622.
[ Wed Apr 25 13:53:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:53:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:53:14 2018 ] Training epoch: 3636
[ Wed Apr 25 13:53:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:53:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:53:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:18 2018 ] Training epoch: 3637
[ Wed Apr 25 13:53:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:53:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:53:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:22 2018 ] Training epoch: 3638
[ Wed Apr 25 13:53:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:26 2018 ] Training epoch: 3639
[ Wed Apr 25 13:53:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:53:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:53:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:31 2018 ] Training epoch: 3640
[ Wed Apr 25 13:53:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:53:35 2018 ] Eval epoch: 3640
[ Wed Apr 25 13:53:38 2018 ] 	Mean test loss of 1 batches: 0.2147618979215622.
[ Wed Apr 25 13:53:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:53:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:53:38 2018 ] Training epoch: 3641
[ Wed Apr 25 13:53:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:42 2018 ] Training epoch: 3642
[ Wed Apr 25 13:53:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:46 2018 ] Training epoch: 3643
[ Wed Apr 25 13:53:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:53:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:53:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:50 2018 ] Training epoch: 3644
[ Wed Apr 25 13:53:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:53:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:53:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:54 2018 ] Training epoch: 3645
[ Wed Apr 25 13:53:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:53:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:53:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:53:58 2018 ] Eval epoch: 3645
[ Wed Apr 25 13:54:01 2018 ] 	Mean test loss of 1 batches: 0.2120238095521927.
[ Wed Apr 25 13:54:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:54:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:54:01 2018 ] Training epoch: 3646
[ Wed Apr 25 13:54:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:05 2018 ] Training epoch: 3647
[ Wed Apr 25 13:54:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:54:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:54:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:09 2018 ] Training epoch: 3648
[ Wed Apr 25 13:54:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:54:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:54:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:13 2018 ] Training epoch: 3649
[ Wed Apr 25 13:54:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 13:54:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 13:54:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:17 2018 ] Training epoch: 3650
[ Wed Apr 25 13:54:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:21 2018 ] Eval epoch: 3650
[ Wed Apr 25 13:54:24 2018 ] 	Mean test loss of 1 batches: 0.20485718548297882.
[ Wed Apr 25 13:54:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:54:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:54:24 2018 ] Training epoch: 3651
[ Wed Apr 25 13:54:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:28 2018 ] Training epoch: 3652
[ Wed Apr 25 13:54:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:54:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:54:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:32 2018 ] Training epoch: 3653
[ Wed Apr 25 13:54:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:54:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:54:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:36 2018 ] Training epoch: 3654
[ Wed Apr 25 13:54:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:54:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:54:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:40 2018 ] Training epoch: 3655
[ Wed Apr 25 13:54:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:54:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:54:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:44 2018 ] Eval epoch: 3655
[ Wed Apr 25 13:54:47 2018 ] 	Mean test loss of 1 batches: 0.20830100774765015.
[ Wed Apr 25 13:54:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:54:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:54:47 2018 ] Training epoch: 3656
[ Wed Apr 25 13:54:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:51 2018 ] Training epoch: 3657
[ Wed Apr 25 13:54:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:55 2018 ] Training epoch: 3658
[ Wed Apr 25 13:54:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:54:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:54:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:54:59 2018 ] Training epoch: 3659
[ Wed Apr 25 13:55:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:03 2018 ] Training epoch: 3660
[ Wed Apr 25 13:55:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:07 2018 ] Eval epoch: 3660
[ Wed Apr 25 13:55:10 2018 ] 	Mean test loss of 1 batches: 0.22025200724601746.
[ Wed Apr 25 13:55:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:55:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:55:10 2018 ] Training epoch: 3661
[ Wed Apr 25 13:55:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:55:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:55:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:14 2018 ] Training epoch: 3662
[ Wed Apr 25 13:55:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:55:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:55:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:19 2018 ] Training epoch: 3663
[ Wed Apr 25 13:55:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:55:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:55:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:23 2018 ] Training epoch: 3664
[ Wed Apr 25 13:55:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:27 2018 ] Training epoch: 3665
[ Wed Apr 25 13:55:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:55:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:55:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:31 2018 ] Eval epoch: 3665
[ Wed Apr 25 13:55:34 2018 ] 	Mean test loss of 1 batches: 0.2270471602678299.
[ Wed Apr 25 13:55:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:55:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:55:34 2018 ] Training epoch: 3666
[ Wed Apr 25 13:55:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:55:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:55:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:38 2018 ] Training epoch: 3667
[ Wed Apr 25 13:55:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:42 2018 ] Training epoch: 3668
[ Wed Apr 25 13:55:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:55:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:55:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:46 2018 ] Training epoch: 3669
[ Wed Apr 25 13:55:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:50 2018 ] Training epoch: 3670
[ Wed Apr 25 13:55:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:55:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:55:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:55:54 2018 ] Eval epoch: 3670
[ Wed Apr 25 13:55:57 2018 ] 	Mean test loss of 1 batches: 0.22345036268234253.
[ Wed Apr 25 13:55:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:55:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:55:57 2018 ] Training epoch: 3671
[ Wed Apr 25 13:56:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:56:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:56:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:01 2018 ] Training epoch: 3672
[ Wed Apr 25 13:56:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:05 2018 ] Training epoch: 3673
[ Wed Apr 25 13:56:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:56:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:56:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:09 2018 ] Training epoch: 3674
[ Wed Apr 25 13:56:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:13 2018 ] Training epoch: 3675
[ Wed Apr 25 13:56:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:17 2018 ] Eval epoch: 3675
[ Wed Apr 25 13:56:20 2018 ] 	Mean test loss of 1 batches: 0.22425949573516846.
[ Wed Apr 25 13:56:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:56:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:56:20 2018 ] Training epoch: 3676
[ Wed Apr 25 13:56:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:24 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:56:24 2018 ] Training epoch: 3677
[ Wed Apr 25 13:56:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:28 2018 ] Training epoch: 3678
[ Wed Apr 25 13:56:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:56:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:56:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:32 2018 ] Training epoch: 3679
[ Wed Apr 25 13:56:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:56:36 2018 ] Training epoch: 3680
[ Wed Apr 25 13:56:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:56:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:56:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:40 2018 ] Eval epoch: 3680
[ Wed Apr 25 13:56:43 2018 ] 	Mean test loss of 1 batches: 0.22104841470718384.
[ Wed Apr 25 13:56:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:56:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:56:43 2018 ] Training epoch: 3681
[ Wed Apr 25 13:56:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:56:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:56:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:47 2018 ] Training epoch: 3682
[ Wed Apr 25 13:56:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:51 2018 ] Training epoch: 3683
[ Wed Apr 25 13:56:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:56:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:56:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:55 2018 ] Training epoch: 3684
[ Wed Apr 25 13:56:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:56:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:56:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:56:59 2018 ] Training epoch: 3685
[ Wed Apr 25 13:57:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:57:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:57:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:03 2018 ] Eval epoch: 3685
[ Wed Apr 25 13:57:06 2018 ] 	Mean test loss of 1 batches: 0.22000190615653992.
[ Wed Apr 25 13:57:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:57:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:57:06 2018 ] Training epoch: 3686
[ Wed Apr 25 13:57:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:10 2018 ] Training epoch: 3687
[ Wed Apr 25 13:57:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:14 2018 ] Training epoch: 3688
[ Wed Apr 25 13:57:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:18 2018 ] Training epoch: 3689
[ Wed Apr 25 13:57:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:22 2018 ] Training epoch: 3690
[ Wed Apr 25 13:57:26 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 13:57:26 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 13:57:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:57:26 2018 ] Eval epoch: 3690
[ Wed Apr 25 13:57:29 2018 ] 	Mean test loss of 1 batches: 0.21953459084033966.
[ Wed Apr 25 13:57:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:57:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:57:29 2018 ] Training epoch: 3691
[ Wed Apr 25 13:57:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:33 2018 ] Training epoch: 3692
[ Wed Apr 25 13:57:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:37 2018 ] Training epoch: 3693
[ Wed Apr 25 13:57:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:41 2018 ] Training epoch: 3694
[ Wed Apr 25 13:57:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:57:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:57:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:45 2018 ] Training epoch: 3695
[ Wed Apr 25 13:57:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:57:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:57:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:50 2018 ] Eval epoch: 3695
[ Wed Apr 25 13:57:52 2018 ] 	Mean test loss of 1 batches: 0.21117399632930756.
[ Wed Apr 25 13:57:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:57:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:57:52 2018 ] Training epoch: 3696
[ Wed Apr 25 13:57:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:57:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:57:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:57:56 2018 ] Training epoch: 3697
[ Wed Apr 25 13:58:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:00 2018 ] Training epoch: 3698
[ Wed Apr 25 13:58:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:05 2018 ] Training epoch: 3699
[ Wed Apr 25 13:58:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:58:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:58:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:09 2018 ] Training epoch: 3700
[ Wed Apr 25 13:58:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:13 2018 ] Eval epoch: 3700
[ Wed Apr 25 13:58:15 2018 ] 	Mean test loss of 1 batches: 0.22399327158927917.
[ Wed Apr 25 13:58:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:58:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:58:15 2018 ] Training epoch: 3701
[ Wed Apr 25 13:58:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:58:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:58:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:20 2018 ] Training epoch: 3702
[ Wed Apr 25 13:58:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:24 2018 ] Training epoch: 3703
[ Wed Apr 25 13:58:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:58:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:58:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:28 2018 ] Training epoch: 3704
[ Wed Apr 25 13:58:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:32 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 13:58:32 2018 ] Training epoch: 3705
[ Wed Apr 25 13:58:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:58:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:58:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 13:58:36 2018 ] Eval epoch: 3705
[ Wed Apr 25 13:58:39 2018 ] 	Mean test loss of 1 batches: 0.23019973933696747.
[ Wed Apr 25 13:58:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:58:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:58:39 2018 ] Training epoch: 3706
[ Wed Apr 25 13:58:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:43 2018 ] Training epoch: 3707
[ Wed Apr 25 13:58:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:47 2018 ] Training epoch: 3708
[ Wed Apr 25 13:58:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:51 2018 ] Training epoch: 3709
[ Wed Apr 25 13:58:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:55 2018 ] Training epoch: 3710
[ Wed Apr 25 13:58:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:58:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:58:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:58:59 2018 ] Eval epoch: 3710
[ Wed Apr 25 13:59:02 2018 ] 	Mean test loss of 1 batches: 0.2172151505947113.
[ Wed Apr 25 13:59:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:59:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:59:02 2018 ] Training epoch: 3711
[ Wed Apr 25 13:59:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:59:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:59:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:06 2018 ] Training epoch: 3712
[ Wed Apr 25 13:59:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:59:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:59:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:10 2018 ] Training epoch: 3713
[ Wed Apr 25 13:59:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:59:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:59:14 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 13:59:14 2018 ] Training epoch: 3714
[ Wed Apr 25 13:59:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:59:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:59:19 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 13:59:19 2018 ] Training epoch: 3715
[ Wed Apr 25 13:59:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:59:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:59:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:23 2018 ] Eval epoch: 3715
[ Wed Apr 25 13:59:26 2018 ] 	Mean test loss of 1 batches: 0.21961893141269684.
[ Wed Apr 25 13:59:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:59:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:59:26 2018 ] Training epoch: 3716
[ Wed Apr 25 13:59:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:59:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:59:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:30 2018 ] Training epoch: 3717
[ Wed Apr 25 13:59:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:59:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:59:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:34 2018 ] Training epoch: 3718
[ Wed Apr 25 13:59:38 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.001000
[ Wed Apr 25 13:59:38 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 13:59:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:38 2018 ] Training epoch: 3719
[ Wed Apr 25 13:59:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 13:59:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 13:59:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:42 2018 ] Training epoch: 3720
[ Wed Apr 25 13:59:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:59:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:59:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:46 2018 ] Eval epoch: 3720
[ Wed Apr 25 13:59:49 2018 ] 	Mean test loss of 1 batches: 0.22100341320037842.
[ Wed Apr 25 13:59:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 13:59:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 13:59:49 2018 ] Training epoch: 3721
[ Wed Apr 25 13:59:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 13:59:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 13:59:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:53 2018 ] Training epoch: 3722
[ Wed Apr 25 13:59:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 13:59:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 13:59:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 13:59:57 2018 ] Training epoch: 3723
[ Wed Apr 25 14:00:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:01 2018 ] Training epoch: 3724
[ Wed Apr 25 14:00:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:00:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:00:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:05 2018 ] Training epoch: 3725
[ Wed Apr 25 14:00:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:09 2018 ] Eval epoch: 3725
[ Wed Apr 25 14:00:12 2018 ] 	Mean test loss of 1 batches: 0.21899643540382385.
[ Wed Apr 25 14:00:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:00:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:00:12 2018 ] Training epoch: 3726
[ Wed Apr 25 14:00:16 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:00:16 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:00:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:16 2018 ] Training epoch: 3727
[ Wed Apr 25 14:00:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:00:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:00:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:20 2018 ] Training epoch: 3728
[ Wed Apr 25 14:00:24 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 14:00:24 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:00:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:24 2018 ] Training epoch: 3729
[ Wed Apr 25 14:00:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:00:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:00:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:28 2018 ] Training epoch: 3730
[ Wed Apr 25 14:00:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:32 2018 ] Eval epoch: 3730
[ Wed Apr 25 14:00:35 2018 ] 	Mean test loss of 1 batches: 0.21420319378376007.
[ Wed Apr 25 14:00:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:00:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:00:35 2018 ] Training epoch: 3731
[ Wed Apr 25 14:00:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:00:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:00:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:39 2018 ] Training epoch: 3732
[ Wed Apr 25 14:00:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:00:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:00:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:43 2018 ] Training epoch: 3733
[ Wed Apr 25 14:00:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:47 2018 ] Training epoch: 3734
[ Wed Apr 25 14:00:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:51 2018 ] Training epoch: 3735
[ Wed Apr 25 14:00:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:00:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:00:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:00:55 2018 ] Eval epoch: 3735
[ Wed Apr 25 14:00:57 2018 ] 	Mean test loss of 1 batches: 0.21450920403003693.
[ Wed Apr 25 14:00:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:00:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:00:57 2018 ] Training epoch: 3736
[ Wed Apr 25 14:01:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:01 2018 ] Training epoch: 3737
[ Wed Apr 25 14:01:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:01:06 2018 ] Training epoch: 3738
[ Wed Apr 25 14:01:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:10 2018 ] Training epoch: 3739
[ Wed Apr 25 14:01:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:14 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:01:14 2018 ] Training epoch: 3740
[ Wed Apr 25 14:01:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:01:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:01:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:18 2018 ] Eval epoch: 3740
[ Wed Apr 25 14:01:21 2018 ] 	Mean test loss of 1 batches: 0.21218504011631012.
[ Wed Apr 25 14:01:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:01:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:01:21 2018 ] Training epoch: 3741
[ Wed Apr 25 14:01:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:25 2018 ] Training epoch: 3742
[ Wed Apr 25 14:01:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:01:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:01:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:29 2018 ] Training epoch: 3743
[ Wed Apr 25 14:01:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:01:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:01:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:33 2018 ] Training epoch: 3744
[ Wed Apr 25 14:01:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:01:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:01:37 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 14:01:37 2018 ] Training epoch: 3745
[ Wed Apr 25 14:01:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:01:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:01:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:41 2018 ] Eval epoch: 3745
[ Wed Apr 25 14:01:44 2018 ] 	Mean test loss of 1 batches: 0.21430979669094086.
[ Wed Apr 25 14:01:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:01:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:01:44 2018 ] Training epoch: 3746
[ Wed Apr 25 14:01:48 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 14:01:48 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:01:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:48 2018 ] Training epoch: 3747
[ Wed Apr 25 14:01:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:52 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:01:52 2018 ] Training epoch: 3748
[ Wed Apr 25 14:01:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:01:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:01:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:01:56 2018 ] Training epoch: 3749
[ Wed Apr 25 14:02:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:02:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:02:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:00 2018 ] Training epoch: 3750
[ Wed Apr 25 14:02:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:02:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:02:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:04 2018 ] Eval epoch: 3750
[ Wed Apr 25 14:02:07 2018 ] 	Mean test loss of 1 batches: 0.21358288824558258.
[ Wed Apr 25 14:02:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:02:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:02:07 2018 ] Training epoch: 3751
[ Wed Apr 25 14:02:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:02:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:02:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:11 2018 ] Training epoch: 3752
[ Wed Apr 25 14:02:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:02:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:02:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:15 2018 ] Training epoch: 3753
[ Wed Apr 25 14:02:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:02:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:02:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:19 2018 ] Training epoch: 3754
[ Wed Apr 25 14:02:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:02:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:02:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:23 2018 ] Training epoch: 3755
[ Wed Apr 25 14:02:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:02:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:02:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:27 2018 ] Eval epoch: 3755
[ Wed Apr 25 14:02:30 2018 ] 	Mean test loss of 1 batches: 0.2186860889196396.
[ Wed Apr 25 14:02:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:02:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:02:30 2018 ] Training epoch: 3756
[ Wed Apr 25 14:02:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:02:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:02:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:34 2018 ] Training epoch: 3757
[ Wed Apr 25 14:02:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:02:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:02:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:38 2018 ] Training epoch: 3758
[ Wed Apr 25 14:02:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:02:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:02:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:42 2018 ] Training epoch: 3759
[ Wed Apr 25 14:02:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:02:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:02:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:46 2018 ] Training epoch: 3760
[ Wed Apr 25 14:02:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:02:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:02:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:02:50 2018 ] Eval epoch: 3760
[ Wed Apr 25 14:02:53 2018 ] 	Mean test loss of 1 batches: 0.20745742321014404.
[ Wed Apr 25 14:02:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:02:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:02:53 2018 ] Training epoch: 3761
[ Wed Apr 25 14:02:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:02:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:02:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:02:57 2018 ] Training epoch: 3762
[ Wed Apr 25 14:03:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:03:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:03:01 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:03:01 2018 ] Training epoch: 3763
[ Wed Apr 25 14:03:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:03:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:03:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:05 2018 ] Training epoch: 3764
[ Wed Apr 25 14:03:09 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:03:09 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:03:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:10 2018 ] Training epoch: 3765
[ Wed Apr 25 14:03:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:03:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:03:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:03:14 2018 ] Eval epoch: 3765
[ Wed Apr 25 14:03:16 2018 ] 	Mean test loss of 1 batches: 0.21243199706077576.
[ Wed Apr 25 14:03:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:03:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:03:16 2018 ] Training epoch: 3766
[ Wed Apr 25 14:03:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:03:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:03:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:21 2018 ] Training epoch: 3767
[ Wed Apr 25 14:03:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:03:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:03:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:25 2018 ] Training epoch: 3768
[ Wed Apr 25 14:03:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:03:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:03:29 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:03:29 2018 ] Training epoch: 3769
[ Wed Apr 25 14:03:33 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.001000
[ Wed Apr 25 14:03:33 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 14:03:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:33 2018 ] Training epoch: 3770
[ Wed Apr 25 14:03:37 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 14:03:37 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:03:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:03:37 2018 ] Eval epoch: 3770
[ Wed Apr 25 14:03:40 2018 ] 	Mean test loss of 1 batches: 0.2282027155160904.
[ Wed Apr 25 14:03:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:03:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:03:40 2018 ] Training epoch: 3771
[ Wed Apr 25 14:03:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:03:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:03:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:44 2018 ] Training epoch: 3772
[ Wed Apr 25 14:03:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:03:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:03:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:48 2018 ] Training epoch: 3773
[ Wed Apr 25 14:03:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:03:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:03:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:03:52 2018 ] Training epoch: 3774
[ Wed Apr 25 14:03:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:03:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:03:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:03:57 2018 ] Training epoch: 3775
[ Wed Apr 25 14:04:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:01 2018 ] Eval epoch: 3775
[ Wed Apr 25 14:04:04 2018 ] 	Mean test loss of 1 batches: 0.22724229097366333.
[ Wed Apr 25 14:04:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:04:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:04:04 2018 ] Training epoch: 3776
[ Wed Apr 25 14:04:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:08 2018 ] Training epoch: 3777
[ Wed Apr 25 14:04:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:04:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:04:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:12 2018 ] Training epoch: 3778
[ Wed Apr 25 14:04:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:04:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:04:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:16 2018 ] Training epoch: 3779
[ Wed Apr 25 14:04:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:20 2018 ] Training epoch: 3780
[ Wed Apr 25 14:04:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:24 2018 ] Eval epoch: 3780
[ Wed Apr 25 14:04:27 2018 ] 	Mean test loss of 1 batches: 0.2361965924501419.
[ Wed Apr 25 14:04:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:04:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:04:27 2018 ] Training epoch: 3781
[ Wed Apr 25 14:04:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:31 2018 ] Training epoch: 3782
[ Wed Apr 25 14:04:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:04:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:04:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:35 2018 ] Training epoch: 3783
[ Wed Apr 25 14:04:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:04:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:04:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:39 2018 ] Training epoch: 3784
[ Wed Apr 25 14:04:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:04:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:04:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:43 2018 ] Training epoch: 3785
[ Wed Apr 25 14:04:47 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 14:04:47 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:04:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:47 2018 ] Eval epoch: 3785
[ Wed Apr 25 14:04:50 2018 ] 	Mean test loss of 1 batches: 0.23497138917446136.
[ Wed Apr 25 14:04:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:04:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:04:50 2018 ] Training epoch: 3786
[ Wed Apr 25 14:04:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:04:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:04:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:04:54 2018 ] Training epoch: 3787
[ Wed Apr 25 14:04:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:04:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:04:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:04:58 2018 ] Training epoch: 3788
[ Wed Apr 25 14:05:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:05:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:05:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:02 2018 ] Training epoch: 3789
[ Wed Apr 25 14:05:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:05:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:05:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:06 2018 ] Training epoch: 3790
[ Wed Apr 25 14:05:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:05:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:05:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:10 2018 ] Eval epoch: 3790
[ Wed Apr 25 14:05:13 2018 ] 	Mean test loss of 1 batches: 0.22880035638809204.
[ Wed Apr 25 14:05:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:05:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:05:13 2018 ] Training epoch: 3791
[ Wed Apr 25 14:05:17 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 14:05:17 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:05:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:17 2018 ] Training epoch: 3792
[ Wed Apr 25 14:05:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:05:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:05:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:21 2018 ] Training epoch: 3793
[ Wed Apr 25 14:05:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:05:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:05:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:25 2018 ] Training epoch: 3794
[ Wed Apr 25 14:05:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:05:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:05:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:29 2018 ] Training epoch: 3795
[ Wed Apr 25 14:05:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:05:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:05:34 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:05:34 2018 ] Eval epoch: 3795
[ Wed Apr 25 14:05:36 2018 ] 	Mean test loss of 1 batches: 0.22471992671489716.
[ Wed Apr 25 14:05:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:05:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:05:36 2018 ] Training epoch: 3796
[ Wed Apr 25 14:05:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:05:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:05:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:40 2018 ] Training epoch: 3797
[ Wed Apr 25 14:05:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:05:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:05:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:45 2018 ] Training epoch: 3798
[ Wed Apr 25 14:05:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:05:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:05:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:49 2018 ] Training epoch: 3799
[ Wed Apr 25 14:05:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:05:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:05:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:05:53 2018 ] Training epoch: 3800
[ Wed Apr 25 14:05:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:05:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:05:57 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 14:05:57 2018 ] Eval epoch: 3800
[ Wed Apr 25 14:06:00 2018 ] 	Mean test loss of 1 batches: 0.22454604506492615.
[ Wed Apr 25 14:06:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:06:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:06:00 2018 ] Training epoch: 3801
[ Wed Apr 25 14:06:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:06:04 2018 ] Training epoch: 3802
[ Wed Apr 25 14:06:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:06:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:06:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:08 2018 ] Training epoch: 3803
[ Wed Apr 25 14:06:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:13 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:06:13 2018 ] Training epoch: 3804
[ Wed Apr 25 14:06:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:06:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:06:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:06:17 2018 ] Training epoch: 3805
[ Wed Apr 25 14:06:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:21 2018 ] Eval epoch: 3805
[ Wed Apr 25 14:06:24 2018 ] 	Mean test loss of 1 batches: 0.23329736292362213.
[ Wed Apr 25 14:06:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:06:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:06:24 2018 ] Training epoch: 3806
[ Wed Apr 25 14:06:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:06:28 2018 ] Training epoch: 3807
[ Wed Apr 25 14:06:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:33 2018 ] Training epoch: 3808
[ Wed Apr 25 14:06:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:06:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:06:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:37 2018 ] Training epoch: 3809
[ Wed Apr 25 14:06:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:41 2018 ] Training epoch: 3810
[ Wed Apr 25 14:06:45 2018 ] 	Batch(0/1) done. Loss: 0.0000  lr:0.001000
[ Wed Apr 25 14:06:45 2018 ] 	Mean training loss: 0.0000.
[ Wed Apr 25 14:06:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:45 2018 ] Eval epoch: 3810
[ Wed Apr 25 14:06:48 2018 ] 	Mean test loss of 1 batches: 0.22098414599895477.
[ Wed Apr 25 14:06:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:06:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:06:48 2018 ] Training epoch: 3811
[ Wed Apr 25 14:06:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:52 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 14:06:52 2018 ] Training epoch: 3812
[ Wed Apr 25 14:06:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:06:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:06:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:06:56 2018 ] Training epoch: 3813
[ Wed Apr 25 14:07:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:07:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:07:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:00 2018 ] Training epoch: 3814
[ Wed Apr 25 14:07:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:07:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:07:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:04 2018 ] Training epoch: 3815
[ Wed Apr 25 14:07:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:07:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:07:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:08 2018 ] Eval epoch: 3815
[ Wed Apr 25 14:07:11 2018 ] 	Mean test loss of 1 batches: 0.21664322912693024.
[ Wed Apr 25 14:07:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:07:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:07:11 2018 ] Training epoch: 3816
[ Wed Apr 25 14:07:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:07:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:07:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:15 2018 ] Training epoch: 3817
[ Wed Apr 25 14:07:19 2018 ] 	Batch(0/1) done. Loss: 0.0012  lr:0.001000
[ Wed Apr 25 14:07:19 2018 ] 	Mean training loss: 0.0012.
[ Wed Apr 25 14:07:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:19 2018 ] Training epoch: 3818
[ Wed Apr 25 14:07:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:07:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:07:23 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:07:23 2018 ] Training epoch: 3819
[ Wed Apr 25 14:07:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:07:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:07:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:07:27 2018 ] Training epoch: 3820
[ Wed Apr 25 14:07:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:07:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:07:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:07:32 2018 ] Eval epoch: 3820
[ Wed Apr 25 14:07:35 2018 ] 	Mean test loss of 1 batches: 0.2126915603876114.
[ Wed Apr 25 14:07:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:07:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:07:35 2018 ] Training epoch: 3821
[ Wed Apr 25 14:07:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:07:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:07:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:07:39 2018 ] Training epoch: 3822
[ Wed Apr 25 14:07:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:07:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:07:43 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:07:43 2018 ] Training epoch: 3823
[ Wed Apr 25 14:07:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:07:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:07:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:47 2018 ] Training epoch: 3824
[ Wed Apr 25 14:07:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:07:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:07:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:51 2018 ] Training epoch: 3825
[ Wed Apr 25 14:07:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:07:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:07:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:07:55 2018 ] Eval epoch: 3825
[ Wed Apr 25 14:07:58 2018 ] 	Mean test loss of 1 batches: 0.2259386032819748.
[ Wed Apr 25 14:07:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:07:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:07:58 2018 ] Training epoch: 3826
[ Wed Apr 25 14:08:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:02 2018 ] Training epoch: 3827
[ Wed Apr 25 14:08:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:06 2018 ] Training epoch: 3828
[ Wed Apr 25 14:08:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:10 2018 ] Training epoch: 3829
[ Wed Apr 25 14:08:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:14 2018 ] Training epoch: 3830
[ Wed Apr 25 14:08:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:18 2018 ] Eval epoch: 3830
[ Wed Apr 25 14:08:21 2018 ] 	Mean test loss of 1 batches: 0.2224324345588684.
[ Wed Apr 25 14:08:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:08:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:08:21 2018 ] Training epoch: 3831
[ Wed Apr 25 14:08:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:25 2018 ] Training epoch: 3832
[ Wed Apr 25 14:08:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:29 2018 ] Training epoch: 3833
[ Wed Apr 25 14:08:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:33 2018 ] Training epoch: 3834
[ Wed Apr 25 14:08:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:37 2018 ] Training epoch: 3835
[ Wed Apr 25 14:08:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:41 2018 ] Eval epoch: 3835
[ Wed Apr 25 14:08:44 2018 ] 	Mean test loss of 1 batches: 0.22222675383090973.
[ Wed Apr 25 14:08:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:08:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:08:44 2018 ] Training epoch: 3836
[ Wed Apr 25 14:08:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:08:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:08:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:48 2018 ] Training epoch: 3837
[ Wed Apr 25 14:08:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:08:52 2018 ] Training epoch: 3838
[ Wed Apr 25 14:08:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:08:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:08:57 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:08:57 2018 ] Training epoch: 3839
[ Wed Apr 25 14:09:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:09:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:09:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:01 2018 ] Training epoch: 3840
[ Wed Apr 25 14:09:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:05 2018 ] Eval epoch: 3840
[ Wed Apr 25 14:09:08 2018 ] 	Mean test loss of 1 batches: 0.22587072849273682.
[ Wed Apr 25 14:09:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:09:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:09:08 2018 ] Training epoch: 3841
[ Wed Apr 25 14:09:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:12 2018 ] Training epoch: 3842
[ Wed Apr 25 14:09:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:16 2018 ] Training epoch: 3843
[ Wed Apr 25 14:09:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:09:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:09:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:20 2018 ] Training epoch: 3844
[ Wed Apr 25 14:09:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:09:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:09:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:24 2018 ] Training epoch: 3845
[ Wed Apr 25 14:09:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:28 2018 ] Eval epoch: 3845
[ Wed Apr 25 14:09:31 2018 ] 	Mean test loss of 1 batches: 0.21628952026367188.
[ Wed Apr 25 14:09:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:09:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:09:31 2018 ] Training epoch: 3846
[ Wed Apr 25 14:09:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:35 2018 ] Training epoch: 3847
[ Wed Apr 25 14:09:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:39 2018 ] Training epoch: 3848
[ Wed Apr 25 14:09:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:09:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:09:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:43 2018 ] Training epoch: 3849
[ Wed Apr 25 14:09:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:09:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:09:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:47 2018 ] Training epoch: 3850
[ Wed Apr 25 14:09:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:52 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:09:52 2018 ] Eval epoch: 3850
[ Wed Apr 25 14:09:55 2018 ] 	Mean test loss of 1 batches: 0.21167507767677307.
[ Wed Apr 25 14:09:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:09:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:09:55 2018 ] Training epoch: 3851
[ Wed Apr 25 14:09:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:09:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:09:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:09:59 2018 ] Training epoch: 3852
[ Wed Apr 25 14:10:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:10:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:10:03 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:10:03 2018 ] Training epoch: 3853
[ Wed Apr 25 14:10:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:10:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:10:07 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:10:07 2018 ] Training epoch: 3854
[ Wed Apr 25 14:10:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:10:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:10:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:11 2018 ] Training epoch: 3855
[ Wed Apr 25 14:10:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:10:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:10:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:15 2018 ] Eval epoch: 3855
[ Wed Apr 25 14:10:18 2018 ] 	Mean test loss of 1 batches: 0.2109144777059555.
[ Wed Apr 25 14:10:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:10:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:10:18 2018 ] Training epoch: 3856
[ Wed Apr 25 14:10:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:22 2018 ] Training epoch: 3857
[ Wed Apr 25 14:10:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:26 2018 ] Training epoch: 3858
[ Wed Apr 25 14:10:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:30 2018 ] Training epoch: 3859
[ Wed Apr 25 14:10:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:10:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:10:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:34 2018 ] Training epoch: 3860
[ Wed Apr 25 14:10:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:10:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:10:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:38 2018 ] Eval epoch: 3860
[ Wed Apr 25 14:10:41 2018 ] 	Mean test loss of 1 batches: 0.208812415599823.
[ Wed Apr 25 14:10:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:10:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:10:41 2018 ] Training epoch: 3861
[ Wed Apr 25 14:10:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:10:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:10:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:45 2018 ] Training epoch: 3862
[ Wed Apr 25 14:10:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:49 2018 ] Training epoch: 3863
[ Wed Apr 25 14:10:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:53 2018 ] Training epoch: 3864
[ Wed Apr 25 14:10:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:10:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:10:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:10:57 2018 ] Training epoch: 3865
[ Wed Apr 25 14:11:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:01 2018 ] Eval epoch: 3865
[ Wed Apr 25 14:11:04 2018 ] 	Mean test loss of 1 batches: 0.21148908138275146.
[ Wed Apr 25 14:11:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:11:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:11:04 2018 ] Training epoch: 3866
[ Wed Apr 25 14:11:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:11:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:11:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:08 2018 ] Training epoch: 3867
[ Wed Apr 25 14:11:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:11:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:11:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:12 2018 ] Training epoch: 3868
[ Wed Apr 25 14:11:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:11:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:11:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:16 2018 ] Training epoch: 3869
[ Wed Apr 25 14:11:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:20 2018 ] Training epoch: 3870
[ Wed Apr 25 14:11:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:24 2018 ] Eval epoch: 3870
[ Wed Apr 25 14:11:27 2018 ] 	Mean test loss of 1 batches: 0.21323691308498383.
[ Wed Apr 25 14:11:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:11:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:11:27 2018 ] Training epoch: 3871
[ Wed Apr 25 14:11:31 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:11:31 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:11:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:31 2018 ] Training epoch: 3872
[ Wed Apr 25 14:11:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:36 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 14:11:36 2018 ] Training epoch: 3873
[ Wed Apr 25 14:11:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:40 2018 ] Training epoch: 3874
[ Wed Apr 25 14:11:44 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 14:11:44 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:11:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:44 2018 ] Training epoch: 3875
[ Wed Apr 25 14:11:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:11:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:11:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:48 2018 ] Eval epoch: 3875
[ Wed Apr 25 14:11:51 2018 ] 	Mean test loss of 1 batches: 0.19959348440170288.
[ Wed Apr 25 14:11:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:11:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:11:51 2018 ] Training epoch: 3876
[ Wed Apr 25 14:11:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:11:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:11:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:55 2018 ] Training epoch: 3877
[ Wed Apr 25 14:11:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:11:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:11:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:11:59 2018 ] Training epoch: 3878
[ Wed Apr 25 14:12:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:12:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:12:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:03 2018 ] Training epoch: 3879
[ Wed Apr 25 14:12:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:07 2018 ] Training epoch: 3880
[ Wed Apr 25 14:12:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:12:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:12:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:11 2018 ] Eval epoch: 3880
[ Wed Apr 25 14:12:14 2018 ] 	Mean test loss of 1 batches: 0.20621070265769958.
[ Wed Apr 25 14:12:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:12:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:12:14 2018 ] Training epoch: 3881
[ Wed Apr 25 14:12:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:12:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:12:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:18 2018 ] Training epoch: 3882
[ Wed Apr 25 14:12:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:22 2018 ] Training epoch: 3883
[ Wed Apr 25 14:12:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:12:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:12:26 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:12:26 2018 ] Training epoch: 3884
[ Wed Apr 25 14:12:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:30 2018 ] Training epoch: 3885
[ Wed Apr 25 14:12:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:34 2018 ] Eval epoch: 3885
[ Wed Apr 25 14:12:37 2018 ] 	Mean test loss of 1 batches: 0.20474638044834137.
[ Wed Apr 25 14:12:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:12:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:12:37 2018 ] Training epoch: 3886
[ Wed Apr 25 14:12:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:12:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:12:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:41 2018 ] Training epoch: 3887
[ Wed Apr 25 14:12:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:45 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:12:45 2018 ] Training epoch: 3888
[ Wed Apr 25 14:12:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:49 2018 ] Training epoch: 3889
[ Wed Apr 25 14:12:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:12:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:12:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:53 2018 ] Training epoch: 3890
[ Wed Apr 25 14:12:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:12:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:12:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:12:57 2018 ] Eval epoch: 3890
[ Wed Apr 25 14:13:00 2018 ] 	Mean test loss of 1 batches: 0.209994375705719.
[ Wed Apr 25 14:13:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:13:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:13:00 2018 ] Training epoch: 3891
[ Wed Apr 25 14:13:04 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 14:13:04 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:13:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:04 2018 ] Training epoch: 3892
[ Wed Apr 25 14:13:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:08 2018 ] Training epoch: 3893
[ Wed Apr 25 14:13:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:13:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:13:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:12 2018 ] Training epoch: 3894
[ Wed Apr 25 14:13:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:13:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:13:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:16 2018 ] Training epoch: 3895
[ Wed Apr 25 14:13:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:20 2018 ] Eval epoch: 3895
[ Wed Apr 25 14:13:23 2018 ] 	Mean test loss of 1 batches: 0.21429777145385742.
[ Wed Apr 25 14:13:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:13:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:13:23 2018 ] Training epoch: 3896
[ Wed Apr 25 14:13:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:27 2018 ] Training epoch: 3897
[ Wed Apr 25 14:13:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:13:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:13:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:31 2018 ] Training epoch: 3898
[ Wed Apr 25 14:13:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:35 2018 ] Training epoch: 3899
[ Wed Apr 25 14:13:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:13:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:13:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:39 2018 ] Training epoch: 3900
[ Wed Apr 25 14:13:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:43 2018 ] Eval epoch: 3900
[ Wed Apr 25 14:13:46 2018 ] 	Mean test loss of 1 batches: 0.2183474451303482.
[ Wed Apr 25 14:13:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:13:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:13:46 2018 ] Training epoch: 3901
[ Wed Apr 25 14:13:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:13:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:13:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:50 2018 ] Training epoch: 3902
[ Wed Apr 25 14:13:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:54 2018 ] Training epoch: 3903
[ Wed Apr 25 14:13:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:13:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:13:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:13:58 2018 ] Training epoch: 3904
[ Wed Apr 25 14:14:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:14:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:14:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:02 2018 ] Training epoch: 3905
[ Wed Apr 25 14:14:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:14:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:14:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:06 2018 ] Eval epoch: 3905
[ Wed Apr 25 14:14:09 2018 ] 	Mean test loss of 1 batches: 0.21740904450416565.
[ Wed Apr 25 14:14:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:14:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:14:09 2018 ] Training epoch: 3906
[ Wed Apr 25 14:14:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:14:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:14:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:13 2018 ] Training epoch: 3907
[ Wed Apr 25 14:14:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:14:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:14:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:17 2018 ] Training epoch: 3908
[ Wed Apr 25 14:14:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:14:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:14:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:21 2018 ] Training epoch: 3909
[ Wed Apr 25 14:14:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:14:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:14:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:25 2018 ] Training epoch: 3910
[ Wed Apr 25 14:14:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:14:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:14:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:29 2018 ] Eval epoch: 3910
[ Wed Apr 25 14:14:32 2018 ] 	Mean test loss of 1 batches: 0.21129386126995087.
[ Wed Apr 25 14:14:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:14:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:14:32 2018 ] Training epoch: 3911
[ Wed Apr 25 14:14:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:14:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:14:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:36 2018 ] Training epoch: 3912
[ Wed Apr 25 14:14:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:14:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:14:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:40 2018 ] Training epoch: 3913
[ Wed Apr 25 14:14:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:14:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:14:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:44 2018 ] Training epoch: 3914
[ Wed Apr 25 14:14:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:14:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:14:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:48 2018 ] Training epoch: 3915
[ Wed Apr 25 14:14:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:14:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:14:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:14:52 2018 ] Eval epoch: 3915
[ Wed Apr 25 14:14:56 2018 ] 	Mean test loss of 1 batches: 0.20964491367340088.
[ Wed Apr 25 14:14:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:14:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:14:56 2018 ] Training epoch: 3916
[ Wed Apr 25 14:15:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:00 2018 ] Training epoch: 3917
[ Wed Apr 25 14:15:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:15:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:15:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:04 2018 ] Training epoch: 3918
[ Wed Apr 25 14:15:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:08 2018 ] Training epoch: 3919
[ Wed Apr 25 14:15:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:12 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:15:12 2018 ] Training epoch: 3920
[ Wed Apr 25 14:15:16 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.001000
[ Wed Apr 25 14:15:16 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:15:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:16 2018 ] Eval epoch: 3920
[ Wed Apr 25 14:15:19 2018 ] 	Mean test loss of 1 batches: 0.21965600550174713.
[ Wed Apr 25 14:15:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:15:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:15:19 2018 ] Training epoch: 3921
[ Wed Apr 25 14:15:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:15:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:15:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:23 2018 ] Training epoch: 3922
[ Wed Apr 25 14:15:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:15:27 2018 ] Training epoch: 3923
[ Wed Apr 25 14:15:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:31 2018 ] Training epoch: 3924
[ Wed Apr 25 14:15:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:15:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:15:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:35 2018 ] Training epoch: 3925
[ Wed Apr 25 14:15:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:15:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:15:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:39 2018 ] Eval epoch: 3925
[ Wed Apr 25 14:15:42 2018 ] 	Mean test loss of 1 batches: 0.21719032526016235.
[ Wed Apr 25 14:15:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:15:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:15:42 2018 ] Training epoch: 3926
[ Wed Apr 25 14:15:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:15:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:15:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:46 2018 ] Training epoch: 3927
[ Wed Apr 25 14:15:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:15:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:15:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:50 2018 ] Training epoch: 3928
[ Wed Apr 25 14:15:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:15:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:15:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:54 2018 ] Training epoch: 3929
[ Wed Apr 25 14:15:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:15:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:15:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:15:58 2018 ] Training epoch: 3930
[ Wed Apr 25 14:16:03 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.001000
[ Wed Apr 25 14:16:03 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 14:16:03 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 14:16:03 2018 ] Eval epoch: 3930
[ Wed Apr 25 14:16:06 2018 ] 	Mean test loss of 1 batches: 0.2262805551290512.
[ Wed Apr 25 14:16:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:16:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:16:06 2018 ] Training epoch: 3931
[ Wed Apr 25 14:16:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:16:10 2018 ] Training epoch: 3932
[ Wed Apr 25 14:16:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:16:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:16:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:14 2018 ] Training epoch: 3933
[ Wed Apr 25 14:16:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:16:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:16:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:18 2018 ] Training epoch: 3934
[ Wed Apr 25 14:16:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:22 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:16:22 2018 ] Training epoch: 3935
[ Wed Apr 25 14:16:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:16:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:16:27 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:16:27 2018 ] Eval epoch: 3935
[ Wed Apr 25 14:16:29 2018 ] 	Mean test loss of 1 batches: 0.22248347103595734.
[ Wed Apr 25 14:16:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:16:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:16:29 2018 ] Training epoch: 3936
[ Wed Apr 25 14:16:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:34 2018 ] Training epoch: 3937
[ Wed Apr 25 14:16:38 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:16:38 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:16:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:38 2018 ] Training epoch: 3938
[ Wed Apr 25 14:16:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:42 2018 ] Training epoch: 3939
[ Wed Apr 25 14:16:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:46 2018 ] Training epoch: 3940
[ Wed Apr 25 14:16:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:50 2018 ] Eval epoch: 3940
[ Wed Apr 25 14:16:53 2018 ] 	Mean test loss of 1 batches: 0.2124253660440445.
[ Wed Apr 25 14:16:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:16:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:16:53 2018 ] Training epoch: 3941
[ Wed Apr 25 14:16:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:16:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:16:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:16:57 2018 ] Training epoch: 3942
[ Wed Apr 25 14:17:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:17:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:17:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:01 2018 ] Training epoch: 3943
[ Wed Apr 25 14:17:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:17:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:17:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:05 2018 ] Training epoch: 3944
[ Wed Apr 25 14:17:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:17:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:17:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:09 2018 ] Training epoch: 3945
[ Wed Apr 25 14:17:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:17:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:17:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:13 2018 ] Eval epoch: 3945
[ Wed Apr 25 14:17:16 2018 ] 	Mean test loss of 1 batches: 0.21796533465385437.
[ Wed Apr 25 14:17:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:17:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:17:16 2018 ] Training epoch: 3946
[ Wed Apr 25 14:17:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:17:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:17:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:20 2018 ] Training epoch: 3947
[ Wed Apr 25 14:17:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:17:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:17:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:24 2018 ] Training epoch: 3948
[ Wed Apr 25 14:17:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:17:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:17:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:17:28 2018 ] Training epoch: 3949
[ Wed Apr 25 14:17:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:17:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:17:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:32 2018 ] Training epoch: 3950
[ Wed Apr 25 14:17:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:17:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:17:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:36 2018 ] Eval epoch: 3950
[ Wed Apr 25 14:17:39 2018 ] 	Mean test loss of 1 batches: 0.21116121113300323.
[ Wed Apr 25 14:17:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:17:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:17:39 2018 ] Training epoch: 3951
[ Wed Apr 25 14:17:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:17:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:17:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:43 2018 ] Training epoch: 3952
[ Wed Apr 25 14:17:47 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:17:47 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:17:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:17:47 2018 ] Training epoch: 3953
[ Wed Apr 25 14:17:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:17:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:17:51 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:17:51 2018 ] Training epoch: 3954
[ Wed Apr 25 14:17:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:17:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:17:56 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:17:56 2018 ] Training epoch: 3955
[ Wed Apr 25 14:18:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:18:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:18:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:00 2018 ] Eval epoch: 3955
[ Wed Apr 25 14:18:03 2018 ] 	Mean test loss of 1 batches: 0.20744015276432037.
[ Wed Apr 25 14:18:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:18:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:18:03 2018 ] Training epoch: 3956
[ Wed Apr 25 14:18:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:18:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:18:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:07 2018 ] Training epoch: 3957
[ Wed Apr 25 14:18:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:11 2018 ] Training epoch: 3958
[ Wed Apr 25 14:18:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:18:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:18:15 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:18:15 2018 ] Training epoch: 3959
[ Wed Apr 25 14:18:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:18:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:18:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:19 2018 ] Training epoch: 3960
[ Wed Apr 25 14:18:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:18:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:18:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:23 2018 ] Eval epoch: 3960
[ Wed Apr 25 14:18:26 2018 ] 	Mean test loss of 1 batches: 0.21689671277999878.
[ Wed Apr 25 14:18:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:18:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:18:26 2018 ] Training epoch: 3961
[ Wed Apr 25 14:18:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:30 2018 ] Training epoch: 3962
[ Wed Apr 25 14:18:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:18:34 2018 ] Training epoch: 3963
[ Wed Apr 25 14:18:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:38 2018 ] Training epoch: 3964
[ Wed Apr 25 14:18:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:18:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:18:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:42 2018 ] Training epoch: 3965
[ Wed Apr 25 14:18:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:47 2018 ] Eval epoch: 3965
[ Wed Apr 25 14:18:49 2018 ] 	Mean test loss of 1 batches: 0.21233174204826355.
[ Wed Apr 25 14:18:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:18:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:18:49 2018 ] Training epoch: 3966
[ Wed Apr 25 14:18:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:18:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:18:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:18:54 2018 ] Training epoch: 3967
[ Wed Apr 25 14:18:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:18:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:18:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:18:58 2018 ] Training epoch: 3968
[ Wed Apr 25 14:19:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:02 2018 ] Training epoch: 3969
[ Wed Apr 25 14:19:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:19:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:19:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:19:06 2018 ] Training epoch: 3970
[ Wed Apr 25 14:19:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:10 2018 ] Eval epoch: 3970
[ Wed Apr 25 14:19:13 2018 ] 	Mean test loss of 1 batches: 0.22505146265029907.
[ Wed Apr 25 14:19:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:19:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:19:13 2018 ] Training epoch: 3971
[ Wed Apr 25 14:19:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:17 2018 ] Training epoch: 3972
[ Wed Apr 25 14:19:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:19:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:19:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:19:21 2018 ] Training epoch: 3973
[ Wed Apr 25 14:19:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:19:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:19:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:25 2018 ] Training epoch: 3974
[ Wed Apr 25 14:19:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:19:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:19:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:29 2018 ] Training epoch: 3975
[ Wed Apr 25 14:19:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:19:34 2018 ] Eval epoch: 3975
[ Wed Apr 25 14:19:36 2018 ] 	Mean test loss of 1 batches: 0.22228585183620453.
[ Wed Apr 25 14:19:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:19:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:19:36 2018 ] Training epoch: 3976
[ Wed Apr 25 14:19:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:19:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:19:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:40 2018 ] Training epoch: 3977
[ Wed Apr 25 14:19:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:19:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:19:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:45 2018 ] Training epoch: 3978
[ Wed Apr 25 14:19:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:19:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:19:49 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:19:49 2018 ] Training epoch: 3979
[ Wed Apr 25 14:19:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:53 2018 ] Training epoch: 3980
[ Wed Apr 25 14:19:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:19:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:19:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:19:57 2018 ] Eval epoch: 3980
[ Wed Apr 25 14:19:59 2018 ] 	Mean test loss of 1 batches: 0.22760054469108582.
[ Wed Apr 25 14:19:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:19:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:19:59 2018 ] Training epoch: 3981
[ Wed Apr 25 14:20:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:04 2018 ] Training epoch: 3982
[ Wed Apr 25 14:20:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:08 2018 ] Training epoch: 3983
[ Wed Apr 25 14:20:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:20:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:20:12 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:20:12 2018 ] Training epoch: 3984
[ Wed Apr 25 14:20:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:20:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:20:16 2018 ] 	Time consumption: [Data]78%, [Network]21%
[ Wed Apr 25 14:20:16 2018 ] Training epoch: 3985
[ Wed Apr 25 14:20:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:20:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:20:21 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:20:21 2018 ] Eval epoch: 3985
[ Wed Apr 25 14:20:24 2018 ] 	Mean test loss of 1 batches: 0.22684113681316376.
[ Wed Apr 25 14:20:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:20:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:20:24 2018 ] Training epoch: 3986
[ Wed Apr 25 14:20:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:28 2018 ] Training epoch: 3987
[ Wed Apr 25 14:20:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:32 2018 ] Training epoch: 3988
[ Wed Apr 25 14:20:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:36 2018 ] Training epoch: 3989
[ Wed Apr 25 14:20:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:20:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:20:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:40 2018 ] Training epoch: 3990
[ Wed Apr 25 14:20:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:20:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:20:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:44 2018 ] Eval epoch: 3990
[ Wed Apr 25 14:20:47 2018 ] 	Mean test loss of 1 batches: 0.2167794108390808.
[ Wed Apr 25 14:20:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:20:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:20:47 2018 ] Training epoch: 3991
[ Wed Apr 25 14:20:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:20:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:20:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:51 2018 ] Training epoch: 3992
[ Wed Apr 25 14:20:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:20:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:20:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:55 2018 ] Training epoch: 3993
[ Wed Apr 25 14:20:59 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.001000
[ Wed Apr 25 14:20:59 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:20:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:20:59 2018 ] Training epoch: 3994
[ Wed Apr 25 14:21:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:21:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:21:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:03 2018 ] Training epoch: 3995
[ Wed Apr 25 14:21:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:21:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:21:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:07 2018 ] Eval epoch: 3995
[ Wed Apr 25 14:21:10 2018 ] 	Mean test loss of 1 batches: 0.22253157198429108.
[ Wed Apr 25 14:21:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:21:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:21:10 2018 ] Training epoch: 3996
[ Wed Apr 25 14:21:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:21:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:21:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:14 2018 ] Training epoch: 3997
[ Wed Apr 25 14:21:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.001000
[ Wed Apr 25 14:21:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:21:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:18 2018 ] Training epoch: 3998
[ Wed Apr 25 14:21:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.001000
[ Wed Apr 25 14:21:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:21:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:22 2018 ] Training epoch: 3999
[ Wed Apr 25 14:21:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.001000
[ Wed Apr 25 14:21:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:21:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:26 2018 ] Training epoch: 4000
[ Wed Apr 25 14:21:30 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.001000
[ Wed Apr 25 14:21:30 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:21:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:30 2018 ] Eval epoch: 4000
[ Wed Apr 25 14:21:33 2018 ] 	Mean test loss of 1 batches: 0.2138623148202896.
[ Wed Apr 25 14:21:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:21:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:21:33 2018 ] Training epoch: 4001
[ Wed Apr 25 14:21:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:21:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:21:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:37 2018 ] Training epoch: 4002
[ Wed Apr 25 14:21:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:21:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:21:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:41 2018 ] Training epoch: 4003
[ Wed Apr 25 14:21:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:21:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:21:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:45 2018 ] Training epoch: 4004
[ Wed Apr 25 14:21:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:21:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:21:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:49 2018 ] Training epoch: 4005
[ Wed Apr 25 14:21:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:21:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:21:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:21:53 2018 ] Eval epoch: 4005
[ Wed Apr 25 14:21:56 2018 ] 	Mean test loss of 1 batches: 0.21127969026565552.
[ Wed Apr 25 14:21:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:21:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:21:56 2018 ] Training epoch: 4006
[ Wed Apr 25 14:22:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:00 2018 ] Training epoch: 4007
[ Wed Apr 25 14:22:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:04 2018 ] Training epoch: 4008
[ Wed Apr 25 14:22:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:22:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:22:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:08 2018 ] Training epoch: 4009
[ Wed Apr 25 14:22:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:12 2018 ] Training epoch: 4010
[ Wed Apr 25 14:22:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:16 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:22:16 2018 ] Eval epoch: 4010
[ Wed Apr 25 14:22:19 2018 ] 	Mean test loss of 1 batches: 0.21434129774570465.
[ Wed Apr 25 14:22:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:22:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:22:19 2018 ] Training epoch: 4011
[ Wed Apr 25 14:22:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:23 2018 ] Training epoch: 4012
[ Wed Apr 25 14:22:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:27 2018 ] Training epoch: 4013
[ Wed Apr 25 14:22:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:31 2018 ] Training epoch: 4014
[ Wed Apr 25 14:22:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:36 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:22:36 2018 ] Training epoch: 4015
[ Wed Apr 25 14:22:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:40 2018 ] Eval epoch: 4015
[ Wed Apr 25 14:22:43 2018 ] 	Mean test loss of 1 batches: 0.222674161195755.
[ Wed Apr 25 14:22:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:22:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:22:43 2018 ] Training epoch: 4016
[ Wed Apr 25 14:22:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:22:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:22:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:47 2018 ] Training epoch: 4017
[ Wed Apr 25 14:22:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:22:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:22:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:22:51 2018 ] Training epoch: 4018
[ Wed Apr 25 14:22:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:55 2018 ] Training epoch: 4019
[ Wed Apr 25 14:22:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:22:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:22:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:22:59 2018 ] Training epoch: 4020
[ Wed Apr 25 14:23:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:23:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:23:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:03 2018 ] Eval epoch: 4020
[ Wed Apr 25 14:23:06 2018 ] 	Mean test loss of 1 batches: 0.22196826338768005.
[ Wed Apr 25 14:23:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:23:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:23:06 2018 ] Training epoch: 4021
[ Wed Apr 25 14:23:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:23:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:23:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:10 2018 ] Training epoch: 4022
[ Wed Apr 25 14:23:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:23:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:23:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:14 2018 ] Training epoch: 4023
[ Wed Apr 25 14:23:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:23:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:23:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:18 2018 ] Training epoch: 4024
[ Wed Apr 25 14:23:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:23:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:23:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:22 2018 ] Training epoch: 4025
[ Wed Apr 25 14:23:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:23:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:23:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:26 2018 ] Eval epoch: 4025
[ Wed Apr 25 14:23:29 2018 ] 	Mean test loss of 1 batches: 0.20375102758407593.
[ Wed Apr 25 14:23:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:23:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:23:29 2018 ] Training epoch: 4026
[ Wed Apr 25 14:23:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:23:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:23:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:33 2018 ] Training epoch: 4027
[ Wed Apr 25 14:23:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:23:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:23:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:37 2018 ] Training epoch: 4028
[ Wed Apr 25 14:23:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:23:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:23:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:41 2018 ] Training epoch: 4029
[ Wed Apr 25 14:23:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:23:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:23:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:45 2018 ] Training epoch: 4030
[ Wed Apr 25 14:23:49 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:23:49 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:23:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:49 2018 ] Eval epoch: 4030
[ Wed Apr 25 14:23:52 2018 ] 	Mean test loss of 1 batches: 0.20798003673553467.
[ Wed Apr 25 14:23:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:23:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:23:52 2018 ] Training epoch: 4031
[ Wed Apr 25 14:23:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:23:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:23:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:23:56 2018 ] Training epoch: 4032
[ Wed Apr 25 14:24:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:00 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:24:00 2018 ] Training epoch: 4033
[ Wed Apr 25 14:24:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:24:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:24:04 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 14:24:04 2018 ] Training epoch: 4034
[ Wed Apr 25 14:24:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:08 2018 ] Training epoch: 4035
[ Wed Apr 25 14:24:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:12 2018 ] Eval epoch: 4035
[ Wed Apr 25 14:24:15 2018 ] 	Mean test loss of 1 batches: 0.21525724232196808.
[ Wed Apr 25 14:24:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:24:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:24:15 2018 ] Training epoch: 4036
[ Wed Apr 25 14:24:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:24:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:24:19 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:24:19 2018 ] Training epoch: 4037
[ Wed Apr 25 14:24:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:23 2018 ] Training epoch: 4038
[ Wed Apr 25 14:24:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:24:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:24:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:24:28 2018 ] Training epoch: 4039
[ Wed Apr 25 14:24:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:32 2018 ] Training epoch: 4040
[ Wed Apr 25 14:24:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:24:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:24:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:36 2018 ] Eval epoch: 4040
[ Wed Apr 25 14:24:39 2018 ] 	Mean test loss of 1 batches: 0.2179051637649536.
[ Wed Apr 25 14:24:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:24:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:24:39 2018 ] Training epoch: 4041
[ Wed Apr 25 14:24:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:24:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:24:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:43 2018 ] Training epoch: 4042
[ Wed Apr 25 14:24:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:24:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:24:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:47 2018 ] Training epoch: 4043
[ Wed Apr 25 14:24:51 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:24:51 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:24:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:51 2018 ] Training epoch: 4044
[ Wed Apr 25 14:24:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:24:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:24:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:55 2018 ] Training epoch: 4045
[ Wed Apr 25 14:24:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:24:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:24:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:24:59 2018 ] Eval epoch: 4045
[ Wed Apr 25 14:25:02 2018 ] 	Mean test loss of 1 batches: 0.22170914709568024.
[ Wed Apr 25 14:25:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:25:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:25:02 2018 ] Training epoch: 4046
[ Wed Apr 25 14:25:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:25:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:25:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:06 2018 ] Training epoch: 4047
[ Wed Apr 25 14:25:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:25:10 2018 ] Training epoch: 4048
[ Wed Apr 25 14:25:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:25:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:25:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:14 2018 ] Training epoch: 4049
[ Wed Apr 25 14:25:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:25:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:25:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:18 2018 ] Training epoch: 4050
[ Wed Apr 25 14:25:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:22 2018 ] Eval epoch: 4050
[ Wed Apr 25 14:25:25 2018 ] 	Mean test loss of 1 batches: 0.22264081239700317.
[ Wed Apr 25 14:25:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:25:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:25:25 2018 ] Training epoch: 4051
[ Wed Apr 25 14:25:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:29 2018 ] Training epoch: 4052
[ Wed Apr 25 14:25:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:25:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:25:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:33 2018 ] Training epoch: 4053
[ Wed Apr 25 14:25:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:25:37 2018 ] Training epoch: 4054
[ Wed Apr 25 14:25:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:25:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:25:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:41 2018 ] Training epoch: 4055
[ Wed Apr 25 14:25:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:45 2018 ] Eval epoch: 4055
[ Wed Apr 25 14:25:48 2018 ] 	Mean test loss of 1 batches: 0.2232208400964737.
[ Wed Apr 25 14:25:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:25:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:25:48 2018 ] Training epoch: 4056
[ Wed Apr 25 14:25:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:52 2018 ] Training epoch: 4057
[ Wed Apr 25 14:25:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:25:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:25:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:25:56 2018 ] Training epoch: 4058
[ Wed Apr 25 14:26:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:00 2018 ] Training epoch: 4059
[ Wed Apr 25 14:26:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:26:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:26:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:04 2018 ] Training epoch: 4060
[ Wed Apr 25 14:26:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:08 2018 ] Eval epoch: 4060
[ Wed Apr 25 14:26:11 2018 ] 	Mean test loss of 1 batches: 0.2260703146457672.
[ Wed Apr 25 14:26:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:26:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:26:11 2018 ] Training epoch: 4061
[ Wed Apr 25 14:26:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:15 2018 ] Training epoch: 4062
[ Wed Apr 25 14:26:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:26:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:26:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:19 2018 ] Training epoch: 4063
[ Wed Apr 25 14:26:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:23 2018 ] Training epoch: 4064
[ Wed Apr 25 14:26:27 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:26:27 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:26:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:27 2018 ] Training epoch: 4065
[ Wed Apr 25 14:26:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:31 2018 ] Eval epoch: 4065
[ Wed Apr 25 14:26:34 2018 ] 	Mean test loss of 1 batches: 0.22334110736846924.
[ Wed Apr 25 14:26:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:26:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:26:34 2018 ] Training epoch: 4066
[ Wed Apr 25 14:26:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:38 2018 ] Training epoch: 4067
[ Wed Apr 25 14:26:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:42 2018 ] Training epoch: 4068
[ Wed Apr 25 14:26:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:26:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:26:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:46 2018 ] Training epoch: 4069
[ Wed Apr 25 14:26:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:50 2018 ] Training epoch: 4070
[ Wed Apr 25 14:26:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:26:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:26:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:26:54 2018 ] Eval epoch: 4070
[ Wed Apr 25 14:26:57 2018 ] 	Mean test loss of 1 batches: 0.2240350991487503.
[ Wed Apr 25 14:26:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:26:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:26:57 2018 ] Training epoch: 4071
[ Wed Apr 25 14:27:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:27:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:27:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:01 2018 ] Training epoch: 4072
[ Wed Apr 25 14:27:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:05 2018 ] Training epoch: 4073
[ Wed Apr 25 14:27:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:09 2018 ] Training epoch: 4074
[ Wed Apr 25 14:27:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:27:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:27:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:13 2018 ] Training epoch: 4075
[ Wed Apr 25 14:27:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:17 2018 ] Eval epoch: 4075
[ Wed Apr 25 14:27:20 2018 ] 	Mean test loss of 1 batches: 0.22871087491512299.
[ Wed Apr 25 14:27:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:27:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:27:20 2018 ] Training epoch: 4076
[ Wed Apr 25 14:27:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:27:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:27:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:24 2018 ] Training epoch: 4077
[ Wed Apr 25 14:27:28 2018 ] 	Batch(0/1) done. Loss: 0.0000  lr:0.000100
[ Wed Apr 25 14:27:28 2018 ] 	Mean training loss: 0.0000.
[ Wed Apr 25 14:27:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:28 2018 ] Training epoch: 4078
[ Wed Apr 25 14:27:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:32 2018 ] Training epoch: 4079
[ Wed Apr 25 14:27:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:36 2018 ] Training epoch: 4080
[ Wed Apr 25 14:27:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:27:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:27:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:40 2018 ] Eval epoch: 4080
[ Wed Apr 25 14:27:43 2018 ] 	Mean test loss of 1 batches: 0.2239638715982437.
[ Wed Apr 25 14:27:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:27:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:27:43 2018 ] Training epoch: 4081
[ Wed Apr 25 14:27:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:27:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:27:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:47 2018 ] Training epoch: 4082
[ Wed Apr 25 14:27:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:27:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:27:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:51 2018 ] Training epoch: 4083
[ Wed Apr 25 14:27:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:27:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:27:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:55 2018 ] Training epoch: 4084
[ Wed Apr 25 14:27:59 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:27:59 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:27:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:27:59 2018 ] Training epoch: 4085
[ Wed Apr 25 14:28:03 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:28:03 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:28:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:03 2018 ] Eval epoch: 4085
[ Wed Apr 25 14:28:06 2018 ] 	Mean test loss of 1 batches: 0.2319549173116684.
[ Wed Apr 25 14:28:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:28:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:28:06 2018 ] Training epoch: 4086
[ Wed Apr 25 14:28:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:28:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:28:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:10 2018 ] Training epoch: 4087
[ Wed Apr 25 14:28:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:28:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:28:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:14 2018 ] Training epoch: 4088
[ Wed Apr 25 14:28:18 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:28:18 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:28:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:18 2018 ] Training epoch: 4089
[ Wed Apr 25 14:28:22 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:28:22 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:28:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:22 2018 ] Training epoch: 4090
[ Wed Apr 25 14:28:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:28:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:28:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:26 2018 ] Eval epoch: 4090
[ Wed Apr 25 14:28:29 2018 ] 	Mean test loss of 1 batches: 0.22463196516036987.
[ Wed Apr 25 14:28:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:28:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:28:29 2018 ] Training epoch: 4091
[ Wed Apr 25 14:28:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:28:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:28:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:33 2018 ] Training epoch: 4092
[ Wed Apr 25 14:28:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:28:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:28:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:37 2018 ] Training epoch: 4093
[ Wed Apr 25 14:28:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:28:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:28:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:41 2018 ] Training epoch: 4094
[ Wed Apr 25 14:28:45 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000100
[ Wed Apr 25 14:28:45 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 14:28:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:45 2018 ] Training epoch: 4095
[ Wed Apr 25 14:28:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:28:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:28:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:49 2018 ] Eval epoch: 4095
[ Wed Apr 25 14:28:52 2018 ] 	Mean test loss of 1 batches: 0.22387583553791046.
[ Wed Apr 25 14:28:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:28:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:28:52 2018 ] Training epoch: 4096
[ Wed Apr 25 14:28:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:28:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:28:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:28:56 2018 ] Training epoch: 4097
[ Wed Apr 25 14:29:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:29:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:29:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:00 2018 ] Training epoch: 4098
[ Wed Apr 25 14:29:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:04 2018 ] Training epoch: 4099
[ Wed Apr 25 14:29:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:08 2018 ] Training epoch: 4100
[ Wed Apr 25 14:29:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:12 2018 ] Eval epoch: 4100
[ Wed Apr 25 14:29:15 2018 ] 	Mean test loss of 1 batches: 0.22610777616500854.
[ Wed Apr 25 14:29:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:29:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:29:15 2018 ] Training epoch: 4101
[ Wed Apr 25 14:29:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:19 2018 ] Training epoch: 4102
[ Wed Apr 25 14:29:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:24 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:29:24 2018 ] Training epoch: 4103
[ Wed Apr 25 14:29:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:29:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:29:28 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:29:28 2018 ] Training epoch: 4104
[ Wed Apr 25 14:29:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:29:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:29:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:32 2018 ] Training epoch: 4105
[ Wed Apr 25 14:29:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:36 2018 ] Eval epoch: 4105
[ Wed Apr 25 14:29:40 2018 ] 	Mean test loss of 1 batches: 0.21461054682731628.
[ Wed Apr 25 14:29:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:29:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:29:40 2018 ] Training epoch: 4106
[ Wed Apr 25 14:29:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:29:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:29:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:44 2018 ] Training epoch: 4107
[ Wed Apr 25 14:29:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:29:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:29:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:29:48 2018 ] Training epoch: 4108
[ Wed Apr 25 14:29:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:29:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:29:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:52 2018 ] Training epoch: 4109
[ Wed Apr 25 14:29:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:29:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:29:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:29:56 2018 ] Training epoch: 4110
[ Wed Apr 25 14:30:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:00 2018 ] Eval epoch: 4110
[ Wed Apr 25 14:30:03 2018 ] 	Mean test loss of 1 batches: 0.22029243409633636.
[ Wed Apr 25 14:30:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:30:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:30:03 2018 ] Training epoch: 4111
[ Wed Apr 25 14:30:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:30:07 2018 ] Training epoch: 4112
[ Wed Apr 25 14:30:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:11 2018 ] Training epoch: 4113
[ Wed Apr 25 14:30:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:15 2018 ] Training epoch: 4114
[ Wed Apr 25 14:30:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:19 2018 ] Training epoch: 4115
[ Wed Apr 25 14:30:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:30:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:30:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:23 2018 ] Eval epoch: 4115
[ Wed Apr 25 14:30:26 2018 ] 	Mean test loss of 1 batches: 0.23328030109405518.
[ Wed Apr 25 14:30:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:30:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:30:26 2018 ] Training epoch: 4116
[ Wed Apr 25 14:30:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:30:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:30:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:30 2018 ] Training epoch: 4117
[ Wed Apr 25 14:30:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:30:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:30:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:34 2018 ] Training epoch: 4118
[ Wed Apr 25 14:30:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:30:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:30:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:39 2018 ] Training epoch: 4119
[ Wed Apr 25 14:30:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:43 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:30:43 2018 ] Training epoch: 4120
[ Wed Apr 25 14:30:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:30:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:30:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:47 2018 ] Eval epoch: 4120
[ Wed Apr 25 14:30:50 2018 ] 	Mean test loss of 1 batches: 0.22154501080513.
[ Wed Apr 25 14:30:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:30:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:30:50 2018 ] Training epoch: 4121
[ Wed Apr 25 14:30:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:30:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:30:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:54 2018 ] Training epoch: 4122
[ Wed Apr 25 14:30:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:30:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:30:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:30:58 2018 ] Training epoch: 4123
[ Wed Apr 25 14:31:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:31:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:31:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:02 2018 ] Training epoch: 4124
[ Wed Apr 25 14:31:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:31:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:31:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:31:06 2018 ] Training epoch: 4125
[ Wed Apr 25 14:31:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:31:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:31:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:10 2018 ] Eval epoch: 4125
[ Wed Apr 25 14:31:13 2018 ] 	Mean test loss of 1 batches: 0.2252812385559082.
[ Wed Apr 25 14:31:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:31:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:31:13 2018 ] Training epoch: 4126
[ Wed Apr 25 14:31:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:31:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:31:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:31:17 2018 ] Training epoch: 4127
[ Wed Apr 25 14:31:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:31:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:31:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:21 2018 ] Training epoch: 4128
[ Wed Apr 25 14:31:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:31:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:31:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:25 2018 ] Training epoch: 4129
[ Wed Apr 25 14:31:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:31:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:31:30 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 14:31:30 2018 ] Training epoch: 4130
[ Wed Apr 25 14:31:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:31:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:31:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:34 2018 ] Eval epoch: 4130
[ Wed Apr 25 14:31:36 2018 ] 	Mean test loss of 1 batches: 0.22582484781742096.
[ Wed Apr 25 14:31:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:31:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:31:36 2018 ] Training epoch: 4131
[ Wed Apr 25 14:31:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:31:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:31:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:41 2018 ] Training epoch: 4132
[ Wed Apr 25 14:31:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:31:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:31:45 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:31:45 2018 ] Training epoch: 4133
[ Wed Apr 25 14:31:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:31:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:31:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:49 2018 ] Training epoch: 4134
[ Wed Apr 25 14:31:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:31:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:31:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:31:53 2018 ] Training epoch: 4135
[ Wed Apr 25 14:31:57 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:31:57 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:31:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:31:57 2018 ] Eval epoch: 4135
[ Wed Apr 25 14:32:00 2018 ] 	Mean test loss of 1 batches: 0.22269926965236664.
[ Wed Apr 25 14:32:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:32:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:32:00 2018 ] Training epoch: 4136
[ Wed Apr 25 14:32:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:04 2018 ] Training epoch: 4137
[ Wed Apr 25 14:32:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:08 2018 ] Training epoch: 4138
[ Wed Apr 25 14:32:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:12 2018 ] Training epoch: 4139
[ Wed Apr 25 14:32:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:16 2018 ] Training epoch: 4140
[ Wed Apr 25 14:32:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:20 2018 ] Eval epoch: 4140
[ Wed Apr 25 14:32:23 2018 ] 	Mean test loss of 1 batches: 0.22402913868427277.
[ Wed Apr 25 14:32:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:32:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:32:23 2018 ] Training epoch: 4141
[ Wed Apr 25 14:32:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:27 2018 ] Training epoch: 4142
[ Wed Apr 25 14:32:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:32:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:32:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:31 2018 ] Training epoch: 4143
[ Wed Apr 25 14:32:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:35 2018 ] Training epoch: 4144
[ Wed Apr 25 14:32:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:32:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:32:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:39 2018 ] Training epoch: 4145
[ Wed Apr 25 14:32:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:32:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:32:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:43 2018 ] Eval epoch: 4145
[ Wed Apr 25 14:32:46 2018 ] 	Mean test loss of 1 batches: 0.21963684260845184.
[ Wed Apr 25 14:32:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:32:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:32:46 2018 ] Training epoch: 4146
[ Wed Apr 25 14:32:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:50 2018 ] Training epoch: 4147
[ Wed Apr 25 14:32:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:32:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:32:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:54 2018 ] Training epoch: 4148
[ Wed Apr 25 14:32:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:32:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:32:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:32:58 2018 ] Training epoch: 4149
[ Wed Apr 25 14:33:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:33:02 2018 ] Training epoch: 4150
[ Wed Apr 25 14:33:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:06 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:33:06 2018 ] Eval epoch: 4150
[ Wed Apr 25 14:33:09 2018 ] 	Mean test loss of 1 batches: 0.23355363309383392.
[ Wed Apr 25 14:33:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:33:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:33:09 2018 ] Training epoch: 4151
[ Wed Apr 25 14:33:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:33:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:33:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:13 2018 ] Training epoch: 4152
[ Wed Apr 25 14:33:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:17 2018 ] Training epoch: 4153
[ Wed Apr 25 14:33:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:21 2018 ] Training epoch: 4154
[ Wed Apr 25 14:33:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:25 2018 ] Training epoch: 4155
[ Wed Apr 25 14:33:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:29 2018 ] Eval epoch: 4155
[ Wed Apr 25 14:33:32 2018 ] 	Mean test loss of 1 batches: 0.22740928828716278.
[ Wed Apr 25 14:33:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:33:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:33:32 2018 ] Training epoch: 4156
[ Wed Apr 25 14:33:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:33:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:33:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:36 2018 ] Training epoch: 4157
[ Wed Apr 25 14:33:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:40 2018 ] Training epoch: 4158
[ Wed Apr 25 14:33:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:44 2018 ] Training epoch: 4159
[ Wed Apr 25 14:33:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:33:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:33:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:48 2018 ] Training epoch: 4160
[ Wed Apr 25 14:33:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:52 2018 ] Eval epoch: 4160
[ Wed Apr 25 14:33:55 2018 ] 	Mean test loss of 1 batches: 0.22650949656963348.
[ Wed Apr 25 14:33:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:33:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:33:55 2018 ] Training epoch: 4161
[ Wed Apr 25 14:33:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:33:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:33:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:33:59 2018 ] Training epoch: 4162
[ Wed Apr 25 14:34:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:34:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:34:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:03 2018 ] Training epoch: 4163
[ Wed Apr 25 14:34:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:07 2018 ] Training epoch: 4164
[ Wed Apr 25 14:34:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:34:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:34:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:11 2018 ] Training epoch: 4165
[ Wed Apr 25 14:34:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:34:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:34:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:15 2018 ] Eval epoch: 4165
[ Wed Apr 25 14:34:18 2018 ] 	Mean test loss of 1 batches: 0.2261175513267517.
[ Wed Apr 25 14:34:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:34:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:34:18 2018 ] Training epoch: 4166
[ Wed Apr 25 14:34:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:22 2018 ] Training epoch: 4167
[ Wed Apr 25 14:34:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:26 2018 ] Training epoch: 4168
[ Wed Apr 25 14:34:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:30 2018 ] Training epoch: 4169
[ Wed Apr 25 14:34:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:34 2018 ] Training epoch: 4170
[ Wed Apr 25 14:34:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:38 2018 ] Eval epoch: 4170
[ Wed Apr 25 14:34:41 2018 ] 	Mean test loss of 1 batches: 0.2234763205051422.
[ Wed Apr 25 14:34:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:34:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:34:41 2018 ] Training epoch: 4171
[ Wed Apr 25 14:34:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:45 2018 ] Training epoch: 4172
[ Wed Apr 25 14:34:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:34:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:34:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:49 2018 ] Training epoch: 4173
[ Wed Apr 25 14:34:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:34:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:34:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:53 2018 ] Training epoch: 4174
[ Wed Apr 25 14:34:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:34:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:34:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:34:57 2018 ] Training epoch: 4175
[ Wed Apr 25 14:35:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:01 2018 ] Eval epoch: 4175
[ Wed Apr 25 14:35:04 2018 ] 	Mean test loss of 1 batches: 0.22186286747455597.
[ Wed Apr 25 14:35:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:35:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:35:04 2018 ] Training epoch: 4176
[ Wed Apr 25 14:35:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:08 2018 ] Training epoch: 4177
[ Wed Apr 25 14:35:12 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:35:12 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:35:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:12 2018 ] Training epoch: 4178
[ Wed Apr 25 14:35:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:35:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:35:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:16 2018 ] Training epoch: 4179
[ Wed Apr 25 14:35:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:20 2018 ] Training epoch: 4180
[ Wed Apr 25 14:35:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:35:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:35:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:24 2018 ] Eval epoch: 4180
[ Wed Apr 25 14:35:27 2018 ] 	Mean test loss of 1 batches: 0.22508056461811066.
[ Wed Apr 25 14:35:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:35:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:35:27 2018 ] Training epoch: 4181
[ Wed Apr 25 14:35:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:35:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:35:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:31 2018 ] Training epoch: 4182
[ Wed Apr 25 14:35:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:35 2018 ] Training epoch: 4183
[ Wed Apr 25 14:35:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:39 2018 ] Training epoch: 4184
[ Wed Apr 25 14:35:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:35:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:35:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:43 2018 ] Training epoch: 4185
[ Wed Apr 25 14:35:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:47 2018 ] Eval epoch: 4185
[ Wed Apr 25 14:35:50 2018 ] 	Mean test loss of 1 batches: 0.21789325773715973.
[ Wed Apr 25 14:35:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:35:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:35:50 2018 ] Training epoch: 4186
[ Wed Apr 25 14:35:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:35:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:35:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:35:54 2018 ] Training epoch: 4187
[ Wed Apr 25 14:35:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:35:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:35:58 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:35:58 2018 ] Training epoch: 4188
[ Wed Apr 25 14:36:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:36:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:36:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:02 2018 ] Training epoch: 4189
[ Wed Apr 25 14:36:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:36:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:36:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:36:06 2018 ] Training epoch: 4190
[ Wed Apr 25 14:36:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:10 2018 ] Eval epoch: 4190
[ Wed Apr 25 14:36:13 2018 ] 	Mean test loss of 1 batches: 0.21488678455352783.
[ Wed Apr 25 14:36:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:36:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:36:13 2018 ] Training epoch: 4191
[ Wed Apr 25 14:36:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:36:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:36:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:17 2018 ] Training epoch: 4192
[ Wed Apr 25 14:36:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:21 2018 ] Training epoch: 4193
[ Wed Apr 25 14:36:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:25 2018 ] Training epoch: 4194
[ Wed Apr 25 14:36:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:29 2018 ] Training epoch: 4195
[ Wed Apr 25 14:36:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:36:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:36:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:36:34 2018 ] Eval epoch: 4195
[ Wed Apr 25 14:36:37 2018 ] 	Mean test loss of 1 batches: 0.21452608704566956.
[ Wed Apr 25 14:36:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:36:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:36:37 2018 ] Training epoch: 4196
[ Wed Apr 25 14:36:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:36:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:36:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:36:41 2018 ] Training epoch: 4197
[ Wed Apr 25 14:36:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:45 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:36:45 2018 ] Training epoch: 4198
[ Wed Apr 25 14:36:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:36:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:36:49 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:36:49 2018 ] Training epoch: 4199
[ Wed Apr 25 14:36:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:53 2018 ] Training epoch: 4200
[ Wed Apr 25 14:36:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:36:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:36:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:36:57 2018 ] Eval epoch: 4200
[ Wed Apr 25 14:37:00 2018 ] 	Mean test loss of 1 batches: 0.21590273082256317.
[ Wed Apr 25 14:37:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:37:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:37:00 2018 ] Training epoch: 4201
[ Wed Apr 25 14:37:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:37:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:37:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:04 2018 ] Training epoch: 4202
[ Wed Apr 25 14:37:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:08 2018 ] Training epoch: 4203
[ Wed Apr 25 14:37:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:37:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:37:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:12 2018 ] Training epoch: 4204
[ Wed Apr 25 14:37:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:16 2018 ] Training epoch: 4205
[ Wed Apr 25 14:37:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:20 2018 ] Eval epoch: 4205
[ Wed Apr 25 14:37:23 2018 ] 	Mean test loss of 1 batches: 0.22783495485782623.
[ Wed Apr 25 14:37:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:37:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:37:23 2018 ] Training epoch: 4206
[ Wed Apr 25 14:37:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:37:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:37:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:27 2018 ] Training epoch: 4207
[ Wed Apr 25 14:37:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:31 2018 ] Training epoch: 4208
[ Wed Apr 25 14:37:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:37:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:37:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:35 2018 ] Training epoch: 4209
[ Wed Apr 25 14:37:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:37:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:37:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:39 2018 ] Training epoch: 4210
[ Wed Apr 25 14:37:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:43 2018 ] Eval epoch: 4210
[ Wed Apr 25 14:37:46 2018 ] 	Mean test loss of 1 batches: 0.22721073031425476.
[ Wed Apr 25 14:37:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:37:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:37:46 2018 ] Training epoch: 4211
[ Wed Apr 25 14:37:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:37:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:37:50 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:37:50 2018 ] Training epoch: 4212
[ Wed Apr 25 14:37:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:37:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:37:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:37:55 2018 ] Training epoch: 4213
[ Wed Apr 25 14:37:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:37:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:37:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:37:59 2018 ] Training epoch: 4214
[ Wed Apr 25 14:38:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:38:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:38:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:03 2018 ] Training epoch: 4215
[ Wed Apr 25 14:38:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:38:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:38:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:07 2018 ] Eval epoch: 4215
[ Wed Apr 25 14:38:10 2018 ] 	Mean test loss of 1 batches: 0.22798240184783936.
[ Wed Apr 25 14:38:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:38:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:38:10 2018 ] Training epoch: 4216
[ Wed Apr 25 14:38:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:38:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:38:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:14 2018 ] Training epoch: 4217
[ Wed Apr 25 14:38:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:38:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:38:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:18 2018 ] Training epoch: 4218
[ Wed Apr 25 14:38:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:38:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:38:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:22 2018 ] Training epoch: 4219
[ Wed Apr 25 14:38:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:38:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:38:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:26 2018 ] Training epoch: 4220
[ Wed Apr 25 14:38:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:38:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:38:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:30 2018 ] Eval epoch: 4220
[ Wed Apr 25 14:38:33 2018 ] 	Mean test loss of 1 batches: 0.21271316707134247.
[ Wed Apr 25 14:38:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:38:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:38:33 2018 ] Training epoch: 4221
[ Wed Apr 25 14:38:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:38:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:38:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:37 2018 ] Training epoch: 4222
[ Wed Apr 25 14:38:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:38:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:38:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:41 2018 ] Training epoch: 4223
[ Wed Apr 25 14:38:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:38:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:38:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:45 2018 ] Training epoch: 4224
[ Wed Apr 25 14:38:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:38:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:38:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:49 2018 ] Training epoch: 4225
[ Wed Apr 25 14:38:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:38:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:38:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:38:53 2018 ] Eval epoch: 4225
[ Wed Apr 25 14:38:56 2018 ] 	Mean test loss of 1 batches: 0.22239679098129272.
[ Wed Apr 25 14:38:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:38:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:38:56 2018 ] Training epoch: 4226
[ Wed Apr 25 14:39:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:39:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:39:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:00 2018 ] Training epoch: 4227
[ Wed Apr 25 14:39:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:39:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:39:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:04 2018 ] Training epoch: 4228
[ Wed Apr 25 14:39:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:08 2018 ] Training epoch: 4229
[ Wed Apr 25 14:39:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:12 2018 ] Training epoch: 4230
[ Wed Apr 25 14:39:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:39:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:39:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:17 2018 ] Eval epoch: 4230
[ Wed Apr 25 14:39:19 2018 ] 	Mean test loss of 1 batches: 0.22000162303447723.
[ Wed Apr 25 14:39:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:39:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:39:19 2018 ] Training epoch: 4231
[ Wed Apr 25 14:39:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:39:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:39:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:24 2018 ] Training epoch: 4232
[ Wed Apr 25 14:39:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:28 2018 ] Training epoch: 4233
[ Wed Apr 25 14:39:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:32 2018 ] Training epoch: 4234
[ Wed Apr 25 14:39:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:36 2018 ] Training epoch: 4235
[ Wed Apr 25 14:39:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:39:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:39:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:40 2018 ] Eval epoch: 4235
[ Wed Apr 25 14:39:43 2018 ] 	Mean test loss of 1 batches: 0.21467696130275726.
[ Wed Apr 25 14:39:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:39:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:39:43 2018 ] Training epoch: 4236
[ Wed Apr 25 14:39:47 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:39:47 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:39:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:47 2018 ] Training epoch: 4237
[ Wed Apr 25 14:39:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:39:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:39:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:51 2018 ] Training epoch: 4238
[ Wed Apr 25 14:39:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:39:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:39:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:55 2018 ] Training epoch: 4239
[ Wed Apr 25 14:39:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:39:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:39:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:39:59 2018 ] Training epoch: 4240
[ Wed Apr 25 14:40:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:40:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:40:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:03 2018 ] Eval epoch: 4240
[ Wed Apr 25 14:40:06 2018 ] 	Mean test loss of 1 batches: 0.21578842401504517.
[ Wed Apr 25 14:40:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:40:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:40:06 2018 ] Training epoch: 4241
[ Wed Apr 25 14:40:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:40:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:40:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:10 2018 ] Training epoch: 4242
[ Wed Apr 25 14:40:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:14 2018 ] Training epoch: 4243
[ Wed Apr 25 14:40:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:40:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:40:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:18 2018 ] Training epoch: 4244
[ Wed Apr 25 14:40:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:22 2018 ] Training epoch: 4245
[ Wed Apr 25 14:40:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:26 2018 ] Eval epoch: 4245
[ Wed Apr 25 14:40:29 2018 ] 	Mean test loss of 1 batches: 0.21979989111423492.
[ Wed Apr 25 14:40:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:40:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:40:29 2018 ] Training epoch: 4246
[ Wed Apr 25 14:40:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:40:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:40:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:33 2018 ] Training epoch: 4247
[ Wed Apr 25 14:40:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:37 2018 ] Training epoch: 4248
[ Wed Apr 25 14:40:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:41 2018 ] Training epoch: 4249
[ Wed Apr 25 14:40:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:40:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:40:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:45 2018 ] Training epoch: 4250
[ Wed Apr 25 14:40:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:40:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:40:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:49 2018 ] Eval epoch: 4250
[ Wed Apr 25 14:40:52 2018 ] 	Mean test loss of 1 batches: 0.21509438753128052.
[ Wed Apr 25 14:40:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:40:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:40:52 2018 ] Training epoch: 4251
[ Wed Apr 25 14:40:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:40:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:40:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:40:56 2018 ] Training epoch: 4252
[ Wed Apr 25 14:41:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:00 2018 ] Training epoch: 4253
[ Wed Apr 25 14:41:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:41:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:41:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:04 2018 ] Training epoch: 4254
[ Wed Apr 25 14:41:08 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 14:41:08 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:41:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:08 2018 ] Training epoch: 4255
[ Wed Apr 25 14:41:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:12 2018 ] Eval epoch: 4255
[ Wed Apr 25 14:41:15 2018 ] 	Mean test loss of 1 batches: 0.21682679653167725.
[ Wed Apr 25 14:41:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:41:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:41:15 2018 ] Training epoch: 4256
[ Wed Apr 25 14:41:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:19 2018 ] Training epoch: 4257
[ Wed Apr 25 14:41:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:41:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:41:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:23 2018 ] Training epoch: 4258
[ Wed Apr 25 14:41:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:41:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:41:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:27 2018 ] Training epoch: 4259
[ Wed Apr 25 14:41:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:31 2018 ] Training epoch: 4260
[ Wed Apr 25 14:41:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:41:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:41:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:35 2018 ] Eval epoch: 4260
[ Wed Apr 25 14:41:38 2018 ] 	Mean test loss of 1 batches: 0.2287813127040863.
[ Wed Apr 25 14:41:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:41:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:41:38 2018 ] Training epoch: 4261
[ Wed Apr 25 14:41:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:41:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:41:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:42 2018 ] Training epoch: 4262
[ Wed Apr 25 14:41:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:46 2018 ] Training epoch: 4263
[ Wed Apr 25 14:41:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:41:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:41:50 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:41:50 2018 ] Training epoch: 4264
[ Wed Apr 25 14:41:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:54 2018 ] Training epoch: 4265
[ Wed Apr 25 14:41:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:41:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:41:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:41:58 2018 ] Eval epoch: 4265
[ Wed Apr 25 14:42:01 2018 ] 	Mean test loss of 1 batches: 0.2320856899023056.
[ Wed Apr 25 14:42:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:42:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:42:01 2018 ] Training epoch: 4266
[ Wed Apr 25 14:42:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:42:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:42:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:05 2018 ] Training epoch: 4267
[ Wed Apr 25 14:42:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:09 2018 ] Training epoch: 4268
[ Wed Apr 25 14:42:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:13 2018 ] Training epoch: 4269
[ Wed Apr 25 14:42:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:18 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 14:42:18 2018 ] Training epoch: 4270
[ Wed Apr 25 14:42:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:22 2018 ] Eval epoch: 4270
[ Wed Apr 25 14:42:25 2018 ] 	Mean test loss of 1 batches: 0.24408699572086334.
[ Wed Apr 25 14:42:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:42:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:42:25 2018 ] Training epoch: 4271
[ Wed Apr 25 14:42:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:29 2018 ] Training epoch: 4272
[ Wed Apr 25 14:42:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:42:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:42:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:33 2018 ] Training epoch: 4273
[ Wed Apr 25 14:42:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:42:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:42:37 2018 ] 	Time consumption: [Data]75%, [Network]25%
[ Wed Apr 25 14:42:37 2018 ] Training epoch: 4274
[ Wed Apr 25 14:42:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:42:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:42:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:41 2018 ] Training epoch: 4275
[ Wed Apr 25 14:42:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:42:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:42:46 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:42:46 2018 ] Eval epoch: 4275
[ Wed Apr 25 14:42:49 2018 ] 	Mean test loss of 1 batches: 0.2253791242837906.
[ Wed Apr 25 14:42:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:42:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:42:49 2018 ] Training epoch: 4276
[ Wed Apr 25 14:42:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:42:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:42:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:53 2018 ] Training epoch: 4277
[ Wed Apr 25 14:42:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:42:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:42:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:42:57 2018 ] Training epoch: 4278
[ Wed Apr 25 14:43:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:43:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:43:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:01 2018 ] Training epoch: 4279
[ Wed Apr 25 14:43:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:43:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:43:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:05 2018 ] Training epoch: 4280
[ Wed Apr 25 14:43:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:09 2018 ] Eval epoch: 4280
[ Wed Apr 25 14:43:11 2018 ] 	Mean test loss of 1 batches: 0.22546114027500153.
[ Wed Apr 25 14:43:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:43:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:43:11 2018 ] Training epoch: 4281
[ Wed Apr 25 14:43:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:15 2018 ] Training epoch: 4282
[ Wed Apr 25 14:43:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:43:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:43:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:19 2018 ] Training epoch: 4283
[ Wed Apr 25 14:43:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:23 2018 ] Training epoch: 4284
[ Wed Apr 25 14:43:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:27 2018 ] Training epoch: 4285
[ Wed Apr 25 14:43:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:31 2018 ] Eval epoch: 4285
[ Wed Apr 25 14:43:34 2018 ] 	Mean test loss of 1 batches: 0.21880954504013062.
[ Wed Apr 25 14:43:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:43:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:43:34 2018 ] Training epoch: 4286
[ Wed Apr 25 14:43:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:38 2018 ] Training epoch: 4287
[ Wed Apr 25 14:43:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:43:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:43:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:42 2018 ] Training epoch: 4288
[ Wed Apr 25 14:43:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:46 2018 ] Training epoch: 4289
[ Wed Apr 25 14:43:50 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:43:50 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:43:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:50 2018 ] Training epoch: 4290
[ Wed Apr 25 14:43:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:43:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:43:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:43:54 2018 ] Eval epoch: 4290
[ Wed Apr 25 14:43:57 2018 ] 	Mean test loss of 1 batches: 0.21667248010635376.
[ Wed Apr 25 14:43:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:43:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:43:57 2018 ] Training epoch: 4291
[ Wed Apr 25 14:44:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:44:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:44:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:01 2018 ] Training epoch: 4292
[ Wed Apr 25 14:44:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:44:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:44:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:05 2018 ] Training epoch: 4293
[ Wed Apr 25 14:44:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:09 2018 ] Training epoch: 4294
[ Wed Apr 25 14:44:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:13 2018 ] Training epoch: 4295
[ Wed Apr 25 14:44:17 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:44:17 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:44:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:17 2018 ] Eval epoch: 4295
[ Wed Apr 25 14:44:20 2018 ] 	Mean test loss of 1 batches: 0.2172349989414215.
[ Wed Apr 25 14:44:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:44:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:44:20 2018 ] Training epoch: 4296
[ Wed Apr 25 14:44:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:24 2018 ] Training epoch: 4297
[ Wed Apr 25 14:44:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:28 2018 ] Training epoch: 4298
[ Wed Apr 25 14:44:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:32 2018 ] Training epoch: 4299
[ Wed Apr 25 14:44:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:36 2018 ] Training epoch: 4300
[ Wed Apr 25 14:44:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:40 2018 ] Eval epoch: 4300
[ Wed Apr 25 14:44:43 2018 ] 	Mean test loss of 1 batches: 0.22969122231006622.
[ Wed Apr 25 14:44:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:44:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:44:43 2018 ] Training epoch: 4301
[ Wed Apr 25 14:44:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:47 2018 ] Training epoch: 4302
[ Wed Apr 25 14:44:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:44:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:44:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:51 2018 ] Training epoch: 4303
[ Wed Apr 25 14:44:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:44:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:44:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:44:55 2018 ] Training epoch: 4304
[ Wed Apr 25 14:44:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:44:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:44:59 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:44:59 2018 ] Training epoch: 4305
[ Wed Apr 25 14:45:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:03 2018 ] Eval epoch: 4305
[ Wed Apr 25 14:45:06 2018 ] 	Mean test loss of 1 batches: 0.22801916301250458.
[ Wed Apr 25 14:45:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:45:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:45:06 2018 ] Training epoch: 4306
[ Wed Apr 25 14:45:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:10 2018 ] Training epoch: 4307
[ Wed Apr 25 14:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:14 2018 ] Training epoch: 4308
[ Wed Apr 25 14:45:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:18 2018 ] Training epoch: 4309
[ Wed Apr 25 14:45:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:22 2018 ] Training epoch: 4310
[ Wed Apr 25 14:45:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:26 2018 ] Eval epoch: 4310
[ Wed Apr 25 14:45:29 2018 ] 	Mean test loss of 1 batches: 0.23534876108169556.
[ Wed Apr 25 14:45:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:45:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:45:29 2018 ] Training epoch: 4311
[ Wed Apr 25 14:45:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:33 2018 ] Training epoch: 4312
[ Wed Apr 25 14:45:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:37 2018 ] Training epoch: 4313
[ Wed Apr 25 14:45:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:45:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:45:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:41 2018 ] Training epoch: 4314
[ Wed Apr 25 14:45:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:45 2018 ] Training epoch: 4315
[ Wed Apr 25 14:45:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:49 2018 ] Eval epoch: 4315
[ Wed Apr 25 14:45:52 2018 ] 	Mean test loss of 1 batches: 0.2421572059392929.
[ Wed Apr 25 14:45:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:45:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:45:52 2018 ] Training epoch: 4316
[ Wed Apr 25 14:45:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:45:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:45:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:45:56 2018 ] Training epoch: 4317
[ Wed Apr 25 14:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:00 2018 ] Training epoch: 4318
[ Wed Apr 25 14:46:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:04 2018 ] Training epoch: 4319
[ Wed Apr 25 14:46:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:08 2018 ] Training epoch: 4320
[ Wed Apr 25 14:46:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:12 2018 ] Eval epoch: 4320
[ Wed Apr 25 14:46:15 2018 ] 	Mean test loss of 1 batches: 0.22830264270305634.
[ Wed Apr 25 14:46:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:46:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:46:15 2018 ] Training epoch: 4321
[ Wed Apr 25 14:46:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:19 2018 ] Training epoch: 4322
[ Wed Apr 25 14:46:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:46:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:46:23 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:46:23 2018 ] Training epoch: 4323
[ Wed Apr 25 14:46:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:27 2018 ] Training epoch: 4324
[ Wed Apr 25 14:46:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:31 2018 ] Training epoch: 4325
[ Wed Apr 25 14:46:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:35 2018 ] Eval epoch: 4325
[ Wed Apr 25 14:46:38 2018 ] 	Mean test loss of 1 batches: 0.22347477078437805.
[ Wed Apr 25 14:46:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:46:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:46:38 2018 ] Training epoch: 4326
[ Wed Apr 25 14:46:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:46:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:46:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:42 2018 ] Training epoch: 4327
[ Wed Apr 25 14:46:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:46:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:46:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:46 2018 ] Training epoch: 4328
[ Wed Apr 25 14:46:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:46:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:46:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:50 2018 ] Training epoch: 4329
[ Wed Apr 25 14:46:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:54 2018 ] Training epoch: 4330
[ Wed Apr 25 14:46:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:46:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:46:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:46:58 2018 ] Eval epoch: 4330
[ Wed Apr 25 14:47:01 2018 ] 	Mean test loss of 1 batches: 0.21533410251140594.
[ Wed Apr 25 14:47:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:47:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:47:01 2018 ] Training epoch: 4331
[ Wed Apr 25 14:47:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:47:06 2018 ] Training epoch: 4332
[ Wed Apr 25 14:47:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:10 2018 ] Training epoch: 4333
[ Wed Apr 25 14:47:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:14 2018 ] Training epoch: 4334
[ Wed Apr 25 14:47:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:47:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:47:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:18 2018 ] Training epoch: 4335
[ Wed Apr 25 14:47:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:47:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:47:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:47:22 2018 ] Eval epoch: 4335
[ Wed Apr 25 14:47:25 2018 ] 	Mean test loss of 1 batches: 0.21412593126296997.
[ Wed Apr 25 14:47:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:47:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:47:25 2018 ] Training epoch: 4336
[ Wed Apr 25 14:47:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:47:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:47:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:29 2018 ] Training epoch: 4337
[ Wed Apr 25 14:47:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:33 2018 ] Training epoch: 4338
[ Wed Apr 25 14:47:37 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:47:37 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:47:37 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:47:37 2018 ] Training epoch: 4339
[ Wed Apr 25 14:47:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:47:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:47:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:41 2018 ] Training epoch: 4340
[ Wed Apr 25 14:47:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:47:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:47:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:47:45 2018 ] Eval epoch: 4340
[ Wed Apr 25 14:47:48 2018 ] 	Mean test loss of 1 batches: 0.22521816194057465.
[ Wed Apr 25 14:47:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:47:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:47:48 2018 ] Training epoch: 4341
[ Wed Apr 25 14:47:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:47:53 2018 ] Training epoch: 4342
[ Wed Apr 25 14:47:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:47:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:47:57 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:47:57 2018 ] Training epoch: 4343
[ Wed Apr 25 14:48:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:48:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:48:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:01 2018 ] Training epoch: 4344
[ Wed Apr 25 14:48:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:48:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:48:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:05 2018 ] Training epoch: 4345
[ Wed Apr 25 14:48:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:48:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:48:09 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:48:09 2018 ] Eval epoch: 4345
[ Wed Apr 25 14:48:12 2018 ] 	Mean test loss of 1 batches: 0.22531498968601227.
[ Wed Apr 25 14:48:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:48:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:48:12 2018 ] Training epoch: 4346
[ Wed Apr 25 14:48:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:16 2018 ] Training epoch: 4347
[ Wed Apr 25 14:48:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:20 2018 ] Training epoch: 4348
[ Wed Apr 25 14:48:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:24 2018 ] Training epoch: 4349
[ Wed Apr 25 14:48:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:48:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:48:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:28 2018 ] Training epoch: 4350
[ Wed Apr 25 14:48:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:48:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:48:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:32 2018 ] Eval epoch: 4350
[ Wed Apr 25 14:48:35 2018 ] 	Mean test loss of 1 batches: 0.22720180451869965.
[ Wed Apr 25 14:48:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:48:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:48:35 2018 ] Training epoch: 4351
[ Wed Apr 25 14:48:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:48:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:48:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:39 2018 ] Training epoch: 4352
[ Wed Apr 25 14:48:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:48:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:48:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:43 2018 ] Training epoch: 4353
[ Wed Apr 25 14:48:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:47 2018 ] Training epoch: 4354
[ Wed Apr 25 14:48:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:51 2018 ] Training epoch: 4355
[ Wed Apr 25 14:48:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:48:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:48:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:48:55 2018 ] Eval epoch: 4355
[ Wed Apr 25 14:48:58 2018 ] 	Mean test loss of 1 batches: 0.22150593996047974.
[ Wed Apr 25 14:48:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:48:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:48:58 2018 ] Training epoch: 4356
[ Wed Apr 25 14:49:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:02 2018 ] Training epoch: 4357
[ Wed Apr 25 14:49:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:07 2018 ] Training epoch: 4358
[ Wed Apr 25 14:49:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:49:11 2018 ] Training epoch: 4359
[ Wed Apr 25 14:49:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:49:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:49:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:15 2018 ] Training epoch: 4360
[ Wed Apr 25 14:49:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:49:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:49:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:19 2018 ] Eval epoch: 4360
[ Wed Apr 25 14:49:22 2018 ] 	Mean test loss of 1 batches: 0.22906357049942017.
[ Wed Apr 25 14:49:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:49:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:49:22 2018 ] Training epoch: 4361
[ Wed Apr 25 14:49:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:49:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:49:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:49:26 2018 ] Training epoch: 4362
[ Wed Apr 25 14:49:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:30 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:49:30 2018 ] Training epoch: 4363
[ Wed Apr 25 14:49:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:34 2018 ] Training epoch: 4364
[ Wed Apr 25 14:49:39 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:49:39 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:49:39 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:49:39 2018 ] Training epoch: 4365
[ Wed Apr 25 14:49:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:43 2018 ] Eval epoch: 4365
[ Wed Apr 25 14:49:46 2018 ] 	Mean test loss of 1 batches: 0.22927437722682953.
[ Wed Apr 25 14:49:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:49:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:49:46 2018 ] Training epoch: 4366
[ Wed Apr 25 14:49:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:49:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:49:50 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:49:50 2018 ] Training epoch: 4367
[ Wed Apr 25 14:49:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:54 2018 ] Training epoch: 4368
[ Wed Apr 25 14:49:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:49:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:49:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:49:58 2018 ] Training epoch: 4369
[ Wed Apr 25 14:50:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:50:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:50:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:02 2018 ] Training epoch: 4370
[ Wed Apr 25 14:50:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:50:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:50:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:06 2018 ] Eval epoch: 4370
[ Wed Apr 25 14:50:09 2018 ] 	Mean test loss of 1 batches: 0.23139545321464539.
[ Wed Apr 25 14:50:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:50:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:50:09 2018 ] Training epoch: 4371
[ Wed Apr 25 14:50:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:13 2018 ] Training epoch: 4372
[ Wed Apr 25 14:50:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:17 2018 ] Training epoch: 4373
[ Wed Apr 25 14:50:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:21 2018 ] Training epoch: 4374
[ Wed Apr 25 14:50:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:50:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:50:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:25 2018 ] Training epoch: 4375
[ Wed Apr 25 14:50:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:29 2018 ] Eval epoch: 4375
[ Wed Apr 25 14:50:32 2018 ] 	Mean test loss of 1 batches: 0.2252727448940277.
[ Wed Apr 25 14:50:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:50:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:50:32 2018 ] Training epoch: 4376
[ Wed Apr 25 14:50:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:50:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:50:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:36 2018 ] Training epoch: 4377
[ Wed Apr 25 14:50:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:50:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:50:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:40 2018 ] Training epoch: 4378
[ Wed Apr 25 14:50:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:50:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:50:44 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:50:44 2018 ] Training epoch: 4379
[ Wed Apr 25 14:50:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:48 2018 ] Training epoch: 4380
[ Wed Apr 25 14:50:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:50:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:50:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:53 2018 ] Eval epoch: 4380
[ Wed Apr 25 14:50:55 2018 ] 	Mean test loss of 1 batches: 0.22288796305656433.
[ Wed Apr 25 14:50:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:50:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:50:55 2018 ] Training epoch: 4381
[ Wed Apr 25 14:50:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:50:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:50:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:50:59 2018 ] Training epoch: 4382
[ Wed Apr 25 14:51:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:03 2018 ] Training epoch: 4383
[ Wed Apr 25 14:51:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:07 2018 ] Training epoch: 4384
[ Wed Apr 25 14:51:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:12 2018 ] Training epoch: 4385
[ Wed Apr 25 14:51:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:16 2018 ] Eval epoch: 4385
[ Wed Apr 25 14:51:18 2018 ] 	Mean test loss of 1 batches: 0.2054293304681778.
[ Wed Apr 25 14:51:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:51:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:51:18 2018 ] Training epoch: 4386
[ Wed Apr 25 14:51:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:23 2018 ] Training epoch: 4387
[ Wed Apr 25 14:51:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:51:27 2018 ] Training epoch: 4388
[ Wed Apr 25 14:51:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:31 2018 ] Training epoch: 4389
[ Wed Apr 25 14:51:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:35 2018 ] Training epoch: 4390
[ Wed Apr 25 14:51:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:39 2018 ] Eval epoch: 4390
[ Wed Apr 25 14:51:42 2018 ] 	Mean test loss of 1 batches: 0.21964778006076813.
[ Wed Apr 25 14:51:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:51:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:51:42 2018 ] Training epoch: 4391
[ Wed Apr 25 14:51:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:46 2018 ] Training epoch: 4392
[ Wed Apr 25 14:51:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:51:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:51:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:50 2018 ] Training epoch: 4393
[ Wed Apr 25 14:51:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:51:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:51:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:51:54 2018 ] Training epoch: 4394
[ Wed Apr 25 14:51:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:51:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:51:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:51:58 2018 ] Training epoch: 4395
[ Wed Apr 25 14:52:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:52:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:52:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:02 2018 ] Eval epoch: 4395
[ Wed Apr 25 14:52:05 2018 ] 	Mean test loss of 1 batches: 0.2190629094839096.
[ Wed Apr 25 14:52:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:52:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:52:05 2018 ] Training epoch: 4396
[ Wed Apr 25 14:52:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:52:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:52:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:09 2018 ] Training epoch: 4397
[ Wed Apr 25 14:52:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:52:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:52:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:13 2018 ] Training epoch: 4398
[ Wed Apr 25 14:52:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:52:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:52:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:17 2018 ] Training epoch: 4399
[ Wed Apr 25 14:52:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:52:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:52:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:21 2018 ] Training epoch: 4400
[ Wed Apr 25 14:52:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:52:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:52:25 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 14:52:25 2018 ] Eval epoch: 4400
[ Wed Apr 25 14:52:28 2018 ] 	Mean test loss of 1 batches: 0.22031401097774506.
[ Wed Apr 25 14:52:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:52:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:52:28 2018 ] Training epoch: 4401
[ Wed Apr 25 14:52:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:52:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:52:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:32 2018 ] Training epoch: 4402
[ Wed Apr 25 14:52:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:52:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:52:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:36 2018 ] Training epoch: 4403
[ Wed Apr 25 14:52:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:52:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:52:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:40 2018 ] Training epoch: 4404
[ Wed Apr 25 14:52:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:52:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:52:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:44 2018 ] Training epoch: 4405
[ Wed Apr 25 14:52:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:52:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:52:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:48 2018 ] Eval epoch: 4405
[ Wed Apr 25 14:52:51 2018 ] 	Mean test loss of 1 batches: 0.22420646250247955.
[ Wed Apr 25 14:52:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:52:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:52:51 2018 ] Training epoch: 4406
[ Wed Apr 25 14:52:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:52:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:52:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:55 2018 ] Training epoch: 4407
[ Wed Apr 25 14:52:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:52:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:52:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:52:59 2018 ] Training epoch: 4408
[ Wed Apr 25 14:53:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:53:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:53:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:03 2018 ] Training epoch: 4409
[ Wed Apr 25 14:53:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:53:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:53:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:07 2018 ] Training epoch: 4410
[ Wed Apr 25 14:53:12 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:53:12 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:53:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:12 2018 ] Eval epoch: 4410
[ Wed Apr 25 14:53:14 2018 ] 	Mean test loss of 1 batches: 0.22810716927051544.
[ Wed Apr 25 14:53:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:53:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:53:14 2018 ] Training epoch: 4411
[ Wed Apr 25 14:53:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:53:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:53:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:18 2018 ] Training epoch: 4412
[ Wed Apr 25 14:53:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:53:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:53:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:23 2018 ] Training epoch: 4413
[ Wed Apr 25 14:53:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:53:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:53:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:27 2018 ] Training epoch: 4414
[ Wed Apr 25 14:53:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:53:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:53:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:31 2018 ] Training epoch: 4415
[ Wed Apr 25 14:53:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:53:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:53:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:35 2018 ] Eval epoch: 4415
[ Wed Apr 25 14:53:37 2018 ] 	Mean test loss of 1 batches: 0.2229371964931488.
[ Wed Apr 25 14:53:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:53:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:53:37 2018 ] Training epoch: 4416
[ Wed Apr 25 14:53:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:53:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:53:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:42 2018 ] Training epoch: 4417
[ Wed Apr 25 14:53:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:53:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:53:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:46 2018 ] Training epoch: 4418
[ Wed Apr 25 14:53:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:53:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:53:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:50 2018 ] Training epoch: 4419
[ Wed Apr 25 14:53:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:53:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:53:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:54 2018 ] Training epoch: 4420
[ Wed Apr 25 14:53:58 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:53:58 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:53:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:53:58 2018 ] Eval epoch: 4420
[ Wed Apr 25 14:54:00 2018 ] 	Mean test loss of 1 batches: 0.22323296964168549.
[ Wed Apr 25 14:54:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:54:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:54:00 2018 ] Training epoch: 4421
[ Wed Apr 25 14:54:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:54:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:54:05 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:54:05 2018 ] Training epoch: 4422
[ Wed Apr 25 14:54:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:54:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:54:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:09 2018 ] Training epoch: 4423
[ Wed Apr 25 14:54:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:13 2018 ] Training epoch: 4424
[ Wed Apr 25 14:54:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:17 2018 ] Training epoch: 4425
[ Wed Apr 25 14:54:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:21 2018 ] Eval epoch: 4425
[ Wed Apr 25 14:54:24 2018 ] 	Mean test loss of 1 batches: 0.2132023125886917.
[ Wed Apr 25 14:54:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:54:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:54:24 2018 ] Training epoch: 4426
[ Wed Apr 25 14:54:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:28 2018 ] Training epoch: 4427
[ Wed Apr 25 14:54:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:32 2018 ] Training epoch: 4428
[ Wed Apr 25 14:54:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:54:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:54:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:36 2018 ] Training epoch: 4429
[ Wed Apr 25 14:54:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:40 2018 ] Training epoch: 4430
[ Wed Apr 25 14:54:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:54:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:54:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:44 2018 ] Eval epoch: 4430
[ Wed Apr 25 14:54:47 2018 ] 	Mean test loss of 1 batches: 0.20608244836330414.
[ Wed Apr 25 14:54:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:54:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:54:47 2018 ] Training epoch: 4431
[ Wed Apr 25 14:54:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:51 2018 ] Training epoch: 4432
[ Wed Apr 25 14:54:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:54:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:54:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:55 2018 ] Training epoch: 4433
[ Wed Apr 25 14:54:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:54:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:54:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:54:59 2018 ] Training epoch: 4434
[ Wed Apr 25 14:55:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:55:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:55:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:03 2018 ] Training epoch: 4435
[ Wed Apr 25 14:55:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:55:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:55:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:07 2018 ] Eval epoch: 4435
[ Wed Apr 25 14:55:09 2018 ] 	Mean test loss of 1 batches: 0.20849010348320007.
[ Wed Apr 25 14:55:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:55:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:55:09 2018 ] Training epoch: 4436
[ Wed Apr 25 14:55:13 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:55:13 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:55:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:13 2018 ] Training epoch: 4437
[ Wed Apr 25 14:55:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:55:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:55:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:17 2018 ] Training epoch: 4438
[ Wed Apr 25 14:55:22 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:55:22 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:55:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:22 2018 ] Training epoch: 4439
[ Wed Apr 25 14:55:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:55:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:55:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:26 2018 ] Training epoch: 4440
[ Wed Apr 25 14:55:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:55:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:55:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:30 2018 ] Eval epoch: 4440
[ Wed Apr 25 14:55:32 2018 ] 	Mean test loss of 1 batches: 0.20928220450878143.
[ Wed Apr 25 14:55:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:55:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:55:32 2018 ] Training epoch: 4441
[ Wed Apr 25 14:55:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:55:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:55:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:36 2018 ] Training epoch: 4442
[ Wed Apr 25 14:55:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:55:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:55:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:55:41 2018 ] Training epoch: 4443
[ Wed Apr 25 14:55:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:55:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:55:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:45 2018 ] Training epoch: 4444
[ Wed Apr 25 14:55:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:55:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:55:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:49 2018 ] Training epoch: 4445
[ Wed Apr 25 14:55:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:55:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:55:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:55:53 2018 ] Eval epoch: 4445
[ Wed Apr 25 14:55:56 2018 ] 	Mean test loss of 1 batches: 0.21244752407073975.
[ Wed Apr 25 14:55:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:55:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:55:56 2018 ] Training epoch: 4446
[ Wed Apr 25 14:56:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:56:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:56:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:00 2018 ] Training epoch: 4447
[ Wed Apr 25 14:56:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:04 2018 ] Training epoch: 4448
[ Wed Apr 25 14:56:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:08 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 14:56:08 2018 ] Training epoch: 4449
[ Wed Apr 25 14:56:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:12 2018 ] Training epoch: 4450
[ Wed Apr 25 14:56:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:56:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:56:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:16 2018 ] Eval epoch: 4450
[ Wed Apr 25 14:56:19 2018 ] 	Mean test loss of 1 batches: 0.21784909069538116.
[ Wed Apr 25 14:56:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:56:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:56:19 2018 ] Training epoch: 4451
[ Wed Apr 25 14:56:23 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:56:23 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:56:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:23 2018 ] Training epoch: 4452
[ Wed Apr 25 14:56:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:27 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:56:27 2018 ] Training epoch: 4453
[ Wed Apr 25 14:56:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:56:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:56:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:31 2018 ] Training epoch: 4454
[ Wed Apr 25 14:56:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:35 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 14:56:35 2018 ] Training epoch: 4455
[ Wed Apr 25 14:56:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:56:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:56:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:39 2018 ] Eval epoch: 4455
[ Wed Apr 25 14:56:42 2018 ] 	Mean test loss of 1 batches: 0.22208648920059204.
[ Wed Apr 25 14:56:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:56:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:56:42 2018 ] Training epoch: 4456
[ Wed Apr 25 14:56:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:56:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:56:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:46 2018 ] Training epoch: 4457
[ Wed Apr 25 14:56:50 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 14:56:50 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 14:56:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:50 2018 ] Training epoch: 4458
[ Wed Apr 25 14:56:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:56:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:56:54 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:56:54 2018 ] Training epoch: 4459
[ Wed Apr 25 14:56:59 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 14:56:59 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 14:56:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:56:59 2018 ] Training epoch: 4460
[ Wed Apr 25 14:57:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:57:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:57:03 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:57:03 2018 ] Eval epoch: 4460
[ Wed Apr 25 14:57:05 2018 ] 	Mean test loss of 1 batches: 0.2125796377658844.
[ Wed Apr 25 14:57:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:57:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:57:05 2018 ] Training epoch: 4461
[ Wed Apr 25 14:57:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:57:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:57:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:09 2018 ] Training epoch: 4462
[ Wed Apr 25 14:57:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:57:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:57:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:14 2018 ] Training epoch: 4463
[ Wed Apr 25 14:57:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:57:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:57:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:18 2018 ] Training epoch: 4464
[ Wed Apr 25 14:57:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:57:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:57:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:57:22 2018 ] Training epoch: 4465
[ Wed Apr 25 14:57:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:57:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:57:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:26 2018 ] Eval epoch: 4465
[ Wed Apr 25 14:57:29 2018 ] 	Mean test loss of 1 batches: 0.21817418932914734.
[ Wed Apr 25 14:57:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:57:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:57:29 2018 ] Training epoch: 4466
[ Wed Apr 25 14:57:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:57:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:57:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:33 2018 ] Training epoch: 4467
[ Wed Apr 25 14:57:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:57:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:57:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:37 2018 ] Training epoch: 4468
[ Wed Apr 25 14:57:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:57:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:57:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:41 2018 ] Training epoch: 4469
[ Wed Apr 25 14:57:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:57:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:57:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:45 2018 ] Training epoch: 4470
[ Wed Apr 25 14:57:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:57:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:57:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:49 2018 ] Eval epoch: 4470
[ Wed Apr 25 14:57:52 2018 ] 	Mean test loss of 1 batches: 0.21647809445858002.
[ Wed Apr 25 14:57:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:57:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:57:52 2018 ] Training epoch: 4471
[ Wed Apr 25 14:57:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:57:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:57:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:57:56 2018 ] Training epoch: 4472
[ Wed Apr 25 14:58:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:58:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:58:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:00 2018 ] Training epoch: 4473
[ Wed Apr 25 14:58:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:04 2018 ] Training epoch: 4474
[ Wed Apr 25 14:58:08 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:58:08 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:58:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:08 2018 ] Training epoch: 4475
[ Wed Apr 25 14:58:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:58:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:58:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:12 2018 ] Eval epoch: 4475
[ Wed Apr 25 14:58:15 2018 ] 	Mean test loss of 1 batches: 0.21744759380817413.
[ Wed Apr 25 14:58:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:58:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:58:15 2018 ] Training epoch: 4476
[ Wed Apr 25 14:58:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:58:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:58:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:19 2018 ] Training epoch: 4477
[ Wed Apr 25 14:58:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:58:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:58:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:23 2018 ] Training epoch: 4478
[ Wed Apr 25 14:58:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:27 2018 ] Training epoch: 4479
[ Wed Apr 25 14:58:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:58:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:58:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:31 2018 ] Training epoch: 4480
[ Wed Apr 25 14:58:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:58:35 2018 ] Eval epoch: 4480
[ Wed Apr 25 14:58:38 2018 ] 	Mean test loss of 1 batches: 0.22653990983963013.
[ Wed Apr 25 14:58:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:58:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:58:38 2018 ] Training epoch: 4481
[ Wed Apr 25 14:58:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:42 2018 ] Training epoch: 4482
[ Wed Apr 25 14:58:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:46 2018 ] Training epoch: 4483
[ Wed Apr 25 14:58:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:58:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:58:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:50 2018 ] Training epoch: 4484
[ Wed Apr 25 14:58:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:58:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:58:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:54 2018 ] Training epoch: 4485
[ Wed Apr 25 14:58:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:58:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:58:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:58:58 2018 ] Eval epoch: 4485
[ Wed Apr 25 14:59:01 2018 ] 	Mean test loss of 1 batches: 0.23199084401130676.
[ Wed Apr 25 14:59:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:59:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:59:01 2018 ] Training epoch: 4486
[ Wed Apr 25 14:59:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:59:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:59:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:05 2018 ] Training epoch: 4487
[ Wed Apr 25 14:59:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:59:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:59:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:09 2018 ] Training epoch: 4488
[ Wed Apr 25 14:59:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:59:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:59:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:13 2018 ] Training epoch: 4489
[ Wed Apr 25 14:59:17 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:59:17 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:59:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:18 2018 ] Training epoch: 4490
[ Wed Apr 25 14:59:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:59:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:59:22 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 14:59:22 2018 ] Eval epoch: 4490
[ Wed Apr 25 14:59:24 2018 ] 	Mean test loss of 1 batches: 0.2239047884941101.
[ Wed Apr 25 14:59:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:59:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:59:24 2018 ] Training epoch: 4491
[ Wed Apr 25 14:59:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:59:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:59:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:29 2018 ] Training epoch: 4492
[ Wed Apr 25 14:59:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:59:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:59:33 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 14:59:33 2018 ] Training epoch: 4493
[ Wed Apr 25 14:59:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 14:59:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 14:59:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:37 2018 ] Training epoch: 4494
[ Wed Apr 25 14:59:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:59:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:59:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:41 2018 ] Training epoch: 4495
[ Wed Apr 25 14:59:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 14:59:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 14:59:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:45 2018 ] Eval epoch: 4495
[ Wed Apr 25 14:59:48 2018 ] 	Mean test loss of 1 batches: 0.22257019579410553.
[ Wed Apr 25 14:59:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 14:59:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 14:59:48 2018 ] Training epoch: 4496
[ Wed Apr 25 14:59:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 14:59:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 14:59:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:52 2018 ] Training epoch: 4497
[ Wed Apr 25 14:59:56 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 14:59:56 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 14:59:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 14:59:56 2018 ] Training epoch: 4498
[ Wed Apr 25 15:00:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:00:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:00:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:00 2018 ] Training epoch: 4499
[ Wed Apr 25 15:00:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:00:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:00:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:04 2018 ] Training epoch: 4500
[ Wed Apr 25 15:00:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:00:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:00:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:08 2018 ] Eval epoch: 4500
[ Wed Apr 25 15:00:11 2018 ] 	Mean test loss of 1 batches: 0.22546949982643127.
[ Wed Apr 25 15:00:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:00:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:00:11 2018 ] Training epoch: 4501
[ Wed Apr 25 15:00:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:00:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:00:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:15 2018 ] Training epoch: 4502
[ Wed Apr 25 15:00:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:00:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:00:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:19 2018 ] Training epoch: 4503
[ Wed Apr 25 15:00:23 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:00:23 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:00:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:23 2018 ] Training epoch: 4504
[ Wed Apr 25 15:00:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:00:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:00:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:27 2018 ] Training epoch: 4505
[ Wed Apr 25 15:00:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:00:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:00:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:31 2018 ] Eval epoch: 4505
[ Wed Apr 25 15:00:34 2018 ] 	Mean test loss of 1 batches: 0.21690422296524048.
[ Wed Apr 25 15:00:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:00:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:00:34 2018 ] Training epoch: 4506
[ Wed Apr 25 15:00:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:00:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:00:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:38 2018 ] Training epoch: 4507
[ Wed Apr 25 15:00:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:00:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:00:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:42 2018 ] Training epoch: 4508
[ Wed Apr 25 15:00:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:00:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:00:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:46 2018 ] Training epoch: 4509
[ Wed Apr 25 15:00:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:00:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:00:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:50 2018 ] Training epoch: 4510
[ Wed Apr 25 15:00:54 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.000100
[ Wed Apr 25 15:00:54 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 15:00:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:00:54 2018 ] Eval epoch: 4510
[ Wed Apr 25 15:00:57 2018 ] 	Mean test loss of 1 batches: 0.2263335883617401.
[ Wed Apr 25 15:00:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:00:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:00:57 2018 ] Training epoch: 4511
[ Wed Apr 25 15:01:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:01:01 2018 ] Training epoch: 4512
[ Wed Apr 25 15:01:05 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:01:05 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:01:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:05 2018 ] Training epoch: 4513
[ Wed Apr 25 15:01:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:09 2018 ] Training epoch: 4514
[ Wed Apr 25 15:01:13 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:01:13 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:01:13 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 15:01:13 2018 ] Training epoch: 4515
[ Wed Apr 25 15:01:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:17 2018 ] Eval epoch: 4515
[ Wed Apr 25 15:01:20 2018 ] 	Mean test loss of 1 batches: 0.22340472042560577.
[ Wed Apr 25 15:01:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:01:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:01:20 2018 ] Training epoch: 4516
[ Wed Apr 25 15:01:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:24 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:01:24 2018 ] Training epoch: 4517
[ Wed Apr 25 15:01:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:01:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:01:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:28 2018 ] Training epoch: 4518
[ Wed Apr 25 15:01:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:32 2018 ] Training epoch: 4519
[ Wed Apr 25 15:01:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:36 2018 ] Training epoch: 4520
[ Wed Apr 25 15:01:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:40 2018 ] Eval epoch: 4520
[ Wed Apr 25 15:01:43 2018 ] 	Mean test loss of 1 batches: 0.23034898936748505.
[ Wed Apr 25 15:01:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:01:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:01:43 2018 ] Training epoch: 4521
[ Wed Apr 25 15:01:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:01:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:01:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:47 2018 ] Training epoch: 4522
[ Wed Apr 25 15:01:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:01:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:01:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:51 2018 ] Training epoch: 4523
[ Wed Apr 25 15:01:55 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:01:55 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:01:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:55 2018 ] Training epoch: 4524
[ Wed Apr 25 15:01:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:01:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:01:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:01:59 2018 ] Training epoch: 4525
[ Wed Apr 25 15:02:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:02:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:02:03 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 15:02:03 2018 ] Eval epoch: 4525
[ Wed Apr 25 15:02:06 2018 ] 	Mean test loss of 1 batches: 0.22298212349414825.
[ Wed Apr 25 15:02:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:02:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:02:06 2018 ] Training epoch: 4526
[ Wed Apr 25 15:02:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:02:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:02:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:10 2018 ] Training epoch: 4527
[ Wed Apr 25 15:02:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:02:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:02:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:14 2018 ] Training epoch: 4528
[ Wed Apr 25 15:02:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:02:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:02:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:18 2018 ] Training epoch: 4529
[ Wed Apr 25 15:02:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:02:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:02:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:22 2018 ] Training epoch: 4530
[ Wed Apr 25 15:02:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:02:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:02:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:26 2018 ] Eval epoch: 4530
[ Wed Apr 25 15:02:29 2018 ] 	Mean test loss of 1 batches: 0.2173650711774826.
[ Wed Apr 25 15:02:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:02:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:02:29 2018 ] Training epoch: 4531
[ Wed Apr 25 15:02:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:02:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:02:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:33 2018 ] Training epoch: 4532
[ Wed Apr 25 15:02:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:02:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:02:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:37 2018 ] Training epoch: 4533
[ Wed Apr 25 15:02:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:02:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:02:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:02:42 2018 ] Training epoch: 4534
[ Wed Apr 25 15:02:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:02:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:02:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:46 2018 ] Training epoch: 4535
[ Wed Apr 25 15:02:50 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:02:50 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:02:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:50 2018 ] Eval epoch: 4535
[ Wed Apr 25 15:02:53 2018 ] 	Mean test loss of 1 batches: 0.22983194887638092.
[ Wed Apr 25 15:02:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:02:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:02:53 2018 ] Training epoch: 4536
[ Wed Apr 25 15:02:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:02:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:02:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:02:57 2018 ] Training epoch: 4537
[ Wed Apr 25 15:03:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:03:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:03:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:01 2018 ] Training epoch: 4538
[ Wed Apr 25 15:03:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:03:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:03:05 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:03:05 2018 ] Training epoch: 4539
[ Wed Apr 25 15:03:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:03:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:03:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:09 2018 ] Training epoch: 4540
[ Wed Apr 25 15:03:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:03:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:03:14 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:03:14 2018 ] Eval epoch: 4540
[ Wed Apr 25 15:03:17 2018 ] 	Mean test loss of 1 batches: 0.22918497025966644.
[ Wed Apr 25 15:03:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:03:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:03:17 2018 ] Training epoch: 4541
[ Wed Apr 25 15:03:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:03:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:03:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:21 2018 ] Training epoch: 4542
[ Wed Apr 25 15:03:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:03:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:03:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:03:25 2018 ] Training epoch: 4543
[ Wed Apr 25 15:03:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:03:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:03:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:29 2018 ] Training epoch: 4544
[ Wed Apr 25 15:03:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:03:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:03:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:33 2018 ] Training epoch: 4545
[ Wed Apr 25 15:03:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:03:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:03:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:37 2018 ] Eval epoch: 4545
[ Wed Apr 25 15:03:40 2018 ] 	Mean test loss of 1 batches: 0.22234328091144562.
[ Wed Apr 25 15:03:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:03:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:03:40 2018 ] Training epoch: 4546
[ Wed Apr 25 15:03:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:03:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:03:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:44 2018 ] Training epoch: 4547
[ Wed Apr 25 15:03:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:03:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:03:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:48 2018 ] Training epoch: 4548
[ Wed Apr 25 15:03:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:03:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:03:52 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:03:52 2018 ] Training epoch: 4549
[ Wed Apr 25 15:03:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:03:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:03:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:03:56 2018 ] Training epoch: 4550
[ Wed Apr 25 15:04:00 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:04:00 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:04:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:00 2018 ] Eval epoch: 4550
[ Wed Apr 25 15:04:03 2018 ] 	Mean test loss of 1 batches: 0.23059062659740448.
[ Wed Apr 25 15:04:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:04:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:04:03 2018 ] Training epoch: 4551
[ Wed Apr 25 15:04:07 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000100
[ Wed Apr 25 15:04:07 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:04:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:07 2018 ] Training epoch: 4552
[ Wed Apr 25 15:04:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:04:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:04:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:11 2018 ] Training epoch: 4553
[ Wed Apr 25 15:04:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:04:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:04:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:15 2018 ] Training epoch: 4554
[ Wed Apr 25 15:04:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:04:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:04:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:19 2018 ] Training epoch: 4555
[ Wed Apr 25 15:04:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:04:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:04:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:23 2018 ] Eval epoch: 4555
[ Wed Apr 25 15:04:26 2018 ] 	Mean test loss of 1 batches: 0.22746817767620087.
[ Wed Apr 25 15:04:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:04:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:04:26 2018 ] Training epoch: 4556
[ Wed Apr 25 15:04:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:04:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:04:30 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:04:30 2018 ] Training epoch: 4557
[ Wed Apr 25 15:04:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:04:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:04:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:34 2018 ] Training epoch: 4558
[ Wed Apr 25 15:04:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:04:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:04:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:38 2018 ] Training epoch: 4559
[ Wed Apr 25 15:04:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:04:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:04:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:42 2018 ] Training epoch: 4560
[ Wed Apr 25 15:04:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:04:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:04:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:46 2018 ] Eval epoch: 4560
[ Wed Apr 25 15:04:49 2018 ] 	Mean test loss of 1 batches: 0.22649499773979187.
[ Wed Apr 25 15:04:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:04:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:04:49 2018 ] Training epoch: 4561
[ Wed Apr 25 15:04:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:04:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:04:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:04:53 2018 ] Training epoch: 4562
[ Wed Apr 25 15:04:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:04:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:04:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:04:57 2018 ] Training epoch: 4563
[ Wed Apr 25 15:05:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:05:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:05:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:01 2018 ] Training epoch: 4564
[ Wed Apr 25 15:05:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:05:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:05:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:05:05 2018 ] Training epoch: 4565
[ Wed Apr 25 15:05:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:05:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:05:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:09 2018 ] Eval epoch: 4565
[ Wed Apr 25 15:05:12 2018 ] 	Mean test loss of 1 batches: 0.22669531404972076.
[ Wed Apr 25 15:05:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:05:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:05:12 2018 ] Training epoch: 4566
[ Wed Apr 25 15:05:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:05:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:05:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:16 2018 ] Training epoch: 4567
[ Wed Apr 25 15:05:20 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:05:20 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:05:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:20 2018 ] Training epoch: 4568
[ Wed Apr 25 15:05:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:05:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:05:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:24 2018 ] Training epoch: 4569
[ Wed Apr 25 15:05:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:05:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:05:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:28 2018 ] Training epoch: 4570
[ Wed Apr 25 15:05:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:05:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:05:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:32 2018 ] Eval epoch: 4570
[ Wed Apr 25 15:05:35 2018 ] 	Mean test loss of 1 batches: 0.23119299113750458.
[ Wed Apr 25 15:05:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:05:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:05:35 2018 ] Training epoch: 4571
[ Wed Apr 25 15:05:39 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:05:39 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:05:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:39 2018 ] Training epoch: 4572
[ Wed Apr 25 15:05:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:05:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:05:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:05:43 2018 ] Training epoch: 4573
[ Wed Apr 25 15:05:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:05:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:05:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:47 2018 ] Training epoch: 4574
[ Wed Apr 25 15:05:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:05:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:05:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:51 2018 ] Training epoch: 4575
[ Wed Apr 25 15:05:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:05:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:05:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:05:55 2018 ] Eval epoch: 4575
[ Wed Apr 25 15:05:58 2018 ] 	Mean test loss of 1 batches: 0.2207150161266327.
[ Wed Apr 25 15:05:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:05:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:05:58 2018 ] Training epoch: 4576
[ Wed Apr 25 15:06:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:06:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:06:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:02 2018 ] Training epoch: 4577
[ Wed Apr 25 15:06:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:06 2018 ] Training epoch: 4578
[ Wed Apr 25 15:06:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:06:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:06:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:10 2018 ] Training epoch: 4579
[ Wed Apr 25 15:06:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:14 2018 ] Training epoch: 4580
[ Wed Apr 25 15:06:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:18 2018 ] Eval epoch: 4580
[ Wed Apr 25 15:06:21 2018 ] 	Mean test loss of 1 batches: 0.2073247879743576.
[ Wed Apr 25 15:06:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:06:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:06:21 2018 ] Training epoch: 4581
[ Wed Apr 25 15:06:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:06:25 2018 ] Training epoch: 4582
[ Wed Apr 25 15:06:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:06:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:06:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:29 2018 ] Training epoch: 4583
[ Wed Apr 25 15:06:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:33 2018 ] Training epoch: 4584
[ Wed Apr 25 15:06:38 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000100
[ Wed Apr 25 15:06:38 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:06:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:38 2018 ] Training epoch: 4585
[ Wed Apr 25 15:06:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:06:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:06:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:42 2018 ] Eval epoch: 4585
[ Wed Apr 25 15:06:44 2018 ] 	Mean test loss of 1 batches: 0.20776136219501495.
[ Wed Apr 25 15:06:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:06:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:06:44 2018 ] Training epoch: 4586
[ Wed Apr 25 15:06:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:48 2018 ] Training epoch: 4587
[ Wed Apr 25 15:06:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:53 2018 ] Training epoch: 4588
[ Wed Apr 25 15:06:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:06:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:06:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:06:57 2018 ] Training epoch: 4589
[ Wed Apr 25 15:07:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:07:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:07:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:01 2018 ] Training epoch: 4590
[ Wed Apr 25 15:07:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:05 2018 ] Eval epoch: 4590
[ Wed Apr 25 15:07:07 2018 ] 	Mean test loss of 1 batches: 0.210630401968956.
[ Wed Apr 25 15:07:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:07:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:07:07 2018 ] Training epoch: 4591
[ Wed Apr 25 15:07:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:11 2018 ] Training epoch: 4592
[ Wed Apr 25 15:07:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:07:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:07:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:15 2018 ] Training epoch: 4593
[ Wed Apr 25 15:07:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:07:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:07:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:20 2018 ] Training epoch: 4594
[ Wed Apr 25 15:07:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:07:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:07:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:24 2018 ] Training epoch: 4595
[ Wed Apr 25 15:07:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:28 2018 ] Eval epoch: 4595
[ Wed Apr 25 15:07:30 2018 ] 	Mean test loss of 1 batches: 0.21477584540843964.
[ Wed Apr 25 15:07:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:07:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:07:30 2018 ] Training epoch: 4596
[ Wed Apr 25 15:07:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:07:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:07:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:07:35 2018 ] Training epoch: 4597
[ Wed Apr 25 15:07:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:39 2018 ] Training epoch: 4598
[ Wed Apr 25 15:07:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:43 2018 ] Training epoch: 4599
[ Wed Apr 25 15:07:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:07:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:07:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:47 2018 ] Training epoch: 4600
[ Wed Apr 25 15:07:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:07:51 2018 ] Eval epoch: 4600
[ Wed Apr 25 15:07:54 2018 ] 	Mean test loss of 1 batches: 0.22172896564006805.
[ Wed Apr 25 15:07:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:07:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:07:54 2018 ] Training epoch: 4601
[ Wed Apr 25 15:07:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:07:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:07:58 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:07:58 2018 ] Training epoch: 4602
[ Wed Apr 25 15:08:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:08:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:08:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:02 2018 ] Training epoch: 4603
[ Wed Apr 25 15:08:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:06 2018 ] Training epoch: 4604
[ Wed Apr 25 15:08:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:08:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:08:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:08:10 2018 ] Training epoch: 4605
[ Wed Apr 25 15:08:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:14 2018 ] Eval epoch: 4605
[ Wed Apr 25 15:08:17 2018 ] 	Mean test loss of 1 batches: 0.22859446704387665.
[ Wed Apr 25 15:08:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:08:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:08:17 2018 ] Training epoch: 4606
[ Wed Apr 25 15:08:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:21 2018 ] Training epoch: 4607
[ Wed Apr 25 15:08:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:08:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:08:25 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:08:25 2018 ] Training epoch: 4608
[ Wed Apr 25 15:08:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:29 2018 ] Training epoch: 4609
[ Wed Apr 25 15:08:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:08:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:08:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:33 2018 ] Training epoch: 4610
[ Wed Apr 25 15:08:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:37 2018 ] Eval epoch: 4610
[ Wed Apr 25 15:08:40 2018 ] 	Mean test loss of 1 batches: 0.22066780924797058.
[ Wed Apr 25 15:08:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:08:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:08:40 2018 ] Training epoch: 4611
[ Wed Apr 25 15:08:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:08:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:08:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:44 2018 ] Training epoch: 4612
[ Wed Apr 25 15:08:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:08:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:08:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:48 2018 ] Training epoch: 4613
[ Wed Apr 25 15:08:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:52 2018 ] Training epoch: 4614
[ Wed Apr 25 15:08:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:08:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:08:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:08:56 2018 ] Training epoch: 4615
[ Wed Apr 25 15:09:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:00 2018 ] Eval epoch: 4615
[ Wed Apr 25 15:09:03 2018 ] 	Mean test loss of 1 batches: 0.21574489772319794.
[ Wed Apr 25 15:09:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:09:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:09:03 2018 ] Training epoch: 4616
[ Wed Apr 25 15:09:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:07 2018 ] Training epoch: 4617
[ Wed Apr 25 15:09:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:11 2018 ] Training epoch: 4618
[ Wed Apr 25 15:09:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:15 2018 ] Training epoch: 4619
[ Wed Apr 25 15:09:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:09:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:09:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:19 2018 ] Training epoch: 4620
[ Wed Apr 25 15:09:23 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:09:23 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:09:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:23 2018 ] Eval epoch: 4620
[ Wed Apr 25 15:09:26 2018 ] 	Mean test loss of 1 batches: 0.21118156611919403.
[ Wed Apr 25 15:09:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:09:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:09:26 2018 ] Training epoch: 4621
[ Wed Apr 25 15:09:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:30 2018 ] Training epoch: 4622
[ Wed Apr 25 15:09:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:34 2018 ] Training epoch: 4623
[ Wed Apr 25 15:09:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:38 2018 ] Training epoch: 4624
[ Wed Apr 25 15:09:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:43 2018 ] Training epoch: 4625
[ Wed Apr 25 15:09:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:47 2018 ] Eval epoch: 4625
[ Wed Apr 25 15:09:49 2018 ] 	Mean test loss of 1 batches: 0.21867932379245758.
[ Wed Apr 25 15:09:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:09:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:09:49 2018 ] Training epoch: 4626
[ Wed Apr 25 15:09:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:09:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:09:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:09:53 2018 ] Training epoch: 4627
[ Wed Apr 25 15:09:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:09:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:09:57 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:09:57 2018 ] Training epoch: 4628
[ Wed Apr 25 15:10:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:10:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:10:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:10:01 2018 ] Training epoch: 4629
[ Wed Apr 25 15:10:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:10:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:10:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:05 2018 ] Training epoch: 4630
[ Wed Apr 25 15:10:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:10:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:10:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:09 2018 ] Eval epoch: 4630
[ Wed Apr 25 15:10:12 2018 ] 	Mean test loss of 1 batches: 0.23155702650547028.
[ Wed Apr 25 15:10:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:10:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:10:12 2018 ] Training epoch: 4631
[ Wed Apr 25 15:10:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:10:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:10:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:16 2018 ] Training epoch: 4632
[ Wed Apr 25 15:10:20 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:10:20 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:10:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:20 2018 ] Training epoch: 4633
[ Wed Apr 25 15:10:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:10:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:10:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:24 2018 ] Training epoch: 4634
[ Wed Apr 25 15:10:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:10:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:10:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:29 2018 ] Training epoch: 4635
[ Wed Apr 25 15:10:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:10:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:10:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:33 2018 ] Eval epoch: 4635
[ Wed Apr 25 15:10:35 2018 ] 	Mean test loss of 1 batches: 0.22963017225265503.
[ Wed Apr 25 15:10:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:10:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:10:36 2018 ] Training epoch: 4636
[ Wed Apr 25 15:10:39 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.000100
[ Wed Apr 25 15:10:39 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 15:10:39 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:10:39 2018 ] Training epoch: 4637
[ Wed Apr 25 15:10:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:10:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:10:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:44 2018 ] Training epoch: 4638
[ Wed Apr 25 15:10:48 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:10:48 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:10:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:48 2018 ] Training epoch: 4639
[ Wed Apr 25 15:10:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:10:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:10:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:52 2018 ] Training epoch: 4640
[ Wed Apr 25 15:10:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:10:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:10:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:10:56 2018 ] Eval epoch: 4640
[ Wed Apr 25 15:10:58 2018 ] 	Mean test loss of 1 batches: 0.23621781170368195.
[ Wed Apr 25 15:10:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:10:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:10:58 2018 ] Training epoch: 4641
[ Wed Apr 25 15:11:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:11:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:11:03 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:11:03 2018 ] Training epoch: 4642
[ Wed Apr 25 15:11:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:11:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:11:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:07 2018 ] Training epoch: 4643
[ Wed Apr 25 15:11:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:11:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:11:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:11 2018 ] Training epoch: 4644
[ Wed Apr 25 15:11:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:11:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:11:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:15 2018 ] Training epoch: 4645
[ Wed Apr 25 15:11:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:11:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:11:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:19 2018 ] Eval epoch: 4645
[ Wed Apr 25 15:11:22 2018 ] 	Mean test loss of 1 batches: 0.22192907333374023.
[ Wed Apr 25 15:11:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:11:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:11:22 2018 ] Training epoch: 4646
[ Wed Apr 25 15:11:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:11:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:11:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:26 2018 ] Training epoch: 4647
[ Wed Apr 25 15:11:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:11:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:11:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:30 2018 ] Training epoch: 4648
[ Wed Apr 25 15:11:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:11:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:11:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:34 2018 ] Training epoch: 4649
[ Wed Apr 25 15:11:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:11:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:11:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:38 2018 ] Training epoch: 4650
[ Wed Apr 25 15:11:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:11:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:11:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:42 2018 ] Eval epoch: 4650
[ Wed Apr 25 15:11:45 2018 ] 	Mean test loss of 1 batches: 0.22657476365566254.
[ Wed Apr 25 15:11:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:11:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:11:45 2018 ] Training epoch: 4651
[ Wed Apr 25 15:11:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:11:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:11:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:49 2018 ] Training epoch: 4652
[ Wed Apr 25 15:11:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:11:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:11:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:53 2018 ] Training epoch: 4653
[ Wed Apr 25 15:11:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:11:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:11:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:11:57 2018 ] Training epoch: 4654
[ Wed Apr 25 15:12:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:12:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:12:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:01 2018 ] Training epoch: 4655
[ Wed Apr 25 15:12:05 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:12:05 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:12:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:05 2018 ] Eval epoch: 4655
[ Wed Apr 25 15:12:08 2018 ] 	Mean test loss of 1 batches: 0.22191283106803894.
[ Wed Apr 25 15:12:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:12:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:12:08 2018 ] Training epoch: 4656
[ Wed Apr 25 15:12:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:12 2018 ] Training epoch: 4657
[ Wed Apr 25 15:12:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:16 2018 ] Training epoch: 4658
[ Wed Apr 25 15:12:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:12:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:12:20 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:12:20 2018 ] Training epoch: 4659
[ Wed Apr 25 15:12:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:24 2018 ] Training epoch: 4660
[ Wed Apr 25 15:12:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:28 2018 ] Eval epoch: 4660
[ Wed Apr 25 15:12:31 2018 ] 	Mean test loss of 1 batches: 0.210955411195755.
[ Wed Apr 25 15:12:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:12:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:12:31 2018 ] Training epoch: 4661
[ Wed Apr 25 15:12:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:12:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:12:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:35 2018 ] Training epoch: 4662
[ Wed Apr 25 15:12:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:12:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:12:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:39 2018 ] Training epoch: 4663
[ Wed Apr 25 15:12:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:43 2018 ] Training epoch: 4664
[ Wed Apr 25 15:12:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:12:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:12:47 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:12:47 2018 ] Training epoch: 4665
[ Wed Apr 25 15:12:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:12:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:12:52 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:12:52 2018 ] Eval epoch: 4665
[ Wed Apr 25 15:12:55 2018 ] 	Mean test loss of 1 batches: 0.20927317440509796.
[ Wed Apr 25 15:12:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:12:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:12:55 2018 ] Training epoch: 4666
[ Wed Apr 25 15:12:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:12:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:12:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:12:59 2018 ] Training epoch: 4667
[ Wed Apr 25 15:13:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:03 2018 ] Training epoch: 4668
[ Wed Apr 25 15:13:07 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:13:07 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:13:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:13:07 2018 ] Training epoch: 4669
[ Wed Apr 25 15:13:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:11 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:13:11 2018 ] Training epoch: 4670
[ Wed Apr 25 15:13:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:15 2018 ] Eval epoch: 4670
[ Wed Apr 25 15:13:18 2018 ] 	Mean test loss of 1 batches: 0.221893310546875.
[ Wed Apr 25 15:13:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:13:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:13:18 2018 ] Training epoch: 4671
[ Wed Apr 25 15:13:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:13:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:13:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:22 2018 ] Training epoch: 4672
[ Wed Apr 25 15:13:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:13:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:13:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:26 2018 ] Training epoch: 4673
[ Wed Apr 25 15:13:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:13:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:13:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:30 2018 ] Training epoch: 4674
[ Wed Apr 25 15:13:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:35 2018 ] Training epoch: 4675
[ Wed Apr 25 15:13:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:13:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:13:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:13:39 2018 ] Eval epoch: 4675
[ Wed Apr 25 15:13:42 2018 ] 	Mean test loss of 1 batches: 0.2176312357187271.
[ Wed Apr 25 15:13:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:13:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:13:42 2018 ] Training epoch: 4676
[ Wed Apr 25 15:13:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:46 2018 ] Training epoch: 4677
[ Wed Apr 25 15:13:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:13:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:13:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:50 2018 ] Training epoch: 4678
[ Wed Apr 25 15:13:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:13:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:13:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:54 2018 ] Training epoch: 4679
[ Wed Apr 25 15:13:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:13:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:13:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:13:58 2018 ] Training epoch: 4680
[ Wed Apr 25 15:14:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:02 2018 ] Eval epoch: 4680
[ Wed Apr 25 15:14:05 2018 ] 	Mean test loss of 1 batches: 0.23025596141815186.
[ Wed Apr 25 15:14:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:14:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:14:05 2018 ] Training epoch: 4681
[ Wed Apr 25 15:14:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:14:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:14:09 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:14:09 2018 ] Training epoch: 4682
[ Wed Apr 25 15:14:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:14 2018 ] Training epoch: 4683
[ Wed Apr 25 15:14:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:14:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:14:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:18 2018 ] Training epoch: 4684
[ Wed Apr 25 15:14:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:14:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:14:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:22 2018 ] Training epoch: 4685
[ Wed Apr 25 15:14:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:14:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:14:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:26 2018 ] Eval epoch: 4685
[ Wed Apr 25 15:14:29 2018 ] 	Mean test loss of 1 batches: 0.23023563623428345.
[ Wed Apr 25 15:14:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:14:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:14:29 2018 ] Training epoch: 4686
[ Wed Apr 25 15:14:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:33 2018 ] Training epoch: 4687
[ Wed Apr 25 15:14:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:37 2018 ] Training epoch: 4688
[ Wed Apr 25 15:14:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:41 2018 ] Training epoch: 4689
[ Wed Apr 25 15:14:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:45 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 15:14:45 2018 ] Training epoch: 4690
[ Wed Apr 25 15:14:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:14:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:14:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:49 2018 ] Eval epoch: 4690
[ Wed Apr 25 15:14:52 2018 ] 	Mean test loss of 1 batches: 0.2204466015100479.
[ Wed Apr 25 15:14:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:14:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:14:52 2018 ] Training epoch: 4691
[ Wed Apr 25 15:14:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:14:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:14:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:14:56 2018 ] Training epoch: 4692
[ Wed Apr 25 15:15:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:15:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:15:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:01 2018 ] Training epoch: 4693
[ Wed Apr 25 15:15:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:15:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:15:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:05 2018 ] Training epoch: 4694
[ Wed Apr 25 15:15:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:09 2018 ] Training epoch: 4695
[ Wed Apr 25 15:15:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:13 2018 ] Eval epoch: 4695
[ Wed Apr 25 15:15:16 2018 ] 	Mean test loss of 1 batches: 0.22818800806999207.
[ Wed Apr 25 15:15:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:15:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:15:16 2018 ] Training epoch: 4696
[ Wed Apr 25 15:15:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:15:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:15:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:20 2018 ] Training epoch: 4697
[ Wed Apr 25 15:15:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:24 2018 ] Training epoch: 4698
[ Wed Apr 25 15:15:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:15:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:15:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:28 2018 ] Training epoch: 4699
[ Wed Apr 25 15:15:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:15:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:15:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:32 2018 ] Training epoch: 4700
[ Wed Apr 25 15:15:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:36 2018 ] Eval epoch: 4700
[ Wed Apr 25 15:15:39 2018 ] 	Mean test loss of 1 batches: 0.22488285601139069.
[ Wed Apr 25 15:15:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:15:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:15:39 2018 ] Training epoch: 4701
[ Wed Apr 25 15:15:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:43 2018 ] Training epoch: 4702
[ Wed Apr 25 15:15:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:47 2018 ] Training epoch: 4703
[ Wed Apr 25 15:15:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:51 2018 ] Training epoch: 4704
[ Wed Apr 25 15:15:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:15:55 2018 ] Training epoch: 4705
[ Wed Apr 25 15:15:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:15:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:15:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:15:59 2018 ] Eval epoch: 4705
[ Wed Apr 25 15:16:02 2018 ] 	Mean test loss of 1 batches: 0.22655890882015228.
[ Wed Apr 25 15:16:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:16:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:16:02 2018 ] Training epoch: 4706
[ Wed Apr 25 15:16:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:16:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:16:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:06 2018 ] Training epoch: 4707
[ Wed Apr 25 15:16:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:16:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:16:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:10 2018 ] Training epoch: 4708
[ Wed Apr 25 15:16:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:16:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:16:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:14 2018 ] Training epoch: 4709
[ Wed Apr 25 15:16:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:16:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:16:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:18 2018 ] Training epoch: 4710
[ Wed Apr 25 15:16:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:16:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:16:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:22 2018 ] Eval epoch: 4710
[ Wed Apr 25 15:16:25 2018 ] 	Mean test loss of 1 batches: 0.2179388850927353.
[ Wed Apr 25 15:16:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:16:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:16:25 2018 ] Training epoch: 4711
[ Wed Apr 25 15:16:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:16:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:16:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:29 2018 ] Training epoch: 4712
[ Wed Apr 25 15:16:33 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:16:33 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:16:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:33 2018 ] Training epoch: 4713
[ Wed Apr 25 15:16:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:16:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:16:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:37 2018 ] Training epoch: 4714
[ Wed Apr 25 15:16:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:16:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:16:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:41 2018 ] Training epoch: 4715
[ Wed Apr 25 15:16:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:16:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:16:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:45 2018 ] Eval epoch: 4715
[ Wed Apr 25 15:16:48 2018 ] 	Mean test loss of 1 batches: 0.21267713606357574.
[ Wed Apr 25 15:16:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:16:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:16:48 2018 ] Training epoch: 4716
[ Wed Apr 25 15:16:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:16:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:16:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:52 2018 ] Training epoch: 4717
[ Wed Apr 25 15:16:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:16:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:16:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:16:56 2018 ] Training epoch: 4718
[ Wed Apr 25 15:17:00 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:17:00 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:17:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:00 2018 ] Training epoch: 4719
[ Wed Apr 25 15:17:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:17:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:17:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:04 2018 ] Training epoch: 4720
[ Wed Apr 25 15:17:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:17:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:17:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:08 2018 ] Eval epoch: 4720
[ Wed Apr 25 15:17:11 2018 ] 	Mean test loss of 1 batches: 0.21631793677806854.
[ Wed Apr 25 15:17:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:17:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:17:11 2018 ] Training epoch: 4721
[ Wed Apr 25 15:17:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:17:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:17:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:15 2018 ] Training epoch: 4722
[ Wed Apr 25 15:17:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:17:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:17:19 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:17:19 2018 ] Training epoch: 4723
[ Wed Apr 25 15:17:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:17:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:17:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:23 2018 ] Training epoch: 4724
[ Wed Apr 25 15:17:27 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:17:27 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:17:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:27 2018 ] Training epoch: 4725
[ Wed Apr 25 15:17:31 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:17:31 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:17:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:31 2018 ] Eval epoch: 4725
[ Wed Apr 25 15:17:34 2018 ] 	Mean test loss of 1 batches: 0.23222483694553375.
[ Wed Apr 25 15:17:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:17:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:17:34 2018 ] Training epoch: 4726
[ Wed Apr 25 15:17:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:17:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:17:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:38 2018 ] Training epoch: 4727
[ Wed Apr 25 15:17:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:17:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:17:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:42 2018 ] Training epoch: 4728
[ Wed Apr 25 15:17:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:17:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:17:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:46 2018 ] Training epoch: 4729
[ Wed Apr 25 15:17:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:17:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:17:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:17:50 2018 ] Training epoch: 4730
[ Wed Apr 25 15:17:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:17:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:17:54 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 15:17:54 2018 ] Eval epoch: 4730
[ Wed Apr 25 15:17:57 2018 ] 	Mean test loss of 1 batches: 0.22517313063144684.
[ Wed Apr 25 15:17:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:17:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:17:57 2018 ] Training epoch: 4731
[ Wed Apr 25 15:18:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:18:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:18:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:01 2018 ] Training epoch: 4732
[ Wed Apr 25 15:18:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:18:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:18:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:05 2018 ] Training epoch: 4733
[ Wed Apr 25 15:18:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:09 2018 ] Training epoch: 4734
[ Wed Apr 25 15:18:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:18:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:18:13 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:18:13 2018 ] Training epoch: 4735
[ Wed Apr 25 15:18:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:17 2018 ] Eval epoch: 4735
[ Wed Apr 25 15:18:20 2018 ] 	Mean test loss of 1 batches: 0.2167392522096634.
[ Wed Apr 25 15:18:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:18:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:18:20 2018 ] Training epoch: 4736
[ Wed Apr 25 15:18:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:18:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:18:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:24 2018 ] Training epoch: 4737
[ Wed Apr 25 15:18:28 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:18:28 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:18:28 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:18:28 2018 ] Training epoch: 4738
[ Wed Apr 25 15:18:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:32 2018 ] Training epoch: 4739
[ Wed Apr 25 15:18:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:18:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:18:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:36 2018 ] Training epoch: 4740
[ Wed Apr 25 15:18:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:40 2018 ] Eval epoch: 4740
[ Wed Apr 25 15:18:43 2018 ] 	Mean test loss of 1 batches: 0.21913360059261322.
[ Wed Apr 25 15:18:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:18:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:18:43 2018 ] Training epoch: 4741
[ Wed Apr 25 15:18:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:18:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:18:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:18:48 2018 ] Training epoch: 4742
[ Wed Apr 25 15:18:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:52 2018 ] Training epoch: 4743
[ Wed Apr 25 15:18:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:18:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:18:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:18:56 2018 ] Training epoch: 4744
[ Wed Apr 25 15:19:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:19:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:19:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:00 2018 ] Training epoch: 4745
[ Wed Apr 25 15:19:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:19:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:19:04 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:19:04 2018 ] Eval epoch: 4745
[ Wed Apr 25 15:19:07 2018 ] 	Mean test loss of 1 batches: 0.21295525133609772.
[ Wed Apr 25 15:19:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:19:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:19:07 2018 ] Training epoch: 4746
[ Wed Apr 25 15:19:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:19:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:19:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:11 2018 ] Training epoch: 4747
[ Wed Apr 25 15:19:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:19:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:19:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:15 2018 ] Training epoch: 4748
[ Wed Apr 25 15:19:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:19:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:19:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:19 2018 ] Training epoch: 4749
[ Wed Apr 25 15:19:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:19:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:19:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:23 2018 ] Training epoch: 4750
[ Wed Apr 25 15:19:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:19:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:19:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:27 2018 ] Eval epoch: 4750
[ Wed Apr 25 15:19:30 2018 ] 	Mean test loss of 1 batches: 0.2212512195110321.
[ Wed Apr 25 15:19:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:19:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:19:30 2018 ] Training epoch: 4751
[ Wed Apr 25 15:19:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:19:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:19:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:34 2018 ] Training epoch: 4752
[ Wed Apr 25 15:19:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:19:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:19:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:19:38 2018 ] Training epoch: 4753
[ Wed Apr 25 15:19:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:19:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:19:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:42 2018 ] Training epoch: 4754
[ Wed Apr 25 15:19:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:19:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:19:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:46 2018 ] Training epoch: 4755
[ Wed Apr 25 15:19:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:19:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:19:51 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:19:51 2018 ] Eval epoch: 4755
[ Wed Apr 25 15:19:54 2018 ] 	Mean test loss of 1 batches: 0.2220693677663803.
[ Wed Apr 25 15:19:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:19:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:19:54 2018 ] Training epoch: 4756
[ Wed Apr 25 15:19:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:19:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:19:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:19:58 2018 ] Training epoch: 4757
[ Wed Apr 25 15:20:02 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:20:02 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:20:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:02 2018 ] Training epoch: 4758
[ Wed Apr 25 15:20:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:20:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:20:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:20:06 2018 ] Training epoch: 4759
[ Wed Apr 25 15:20:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:20:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:20:10 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:20:10 2018 ] Training epoch: 4760
[ Wed Apr 25 15:20:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:20:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:20:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:14 2018 ] Eval epoch: 4760
[ Wed Apr 25 15:20:17 2018 ] 	Mean test loss of 1 batches: 0.21927566826343536.
[ Wed Apr 25 15:20:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:20:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:20:17 2018 ] Training epoch: 4761
[ Wed Apr 25 15:20:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:20:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:20:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:21 2018 ] Training epoch: 4762
[ Wed Apr 25 15:20:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:20:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:20:26 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:20:26 2018 ] Training epoch: 4763
[ Wed Apr 25 15:20:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:20:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:20:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:30 2018 ] Training epoch: 4764
[ Wed Apr 25 15:20:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:20:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:20:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:20:34 2018 ] Training epoch: 4765
[ Wed Apr 25 15:20:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:20:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:20:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:38 2018 ] Eval epoch: 4765
[ Wed Apr 25 15:20:41 2018 ] 	Mean test loss of 1 batches: 0.22149132192134857.
[ Wed Apr 25 15:20:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:20:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:20:41 2018 ] Training epoch: 4766
[ Wed Apr 25 15:20:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:20:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:20:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:45 2018 ] Training epoch: 4767
[ Wed Apr 25 15:20:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:20:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:20:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:49 2018 ] Training epoch: 4768
[ Wed Apr 25 15:20:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:20:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:20:53 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 15:20:53 2018 ] Training epoch: 4769
[ Wed Apr 25 15:20:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:20:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:20:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:20:57 2018 ] Training epoch: 4770
[ Wed Apr 25 15:21:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:02 2018 ] 	Time consumption: [Data]78%, [Network]21%
[ Wed Apr 25 15:21:02 2018 ] Eval epoch: 4770
[ Wed Apr 25 15:21:05 2018 ] 	Mean test loss of 1 batches: 0.22394607961177826.
[ Wed Apr 25 15:21:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:21:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:21:05 2018 ] Training epoch: 4771
[ Wed Apr 25 15:21:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:21:09 2018 ] Training epoch: 4772
[ Wed Apr 25 15:21:13 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:21:13 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:21:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:21:13 2018 ] Training epoch: 4773
[ Wed Apr 25 15:21:17 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:21:17 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:21:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:17 2018 ] Training epoch: 4774
[ Wed Apr 25 15:21:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:21:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:21:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:21 2018 ] Training epoch: 4775
[ Wed Apr 25 15:21:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:21:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:21:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:25 2018 ] Eval epoch: 4775
[ Wed Apr 25 15:21:28 2018 ] 	Mean test loss of 1 batches: 0.22512170672416687.
[ Wed Apr 25 15:21:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:21:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:21:28 2018 ] Training epoch: 4776
[ Wed Apr 25 15:21:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:32 2018 ] Training epoch: 4777
[ Wed Apr 25 15:21:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:36 2018 ] Training epoch: 4778
[ Wed Apr 25 15:21:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:40 2018 ] Training epoch: 4779
[ Wed Apr 25 15:21:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:21:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:21:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:44 2018 ] Training epoch: 4780
[ Wed Apr 25 15:21:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:48 2018 ] Eval epoch: 4780
[ Wed Apr 25 15:21:51 2018 ] 	Mean test loss of 1 batches: 0.22394311428070068.
[ Wed Apr 25 15:21:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:21:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:21:51 2018 ] Training epoch: 4781
[ Wed Apr 25 15:21:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:21:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:21:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:55 2018 ] Training epoch: 4782
[ Wed Apr 25 15:21:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:21:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:21:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:21:59 2018 ] Training epoch: 4783
[ Wed Apr 25 15:22:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:03 2018 ] Training epoch: 4784
[ Wed Apr 25 15:22:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:22:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:22:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:07 2018 ] Training epoch: 4785
[ Wed Apr 25 15:22:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:12 2018 ] Eval epoch: 4785
[ Wed Apr 25 15:22:15 2018 ] 	Mean test loss of 1 batches: 0.22803351283073425.
[ Wed Apr 25 15:22:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:22:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:22:15 2018 ] Training epoch: 4786
[ Wed Apr 25 15:22:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:19 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:22:19 2018 ] Training epoch: 4787
[ Wed Apr 25 15:22:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:23 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:22:23 2018 ] Training epoch: 4788
[ Wed Apr 25 15:22:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:22:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:22:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:27 2018 ] Training epoch: 4789
[ Wed Apr 25 15:22:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:22:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:22:31 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:22:31 2018 ] Training epoch: 4790
[ Wed Apr 25 15:22:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:22:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:22:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:35 2018 ] Eval epoch: 4790
[ Wed Apr 25 15:22:38 2018 ] 	Mean test loss of 1 batches: 0.23212522268295288.
[ Wed Apr 25 15:22:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:22:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:22:38 2018 ] Training epoch: 4791
[ Wed Apr 25 15:22:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:42 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:22:42 2018 ] Training epoch: 4792
[ Wed Apr 25 15:22:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:46 2018 ] Training epoch: 4793
[ Wed Apr 25 15:22:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:50 2018 ] Training epoch: 4794
[ Wed Apr 25 15:22:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:22:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:22:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:54 2018 ] Training epoch: 4795
[ Wed Apr 25 15:22:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:22:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:22:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:22:58 2018 ] Eval epoch: 4795
[ Wed Apr 25 15:23:01 2018 ] 	Mean test loss of 1 batches: 0.22889024019241333.
[ Wed Apr 25 15:23:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:23:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:23:01 2018 ] Training epoch: 4796
[ Wed Apr 25 15:23:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:23:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:23:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:05 2018 ] Training epoch: 4797
[ Wed Apr 25 15:23:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:09 2018 ] Training epoch: 4798
[ Wed Apr 25 15:23:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:23:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:23:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:13 2018 ] Training epoch: 4799
[ Wed Apr 25 15:23:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:23:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:23:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:17 2018 ] Training epoch: 4800
[ Wed Apr 25 15:23:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:21 2018 ] Eval epoch: 4800
[ Wed Apr 25 15:23:24 2018 ] 	Mean test loss of 1 batches: 0.23559939861297607.
[ Wed Apr 25 15:23:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:23:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:23:24 2018 ] Training epoch: 4801
[ Wed Apr 25 15:23:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:23:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:23:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:28 2018 ] Training epoch: 4802
[ Wed Apr 25 15:23:32 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:23:32 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:23:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:32 2018 ] Training epoch: 4803
[ Wed Apr 25 15:23:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:23:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:23:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:36 2018 ] Training epoch: 4804
[ Wed Apr 25 15:23:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:40 2018 ] Training epoch: 4805
[ Wed Apr 25 15:23:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:23:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:23:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:44 2018 ] Eval epoch: 4805
[ Wed Apr 25 15:23:47 2018 ] 	Mean test loss of 1 batches: 0.21671220660209656.
[ Wed Apr 25 15:23:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:23:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:23:47 2018 ] Training epoch: 4806
[ Wed Apr 25 15:23:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:51 2018 ] Training epoch: 4807
[ Wed Apr 25 15:23:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:55 2018 ] Training epoch: 4808
[ Wed Apr 25 15:23:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:23:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:23:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:23:59 2018 ] Training epoch: 4809
[ Wed Apr 25 15:24:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:24:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:24:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:04 2018 ] Training epoch: 4810
[ Wed Apr 25 15:24:07 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:24:07 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:24:07 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:24:07 2018 ] Eval epoch: 4810
[ Wed Apr 25 15:24:10 2018 ] 	Mean test loss of 1 batches: 0.22420233488082886.
[ Wed Apr 25 15:24:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:24:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:24:10 2018 ] Training epoch: 4811
[ Wed Apr 25 15:24:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:24:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:24:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:15 2018 ] Training epoch: 4812
[ Wed Apr 25 15:24:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:24:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:24:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:19 2018 ] Training epoch: 4813
[ Wed Apr 25 15:24:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:24:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:24:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:23 2018 ] Training epoch: 4814
[ Wed Apr 25 15:24:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:24:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:24:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:27 2018 ] Training epoch: 4815
[ Wed Apr 25 15:24:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:24:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:24:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:31 2018 ] Eval epoch: 4815
[ Wed Apr 25 15:24:34 2018 ] 	Mean test loss of 1 batches: 0.2299017757177353.
[ Wed Apr 25 15:24:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:24:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:24:34 2018 ] Training epoch: 4816
[ Wed Apr 25 15:24:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:24:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:24:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:38 2018 ] Training epoch: 4817
[ Wed Apr 25 15:24:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:24:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:24:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:42 2018 ] Training epoch: 4818
[ Wed Apr 25 15:24:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:24:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:24:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:46 2018 ] Training epoch: 4819
[ Wed Apr 25 15:24:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:24:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:24:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:24:50 2018 ] Training epoch: 4820
[ Wed Apr 25 15:24:54 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:24:54 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:24:54 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 15:24:54 2018 ] Eval epoch: 4820
[ Wed Apr 25 15:24:57 2018 ] 	Mean test loss of 1 batches: 0.22645103931427002.
[ Wed Apr 25 15:24:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:24:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:24:57 2018 ] Training epoch: 4821
[ Wed Apr 25 15:25:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:25:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:25:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:01 2018 ] Training epoch: 4822
[ Wed Apr 25 15:25:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:25:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:25:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:05 2018 ] Training epoch: 4823
[ Wed Apr 25 15:25:09 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:25:09 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:25:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:09 2018 ] Training epoch: 4824
[ Wed Apr 25 15:25:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:25:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:25:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:13 2018 ] Training epoch: 4825
[ Wed Apr 25 15:25:17 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:25:17 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:25:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:17 2018 ] Eval epoch: 4825
[ Wed Apr 25 15:25:20 2018 ] 	Mean test loss of 1 batches: 0.2212352454662323.
[ Wed Apr 25 15:25:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:25:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:25:20 2018 ] Training epoch: 4826
[ Wed Apr 25 15:25:24 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000100
[ Wed Apr 25 15:25:24 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:25:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:24 2018 ] Training epoch: 4827
[ Wed Apr 25 15:25:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:25:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:25:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:28 2018 ] Training epoch: 4828
[ Wed Apr 25 15:25:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:25:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:25:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:32 2018 ] Training epoch: 4829
[ Wed Apr 25 15:25:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:25:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:25:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:36 2018 ] Training epoch: 4830
[ Wed Apr 25 15:25:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:25:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:25:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:40 2018 ] Eval epoch: 4830
[ Wed Apr 25 15:25:43 2018 ] 	Mean test loss of 1 batches: 0.22379200160503387.
[ Wed Apr 25 15:25:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:25:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:25:43 2018 ] Training epoch: 4831
[ Wed Apr 25 15:25:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:25:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:25:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:47 2018 ] Training epoch: 4832
[ Wed Apr 25 15:25:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:25:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:25:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:51 2018 ] Training epoch: 4833
[ Wed Apr 25 15:25:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:25:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:25:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:55 2018 ] Training epoch: 4834
[ Wed Apr 25 15:25:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:25:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:25:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:25:59 2018 ] Training epoch: 4835
[ Wed Apr 25 15:26:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:26:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:26:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:03 2018 ] Eval epoch: 4835
[ Wed Apr 25 15:26:06 2018 ] 	Mean test loss of 1 batches: 0.21056248247623444.
[ Wed Apr 25 15:26:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:26:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:26:06 2018 ] Training epoch: 4836
[ Wed Apr 25 15:26:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:26:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:26:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:10 2018 ] Training epoch: 4837
[ Wed Apr 25 15:26:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:26:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:26:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:14 2018 ] Training epoch: 4838
[ Wed Apr 25 15:26:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:26:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:26:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:18 2018 ] Training epoch: 4839
[ Wed Apr 25 15:26:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:26:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:26:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:23 2018 ] Training epoch: 4840
[ Wed Apr 25 15:26:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:26:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:26:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:27 2018 ] Eval epoch: 4840
[ Wed Apr 25 15:26:29 2018 ] 	Mean test loss of 1 batches: 0.20952846109867096.
[ Wed Apr 25 15:26:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:26:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:26:29 2018 ] Training epoch: 4841
[ Wed Apr 25 15:26:34 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:26:34 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:26:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:34 2018 ] Training epoch: 4842
[ Wed Apr 25 15:26:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:26:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:26:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:38 2018 ] Training epoch: 4843
[ Wed Apr 25 15:26:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:26:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:26:42 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:26:42 2018 ] Training epoch: 4844
[ Wed Apr 25 15:26:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:26:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:26:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:46 2018 ] Training epoch: 4845
[ Wed Apr 25 15:26:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:26:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:26:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:50 2018 ] Eval epoch: 4845
[ Wed Apr 25 15:26:53 2018 ] 	Mean test loss of 1 batches: 0.20654413104057312.
[ Wed Apr 25 15:26:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:26:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:26:53 2018 ] Training epoch: 4846
[ Wed Apr 25 15:26:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:26:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:26:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:26:57 2018 ] Training epoch: 4847
[ Wed Apr 25 15:27:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:01 2018 ] Training epoch: 4848
[ Wed Apr 25 15:27:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:27:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:27:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:05 2018 ] Training epoch: 4849
[ Wed Apr 25 15:27:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:09 2018 ] Training epoch: 4850
[ Wed Apr 25 15:27:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:13 2018 ] Eval epoch: 4850
[ Wed Apr 25 15:27:16 2018 ] 	Mean test loss of 1 batches: 0.2146107703447342.
[ Wed Apr 25 15:27:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:27:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:27:16 2018 ] Training epoch: 4851
[ Wed Apr 25 15:27:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:27:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:27:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:20 2018 ] Training epoch: 4852
[ Wed Apr 25 15:27:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:24 2018 ] Training epoch: 4853
[ Wed Apr 25 15:27:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:28 2018 ] Training epoch: 4854
[ Wed Apr 25 15:27:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:32 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:27:32 2018 ] Training epoch: 4855
[ Wed Apr 25 15:27:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:27:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:27:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:27:36 2018 ] Eval epoch: 4855
[ Wed Apr 25 15:27:39 2018 ] 	Mean test loss of 1 batches: 0.2136169672012329.
[ Wed Apr 25 15:27:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:27:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:27:39 2018 ] Training epoch: 4856
[ Wed Apr 25 15:27:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:27:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:27:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:43 2018 ] Training epoch: 4857
[ Wed Apr 25 15:27:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:27:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:27:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:47 2018 ] Training epoch: 4858
[ Wed Apr 25 15:27:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:27:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:27:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:51 2018 ] Training epoch: 4859
[ Wed Apr 25 15:27:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:27:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:27:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:55 2018 ] Training epoch: 4860
[ Wed Apr 25 15:27:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:27:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:27:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:27:59 2018 ] Eval epoch: 4860
[ Wed Apr 25 15:28:02 2018 ] 	Mean test loss of 1 batches: 0.21594661474227905.
[ Wed Apr 25 15:28:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:28:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:28:02 2018 ] Training epoch: 4861
[ Wed Apr 25 15:28:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:06 2018 ] Training epoch: 4862
[ Wed Apr 25 15:28:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:10 2018 ] Training epoch: 4863
[ Wed Apr 25 15:28:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:28:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:28:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:14 2018 ] Training epoch: 4864
[ Wed Apr 25 15:28:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:28:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:28:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:18 2018 ] Training epoch: 4865
[ Wed Apr 25 15:28:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:22 2018 ] Eval epoch: 4865
[ Wed Apr 25 15:28:25 2018 ] 	Mean test loss of 1 batches: 0.20984433591365814.
[ Wed Apr 25 15:28:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:28:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:28:25 2018 ] Training epoch: 4866
[ Wed Apr 25 15:28:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:28:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:28:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:29 2018 ] Training epoch: 4867
[ Wed Apr 25 15:28:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:28:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:28:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:33 2018 ] Training epoch: 4868
[ Wed Apr 25 15:28:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:37 2018 ] Training epoch: 4869
[ Wed Apr 25 15:28:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:28:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:28:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:41 2018 ] Training epoch: 4870
[ Wed Apr 25 15:28:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:45 2018 ] Eval epoch: 4870
[ Wed Apr 25 15:28:48 2018 ] 	Mean test loss of 1 batches: 0.2129211276769638.
[ Wed Apr 25 15:28:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:28:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:28:48 2018 ] Training epoch: 4871
[ Wed Apr 25 15:28:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:28:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:28:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:28:52 2018 ] Training epoch: 4872
[ Wed Apr 25 15:28:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:28:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:28:56 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:28:56 2018 ] Training epoch: 4873
[ Wed Apr 25 15:29:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:29:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:29:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:00 2018 ] Training epoch: 4874
[ Wed Apr 25 15:29:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:29:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:29:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:29:04 2018 ] Training epoch: 4875
[ Wed Apr 25 15:29:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:29:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:29:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:08 2018 ] Eval epoch: 4875
[ Wed Apr 25 15:29:11 2018 ] 	Mean test loss of 1 batches: 0.21896225214004517.
[ Wed Apr 25 15:29:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:29:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:29:11 2018 ] Training epoch: 4876
[ Wed Apr 25 15:29:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:15 2018 ] Training epoch: 4877
[ Wed Apr 25 15:29:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:29:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:29:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:19 2018 ] Training epoch: 4878
[ Wed Apr 25 15:29:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:23 2018 ] Training epoch: 4879
[ Wed Apr 25 15:29:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:27 2018 ] Training epoch: 4880
[ Wed Apr 25 15:29:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:31 2018 ] Eval epoch: 4880
[ Wed Apr 25 15:29:34 2018 ] 	Mean test loss of 1 batches: 0.2151489108800888.
[ Wed Apr 25 15:29:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:29:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:29:34 2018 ] Training epoch: 4881
[ Wed Apr 25 15:29:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:38 2018 ] Training epoch: 4882
[ Wed Apr 25 15:29:42 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000100
[ Wed Apr 25 15:29:42 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:29:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:42 2018 ] Training epoch: 4883
[ Wed Apr 25 15:29:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:46 2018 ] Training epoch: 4884
[ Wed Apr 25 15:29:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:50 2018 ] Training epoch: 4885
[ Wed Apr 25 15:29:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:29:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:29:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:29:54 2018 ] Eval epoch: 4885
[ Wed Apr 25 15:29:57 2018 ] 	Mean test loss of 1 batches: 0.22601258754730225.
[ Wed Apr 25 15:29:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:29:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:29:57 2018 ] Training epoch: 4886
[ Wed Apr 25 15:30:01 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:30:01 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:30:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:01 2018 ] Training epoch: 4887
[ Wed Apr 25 15:30:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:05 2018 ] Training epoch: 4888
[ Wed Apr 25 15:30:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:30:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:30:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:09 2018 ] Training epoch: 4889
[ Wed Apr 25 15:30:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:30:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:30:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:13 2018 ] Training epoch: 4890
[ Wed Apr 25 15:30:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:30:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:30:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:30:17 2018 ] Eval epoch: 4890
[ Wed Apr 25 15:30:20 2018 ] 	Mean test loss of 1 batches: 0.22661112248897552.
[ Wed Apr 25 15:30:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:30:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:30:20 2018 ] Training epoch: 4891
[ Wed Apr 25 15:30:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:24 2018 ] Training epoch: 4892
[ Wed Apr 25 15:30:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:30:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:30:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:28 2018 ] Training epoch: 4893
[ Wed Apr 25 15:30:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:32 2018 ] Training epoch: 4894
[ Wed Apr 25 15:30:36 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:30:36 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:30:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:30:36 2018 ] Training epoch: 4895
[ Wed Apr 25 15:30:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:30:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:30:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:40 2018 ] Eval epoch: 4895
[ Wed Apr 25 15:30:43 2018 ] 	Mean test loss of 1 batches: 0.22334471344947815.
[ Wed Apr 25 15:30:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:30:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:30:43 2018 ] Training epoch: 4896
[ Wed Apr 25 15:30:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:47 2018 ] Training epoch: 4897
[ Wed Apr 25 15:30:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:51 2018 ] Training epoch: 4898
[ Wed Apr 25 15:30:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:30:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:30:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:55 2018 ] Training epoch: 4899
[ Wed Apr 25 15:30:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:30:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:30:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:30:59 2018 ] Training epoch: 4900
[ Wed Apr 25 15:31:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:03 2018 ] Eval epoch: 4900
[ Wed Apr 25 15:31:06 2018 ] 	Mean test loss of 1 batches: 0.22820138931274414.
[ Wed Apr 25 15:31:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:31:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:31:06 2018 ] Training epoch: 4901
[ Wed Apr 25 15:31:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:10 2018 ] Training epoch: 4902
[ Wed Apr 25 15:31:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:14 2018 ] Training epoch: 4903
[ Wed Apr 25 15:31:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:18 2018 ] Training epoch: 4904
[ Wed Apr 25 15:31:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:22 2018 ] Training epoch: 4905
[ Wed Apr 25 15:31:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:26 2018 ] Eval epoch: 4905
[ Wed Apr 25 15:31:29 2018 ] 	Mean test loss of 1 batches: 0.22397737205028534.
[ Wed Apr 25 15:31:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:31:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:31:29 2018 ] Training epoch: 4906
[ Wed Apr 25 15:31:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:31:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:31:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:33 2018 ] Training epoch: 4907
[ Wed Apr 25 15:31:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:31:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:31:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:37 2018 ] Training epoch: 4908
[ Wed Apr 25 15:31:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:31:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:31:42 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:31:42 2018 ] Training epoch: 4909
[ Wed Apr 25 15:31:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:31:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:31:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:46 2018 ] Training epoch: 4910
[ Wed Apr 25 15:31:50 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.000100
[ Wed Apr 25 15:31:50 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 15:31:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:50 2018 ] Eval epoch: 4910
[ Wed Apr 25 15:31:53 2018 ] 	Mean test loss of 1 batches: 0.21260622143745422.
[ Wed Apr 25 15:31:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:31:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:31:53 2018 ] Training epoch: 4911
[ Wed Apr 25 15:31:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:31:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:31:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:31:57 2018 ] Training epoch: 4912
[ Wed Apr 25 15:32:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:32:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:32:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:01 2018 ] Training epoch: 4913
[ Wed Apr 25 15:32:05 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:32:05 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:32:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:05 2018 ] Training epoch: 4914
[ Wed Apr 25 15:32:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:09 2018 ] Training epoch: 4915
[ Wed Apr 25 15:32:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:13 2018 ] Eval epoch: 4915
[ Wed Apr 25 15:32:16 2018 ] 	Mean test loss of 1 batches: 0.22007693350315094.
[ Wed Apr 25 15:32:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:32:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:32:16 2018 ] Training epoch: 4916
[ Wed Apr 25 15:32:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:32:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:32:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:20 2018 ] Training epoch: 4917
[ Wed Apr 25 15:32:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:32:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:32:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:24 2018 ] Training epoch: 4918
[ Wed Apr 25 15:32:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:28 2018 ] Training epoch: 4919
[ Wed Apr 25 15:32:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:32:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:32:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:32 2018 ] Training epoch: 4920
[ Wed Apr 25 15:32:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:36 2018 ] Eval epoch: 4920
[ Wed Apr 25 15:32:39 2018 ] 	Mean test loss of 1 batches: 0.23610670864582062.
[ Wed Apr 25 15:32:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:32:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:32:39 2018 ] Training epoch: 4921
[ Wed Apr 25 15:32:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:32:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:32:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:43 2018 ] Training epoch: 4922
[ Wed Apr 25 15:32:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:47 2018 ] Training epoch: 4923
[ Wed Apr 25 15:32:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:51 2018 ] Training epoch: 4924
[ Wed Apr 25 15:32:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:32:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:32:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:55 2018 ] Training epoch: 4925
[ Wed Apr 25 15:32:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:32:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:32:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:32:59 2018 ] Eval epoch: 4925
[ Wed Apr 25 15:33:02 2018 ] 	Mean test loss of 1 batches: 0.23829269409179688.
[ Wed Apr 25 15:33:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:33:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:33:02 2018 ] Training epoch: 4926
[ Wed Apr 25 15:33:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:06 2018 ] Training epoch: 4927
[ Wed Apr 25 15:33:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:10 2018 ] Training epoch: 4928
[ Wed Apr 25 15:33:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:33:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:33:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:14 2018 ] Training epoch: 4929
[ Wed Apr 25 15:33:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:18 2018 ] Training epoch: 4930
[ Wed Apr 25 15:33:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:22 2018 ] Eval epoch: 4930
[ Wed Apr 25 15:33:25 2018 ] 	Mean test loss of 1 batches: 0.23583118617534637.
[ Wed Apr 25 15:33:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:33:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:33:25 2018 ] Training epoch: 4931
[ Wed Apr 25 15:33:29 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:33:29 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:33:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:29 2018 ] Training epoch: 4932
[ Wed Apr 25 15:33:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:33 2018 ] Training epoch: 4933
[ Wed Apr 25 15:33:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:37 2018 ] Training epoch: 4934
[ Wed Apr 25 15:33:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:33:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:33:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:41 2018 ] Training epoch: 4935
[ Wed Apr 25 15:33:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:33:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:33:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:45 2018 ] Eval epoch: 4935
[ Wed Apr 25 15:33:48 2018 ] 	Mean test loss of 1 batches: 0.23202161490917206.
[ Wed Apr 25 15:33:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:33:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:33:48 2018 ] Training epoch: 4936
[ Wed Apr 25 15:33:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:33:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:33:52 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:33:52 2018 ] Training epoch: 4937
[ Wed Apr 25 15:33:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:33:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:33:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:33:56 2018 ] Training epoch: 4938
[ Wed Apr 25 15:34:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:00 2018 ] Training epoch: 4939
[ Wed Apr 25 15:34:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:04 2018 ] Training epoch: 4940
[ Wed Apr 25 15:34:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:34:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:34:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:09 2018 ] Eval epoch: 4940
[ Wed Apr 25 15:34:11 2018 ] 	Mean test loss of 1 batches: 0.21608784794807434.
[ Wed Apr 25 15:34:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:34:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:34:11 2018 ] Training epoch: 4941
[ Wed Apr 25 15:34:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:34:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:34:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:15 2018 ] Training epoch: 4942
[ Wed Apr 25 15:34:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:34:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:34:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:19 2018 ] Training epoch: 4943
[ Wed Apr 25 15:34:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:23 2018 ] Training epoch: 4944
[ Wed Apr 25 15:34:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:34:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:34:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:27 2018 ] Training epoch: 4945
[ Wed Apr 25 15:34:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:34:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:34:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:32 2018 ] Eval epoch: 4945
[ Wed Apr 25 15:34:34 2018 ] 	Mean test loss of 1 batches: 0.21714308857917786.
[ Wed Apr 25 15:34:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:34:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:34:34 2018 ] Training epoch: 4946
[ Wed Apr 25 15:34:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:39 2018 ] Training epoch: 4947
[ Wed Apr 25 15:34:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:43 2018 ] Training epoch: 4948
[ Wed Apr 25 15:34:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:47 2018 ] Training epoch: 4949
[ Wed Apr 25 15:34:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:34:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:34:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:51 2018 ] Training epoch: 4950
[ Wed Apr 25 15:34:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:34:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:34:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:34:55 2018 ] Eval epoch: 4950
[ Wed Apr 25 15:34:58 2018 ] 	Mean test loss of 1 batches: 0.222232848405838.
[ Wed Apr 25 15:34:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:34:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:34:58 2018 ] Training epoch: 4951
[ Wed Apr 25 15:35:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:35:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:35:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:02 2018 ] Training epoch: 4952
[ Wed Apr 25 15:35:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:35:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:35:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:06 2018 ] Training epoch: 4953
[ Wed Apr 25 15:35:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:35:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:35:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:10 2018 ] Training epoch: 4954
[ Wed Apr 25 15:35:14 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000100
[ Wed Apr 25 15:35:14 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:35:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:14 2018 ] Training epoch: 4955
[ Wed Apr 25 15:35:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:35:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:35:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:18 2018 ] Eval epoch: 4955
[ Wed Apr 25 15:35:21 2018 ] 	Mean test loss of 1 batches: 0.21904738247394562.
[ Wed Apr 25 15:35:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:35:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:35:21 2018 ] Training epoch: 4956
[ Wed Apr 25 15:35:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:35:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:35:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:25 2018 ] Training epoch: 4957
[ Wed Apr 25 15:35:29 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:35:29 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:35:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:29 2018 ] Training epoch: 4958
[ Wed Apr 25 15:35:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:35:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:35:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:33 2018 ] Training epoch: 4959
[ Wed Apr 25 15:35:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:35:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:35:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:37 2018 ] Training epoch: 4960
[ Wed Apr 25 15:35:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:35:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:35:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:41 2018 ] Eval epoch: 4960
[ Wed Apr 25 15:35:44 2018 ] 	Mean test loss of 1 batches: 0.22334350645542145.
[ Wed Apr 25 15:35:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:35:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:35:44 2018 ] Training epoch: 4961
[ Wed Apr 25 15:35:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:35:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:35:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:48 2018 ] Training epoch: 4962
[ Wed Apr 25 15:35:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:35:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:35:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:52 2018 ] Training epoch: 4963
[ Wed Apr 25 15:35:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:35:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:35:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:35:56 2018 ] Training epoch: 4964
[ Wed Apr 25 15:36:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:00 2018 ] Training epoch: 4965
[ Wed Apr 25 15:36:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:36:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:36:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:04 2018 ] Eval epoch: 4965
[ Wed Apr 25 15:36:07 2018 ] 	Mean test loss of 1 batches: 0.2175847738981247.
[ Wed Apr 25 15:36:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:36:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:36:07 2018 ] Training epoch: 4966
[ Wed Apr 25 15:36:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:36:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:36:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:11 2018 ] Training epoch: 4967
[ Wed Apr 25 15:36:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:15 2018 ] Training epoch: 4968
[ Wed Apr 25 15:36:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:19 2018 ] Training epoch: 4969
[ Wed Apr 25 15:36:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:36:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:36:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:23 2018 ] Training epoch: 4970
[ Wed Apr 25 15:36:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:36:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:36:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:27 2018 ] Eval epoch: 4970
[ Wed Apr 25 15:36:30 2018 ] 	Mean test loss of 1 batches: 0.22702331840991974.
[ Wed Apr 25 15:36:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:36:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:36:30 2018 ] Training epoch: 4971
[ Wed Apr 25 15:36:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:34 2018 ] Training epoch: 4972
[ Wed Apr 25 15:36:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:36:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:36:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:38 2018 ] Training epoch: 4973
[ Wed Apr 25 15:36:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:42 2018 ] Training epoch: 4974
[ Wed Apr 25 15:36:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:46 2018 ] Training epoch: 4975
[ Wed Apr 25 15:36:50 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.000100
[ Wed Apr 25 15:36:50 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 15:36:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:50 2018 ] Eval epoch: 4975
[ Wed Apr 25 15:36:53 2018 ] 	Mean test loss of 1 batches: 0.22967372834682465.
[ Wed Apr 25 15:36:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:36:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:36:53 2018 ] Training epoch: 4976
[ Wed Apr 25 15:36:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:36:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:36:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:36:57 2018 ] Training epoch: 4977
[ Wed Apr 25 15:37:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:01 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:37:01 2018 ] Training epoch: 4978
[ Wed Apr 25 15:37:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:37:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:37:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:05 2018 ] Training epoch: 4979
[ Wed Apr 25 15:37:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:37:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:37:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:09 2018 ] Training epoch: 4980
[ Wed Apr 25 15:37:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:37:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:37:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:13 2018 ] Eval epoch: 4980
[ Wed Apr 25 15:37:16 2018 ] 	Mean test loss of 1 batches: 0.21995842456817627.
[ Wed Apr 25 15:37:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:37:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:37:16 2018 ] Training epoch: 4981
[ Wed Apr 25 15:37:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:37:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:37:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:20 2018 ] Training epoch: 4982
[ Wed Apr 25 15:37:24 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:37:24 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:37:24 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:37:24 2018 ] Training epoch: 4983
[ Wed Apr 25 15:37:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:37:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:37:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:28 2018 ] Training epoch: 4984
[ Wed Apr 25 15:37:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:32 2018 ] Training epoch: 4985
[ Wed Apr 25 15:37:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:36 2018 ] Eval epoch: 4985
[ Wed Apr 25 15:37:39 2018 ] 	Mean test loss of 1 batches: 0.22407180070877075.
[ Wed Apr 25 15:37:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:37:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:37:39 2018 ] Training epoch: 4986
[ Wed Apr 25 15:37:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:43 2018 ] Training epoch: 4987
[ Wed Apr 25 15:37:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:47 2018 ] Training epoch: 4988
[ Wed Apr 25 15:37:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:37:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:37:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:51 2018 ] Training epoch: 4989
[ Wed Apr 25 15:37:55 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000100
[ Wed Apr 25 15:37:55 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:37:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:55 2018 ] Training epoch: 4990
[ Wed Apr 25 15:37:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:37:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:37:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:37:59 2018 ] Eval epoch: 4990
[ Wed Apr 25 15:38:02 2018 ] 	Mean test loss of 1 batches: 0.22902947664260864.
[ Wed Apr 25 15:38:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:38:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:38:02 2018 ] Training epoch: 4991
[ Wed Apr 25 15:38:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:38:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:38:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:06 2018 ] Training epoch: 4992
[ Wed Apr 25 15:38:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:38:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:38:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:38:11 2018 ] Training epoch: 4993
[ Wed Apr 25 15:38:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:38:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:38:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:15 2018 ] Training epoch: 4994
[ Wed Apr 25 15:38:19 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000100
[ Wed Apr 25 15:38:19 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:38:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:19 2018 ] Training epoch: 4995
[ Wed Apr 25 15:38:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:38:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:38:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:23 2018 ] Eval epoch: 4995
[ Wed Apr 25 15:38:26 2018 ] 	Mean test loss of 1 batches: 0.22362205386161804.
[ Wed Apr 25 15:38:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:38:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:38:26 2018 ] Training epoch: 4996
[ Wed Apr 25 15:38:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:38:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:38:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:30 2018 ] Training epoch: 4997
[ Wed Apr 25 15:38:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:38:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:38:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:34 2018 ] Training epoch: 4998
[ Wed Apr 25 15:38:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000100
[ Wed Apr 25 15:38:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:38:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:38:38 2018 ] Training epoch: 4999
[ Wed Apr 25 15:38:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000100
[ Wed Apr 25 15:38:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:38:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:42 2018 ] Training epoch: 5000
[ Wed Apr 25 15:38:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000100
[ Wed Apr 25 15:38:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:38:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:46 2018 ] Eval epoch: 5000
[ Wed Apr 25 15:38:49 2018 ] 	Mean test loss of 1 batches: 0.22351694107055664.
[ Wed Apr 25 15:38:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:38:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:38:49 2018 ] Training epoch: 5001
[ Wed Apr 25 15:38:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 15:38:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:38:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:53 2018 ] Training epoch: 5002
[ Wed Apr 25 15:38:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:38:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:38:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:38:57 2018 ] Training epoch: 5003
[ Wed Apr 25 15:39:01 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.000010
[ Wed Apr 25 15:39:01 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 15:39:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:01 2018 ] Training epoch: 5004
[ Wed Apr 25 15:39:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:39:05 2018 ] Training epoch: 5005
[ Wed Apr 25 15:39:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:09 2018 ] Eval epoch: 5005
[ Wed Apr 25 15:39:12 2018 ] 	Mean test loss of 1 batches: 0.2209257334470749.
[ Wed Apr 25 15:39:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:39:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:39:12 2018 ] Training epoch: 5006
[ Wed Apr 25 15:39:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:16 2018 ] Training epoch: 5007
[ Wed Apr 25 15:39:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:39:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:39:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:20 2018 ] Training epoch: 5008
[ Wed Apr 25 15:39:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:24 2018 ] Training epoch: 5009
[ Wed Apr 25 15:39:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:28 2018 ] Training epoch: 5010
[ Wed Apr 25 15:39:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:32 2018 ] Eval epoch: 5010
[ Wed Apr 25 15:39:34 2018 ] 	Mean test loss of 1 batches: 0.2302590161561966.
[ Wed Apr 25 15:39:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:39:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:39:34 2018 ] Training epoch: 5011
[ Wed Apr 25 15:39:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:39:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:39:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:38 2018 ] Training epoch: 5012
[ Wed Apr 25 15:39:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:39:43 2018 ] Training epoch: 5013
[ Wed Apr 25 15:39:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:39:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:39:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:39:47 2018 ] Training epoch: 5014
[ Wed Apr 25 15:39:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:39:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:39:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:51 2018 ] Training epoch: 5015
[ Wed Apr 25 15:39:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:39:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:39:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:39:55 2018 ] Eval epoch: 5015
[ Wed Apr 25 15:39:58 2018 ] 	Mean test loss of 1 batches: 0.2274215817451477.
[ Wed Apr 25 15:39:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:39:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:39:58 2018 ] Training epoch: 5016
[ Wed Apr 25 15:40:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:40:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:40:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:02 2018 ] Training epoch: 5017
[ Wed Apr 25 15:40:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:40:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:40:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:06 2018 ] Training epoch: 5018
[ Wed Apr 25 15:40:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:40:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:40:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:10 2018 ] Training epoch: 5019
[ Wed Apr 25 15:40:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:40:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:40:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:14 2018 ] Training epoch: 5020
[ Wed Apr 25 15:40:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:40:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:40:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:18 2018 ] Eval epoch: 5020
[ Wed Apr 25 15:40:21 2018 ] 	Mean test loss of 1 batches: 0.228049635887146.
[ Wed Apr 25 15:40:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:40:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:40:21 2018 ] Training epoch: 5021
[ Wed Apr 25 15:40:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:40:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:40:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:25 2018 ] Training epoch: 5022
[ Wed Apr 25 15:40:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:40:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:40:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:29 2018 ] Training epoch: 5023
[ Wed Apr 25 15:40:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:40:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:40:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:40:34 2018 ] Training epoch: 5024
[ Wed Apr 25 15:40:38 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 15:40:38 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:40:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:38 2018 ] Training epoch: 5025
[ Wed Apr 25 15:40:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:40:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:40:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:42 2018 ] Eval epoch: 5025
[ Wed Apr 25 15:40:44 2018 ] 	Mean test loss of 1 batches: 0.21909086406230927.
[ Wed Apr 25 15:40:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:40:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:40:44 2018 ] Training epoch: 5026
[ Wed Apr 25 15:40:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:40:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:40:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:48 2018 ] Training epoch: 5027
[ Wed Apr 25 15:40:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:40:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:40:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:52 2018 ] Training epoch: 5028
[ Wed Apr 25 15:40:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:40:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:40:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:40:57 2018 ] Training epoch: 5029
[ Wed Apr 25 15:41:01 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 15:41:01 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:41:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:01 2018 ] Training epoch: 5030
[ Wed Apr 25 15:41:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:41:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:41:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:05 2018 ] Eval epoch: 5030
[ Wed Apr 25 15:41:07 2018 ] 	Mean test loss of 1 batches: 0.2223900854587555.
[ Wed Apr 25 15:41:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:41:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:41:07 2018 ] Training epoch: 5031
[ Wed Apr 25 15:41:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:41:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:41:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:11 2018 ] Training epoch: 5032
[ Wed Apr 25 15:41:15 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000010
[ Wed Apr 25 15:41:15 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:41:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:15 2018 ] Training epoch: 5033
[ Wed Apr 25 15:41:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:41:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:41:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:20 2018 ] Training epoch: 5034
[ Wed Apr 25 15:41:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:41:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:41:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:24 2018 ] Training epoch: 5035
[ Wed Apr 25 15:41:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:41:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:41:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:28 2018 ] Eval epoch: 5035
[ Wed Apr 25 15:41:31 2018 ] 	Mean test loss of 1 batches: 0.2100927233695984.
[ Wed Apr 25 15:41:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:41:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:41:31 2018 ] Training epoch: 5036
[ Wed Apr 25 15:41:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:41:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:41:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:35 2018 ] Training epoch: 5037
[ Wed Apr 25 15:41:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:41:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:41:39 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 15:41:39 2018 ] Training epoch: 5038
[ Wed Apr 25 15:41:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:41:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:41:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:43 2018 ] Training epoch: 5039
[ Wed Apr 25 15:41:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:41:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:41:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:47 2018 ] Training epoch: 5040
[ Wed Apr 25 15:41:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:41:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:41:52 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:41:52 2018 ] Eval epoch: 5040
[ Wed Apr 25 15:41:55 2018 ] 	Mean test loss of 1 batches: 0.21326719224452972.
[ Wed Apr 25 15:41:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:41:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:41:55 2018 ] Training epoch: 5041
[ Wed Apr 25 15:41:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:41:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:41:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:41:59 2018 ] Training epoch: 5042
[ Wed Apr 25 15:42:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:42:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:42:03 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:42:03 2018 ] Training epoch: 5043
[ Wed Apr 25 15:42:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:42:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:42:07 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:42:07 2018 ] Training epoch: 5044
[ Wed Apr 25 15:42:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:42:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:42:11 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:42:11 2018 ] Training epoch: 5045
[ Wed Apr 25 15:42:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:42:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:42:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:15 2018 ] Eval epoch: 5045
[ Wed Apr 25 15:42:18 2018 ] 	Mean test loss of 1 batches: 0.20821136236190796.
[ Wed Apr 25 15:42:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:42:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:42:18 2018 ] Training epoch: 5046
[ Wed Apr 25 15:42:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:42:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:42:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:22 2018 ] Training epoch: 5047
[ Wed Apr 25 15:42:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:42:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:42:27 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 15:42:27 2018 ] Training epoch: 5048
[ Wed Apr 25 15:42:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:42:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:42:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:31 2018 ] Training epoch: 5049
[ Wed Apr 25 15:42:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:42:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:42:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:42:35 2018 ] Training epoch: 5050
[ Wed Apr 25 15:42:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:42:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:42:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:39 2018 ] Eval epoch: 5050
[ Wed Apr 25 15:42:42 2018 ] 	Mean test loss of 1 batches: 0.2241279035806656.
[ Wed Apr 25 15:42:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:42:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:42:42 2018 ] Training epoch: 5051
[ Wed Apr 25 15:42:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:42:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:42:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:46 2018 ] Training epoch: 5052
[ Wed Apr 25 15:42:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:42:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:42:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:50 2018 ] Training epoch: 5053
[ Wed Apr 25 15:42:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:42:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:42:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:54 2018 ] Training epoch: 5054
[ Wed Apr 25 15:42:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:42:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:42:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:42:58 2018 ] Training epoch: 5055
[ Wed Apr 25 15:43:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:02 2018 ] Eval epoch: 5055
[ Wed Apr 25 15:43:05 2018 ] 	Mean test loss of 1 batches: 0.2150089591741562.
[ Wed Apr 25 15:43:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:43:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:43:05 2018 ] Training epoch: 5056
[ Wed Apr 25 15:43:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:09 2018 ] Training epoch: 5057
[ Wed Apr 25 15:43:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:13 2018 ] Training epoch: 5058
[ Wed Apr 25 15:43:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:43:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:43:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:17 2018 ] Training epoch: 5059
[ Wed Apr 25 15:43:21 2018 ] 	Batch(0/1) done. Loss: 0.0017  lr:0.000010
[ Wed Apr 25 15:43:21 2018 ] 	Mean training loss: 0.0017.
[ Wed Apr 25 15:43:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:21 2018 ] Training epoch: 5060
[ Wed Apr 25 15:43:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:43:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:43:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:25 2018 ] Eval epoch: 5060
[ Wed Apr 25 15:43:28 2018 ] 	Mean test loss of 1 batches: 0.220367431640625.
[ Wed Apr 25 15:43:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:43:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:43:28 2018 ] Training epoch: 5061
[ Wed Apr 25 15:43:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:32 2018 ] Training epoch: 5062
[ Wed Apr 25 15:43:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:43:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:43:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:36 2018 ] Training epoch: 5063
[ Wed Apr 25 15:43:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:43:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:43:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:43:41 2018 ] Training epoch: 5064
[ Wed Apr 25 15:43:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:45 2018 ] Training epoch: 5065
[ Wed Apr 25 15:43:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:43:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:43:49 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:43:49 2018 ] Eval epoch: 5065
[ Wed Apr 25 15:43:52 2018 ] 	Mean test loss of 1 batches: 0.22221586108207703.
[ Wed Apr 25 15:43:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:43:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:43:52 2018 ] Training epoch: 5066
[ Wed Apr 25 15:43:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:43:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:43:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:43:56 2018 ] Training epoch: 5067
[ Wed Apr 25 15:44:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:44:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:44:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:00 2018 ] Training epoch: 5068
[ Wed Apr 25 15:44:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:04 2018 ] Training epoch: 5069
[ Wed Apr 25 15:44:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:08 2018 ] Training epoch: 5070
[ Wed Apr 25 15:44:12 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:44:12 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:44:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:12 2018 ] Eval epoch: 5070
[ Wed Apr 25 15:44:15 2018 ] 	Mean test loss of 1 batches: 0.21307748556137085.
[ Wed Apr 25 15:44:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:44:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:44:15 2018 ] Training epoch: 5071
[ Wed Apr 25 15:44:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:19 2018 ] Training epoch: 5072
[ Wed Apr 25 15:44:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:23 2018 ] Training epoch: 5073
[ Wed Apr 25 15:44:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:27 2018 ] Training epoch: 5074
[ Wed Apr 25 15:44:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:44:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:44:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:31 2018 ] Training epoch: 5075
[ Wed Apr 25 15:44:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:44:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:44:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:35 2018 ] Eval epoch: 5075
[ Wed Apr 25 15:44:38 2018 ] 	Mean test loss of 1 batches: 0.2174324095249176.
[ Wed Apr 25 15:44:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:44:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:44:38 2018 ] Training epoch: 5076
[ Wed Apr 25 15:44:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:44:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:44:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:42 2018 ] Training epoch: 5077
[ Wed Apr 25 15:44:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:46 2018 ] Training epoch: 5078
[ Wed Apr 25 15:44:50 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:44:50 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:44:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:50 2018 ] Training epoch: 5079
[ Wed Apr 25 15:44:54 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:44:54 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:44:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:54 2018 ] Training epoch: 5080
[ Wed Apr 25 15:44:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:44:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:44:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:44:58 2018 ] Eval epoch: 5080
[ Wed Apr 25 15:45:01 2018 ] 	Mean test loss of 1 batches: 0.21813631057739258.
[ Wed Apr 25 15:45:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:45:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:45:01 2018 ] Training epoch: 5081
[ Wed Apr 25 15:45:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:45:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:45:05 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:45:05 2018 ] Training epoch: 5082
[ Wed Apr 25 15:45:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:45:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:45:09 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:45:09 2018 ] Training epoch: 5083
[ Wed Apr 25 15:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:45:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:14 2018 ] Training epoch: 5084
[ Wed Apr 25 15:45:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:45:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:45:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:18 2018 ] Training epoch: 5085
[ Wed Apr 25 15:45:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:45:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:45:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:22 2018 ] Eval epoch: 5085
[ Wed Apr 25 15:45:25 2018 ] 	Mean test loss of 1 batches: 0.22575126588344574.
[ Wed Apr 25 15:45:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:45:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:45:25 2018 ] Training epoch: 5086
[ Wed Apr 25 15:45:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:45:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:45:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:29 2018 ] Training epoch: 5087
[ Wed Apr 25 15:45:33 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000010
[ Wed Apr 25 15:45:33 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:45:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:33 2018 ] Training epoch: 5088
[ Wed Apr 25 15:45:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:45:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:45:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:37 2018 ] Training epoch: 5089
[ Wed Apr 25 15:45:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:45:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:45:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:41 2018 ] Training epoch: 5090
[ Wed Apr 25 15:45:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:45:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:45:45 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:45:45 2018 ] Eval epoch: 5090
[ Wed Apr 25 15:45:48 2018 ] 	Mean test loss of 1 batches: 0.22135943174362183.
[ Wed Apr 25 15:45:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:45:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:45:48 2018 ] Training epoch: 5091
[ Wed Apr 25 15:45:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:45:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:45:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:52 2018 ] Training epoch: 5092
[ Wed Apr 25 15:45:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:45:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:45:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:45:56 2018 ] Training epoch: 5093
[ Wed Apr 25 15:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:46:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:46:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:00 2018 ] Training epoch: 5094
[ Wed Apr 25 15:46:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:04 2018 ] Training epoch: 5095
[ Wed Apr 25 15:46:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:08 2018 ] Eval epoch: 5095
[ Wed Apr 25 15:46:11 2018 ] 	Mean test loss of 1 batches: 0.22648073732852936.
[ Wed Apr 25 15:46:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:46:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:46:11 2018 ] Training epoch: 5096
[ Wed Apr 25 15:46:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:46:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:46:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:15 2018 ] Training epoch: 5097
[ Wed Apr 25 15:46:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:19 2018 ] Training epoch: 5098
[ Wed Apr 25 15:46:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:23 2018 ] Training epoch: 5099
[ Wed Apr 25 15:46:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:27 2018 ] Training epoch: 5100
[ Wed Apr 25 15:46:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:46:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:46:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:31 2018 ] Eval epoch: 5100
[ Wed Apr 25 15:46:34 2018 ] 	Mean test loss of 1 batches: 0.22557951509952545.
[ Wed Apr 25 15:46:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:46:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:46:34 2018 ] Training epoch: 5101
[ Wed Apr 25 15:46:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:38 2018 ] Training epoch: 5102
[ Wed Apr 25 15:46:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:46:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:46:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:42 2018 ] Training epoch: 5103
[ Wed Apr 25 15:46:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:46 2018 ] Training epoch: 5104
[ Wed Apr 25 15:46:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:51 2018 ] Training epoch: 5105
[ Wed Apr 25 15:46:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:46:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:46:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:46:55 2018 ] Eval epoch: 5105
[ Wed Apr 25 15:46:58 2018 ] 	Mean test loss of 1 batches: 0.23293368518352509.
[ Wed Apr 25 15:46:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:46:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:46:58 2018 ] Training epoch: 5106
[ Wed Apr 25 15:47:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:47:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:47:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:02 2018 ] Training epoch: 5107
[ Wed Apr 25 15:47:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:47:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:47:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:06 2018 ] Training epoch: 5108
[ Wed Apr 25 15:47:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:47:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:47:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:10 2018 ] Training epoch: 5109
[ Wed Apr 25 15:47:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:47:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:47:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:14 2018 ] Training epoch: 5110
[ Wed Apr 25 15:47:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:47:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:47:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:18 2018 ] Eval epoch: 5110
[ Wed Apr 25 15:47:21 2018 ] 	Mean test loss of 1 batches: 0.23285214602947235.
[ Wed Apr 25 15:47:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:47:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:47:21 2018 ] Training epoch: 5111
[ Wed Apr 25 15:47:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:47:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:47:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:25 2018 ] Training epoch: 5112
[ Wed Apr 25 15:47:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:47:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:47:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:29 2018 ] Training epoch: 5113
[ Wed Apr 25 15:47:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:47:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:47:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:33 2018 ] Training epoch: 5114
[ Wed Apr 25 15:47:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:47:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:47:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:37 2018 ] Training epoch: 5115
[ Wed Apr 25 15:47:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:47:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:47:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:41 2018 ] Eval epoch: 5115
[ Wed Apr 25 15:47:44 2018 ] 	Mean test loss of 1 batches: 0.22494147717952728.
[ Wed Apr 25 15:47:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:47:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:47:44 2018 ] Training epoch: 5116
[ Wed Apr 25 15:47:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:47:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:47:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:48 2018 ] Training epoch: 5117
[ Wed Apr 25 15:47:52 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:47:52 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:47:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:52 2018 ] Training epoch: 5118
[ Wed Apr 25 15:47:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:47:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:47:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:47:56 2018 ] Training epoch: 5119
[ Wed Apr 25 15:48:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:00 2018 ] Training epoch: 5120
[ Wed Apr 25 15:48:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:48:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:48:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:04 2018 ] Eval epoch: 5120
[ Wed Apr 25 15:48:07 2018 ] 	Mean test loss of 1 batches: 0.2262505739927292.
[ Wed Apr 25 15:48:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:48:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:48:07 2018 ] Training epoch: 5121
[ Wed Apr 25 15:48:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:48:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:48:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:11 2018 ] Training epoch: 5122
[ Wed Apr 25 15:48:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:48:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:48:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:15 2018 ] Training epoch: 5123
[ Wed Apr 25 15:48:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:19 2018 ] Training epoch: 5124
[ Wed Apr 25 15:48:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:23 2018 ] Training epoch: 5125
[ Wed Apr 25 15:48:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:48:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:48:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:27 2018 ] Eval epoch: 5125
[ Wed Apr 25 15:48:30 2018 ] 	Mean test loss of 1 batches: 0.2306405007839203.
[ Wed Apr 25 15:48:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:48:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:48:30 2018 ] Training epoch: 5126
[ Wed Apr 25 15:48:34 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:48:34 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:48:34 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:48:34 2018 ] Training epoch: 5127
[ Wed Apr 25 15:48:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:38 2018 ] Training epoch: 5128
[ Wed Apr 25 15:48:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:42 2018 ] Training epoch: 5129
[ Wed Apr 25 15:48:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:48:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:48:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:46 2018 ] Training epoch: 5130
[ Wed Apr 25 15:48:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:48:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:48:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:50 2018 ] Eval epoch: 5130
[ Wed Apr 25 15:48:53 2018 ] 	Mean test loss of 1 batches: 0.22696855664253235.
[ Wed Apr 25 15:48:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:48:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:48:53 2018 ] Training epoch: 5131
[ Wed Apr 25 15:48:57 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 15:48:57 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:48:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:48:57 2018 ] Training epoch: 5132
[ Wed Apr 25 15:49:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:01 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:49:01 2018 ] Training epoch: 5133
[ Wed Apr 25 15:49:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:49:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:49:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:05 2018 ] Training epoch: 5134
[ Wed Apr 25 15:49:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:49:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:49:09 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 15:49:09 2018 ] Training epoch: 5135
[ Wed Apr 25 15:49:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:13 2018 ] Eval epoch: 5135
[ Wed Apr 25 15:49:16 2018 ] 	Mean test loss of 1 batches: 0.23623086512088776.
[ Wed Apr 25 15:49:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:49:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:49:16 2018 ] Training epoch: 5136
[ Wed Apr 25 15:49:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:20 2018 ] Training epoch: 5137
[ Wed Apr 25 15:49:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:24 2018 ] Training epoch: 5138
[ Wed Apr 25 15:49:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:28 2018 ] Training epoch: 5139
[ Wed Apr 25 15:49:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:32 2018 ] Training epoch: 5140
[ Wed Apr 25 15:49:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:49:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:49:36 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:49:36 2018 ] Eval epoch: 5140
[ Wed Apr 25 15:49:39 2018 ] 	Mean test loss of 1 batches: 0.2353249192237854.
[ Wed Apr 25 15:49:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:49:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:49:39 2018 ] Training epoch: 5141
[ Wed Apr 25 15:49:43 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:49:43 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:49:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:43 2018 ] Training epoch: 5142
[ Wed Apr 25 15:49:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:49:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:49:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:47 2018 ] Training epoch: 5143
[ Wed Apr 25 15:49:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:49:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:49:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:51 2018 ] Training epoch: 5144
[ Wed Apr 25 15:49:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:49:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:49:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:55 2018 ] Training epoch: 5145
[ Wed Apr 25 15:49:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:49:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:49:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:49:59 2018 ] Eval epoch: 5145
[ Wed Apr 25 15:50:02 2018 ] 	Mean test loss of 1 batches: 0.23584726452827454.
[ Wed Apr 25 15:50:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:50:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:50:02 2018 ] Training epoch: 5146
[ Wed Apr 25 15:50:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:50:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:50:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:06 2018 ] Training epoch: 5147
[ Wed Apr 25 15:50:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:50:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:50:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:10 2018 ] Training epoch: 5148
[ Wed Apr 25 15:50:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:50:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:50:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:14 2018 ] Training epoch: 5149
[ Wed Apr 25 15:50:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:50:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:50:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:18 2018 ] Training epoch: 5150
[ Wed Apr 25 15:50:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:50:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:50:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:22 2018 ] Eval epoch: 5150
[ Wed Apr 25 15:50:25 2018 ] 	Mean test loss of 1 batches: 0.2312057763338089.
[ Wed Apr 25 15:50:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:50:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:50:25 2018 ] Training epoch: 5151
[ Wed Apr 25 15:50:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:50:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:50:30 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:50:30 2018 ] Training epoch: 5152
[ Wed Apr 25 15:50:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:50:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:50:34 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:50:34 2018 ] Training epoch: 5153
[ Wed Apr 25 15:50:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:50:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:50:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:38 2018 ] Training epoch: 5154
[ Wed Apr 25 15:50:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:50:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:50:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:42 2018 ] Training epoch: 5155
[ Wed Apr 25 15:50:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:50:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:50:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:46 2018 ] Eval epoch: 5155
[ Wed Apr 25 15:50:49 2018 ] 	Mean test loss of 1 batches: 0.22366537153720856.
[ Wed Apr 25 15:50:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:50:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:50:49 2018 ] Training epoch: 5156
[ Wed Apr 25 15:50:53 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 15:50:53 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:50:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:53 2018 ] Training epoch: 5157
[ Wed Apr 25 15:50:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:50:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:50:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:50:57 2018 ] Training epoch: 5158
[ Wed Apr 25 15:51:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:01 2018 ] Training epoch: 5159
[ Wed Apr 25 15:51:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:51:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:51:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:05 2018 ] Training epoch: 5160
[ Wed Apr 25 15:51:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:51:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:51:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:09 2018 ] Eval epoch: 5160
[ Wed Apr 25 15:51:12 2018 ] 	Mean test loss of 1 batches: 0.21652637422084808.
[ Wed Apr 25 15:51:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:51:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:51:12 2018 ] Training epoch: 5161
[ Wed Apr 25 15:51:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:16 2018 ] Training epoch: 5162
[ Wed Apr 25 15:51:20 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:51:20 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:51:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:20 2018 ] Training epoch: 5163
[ Wed Apr 25 15:51:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:24 2018 ] Training epoch: 5164
[ Wed Apr 25 15:51:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:28 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 15:51:28 2018 ] Training epoch: 5165
[ Wed Apr 25 15:51:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:32 2018 ] Eval epoch: 5165
[ Wed Apr 25 15:51:35 2018 ] 	Mean test loss of 1 batches: 0.21302306652069092.
[ Wed Apr 25 15:51:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:51:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:51:35 2018 ] Training epoch: 5166
[ Wed Apr 25 15:51:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:51:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:51:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:39 2018 ] Training epoch: 5167
[ Wed Apr 25 15:51:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:43 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:51:43 2018 ] Training epoch: 5168
[ Wed Apr 25 15:51:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:51:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:51:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:47 2018 ] Training epoch: 5169
[ Wed Apr 25 15:51:51 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:51:51 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:51:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:51:51 2018 ] Training epoch: 5170
[ Wed Apr 25 15:51:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:51:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:51:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:51:55 2018 ] Eval epoch: 5170
[ Wed Apr 25 15:51:58 2018 ] 	Mean test loss of 1 batches: 0.22530800104141235.
[ Wed Apr 25 15:51:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:51:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:51:58 2018 ] Training epoch: 5171
[ Wed Apr 25 15:52:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:02 2018 ] Training epoch: 5172
[ Wed Apr 25 15:52:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:52:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:52:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:06 2018 ] Training epoch: 5173
[ Wed Apr 25 15:52:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:52:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:52:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:52:10 2018 ] Training epoch: 5174
[ Wed Apr 25 15:52:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:14 2018 ] Training epoch: 5175
[ Wed Apr 25 15:52:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:19 2018 ] Eval epoch: 5175
[ Wed Apr 25 15:52:21 2018 ] 	Mean test loss of 1 batches: 0.22534625232219696.
[ Wed Apr 25 15:52:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:52:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:52:21 2018 ] Training epoch: 5176
[ Wed Apr 25 15:52:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:25 2018 ] Training epoch: 5177
[ Wed Apr 25 15:52:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:29 2018 ] Training epoch: 5178
[ Wed Apr 25 15:52:33 2018 ] 	Batch(0/1) done. Loss: 0.0008  lr:0.000010
[ Wed Apr 25 15:52:33 2018 ] 	Mean training loss: 0.0008.
[ Wed Apr 25 15:52:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:33 2018 ] Training epoch: 5179
[ Wed Apr 25 15:52:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:37 2018 ] Training epoch: 5180
[ Wed Apr 25 15:52:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:41 2018 ] Eval epoch: 5180
[ Wed Apr 25 15:52:44 2018 ] 	Mean test loss of 1 batches: 0.22642219066619873.
[ Wed Apr 25 15:52:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:52:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:52:44 2018 ] Training epoch: 5181
[ Wed Apr 25 15:52:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:52:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:52:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:48 2018 ] Training epoch: 5182
[ Wed Apr 25 15:52:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:52:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:52:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:52 2018 ] Training epoch: 5183
[ Wed Apr 25 15:52:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:52:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:52:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:52:56 2018 ] Training epoch: 5184
[ Wed Apr 25 15:53:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:53:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:53:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:01 2018 ] Training epoch: 5185
[ Wed Apr 25 15:53:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:53:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:53:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:05 2018 ] Eval epoch: 5185
[ Wed Apr 25 15:53:07 2018 ] 	Mean test loss of 1 batches: 0.2176664024591446.
[ Wed Apr 25 15:53:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:53:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:53:07 2018 ] Training epoch: 5186
[ Wed Apr 25 15:53:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:53:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:53:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:11 2018 ] Training epoch: 5187
[ Wed Apr 25 15:53:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:16 2018 ] Training epoch: 5188
[ Wed Apr 25 15:53:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:53:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:53:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:20 2018 ] Training epoch: 5189
[ Wed Apr 25 15:53:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:53:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:53:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:24 2018 ] Training epoch: 5190
[ Wed Apr 25 15:53:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:28 2018 ] Eval epoch: 5190
[ Wed Apr 25 15:53:31 2018 ] 	Mean test loss of 1 batches: 0.2158074676990509.
[ Wed Apr 25 15:53:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:53:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:53:31 2018 ] Training epoch: 5191
[ Wed Apr 25 15:53:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:53:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:53:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:35 2018 ] Training epoch: 5192
[ Wed Apr 25 15:53:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:39 2018 ] Training epoch: 5193
[ Wed Apr 25 15:53:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:43 2018 ] Training epoch: 5194
[ Wed Apr 25 15:53:47 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:53:47 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:53:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:47 2018 ] Training epoch: 5195
[ Wed Apr 25 15:53:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:51 2018 ] Eval epoch: 5195
[ Wed Apr 25 15:53:54 2018 ] 	Mean test loss of 1 batches: 0.21382620930671692.
[ Wed Apr 25 15:53:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:53:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:53:54 2018 ] Training epoch: 5196
[ Wed Apr 25 15:53:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:53:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:53:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:53:58 2018 ] Training epoch: 5197
[ Wed Apr 25 15:54:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:54:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:54:02 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:54:02 2018 ] Training epoch: 5198
[ Wed Apr 25 15:54:06 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:54:06 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:54:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:06 2018 ] Training epoch: 5199
[ Wed Apr 25 15:54:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:54:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:54:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:10 2018 ] Training epoch: 5200
[ Wed Apr 25 15:54:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:54:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:54:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:14 2018 ] Eval epoch: 5200
[ Wed Apr 25 15:54:17 2018 ] 	Mean test loss of 1 batches: 0.21397869288921356.
[ Wed Apr 25 15:54:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:54:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:54:17 2018 ] Training epoch: 5201
[ Wed Apr 25 15:54:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:54:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:54:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:21 2018 ] Training epoch: 5202
[ Wed Apr 25 15:54:25 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 15:54:25 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 15:54:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:25 2018 ] Training epoch: 5203
[ Wed Apr 25 15:54:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:54:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:54:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:29 2018 ] Training epoch: 5204
[ Wed Apr 25 15:54:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:54:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:54:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:33 2018 ] Training epoch: 5205
[ Wed Apr 25 15:54:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:54:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:54:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:37 2018 ] Eval epoch: 5205
[ Wed Apr 25 15:54:40 2018 ] 	Mean test loss of 1 batches: 0.21864277124404907.
[ Wed Apr 25 15:54:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:54:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:54:40 2018 ] Training epoch: 5206
[ Wed Apr 25 15:54:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:54:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:54:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:44 2018 ] Training epoch: 5207
[ Wed Apr 25 15:54:49 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000010
[ Wed Apr 25 15:54:49 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 15:54:49 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:54:49 2018 ] Training epoch: 5208
[ Wed Apr 25 15:54:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:54:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:54:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:53 2018 ] Training epoch: 5209
[ Wed Apr 25 15:54:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:54:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:54:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:54:57 2018 ] Training epoch: 5210
[ Wed Apr 25 15:55:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:55:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:55:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:01 2018 ] Eval epoch: 5210
[ Wed Apr 25 15:55:04 2018 ] 	Mean test loss of 1 batches: 0.2162635773420334.
[ Wed Apr 25 15:55:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:55:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:55:04 2018 ] Training epoch: 5211
[ Wed Apr 25 15:55:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:08 2018 ] Training epoch: 5212
[ Wed Apr 25 15:55:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:12 2018 ] Training epoch: 5213
[ Wed Apr 25 15:55:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:16 2018 ] Training epoch: 5214
[ Wed Apr 25 15:55:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:55:20 2018 ] Training epoch: 5215
[ Wed Apr 25 15:55:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:55:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:55:24 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:55:24 2018 ] Eval epoch: 5215
[ Wed Apr 25 15:55:27 2018 ] 	Mean test loss of 1 batches: 0.21236683428287506.
[ Wed Apr 25 15:55:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:55:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:55:27 2018 ] Training epoch: 5216
[ Wed Apr 25 15:55:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:31 2018 ] Training epoch: 5217
[ Wed Apr 25 15:55:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:55:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:55:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:35 2018 ] Training epoch: 5218
[ Wed Apr 25 15:55:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:40 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:55:40 2018 ] Training epoch: 5219
[ Wed Apr 25 15:55:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:55:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:55:44 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 15:55:44 2018 ] Training epoch: 5220
[ Wed Apr 25 15:55:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:48 2018 ] Eval epoch: 5220
[ Wed Apr 25 15:55:51 2018 ] 	Mean test loss of 1 batches: 0.21624907851219177.
[ Wed Apr 25 15:55:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:55:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:55:51 2018 ] Training epoch: 5221
[ Wed Apr 25 15:55:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:55 2018 ] Training epoch: 5222
[ Wed Apr 25 15:55:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:55:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:55:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:55:59 2018 ] Training epoch: 5223
[ Wed Apr 25 15:56:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:56:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:56:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:03 2018 ] Training epoch: 5224
[ Wed Apr 25 15:56:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:56:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:56:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:07 2018 ] Training epoch: 5225
[ Wed Apr 25 15:56:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:56:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:56:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:11 2018 ] Eval epoch: 5225
[ Wed Apr 25 15:56:14 2018 ] 	Mean test loss of 1 batches: 0.2227773517370224.
[ Wed Apr 25 15:56:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:56:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:56:14 2018 ] Training epoch: 5226
[ Wed Apr 25 15:56:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:56:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:56:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:18 2018 ] Training epoch: 5227
[ Wed Apr 25 15:56:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:56:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:56:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:22 2018 ] Training epoch: 5228
[ Wed Apr 25 15:56:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:56:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:56:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:26 2018 ] Training epoch: 5229
[ Wed Apr 25 15:56:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:56:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:56:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:30 2018 ] Training epoch: 5230
[ Wed Apr 25 15:56:34 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 15:56:34 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 15:56:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:34 2018 ] Eval epoch: 5230
[ Wed Apr 25 15:56:37 2018 ] 	Mean test loss of 1 batches: 0.22874166071414948.
[ Wed Apr 25 15:56:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:56:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:56:37 2018 ] Training epoch: 5231
[ Wed Apr 25 15:56:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:56:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:56:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:56:41 2018 ] Training epoch: 5232
[ Wed Apr 25 15:56:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:56:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:56:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:45 2018 ] Training epoch: 5233
[ Wed Apr 25 15:56:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:56:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:56:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:49 2018 ] Training epoch: 5234
[ Wed Apr 25 15:56:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:56:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:56:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:53 2018 ] Training epoch: 5235
[ Wed Apr 25 15:56:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:56:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:56:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:56:57 2018 ] Eval epoch: 5235
[ Wed Apr 25 15:57:00 2018 ] 	Mean test loss of 1 batches: 0.22456608712673187.
[ Wed Apr 25 15:57:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:57:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:57:00 2018 ] Training epoch: 5236
[ Wed Apr 25 15:57:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:04 2018 ] Training epoch: 5237
[ Wed Apr 25 15:57:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:57:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:57:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:08 2018 ] Training epoch: 5238
[ Wed Apr 25 15:57:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:12 2018 ] Training epoch: 5239
[ Wed Apr 25 15:57:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:17 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 15:57:17 2018 ] Training epoch: 5240
[ Wed Apr 25 15:57:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:57:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:57:21 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 15:57:21 2018 ] Eval epoch: 5240
[ Wed Apr 25 15:57:24 2018 ] 	Mean test loss of 1 batches: 0.21333849430084229.
[ Wed Apr 25 15:57:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:57:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:57:24 2018 ] Training epoch: 5241
[ Wed Apr 25 15:57:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:57:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:57:28 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 15:57:28 2018 ] Training epoch: 5242
[ Wed Apr 25 15:57:32 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 15:57:32 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 15:57:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:32 2018 ] Training epoch: 5243
[ Wed Apr 25 15:57:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:57:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:57:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:36 2018 ] Training epoch: 5244
[ Wed Apr 25 15:57:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:40 2018 ] Training epoch: 5245
[ Wed Apr 25 15:57:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:57:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:57:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:44 2018 ] Eval epoch: 5245
[ Wed Apr 25 15:57:47 2018 ] 	Mean test loss of 1 batches: 0.21035358309745789.
[ Wed Apr 25 15:57:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:57:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:57:47 2018 ] Training epoch: 5246
[ Wed Apr 25 15:57:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:51 2018 ] Training epoch: 5247
[ Wed Apr 25 15:57:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:57:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:57:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:55 2018 ] Training epoch: 5248
[ Wed Apr 25 15:57:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:57:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:57:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:57:59 2018 ] Training epoch: 5249
[ Wed Apr 25 15:58:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:58:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:58:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:03 2018 ] Training epoch: 5250
[ Wed Apr 25 15:58:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:07 2018 ] Eval epoch: 5250
[ Wed Apr 25 15:58:10 2018 ] 	Mean test loss of 1 batches: 0.2214432805776596.
[ Wed Apr 25 15:58:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:58:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:58:10 2018 ] Training epoch: 5251
[ Wed Apr 25 15:58:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:14 2018 ] Training epoch: 5252
[ Wed Apr 25 15:58:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:18 2018 ] Training epoch: 5253
[ Wed Apr 25 15:58:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:22 2018 ] Training epoch: 5254
[ Wed Apr 25 15:58:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:26 2018 ] Training epoch: 5255
[ Wed Apr 25 15:58:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:30 2018 ] Eval epoch: 5255
[ Wed Apr 25 15:58:33 2018 ] 	Mean test loss of 1 batches: 0.22486919164657593.
[ Wed Apr 25 15:58:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:58:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:58:33 2018 ] Training epoch: 5256
[ Wed Apr 25 15:58:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:37 2018 ] Training epoch: 5257
[ Wed Apr 25 15:58:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:58:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:58:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:41 2018 ] Training epoch: 5258
[ Wed Apr 25 15:58:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:45 2018 ] Training epoch: 5259
[ Wed Apr 25 15:58:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:58:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:58:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:49 2018 ] Training epoch: 5260
[ Wed Apr 25 15:58:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:58:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:58:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:58:53 2018 ] Eval epoch: 5260
[ Wed Apr 25 15:58:56 2018 ] 	Mean test loss of 1 batches: 0.21081425249576569.
[ Wed Apr 25 15:58:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:58:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:58:56 2018 ] Training epoch: 5261
[ Wed Apr 25 15:59:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 15:59:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 15:59:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:00 2018 ] Training epoch: 5262
[ Wed Apr 25 15:59:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:04 2018 ] Training epoch: 5263
[ Wed Apr 25 15:59:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:59:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:59:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:08 2018 ] Training epoch: 5264
[ Wed Apr 25 15:59:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:12 2018 ] Training epoch: 5265
[ Wed Apr 25 15:59:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:16 2018 ] Eval epoch: 5265
[ Wed Apr 25 15:59:19 2018 ] 	Mean test loss of 1 batches: 0.22458869218826294.
[ Wed Apr 25 15:59:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:59:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:59:19 2018 ] Training epoch: 5266
[ Wed Apr 25 15:59:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:59:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:59:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:23 2018 ] Training epoch: 5267
[ Wed Apr 25 15:59:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:27 2018 ] Training epoch: 5268
[ Wed Apr 25 15:59:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:31 2018 ] Training epoch: 5269
[ Wed Apr 25 15:59:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:36 2018 ] Training epoch: 5270
[ Wed Apr 25 15:59:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 15:59:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 15:59:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:40 2018 ] Eval epoch: 5270
[ Wed Apr 25 15:59:42 2018 ] 	Mean test loss of 1 batches: 0.22467733919620514.
[ Wed Apr 25 15:59:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 15:59:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 15:59:42 2018 ] Training epoch: 5271
[ Wed Apr 25 15:59:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:47 2018 ] Training epoch: 5272
[ Wed Apr 25 15:59:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:51 2018 ] Training epoch: 5273
[ Wed Apr 25 15:59:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:55 2018 ] Training epoch: 5274
[ Wed Apr 25 15:59:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 15:59:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 15:59:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 15:59:59 2018 ] Training epoch: 5275
[ Wed Apr 25 16:00:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:00:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:00:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:03 2018 ] Eval epoch: 5275
[ Wed Apr 25 16:00:05 2018 ] 	Mean test loss of 1 batches: 0.2189083695411682.
[ Wed Apr 25 16:00:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:00:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:00:05 2018 ] Training epoch: 5276
[ Wed Apr 25 16:00:09 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000010
[ Wed Apr 25 16:00:09 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 16:00:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:09 2018 ] Training epoch: 5277
[ Wed Apr 25 16:00:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:00:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:00:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:14 2018 ] Training epoch: 5278
[ Wed Apr 25 16:00:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:00:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:00:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:18 2018 ] Training epoch: 5279
[ Wed Apr 25 16:00:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:00:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:00:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:22 2018 ] Training epoch: 5280
[ Wed Apr 25 16:00:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:00:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:00:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:26 2018 ] Eval epoch: 5280
[ Wed Apr 25 16:00:28 2018 ] 	Mean test loss of 1 batches: 0.20996560156345367.
[ Wed Apr 25 16:00:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:00:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:00:28 2018 ] Training epoch: 5281
[ Wed Apr 25 16:00:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:00:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:00:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:32 2018 ] Training epoch: 5282
[ Wed Apr 25 16:00:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:00:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:00:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:00:37 2018 ] Training epoch: 5283
[ Wed Apr 25 16:00:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:00:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:00:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:41 2018 ] Training epoch: 5284
[ Wed Apr 25 16:00:45 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.000010
[ Wed Apr 25 16:00:45 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 16:00:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:45 2018 ] Training epoch: 5285
[ Wed Apr 25 16:00:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:00:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:00:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:49 2018 ] Eval epoch: 5285
[ Wed Apr 25 16:00:52 2018 ] 	Mean test loss of 1 batches: 0.22336162626743317.
[ Wed Apr 25 16:00:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:00:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:00:52 2018 ] Training epoch: 5286
[ Wed Apr 25 16:00:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:00:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:00:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:00:56 2018 ] Training epoch: 5287
[ Wed Apr 25 16:01:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:00 2018 ] Training epoch: 5288
[ Wed Apr 25 16:01:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:04 2018 ] Training epoch: 5289
[ Wed Apr 25 16:01:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:08 2018 ] Training epoch: 5290
[ Wed Apr 25 16:01:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:12 2018 ] Eval epoch: 5290
[ Wed Apr 25 16:01:14 2018 ] 	Mean test loss of 1 batches: 0.2294030785560608.
[ Wed Apr 25 16:01:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:01:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:01:14 2018 ] Training epoch: 5291
[ Wed Apr 25 16:01:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:18 2018 ] Training epoch: 5292
[ Wed Apr 25 16:01:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:22 2018 ] Training epoch: 5293
[ Wed Apr 25 16:01:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:26 2018 ] Training epoch: 5294
[ Wed Apr 25 16:01:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:30 2018 ] Training epoch: 5295
[ Wed Apr 25 16:01:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:35 2018 ] Eval epoch: 5295
[ Wed Apr 25 16:01:37 2018 ] 	Mean test loss of 1 batches: 0.23033536970615387.
[ Wed Apr 25 16:01:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:01:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:01:37 2018 ] Training epoch: 5296
[ Wed Apr 25 16:01:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:01:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:01:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:41 2018 ] Training epoch: 5297
[ Wed Apr 25 16:01:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:45 2018 ] Training epoch: 5298
[ Wed Apr 25 16:01:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:01:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:01:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:49 2018 ] Training epoch: 5299
[ Wed Apr 25 16:01:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:01:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:01:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:53 2018 ] Training epoch: 5300
[ Wed Apr 25 16:01:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:01:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:01:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:01:57 2018 ] Eval epoch: 5300
[ Wed Apr 25 16:02:00 2018 ] 	Mean test loss of 1 batches: 0.22770491242408752.
[ Wed Apr 25 16:02:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:02:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:02:00 2018 ] Training epoch: 5301
[ Wed Apr 25 16:02:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:02:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:02:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:04 2018 ] Training epoch: 5302
[ Wed Apr 25 16:02:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:02:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:02:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:08 2018 ] Training epoch: 5303
[ Wed Apr 25 16:02:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:12 2018 ] Training epoch: 5304
[ Wed Apr 25 16:02:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:16 2018 ] Training epoch: 5305
[ Wed Apr 25 16:02:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:02:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:02:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:02:21 2018 ] Eval epoch: 5305
[ Wed Apr 25 16:02:23 2018 ] 	Mean test loss of 1 batches: 0.21970736980438232.
[ Wed Apr 25 16:02:23 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:02:23 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:02:23 2018 ] Training epoch: 5306
[ Wed Apr 25 16:02:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:27 2018 ] Training epoch: 5307
[ Wed Apr 25 16:02:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:31 2018 ] Training epoch: 5308
[ Wed Apr 25 16:02:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:35 2018 ] Training epoch: 5309
[ Wed Apr 25 16:02:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:02:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:02:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:39 2018 ] Training epoch: 5310
[ Wed Apr 25 16:02:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:02:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:02:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:44 2018 ] Eval epoch: 5310
[ Wed Apr 25 16:02:46 2018 ] 	Mean test loss of 1 batches: 0.21593910455703735.
[ Wed Apr 25 16:02:46 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:02:46 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:02:46 2018 ] Training epoch: 5311
[ Wed Apr 25 16:02:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:50 2018 ] Training epoch: 5312
[ Wed Apr 25 16:02:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:02:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:02:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:55 2018 ] Training epoch: 5313
[ Wed Apr 25 16:02:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:02:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:02:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:02:58 2018 ] Training epoch: 5314
[ Wed Apr 25 16:03:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:03:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:03:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:03 2018 ] Training epoch: 5315
[ Wed Apr 25 16:03:07 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:03:07 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:03:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:07 2018 ] Eval epoch: 5315
[ Wed Apr 25 16:03:09 2018 ] 	Mean test loss of 1 batches: 0.21521374583244324.
[ Wed Apr 25 16:03:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:03:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:03:09 2018 ] Training epoch: 5316
[ Wed Apr 25 16:03:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:03:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:03:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:13 2018 ] Training epoch: 5317
[ Wed Apr 25 16:03:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:03:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:03:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:17 2018 ] Training epoch: 5318
[ Wed Apr 25 16:03:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:03:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:03:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:22 2018 ] Training epoch: 5319
[ Wed Apr 25 16:03:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:03:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:03:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:26 2018 ] Training epoch: 5320
[ Wed Apr 25 16:03:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:03:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:03:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:30 2018 ] Eval epoch: 5320
[ Wed Apr 25 16:03:33 2018 ] 	Mean test loss of 1 batches: 0.21796949207782745.
[ Wed Apr 25 16:03:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:03:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:03:33 2018 ] Training epoch: 5321
[ Wed Apr 25 16:03:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:03:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:03:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:37 2018 ] Training epoch: 5322
[ Wed Apr 25 16:03:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:03:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:03:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:41 2018 ] Training epoch: 5323
[ Wed Apr 25 16:03:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:03:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:03:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:45 2018 ] Training epoch: 5324
[ Wed Apr 25 16:03:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:03:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:03:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:49 2018 ] Training epoch: 5325
[ Wed Apr 25 16:03:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:03:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:03:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:03:53 2018 ] Eval epoch: 5325
[ Wed Apr 25 16:03:56 2018 ] 	Mean test loss of 1 batches: 0.21766585111618042.
[ Wed Apr 25 16:03:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:03:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:03:56 2018 ] Training epoch: 5326
[ Wed Apr 25 16:04:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:00 2018 ] Training epoch: 5327
[ Wed Apr 25 16:04:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:04 2018 ] Training epoch: 5328
[ Wed Apr 25 16:04:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:08 2018 ] Training epoch: 5329
[ Wed Apr 25 16:04:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:12 2018 ] Training epoch: 5330
[ Wed Apr 25 16:04:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:04:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:04:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:16 2018 ] Eval epoch: 5330
[ Wed Apr 25 16:04:19 2018 ] 	Mean test loss of 1 batches: 0.22683990001678467.
[ Wed Apr 25 16:04:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:04:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:04:19 2018 ] Training epoch: 5331
[ Wed Apr 25 16:04:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:23 2018 ] Training epoch: 5332
[ Wed Apr 25 16:04:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:27 2018 ] Training epoch: 5333
[ Wed Apr 25 16:04:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:04:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:04:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:31 2018 ] Training epoch: 5334
[ Wed Apr 25 16:04:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:35 2018 ] Training epoch: 5335
[ Wed Apr 25 16:04:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:04:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:04:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:39 2018 ] Eval epoch: 5335
[ Wed Apr 25 16:04:42 2018 ] 	Mean test loss of 1 batches: 0.22877556085586548.
[ Wed Apr 25 16:04:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:04:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:04:42 2018 ] Training epoch: 5336
[ Wed Apr 25 16:04:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:04:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:04:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:46 2018 ] Training epoch: 5337
[ Wed Apr 25 16:04:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:04:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:04:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:50 2018 ] Training epoch: 5338
[ Wed Apr 25 16:04:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:04:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:04:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:54 2018 ] Training epoch: 5339
[ Wed Apr 25 16:04:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:04:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:04:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:04:58 2018 ] Training epoch: 5340
[ Wed Apr 25 16:05:02 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:05:02 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:05:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:02 2018 ] Eval epoch: 5340
[ Wed Apr 25 16:05:05 2018 ] 	Mean test loss of 1 batches: 0.22765083611011505.
[ Wed Apr 25 16:05:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:05:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:05:05 2018 ] Training epoch: 5341
[ Wed Apr 25 16:05:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:05:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:05:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:09 2018 ] Training epoch: 5342
[ Wed Apr 25 16:05:13 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:05:13 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:05:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:13 2018 ] Training epoch: 5343
[ Wed Apr 25 16:05:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:05:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:05:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:17 2018 ] Training epoch: 5344
[ Wed Apr 25 16:05:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:05:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:05:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:21 2018 ] Training epoch: 5345
[ Wed Apr 25 16:05:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:05:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:05:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:25 2018 ] Eval epoch: 5345
[ Wed Apr 25 16:05:28 2018 ] 	Mean test loss of 1 batches: 0.2209557145833969.
[ Wed Apr 25 16:05:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:05:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:05:28 2018 ] Training epoch: 5346
[ Wed Apr 25 16:05:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:05:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:05:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:32 2018 ] Training epoch: 5347
[ Wed Apr 25 16:05:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:05:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:05:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:36 2018 ] Training epoch: 5348
[ Wed Apr 25 16:05:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:05:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:05:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:40 2018 ] Training epoch: 5349
[ Wed Apr 25 16:05:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:05:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:05:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:44 2018 ] Training epoch: 5350
[ Wed Apr 25 16:05:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:05:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:05:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:48 2018 ] Eval epoch: 5350
[ Wed Apr 25 16:05:51 2018 ] 	Mean test loss of 1 batches: 0.2178099900484085.
[ Wed Apr 25 16:05:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:05:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:05:51 2018 ] Training epoch: 5351
[ Wed Apr 25 16:05:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:05:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:05:55 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:05:55 2018 ] Training epoch: 5352
[ Wed Apr 25 16:05:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:05:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:05:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:05:59 2018 ] Training epoch: 5353
[ Wed Apr 25 16:06:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:06:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:06:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:03 2018 ] Training epoch: 5354
[ Wed Apr 25 16:06:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:07 2018 ] Training epoch: 5355
[ Wed Apr 25 16:06:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:11 2018 ] Eval epoch: 5355
[ Wed Apr 25 16:06:14 2018 ] 	Mean test loss of 1 batches: 0.21432632207870483.
[ Wed Apr 25 16:06:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:06:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:06:14 2018 ] Training epoch: 5356
[ Wed Apr 25 16:06:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:18 2018 ] Training epoch: 5357
[ Wed Apr 25 16:06:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:22 2018 ] Training epoch: 5358
[ Wed Apr 25 16:06:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:26 2018 ] Training epoch: 5359
[ Wed Apr 25 16:06:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:30 2018 ] Training epoch: 5360
[ Wed Apr 25 16:06:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:34 2018 ] Eval epoch: 5360
[ Wed Apr 25 16:06:37 2018 ] 	Mean test loss of 1 batches: 0.2176712602376938.
[ Wed Apr 25 16:06:37 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:06:37 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:06:37 2018 ] Training epoch: 5361
[ Wed Apr 25 16:06:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:06:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:06:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:41 2018 ] Training epoch: 5362
[ Wed Apr 25 16:06:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:45 2018 ] Training epoch: 5363
[ Wed Apr 25 16:06:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:49 2018 ] Training epoch: 5364
[ Wed Apr 25 16:06:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:53 2018 ] Training epoch: 5365
[ Wed Apr 25 16:06:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:06:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:06:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:06:57 2018 ] Eval epoch: 5365
[ Wed Apr 25 16:07:00 2018 ] 	Mean test loss of 1 batches: 0.21480253338813782.
[ Wed Apr 25 16:07:00 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:07:00 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:07:00 2018 ] Training epoch: 5366
[ Wed Apr 25 16:07:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:07:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:07:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:04 2018 ] Training epoch: 5367
[ Wed Apr 25 16:07:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:07:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:07:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:08 2018 ] Training epoch: 5368
[ Wed Apr 25 16:07:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:07:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:07:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:12 2018 ] Training epoch: 5369
[ Wed Apr 25 16:07:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:07:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:07:17 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:07:17 2018 ] Training epoch: 5370
[ Wed Apr 25 16:07:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:07:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:07:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:21 2018 ] Eval epoch: 5370
[ Wed Apr 25 16:07:24 2018 ] 	Mean test loss of 1 batches: 0.2046533226966858.
[ Wed Apr 25 16:07:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:07:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:07:24 2018 ] Training epoch: 5371
[ Wed Apr 25 16:07:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:07:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:07:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:28 2018 ] Training epoch: 5372
[ Wed Apr 25 16:07:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:07:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:07:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:32 2018 ] Training epoch: 5373
[ Wed Apr 25 16:07:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:07:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:07:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:36 2018 ] Training epoch: 5374
[ Wed Apr 25 16:07:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:07:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:07:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:40 2018 ] Training epoch: 5375
[ Wed Apr 25 16:07:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:07:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:07:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:44 2018 ] Eval epoch: 5375
[ Wed Apr 25 16:07:47 2018 ] 	Mean test loss of 1 batches: 0.19340896606445312.
[ Wed Apr 25 16:07:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:07:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:07:47 2018 ] Training epoch: 5376
[ Wed Apr 25 16:07:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:07:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:07:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:51 2018 ] Training epoch: 5377
[ Wed Apr 25 16:07:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:07:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:07:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:07:55 2018 ] Training epoch: 5378
[ Wed Apr 25 16:07:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:07:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:07:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:07:59 2018 ] Training epoch: 5379
[ Wed Apr 25 16:08:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:08:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:08:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:03 2018 ] Training epoch: 5380
[ Wed Apr 25 16:08:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:08:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:08:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:07 2018 ] Eval epoch: 5380
[ Wed Apr 25 16:08:10 2018 ] 	Mean test loss of 1 batches: 0.211116224527359.
[ Wed Apr 25 16:08:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:08:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:08:10 2018 ] Training epoch: 5381
[ Wed Apr 25 16:08:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:08:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:08:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:14 2018 ] Training epoch: 5382
[ Wed Apr 25 16:08:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:08:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:08:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:18 2018 ] Training epoch: 5383
[ Wed Apr 25 16:08:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:08:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:08:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:22 2018 ] Training epoch: 5384
[ Wed Apr 25 16:08:26 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:08:26 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:08:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:26 2018 ] Training epoch: 5385
[ Wed Apr 25 16:08:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:08:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:08:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:30 2018 ] Eval epoch: 5385
[ Wed Apr 25 16:08:33 2018 ] 	Mean test loss of 1 batches: 0.21185684204101562.
[ Wed Apr 25 16:08:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:08:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:08:33 2018 ] Training epoch: 5386
[ Wed Apr 25 16:08:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:08:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:08:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:37 2018 ] Training epoch: 5387
[ Wed Apr 25 16:08:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:08:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:08:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:41 2018 ] Training epoch: 5388
[ Wed Apr 25 16:08:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:08:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:08:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:45 2018 ] Training epoch: 5389
[ Wed Apr 25 16:08:49 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:08:49 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:08:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:49 2018 ] Training epoch: 5390
[ Wed Apr 25 16:08:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:08:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:08:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:08:53 2018 ] Eval epoch: 5390
[ Wed Apr 25 16:08:56 2018 ] 	Mean test loss of 1 batches: 0.2147192806005478.
[ Wed Apr 25 16:08:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:08:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:08:56 2018 ] Training epoch: 5391
[ Wed Apr 25 16:09:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:09:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:09:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:00 2018 ] Training epoch: 5392
[ Wed Apr 25 16:09:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:04 2018 ] Training epoch: 5393
[ Wed Apr 25 16:09:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:08 2018 ] Training epoch: 5394
[ Wed Apr 25 16:09:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:09:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:09:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:12 2018 ] Training epoch: 5395
[ Wed Apr 25 16:09:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:09:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:09:16 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:09:16 2018 ] Eval epoch: 5395
[ Wed Apr 25 16:09:19 2018 ] 	Mean test loss of 1 batches: 0.19871769845485687.
[ Wed Apr 25 16:09:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:09:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:09:19 2018 ] Training epoch: 5396
[ Wed Apr 25 16:09:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:23 2018 ] Training epoch: 5397
[ Wed Apr 25 16:09:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:09:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:09:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:27 2018 ] Training epoch: 5398
[ Wed Apr 25 16:09:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:31 2018 ] Training epoch: 5399
[ Wed Apr 25 16:09:35 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:09:35 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:09:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:35 2018 ] Training epoch: 5400
[ Wed Apr 25 16:09:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:09:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:09:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:39 2018 ] Eval epoch: 5400
[ Wed Apr 25 16:09:42 2018 ] 	Mean test loss of 1 batches: 0.20597894489765167.
[ Wed Apr 25 16:09:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:09:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:09:42 2018 ] Training epoch: 5401
[ Wed Apr 25 16:09:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:46 2018 ] Training epoch: 5402
[ Wed Apr 25 16:09:50 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:09:50 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:09:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:50 2018 ] Training epoch: 5403
[ Wed Apr 25 16:09:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:09:54 2018 ] Training epoch: 5404
[ Wed Apr 25 16:09:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:09:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:09:58 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:09:58 2018 ] Training epoch: 5405
[ Wed Apr 25 16:10:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:10:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:10:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:02 2018 ] Eval epoch: 5405
[ Wed Apr 25 16:10:05 2018 ] 	Mean test loss of 1 batches: 0.20682431757450104.
[ Wed Apr 25 16:10:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:10:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:10:05 2018 ] Training epoch: 5406
[ Wed Apr 25 16:10:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:10:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:10:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:09 2018 ] Training epoch: 5407
[ Wed Apr 25 16:10:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:10:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:10:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:13 2018 ] Training epoch: 5408
[ Wed Apr 25 16:10:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:10:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:10:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:18 2018 ] Training epoch: 5409
[ Wed Apr 25 16:10:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:10:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:10:22 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:10:22 2018 ] Training epoch: 5410
[ Wed Apr 25 16:10:26 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:10:26 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:10:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:26 2018 ] Eval epoch: 5410
[ Wed Apr 25 16:10:29 2018 ] 	Mean test loss of 1 batches: 0.21103452146053314.
[ Wed Apr 25 16:10:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:10:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:10:29 2018 ] Training epoch: 5411
[ Wed Apr 25 16:10:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:10:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:10:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:33 2018 ] Training epoch: 5412
[ Wed Apr 25 16:10:37 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:10:37 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:10:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:37 2018 ] Training epoch: 5413
[ Wed Apr 25 16:10:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:10:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:10:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:41 2018 ] Training epoch: 5414
[ Wed Apr 25 16:10:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:10:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:10:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:45 2018 ] Training epoch: 5415
[ Wed Apr 25 16:10:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:10:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:10:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:49 2018 ] Eval epoch: 5415
[ Wed Apr 25 16:10:52 2018 ] 	Mean test loss of 1 batches: 0.215239018201828.
[ Wed Apr 25 16:10:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:10:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:10:52 2018 ] Training epoch: 5416
[ Wed Apr 25 16:10:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:10:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:10:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:10:56 2018 ] Training epoch: 5417
[ Wed Apr 25 16:11:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:00 2018 ] Training epoch: 5418
[ Wed Apr 25 16:11:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:11:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:11:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:04 2018 ] Training epoch: 5419
[ Wed Apr 25 16:11:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:11:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:11:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:08 2018 ] Training epoch: 5420
[ Wed Apr 25 16:11:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:12 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:11:12 2018 ] Eval epoch: 5420
[ Wed Apr 25 16:11:15 2018 ] 	Mean test loss of 1 batches: 0.2266644686460495.
[ Wed Apr 25 16:11:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:11:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:11:15 2018 ] Training epoch: 5421
[ Wed Apr 25 16:11:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:11:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:11:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:19 2018 ] Training epoch: 5422
[ Wed Apr 25 16:11:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:23 2018 ] Training epoch: 5423
[ Wed Apr 25 16:11:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:27 2018 ] Training epoch: 5424
[ Wed Apr 25 16:11:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:31 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:11:31 2018 ] Training epoch: 5425
[ Wed Apr 25 16:11:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:35 2018 ] Eval epoch: 5425
[ Wed Apr 25 16:11:38 2018 ] 	Mean test loss of 1 batches: 0.21861177682876587.
[ Wed Apr 25 16:11:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:11:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:11:38 2018 ] Training epoch: 5426
[ Wed Apr 25 16:11:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:11:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:11:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:42 2018 ] Training epoch: 5427
[ Wed Apr 25 16:11:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:11:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:11:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:46 2018 ] Training epoch: 5428
[ Wed Apr 25 16:11:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:50 2018 ] Training epoch: 5429
[ Wed Apr 25 16:11:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:11:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:11:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:54 2018 ] Training epoch: 5430
[ Wed Apr 25 16:11:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:11:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:11:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:11:58 2018 ] Eval epoch: 5430
[ Wed Apr 25 16:12:01 2018 ] 	Mean test loss of 1 batches: 0.2265961915254593.
[ Wed Apr 25 16:12:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:12:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:12:01 2018 ] Training epoch: 5431
[ Wed Apr 25 16:12:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:12:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:12:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:05 2018 ] Training epoch: 5432
[ Wed Apr 25 16:12:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:12:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:12:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:09 2018 ] Training epoch: 5433
[ Wed Apr 25 16:12:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:12:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:12:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:13 2018 ] Training epoch: 5434
[ Wed Apr 25 16:12:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:12:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:12:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:17 2018 ] Training epoch: 5435
[ Wed Apr 25 16:12:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:12:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:12:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:21 2018 ] Eval epoch: 5435
[ Wed Apr 25 16:12:24 2018 ] 	Mean test loss of 1 batches: 0.22402094304561615.
[ Wed Apr 25 16:12:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:12:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:12:24 2018 ] Training epoch: 5436
[ Wed Apr 25 16:12:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:12:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:12:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:28 2018 ] Training epoch: 5437
[ Wed Apr 25 16:12:32 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:12:32 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:12:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:32 2018 ] Training epoch: 5438
[ Wed Apr 25 16:12:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:12:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:12:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:36 2018 ] Training epoch: 5439
[ Wed Apr 25 16:12:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:12:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:12:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:40 2018 ] Training epoch: 5440
[ Wed Apr 25 16:12:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:12:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:12:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:44 2018 ] Eval epoch: 5440
[ Wed Apr 25 16:12:47 2018 ] 	Mean test loss of 1 batches: 0.20956948399543762.
[ Wed Apr 25 16:12:47 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:12:47 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:12:47 2018 ] Training epoch: 5441
[ Wed Apr 25 16:12:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:12:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:12:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:51 2018 ] Training epoch: 5442
[ Wed Apr 25 16:12:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:12:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:12:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:55 2018 ] Training epoch: 5443
[ Wed Apr 25 16:12:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:12:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:12:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:12:59 2018 ] Training epoch: 5444
[ Wed Apr 25 16:13:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:03 2018 ] Training epoch: 5445
[ Wed Apr 25 16:13:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:13:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:13:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:07 2018 ] Eval epoch: 5445
[ Wed Apr 25 16:13:10 2018 ] 	Mean test loss of 1 batches: 0.21857787668704987.
[ Wed Apr 25 16:13:10 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:13:10 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:13:10 2018 ] Training epoch: 5446
[ Wed Apr 25 16:13:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:14 2018 ] Training epoch: 5447
[ Wed Apr 25 16:13:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:18 2018 ] Training epoch: 5448
[ Wed Apr 25 16:13:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:13:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:13:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:22 2018 ] Training epoch: 5449
[ Wed Apr 25 16:13:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:26 2018 ] Training epoch: 5450
[ Wed Apr 25 16:13:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:30 2018 ] Eval epoch: 5450
[ Wed Apr 25 16:13:33 2018 ] 	Mean test loss of 1 batches: 0.23223532736301422.
[ Wed Apr 25 16:13:33 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:13:33 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:13:33 2018 ] Training epoch: 5451
[ Wed Apr 25 16:13:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:37 2018 ] Training epoch: 5452
[ Wed Apr 25 16:13:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:13:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:13:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:41 2018 ] Training epoch: 5453
[ Wed Apr 25 16:13:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:13:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:13:45 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:13:45 2018 ] Training epoch: 5454
[ Wed Apr 25 16:13:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:13:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:13:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:13:49 2018 ] Training epoch: 5455
[ Wed Apr 25 16:13:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:13:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:13:53 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:13:53 2018 ] Eval epoch: 5455
[ Wed Apr 25 16:13:56 2018 ] 	Mean test loss of 1 batches: 0.2360127568244934.
[ Wed Apr 25 16:13:56 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:13:56 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:13:56 2018 ] Training epoch: 5456
[ Wed Apr 25 16:14:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:14:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:14:00 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:14:00 2018 ] Training epoch: 5457
[ Wed Apr 25 16:14:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:04 2018 ] Training epoch: 5458
[ Wed Apr 25 16:14:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:09 2018 ] Training epoch: 5459
[ Wed Apr 25 16:14:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:14:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:14:13 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:14:13 2018 ] Training epoch: 5460
[ Wed Apr 25 16:14:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:14:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:14:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:17 2018 ] Eval epoch: 5460
[ Wed Apr 25 16:14:20 2018 ] 	Mean test loss of 1 batches: 0.23059013485908508.
[ Wed Apr 25 16:14:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:14:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:14:20 2018 ] Training epoch: 5461
[ Wed Apr 25 16:14:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:24 2018 ] Training epoch: 5462
[ Wed Apr 25 16:14:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:14:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:14:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:28 2018 ] Training epoch: 5463
[ Wed Apr 25 16:14:32 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:14:32 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:14:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:32 2018 ] Training epoch: 5464
[ Wed Apr 25 16:14:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:14:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:14:36 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:14:36 2018 ] Training epoch: 5465
[ Wed Apr 25 16:14:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:40 2018 ] Eval epoch: 5465
[ Wed Apr 25 16:14:42 2018 ] 	Mean test loss of 1 batches: 0.22556647658348083.
[ Wed Apr 25 16:14:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:14:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:14:42 2018 ] Training epoch: 5466
[ Wed Apr 25 16:14:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:47 2018 ] Training epoch: 5467
[ Wed Apr 25 16:14:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:14:51 2018 ] Training epoch: 5468
[ Wed Apr 25 16:14:55 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:14:55 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:14:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:55 2018 ] Training epoch: 5469
[ Wed Apr 25 16:14:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:14:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:14:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:14:59 2018 ] Training epoch: 5470
[ Wed Apr 25 16:15:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:15:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:15:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:03 2018 ] Eval epoch: 5470
[ Wed Apr 25 16:15:06 2018 ] 	Mean test loss of 1 batches: 0.2192518562078476.
[ Wed Apr 25 16:15:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:15:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:15:06 2018 ] Training epoch: 5471
[ Wed Apr 25 16:15:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:15:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:15:10 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:15:10 2018 ] Training epoch: 5472
[ Wed Apr 25 16:15:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:15:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:15:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:14 2018 ] Training epoch: 5473
[ Wed Apr 25 16:15:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:15:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:15:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:18 2018 ] Training epoch: 5474
[ Wed Apr 25 16:15:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:15:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:15:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:22 2018 ] Training epoch: 5475
[ Wed Apr 25 16:15:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:15:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:15:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:26 2018 ] Eval epoch: 5475
[ Wed Apr 25 16:15:29 2018 ] 	Mean test loss of 1 batches: 0.22358667850494385.
[ Wed Apr 25 16:15:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:15:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:15:29 2018 ] Training epoch: 5476
[ Wed Apr 25 16:15:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:15:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:15:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:33 2018 ] Training epoch: 5477
[ Wed Apr 25 16:15:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:15:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:15:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:37 2018 ] Training epoch: 5478
[ Wed Apr 25 16:15:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:15:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:15:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:41 2018 ] Training epoch: 5479
[ Wed Apr 25 16:15:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:15:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:15:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:45 2018 ] Training epoch: 5480
[ Wed Apr 25 16:15:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:15:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:15:49 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:15:49 2018 ] Eval epoch: 5480
[ Wed Apr 25 16:15:52 2018 ] 	Mean test loss of 1 batches: 0.21921777725219727.
[ Wed Apr 25 16:15:52 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:15:52 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:15:52 2018 ] Training epoch: 5481
[ Wed Apr 25 16:15:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:15:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:15:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:15:56 2018 ] Training epoch: 5482
[ Wed Apr 25 16:16:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:00 2018 ] Training epoch: 5483
[ Wed Apr 25 16:16:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:04 2018 ] Training epoch: 5484
[ Wed Apr 25 16:16:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:16:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:16:08 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:16:08 2018 ] Training epoch: 5485
[ Wed Apr 25 16:16:12 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:16:12 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:16:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:12 2018 ] Eval epoch: 5485
[ Wed Apr 25 16:16:15 2018 ] 	Mean test loss of 1 batches: 0.2117687463760376.
[ Wed Apr 25 16:16:15 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:16:15 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:16:15 2018 ] Training epoch: 5486
[ Wed Apr 25 16:16:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:19 2018 ] Training epoch: 5487
[ Wed Apr 25 16:16:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:23 2018 ] Training epoch: 5488
[ Wed Apr 25 16:16:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:16:28 2018 ] Training epoch: 5489
[ Wed Apr 25 16:16:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:32 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:16:32 2018 ] Training epoch: 5490
[ Wed Apr 25 16:16:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:36 2018 ] Eval epoch: 5490
[ Wed Apr 25 16:16:39 2018 ] 	Mean test loss of 1 batches: 0.2142973691225052.
[ Wed Apr 25 16:16:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:16:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:16:39 2018 ] Training epoch: 5491
[ Wed Apr 25 16:16:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:16:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:16:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:43 2018 ] Training epoch: 5492
[ Wed Apr 25 16:16:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:47 2018 ] Training epoch: 5493
[ Wed Apr 25 16:16:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:16:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:16:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:51 2018 ] Training epoch: 5494
[ Wed Apr 25 16:16:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:16:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:16:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:55 2018 ] Training epoch: 5495
[ Wed Apr 25 16:16:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:16:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:16:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:16:59 2018 ] Eval epoch: 5495
[ Wed Apr 25 16:17:02 2018 ] 	Mean test loss of 1 batches: 0.22485996782779694.
[ Wed Apr 25 16:17:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:17:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:17:02 2018 ] Training epoch: 5496
[ Wed Apr 25 16:17:06 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:17:06 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:17:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:06 2018 ] Training epoch: 5497
[ Wed Apr 25 16:17:10 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:17:10 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:17:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:10 2018 ] Training epoch: 5498
[ Wed Apr 25 16:17:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:17:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:17:14 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:17:14 2018 ] Training epoch: 5499
[ Wed Apr 25 16:17:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:18 2018 ] Training epoch: 5500
[ Wed Apr 25 16:17:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:22 2018 ] Eval epoch: 5500
[ Wed Apr 25 16:17:25 2018 ] 	Mean test loss of 1 batches: 0.21930043399333954.
[ Wed Apr 25 16:17:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:17:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:17:25 2018 ] Training epoch: 5501
[ Wed Apr 25 16:17:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:17:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:17:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:29 2018 ] Training epoch: 5502
[ Wed Apr 25 16:17:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:17:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:17:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:33 2018 ] Training epoch: 5503
[ Wed Apr 25 16:17:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:37 2018 ] Training epoch: 5504
[ Wed Apr 25 16:17:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:17:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:17:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:41 2018 ] Training epoch: 5505
[ Wed Apr 25 16:17:45 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:45 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:45 2018 ] Eval epoch: 5505
[ Wed Apr 25 16:17:48 2018 ] 	Mean test loss of 1 batches: 0.21907061338424683.
[ Wed Apr 25 16:17:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:17:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:17:48 2018 ] Training epoch: 5506
[ Wed Apr 25 16:17:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:52 2018 ] Training epoch: 5507
[ Wed Apr 25 16:17:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:17:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:17:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:17:56 2018 ] Training epoch: 5508
[ Wed Apr 25 16:18:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:00 2018 ] Training epoch: 5509
[ Wed Apr 25 16:18:04 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:18:04 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:18:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:04 2018 ] Training epoch: 5510
[ Wed Apr 25 16:18:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:18:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:18:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:08 2018 ] Eval epoch: 5510
[ Wed Apr 25 16:18:11 2018 ] 	Mean test loss of 1 batches: 0.2292945235967636.
[ Wed Apr 25 16:18:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:18:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:18:11 2018 ] Training epoch: 5511
[ Wed Apr 25 16:18:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:15 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:18:15 2018 ] Training epoch: 5512
[ Wed Apr 25 16:18:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:20 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:18:20 2018 ] Training epoch: 5513
[ Wed Apr 25 16:18:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:24 2018 ] Training epoch: 5514
[ Wed Apr 25 16:18:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:18:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:18:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:28 2018 ] Training epoch: 5515
[ Wed Apr 25 16:18:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:32 2018 ] Eval epoch: 5515
[ Wed Apr 25 16:18:35 2018 ] 	Mean test loss of 1 batches: 0.21579164266586304.
[ Wed Apr 25 16:18:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:18:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:18:35 2018 ] Training epoch: 5516
[ Wed Apr 25 16:18:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:18:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:18:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:39 2018 ] Training epoch: 5517
[ Wed Apr 25 16:18:43 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.000010
[ Wed Apr 25 16:18:43 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 16:18:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:43 2018 ] Training epoch: 5518
[ Wed Apr 25 16:18:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:18:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:18:47 2018 ] 	Time consumption: [Data]75%, [Network]24%
[ Wed Apr 25 16:18:47 2018 ] Training epoch: 5519
[ Wed Apr 25 16:18:51 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:18:51 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:18:51 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:18:51 2018 ] Training epoch: 5520
[ Wed Apr 25 16:18:55 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:18:55 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:18:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:18:55 2018 ] Eval epoch: 5520
[ Wed Apr 25 16:18:58 2018 ] 	Mean test loss of 1 batches: 0.2100755125284195.
[ Wed Apr 25 16:18:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:18:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:18:58 2018 ] Training epoch: 5521
[ Wed Apr 25 16:19:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:19:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:19:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:02 2018 ] Training epoch: 5522
[ Wed Apr 25 16:19:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:19:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:19:06 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:19:06 2018 ] Training epoch: 5523
[ Wed Apr 25 16:19:11 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:19:11 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:19:11 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:19:11 2018 ] Training epoch: 5524
[ Wed Apr 25 16:19:15 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 16:19:15 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 16:19:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:15 2018 ] Training epoch: 5525
[ Wed Apr 25 16:19:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:19:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:19:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:19 2018 ] Eval epoch: 5525
[ Wed Apr 25 16:19:22 2018 ] 	Mean test loss of 1 batches: 0.20737336575984955.
[ Wed Apr 25 16:19:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:19:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:19:22 2018 ] Training epoch: 5526
[ Wed Apr 25 16:19:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:19:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:19:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:26 2018 ] Training epoch: 5527
[ Wed Apr 25 16:19:30 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:19:30 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:19:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:30 2018 ] Training epoch: 5528
[ Wed Apr 25 16:19:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:19:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:19:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:34 2018 ] Training epoch: 5529
[ Wed Apr 25 16:19:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:19:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:19:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:38 2018 ] Training epoch: 5530
[ Wed Apr 25 16:19:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:19:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:19:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:42 2018 ] Eval epoch: 5530
[ Wed Apr 25 16:19:45 2018 ] 	Mean test loss of 1 batches: 0.21173174679279327.
[ Wed Apr 25 16:19:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:19:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:19:45 2018 ] Training epoch: 5531
[ Wed Apr 25 16:19:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:19:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:19:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:49 2018 ] Training epoch: 5532
[ Wed Apr 25 16:19:53 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:19:53 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:19:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:53 2018 ] Training epoch: 5533
[ Wed Apr 25 16:19:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:19:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:19:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:19:57 2018 ] Training epoch: 5534
[ Wed Apr 25 16:20:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:20:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:20:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:01 2018 ] Training epoch: 5535
[ Wed Apr 25 16:20:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:20:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:20:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:05 2018 ] Eval epoch: 5535
[ Wed Apr 25 16:20:08 2018 ] 	Mean test loss of 1 batches: 0.22443702816963196.
[ Wed Apr 25 16:20:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:20:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:20:08 2018 ] Training epoch: 5536
[ Wed Apr 25 16:20:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:20:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:20:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:12 2018 ] Training epoch: 5537
[ Wed Apr 25 16:20:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:16 2018 ] Training epoch: 5538
[ Wed Apr 25 16:20:20 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:20:20 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:20:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:20 2018 ] Training epoch: 5539
[ Wed Apr 25 16:20:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:24 2018 ] Training epoch: 5540
[ Wed Apr 25 16:20:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:28 2018 ] Eval epoch: 5540
[ Wed Apr 25 16:20:31 2018 ] 	Mean test loss of 1 batches: 0.22645816206932068.
[ Wed Apr 25 16:20:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:20:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:20:31 2018 ] Training epoch: 5541
[ Wed Apr 25 16:20:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:20:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:20:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:35 2018 ] Training epoch: 5542
[ Wed Apr 25 16:20:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:20:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:20:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:39 2018 ] Training epoch: 5543
[ Wed Apr 25 16:20:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:43 2018 ] Training epoch: 5544
[ Wed Apr 25 16:20:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:47 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:20:47 2018 ] Training epoch: 5545
[ Wed Apr 25 16:20:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:51 2018 ] Eval epoch: 5545
[ Wed Apr 25 16:20:54 2018 ] 	Mean test loss of 1 batches: 0.2351681888103485.
[ Wed Apr 25 16:20:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:20:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:20:54 2018 ] Training epoch: 5546
[ Wed Apr 25 16:20:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:20:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:20:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:20:58 2018 ] Training epoch: 5547
[ Wed Apr 25 16:21:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:21:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:21:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:02 2018 ] Training epoch: 5548
[ Wed Apr 25 16:21:06 2018 ] 	Batch(0/1) done. Loss: 0.0007  lr:0.000010
[ Wed Apr 25 16:21:06 2018 ] 	Mean training loss: 0.0007.
[ Wed Apr 25 16:21:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:06 2018 ] Training epoch: 5549
[ Wed Apr 25 16:21:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:21:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:21:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:10 2018 ] Training epoch: 5550
[ Wed Apr 25 16:21:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:21:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:21:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:14 2018 ] Eval epoch: 5550
[ Wed Apr 25 16:21:17 2018 ] 	Mean test loss of 1 batches: 0.23491668701171875.
[ Wed Apr 25 16:21:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:21:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:21:17 2018 ] Training epoch: 5551
[ Wed Apr 25 16:21:21 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:21:21 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:21:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:21 2018 ] Training epoch: 5552
[ Wed Apr 25 16:21:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:21:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:21:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:25 2018 ] Training epoch: 5553
[ Wed Apr 25 16:21:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:21:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:21:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:29 2018 ] Training epoch: 5554
[ Wed Apr 25 16:21:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:21:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:21:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:33 2018 ] Training epoch: 5555
[ Wed Apr 25 16:21:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:21:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:21:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:37 2018 ] Eval epoch: 5555
[ Wed Apr 25 16:21:40 2018 ] 	Mean test loss of 1 batches: 0.2405964583158493.
[ Wed Apr 25 16:21:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:21:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:21:40 2018 ] Training epoch: 5556
[ Wed Apr 25 16:21:44 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:21:44 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:21:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:44 2018 ] Training epoch: 5557
[ Wed Apr 25 16:21:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:21:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:21:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:48 2018 ] Training epoch: 5558
[ Wed Apr 25 16:21:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:21:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:21:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:52 2018 ] Training epoch: 5559
[ Wed Apr 25 16:21:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:21:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:21:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:21:56 2018 ] Training epoch: 5560
[ Wed Apr 25 16:22:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:22:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:22:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:00 2018 ] Eval epoch: 5560
[ Wed Apr 25 16:22:03 2018 ] 	Mean test loss of 1 batches: 0.22456039488315582.
[ Wed Apr 25 16:22:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:22:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:22:03 2018 ] Training epoch: 5561
[ Wed Apr 25 16:22:07 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:07 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:07 2018 ] Training epoch: 5562
[ Wed Apr 25 16:22:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:11 2018 ] Training epoch: 5563
[ Wed Apr 25 16:22:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:22:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:22:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:15 2018 ] Training epoch: 5564
[ Wed Apr 25 16:22:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:19 2018 ] Training epoch: 5565
[ Wed Apr 25 16:22:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:22:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:22:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:23 2018 ] Eval epoch: 5565
[ Wed Apr 25 16:22:26 2018 ] 	Mean test loss of 1 batches: 0.221259206533432.
[ Wed Apr 25 16:22:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:22:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:22:26 2018 ] Training epoch: 5566
[ Wed Apr 25 16:22:30 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:22:30 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:22:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:30 2018 ] Training epoch: 5567
[ Wed Apr 25 16:22:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:34 2018 ] Training epoch: 5568
[ Wed Apr 25 16:22:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:38 2018 ] Training epoch: 5569
[ Wed Apr 25 16:22:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:42 2018 ] Training epoch: 5570
[ Wed Apr 25 16:22:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:22:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:22:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:46 2018 ] Eval epoch: 5570
[ Wed Apr 25 16:22:49 2018 ] 	Mean test loss of 1 batches: 0.21517649292945862.
[ Wed Apr 25 16:22:49 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:22:49 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:22:49 2018 ] Training epoch: 5571
[ Wed Apr 25 16:22:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:22:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:22:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:53 2018 ] Training epoch: 5572
[ Wed Apr 25 16:22:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:22:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:22:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:22:57 2018 ] Training epoch: 5573
[ Wed Apr 25 16:23:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:01 2018 ] Training epoch: 5574
[ Wed Apr 25 16:23:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:05 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:23:05 2018 ] Training epoch: 5575
[ Wed Apr 25 16:23:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:23:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:23:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:09 2018 ] Eval epoch: 5575
[ Wed Apr 25 16:23:12 2018 ] 	Mean test loss of 1 batches: 0.2176557183265686.
[ Wed Apr 25 16:23:12 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:23:12 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:23:12 2018 ] Training epoch: 5576
[ Wed Apr 25 16:23:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:23:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:23:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:16 2018 ] Training epoch: 5577
[ Wed Apr 25 16:23:20 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:23:20 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:23:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:20 2018 ] Training epoch: 5578
[ Wed Apr 25 16:23:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:23:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:23:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:24 2018 ] Training epoch: 5579
[ Wed Apr 25 16:23:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:28 2018 ] Training epoch: 5580
[ Wed Apr 25 16:23:32 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:32 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:32 2018 ] Eval epoch: 5580
[ Wed Apr 25 16:23:35 2018 ] 	Mean test loss of 1 batches: 0.21536189317703247.
[ Wed Apr 25 16:23:35 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:23:35 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:23:35 2018 ] Training epoch: 5581
[ Wed Apr 25 16:23:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:23:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:23:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:39 2018 ] Training epoch: 5582
[ Wed Apr 25 16:23:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:43 2018 ] Training epoch: 5583
[ Wed Apr 25 16:23:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:23:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:23:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:47 2018 ] Training epoch: 5584
[ Wed Apr 25 16:23:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:23:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:23:51 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:23:51 2018 ] Training epoch: 5585
[ Wed Apr 25 16:23:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:23:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:23:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:23:55 2018 ] Eval epoch: 5585
[ Wed Apr 25 16:23:58 2018 ] 	Mean test loss of 1 batches: 0.20453473925590515.
[ Wed Apr 25 16:23:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:23:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:23:58 2018 ] Training epoch: 5586
[ Wed Apr 25 16:24:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:24:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:24:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:02 2018 ] Training epoch: 5587
[ Wed Apr 25 16:24:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:24:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:24:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:06 2018 ] Training epoch: 5588
[ Wed Apr 25 16:24:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:24:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:24:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:10 2018 ] Training epoch: 5589
[ Wed Apr 25 16:24:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:24:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:24:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:14 2018 ] Training epoch: 5590
[ Wed Apr 25 16:24:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:24:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:24:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:18 2018 ] Eval epoch: 5590
[ Wed Apr 25 16:24:21 2018 ] 	Mean test loss of 1 batches: 0.2162267565727234.
[ Wed Apr 25 16:24:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:24:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:24:21 2018 ] Training epoch: 5591
[ Wed Apr 25 16:24:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:24:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:24:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:25 2018 ] Training epoch: 5592
[ Wed Apr 25 16:24:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:24:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:24:29 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:24:29 2018 ] Training epoch: 5593
[ Wed Apr 25 16:24:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:24:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:24:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:33 2018 ] Training epoch: 5594
[ Wed Apr 25 16:24:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:24:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:24:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:38 2018 ] Training epoch: 5595
[ Wed Apr 25 16:24:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:24:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:24:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:42 2018 ] Eval epoch: 5595
[ Wed Apr 25 16:24:44 2018 ] 	Mean test loss of 1 batches: 0.2273758053779602.
[ Wed Apr 25 16:24:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:24:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:24:44 2018 ] Training epoch: 5596
[ Wed Apr 25 16:24:49 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:24:49 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:24:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:49 2018 ] Training epoch: 5597
[ Wed Apr 25 16:24:53 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:24:53 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:24:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:53 2018 ] Training epoch: 5598
[ Wed Apr 25 16:24:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:24:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:24:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:24:57 2018 ] Training epoch: 5599
[ Wed Apr 25 16:25:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:25:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:25:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:01 2018 ] Training epoch: 5600
[ Wed Apr 25 16:25:05 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 16:25:05 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 16:25:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:05 2018 ] Eval epoch: 5600
[ Wed Apr 25 16:25:07 2018 ] 	Mean test loss of 1 batches: 0.22132070362567902.
[ Wed Apr 25 16:25:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:25:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:25:07 2018 ] Training epoch: 5601
[ Wed Apr 25 16:25:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:12 2018 ] Training epoch: 5602
[ Wed Apr 25 16:25:16 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:16 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:16 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:16 2018 ] Training epoch: 5603
[ Wed Apr 25 16:25:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:20 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:25:20 2018 ] Training epoch: 5604
[ Wed Apr 25 16:25:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:25:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:25:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:24 2018 ] Training epoch: 5605
[ Wed Apr 25 16:25:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:28 2018 ] Eval epoch: 5605
[ Wed Apr 25 16:25:31 2018 ] 	Mean test loss of 1 batches: 0.2219490110874176.
[ Wed Apr 25 16:25:31 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:25:31 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:25:31 2018 ] Training epoch: 5606
[ Wed Apr 25 16:25:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:35 2018 ] Training epoch: 5607
[ Wed Apr 25 16:25:39 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:25:39 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:25:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:39 2018 ] Training epoch: 5608
[ Wed Apr 25 16:25:43 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:25:43 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:25:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:43 2018 ] Training epoch: 5609
[ Wed Apr 25 16:25:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:25:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:25:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:47 2018 ] Training epoch: 5610
[ Wed Apr 25 16:25:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:25:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:25:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:51 2018 ] Eval epoch: 5610
[ Wed Apr 25 16:25:54 2018 ] 	Mean test loss of 1 batches: 0.22546321153640747.
[ Wed Apr 25 16:25:54 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:25:54 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:25:54 2018 ] Training epoch: 5611
[ Wed Apr 25 16:25:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:25:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:25:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:25:58 2018 ] Training epoch: 5612
[ Wed Apr 25 16:26:02 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:26:02 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:26:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:02 2018 ] Training epoch: 5613
[ Wed Apr 25 16:26:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:06 2018 ] Training epoch: 5614
[ Wed Apr 25 16:26:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:10 2018 ] Training epoch: 5615
[ Wed Apr 25 16:26:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:26:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:26:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:14 2018 ] Eval epoch: 5615
[ Wed Apr 25 16:26:17 2018 ] 	Mean test loss of 1 batches: 0.22240760922431946.
[ Wed Apr 25 16:26:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:26:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:26:17 2018 ] Training epoch: 5616
[ Wed Apr 25 16:26:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:21 2018 ] Training epoch: 5617
[ Wed Apr 25 16:26:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:26:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:26:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:25 2018 ] Training epoch: 5618
[ Wed Apr 25 16:26:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:26:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:26:30 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:26:30 2018 ] Training epoch: 5619
[ Wed Apr 25 16:26:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:26:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:26:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:34 2018 ] Training epoch: 5620
[ Wed Apr 25 16:26:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:38 2018 ] Eval epoch: 5620
[ Wed Apr 25 16:26:41 2018 ] 	Mean test loss of 1 batches: 0.2301178276538849.
[ Wed Apr 25 16:26:41 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:26:41 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:26:41 2018 ] Training epoch: 5621
[ Wed Apr 25 16:26:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:45 2018 ] Training epoch: 5622
[ Wed Apr 25 16:26:49 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:26:49 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:26:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:49 2018 ] Training epoch: 5623
[ Wed Apr 25 16:26:53 2018 ] 	Batch(0/1) done. Loss: 0.0010  lr:0.000010
[ Wed Apr 25 16:26:53 2018 ] 	Mean training loss: 0.0010.
[ Wed Apr 25 16:26:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:53 2018 ] Training epoch: 5624
[ Wed Apr 25 16:26:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:26:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:26:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:26:57 2018 ] Training epoch: 5625
[ Wed Apr 25 16:27:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:27:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:27:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:01 2018 ] Eval epoch: 5625
[ Wed Apr 25 16:27:04 2018 ] 	Mean test loss of 1 batches: 0.2203390896320343.
[ Wed Apr 25 16:27:04 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:27:04 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:27:04 2018 ] Training epoch: 5626
[ Wed Apr 25 16:27:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:27:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:27:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:08 2018 ] Training epoch: 5627
[ Wed Apr 25 16:27:12 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:27:12 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:27:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:12 2018 ] Training epoch: 5628
[ Wed Apr 25 16:27:16 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:27:16 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:27:16 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:27:16 2018 ] Training epoch: 5629
[ Wed Apr 25 16:27:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:27:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:27:20 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:27:20 2018 ] Training epoch: 5630
[ Wed Apr 25 16:27:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:27:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:27:24 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:27:24 2018 ] Eval epoch: 5630
[ Wed Apr 25 16:27:27 2018 ] 	Mean test loss of 1 batches: 0.21623888611793518.
[ Wed Apr 25 16:27:27 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:27:27 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:27:27 2018 ] Training epoch: 5631
[ Wed Apr 25 16:27:31 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:27:31 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:27:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:31 2018 ] Training epoch: 5632
[ Wed Apr 25 16:27:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:27:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:27:35 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:27:35 2018 ] Training epoch: 5633
[ Wed Apr 25 16:27:40 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:27:40 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:27:40 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:27:40 2018 ] Training epoch: 5634
[ Wed Apr 25 16:27:44 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:27:44 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:27:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:44 2018 ] Training epoch: 5635
[ Wed Apr 25 16:27:48 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:27:48 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:27:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:27:48 2018 ] Eval epoch: 5635
[ Wed Apr 25 16:27:51 2018 ] 	Mean test loss of 1 batches: 0.22361260652542114.
[ Wed Apr 25 16:27:51 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:27:51 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:27:51 2018 ] Training epoch: 5636
[ Wed Apr 25 16:27:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:27:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:27:55 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:27:55 2018 ] Training epoch: 5637
[ Wed Apr 25 16:27:59 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 16:27:59 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 16:27:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:27:59 2018 ] Training epoch: 5638
[ Wed Apr 25 16:28:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:28:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:28:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:03 2018 ] Training epoch: 5639
[ Wed Apr 25 16:28:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:28:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:28:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:07 2018 ] Training epoch: 5640
[ Wed Apr 25 16:28:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:28:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:28:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:11 2018 ] Eval epoch: 5640
[ Wed Apr 25 16:28:14 2018 ] 	Mean test loss of 1 batches: 0.2173713892698288.
[ Wed Apr 25 16:28:14 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:28:14 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:28:14 2018 ] Training epoch: 5641
[ Wed Apr 25 16:28:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:28:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:28:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:18 2018 ] Training epoch: 5642
[ Wed Apr 25 16:28:23 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:28:23 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:28:23 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:28:23 2018 ] Training epoch: 5643
[ Wed Apr 25 16:28:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:28:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:28:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:27 2018 ] Training epoch: 5644
[ Wed Apr 25 16:28:31 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:28:31 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:28:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:31 2018 ] Training epoch: 5645
[ Wed Apr 25 16:28:35 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:28:35 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:28:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:35 2018 ] Eval epoch: 5645
[ Wed Apr 25 16:28:38 2018 ] 	Mean test loss of 1 batches: 0.209784135222435.
[ Wed Apr 25 16:28:38 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:28:38 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:28:38 2018 ] Training epoch: 5646
[ Wed Apr 25 16:28:42 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:28:42 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:28:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:42 2018 ] Training epoch: 5647
[ Wed Apr 25 16:28:46 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:28:46 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:28:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:46 2018 ] Training epoch: 5648
[ Wed Apr 25 16:28:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:28:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:28:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:50 2018 ] Training epoch: 5649
[ Wed Apr 25 16:28:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:28:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:28:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:54 2018 ] Training epoch: 5650
[ Wed Apr 25 16:28:58 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:28:58 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:28:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:28:58 2018 ] Eval epoch: 5650
[ Wed Apr 25 16:29:01 2018 ] 	Mean test loss of 1 batches: 0.21341025829315186.
[ Wed Apr 25 16:29:01 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:29:01 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:29:01 2018 ] Training epoch: 5651
[ Wed Apr 25 16:29:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:29:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:29:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:05 2018 ] Training epoch: 5652
[ Wed Apr 25 16:29:09 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:29:09 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:29:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:09 2018 ] Training epoch: 5653
[ Wed Apr 25 16:29:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:29:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:29:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:13 2018 ] Training epoch: 5654
[ Wed Apr 25 16:29:17 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:29:17 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:29:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:29:17 2018 ] Training epoch: 5655
[ Wed Apr 25 16:29:21 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:29:21 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:29:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:21 2018 ] Eval epoch: 5655
[ Wed Apr 25 16:29:24 2018 ] 	Mean test loss of 1 batches: 0.23206570744514465.
[ Wed Apr 25 16:29:24 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:29:24 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:29:24 2018 ] Training epoch: 5656
[ Wed Apr 25 16:29:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:29:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:29:28 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:29:28 2018 ] Training epoch: 5657
[ Wed Apr 25 16:29:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:29:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:29:32 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:29:32 2018 ] Training epoch: 5658
[ Wed Apr 25 16:29:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:29:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:29:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:36 2018 ] Training epoch: 5659
[ Wed Apr 25 16:29:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:29:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:29:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:41 2018 ] Training epoch: 5660
[ Wed Apr 25 16:29:45 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:29:45 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:29:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:45 2018 ] Eval epoch: 5660
[ Wed Apr 25 16:29:48 2018 ] 	Mean test loss of 1 batches: 0.21545419096946716.
[ Wed Apr 25 16:29:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:29:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:29:48 2018 ] Training epoch: 5661
[ Wed Apr 25 16:29:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:29:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:29:52 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:29:52 2018 ] Training epoch: 5662
[ Wed Apr 25 16:29:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:29:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:29:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:29:56 2018 ] Training epoch: 5663
[ Wed Apr 25 16:30:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:00 2018 ] Training epoch: 5664
[ Wed Apr 25 16:30:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:04 2018 ] Training epoch: 5665
[ Wed Apr 25 16:30:08 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:08 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:08 2018 ] Eval epoch: 5665
[ Wed Apr 25 16:30:11 2018 ] 	Mean test loss of 1 batches: 0.21593791246414185.
[ Wed Apr 25 16:30:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:30:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:30:11 2018 ] Training epoch: 5666
[ Wed Apr 25 16:30:15 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:30:15 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:30:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:15 2018 ] Training epoch: 5667
[ Wed Apr 25 16:30:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:19 2018 ] Training epoch: 5668
[ Wed Apr 25 16:30:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:23 2018 ] Training epoch: 5669
[ Wed Apr 25 16:30:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:30:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:30:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:27 2018 ] Training epoch: 5670
[ Wed Apr 25 16:30:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:30:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:30:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:31 2018 ] Eval epoch: 5670
[ Wed Apr 25 16:30:34 2018 ] 	Mean test loss of 1 batches: 0.23094893991947174.
[ Wed Apr 25 16:30:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:30:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:30:34 2018 ] Training epoch: 5671
[ Wed Apr 25 16:30:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:30:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:30:38 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:30:38 2018 ] Training epoch: 5672
[ Wed Apr 25 16:30:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:30:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:30:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:42 2018 ] Training epoch: 5673
[ Wed Apr 25 16:30:46 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:30:46 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:30:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:46 2018 ] Training epoch: 5674
[ Wed Apr 25 16:30:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:30:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:30:51 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:30:51 2018 ] Training epoch: 5675
[ Wed Apr 25 16:30:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:30:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:30:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:30:55 2018 ] Eval epoch: 5675
[ Wed Apr 25 16:30:58 2018 ] 	Mean test loss of 1 batches: 0.23098629713058472.
[ Wed Apr 25 16:30:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:30:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:30:58 2018 ] Training epoch: 5676
[ Wed Apr 25 16:31:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:02 2018 ] Training epoch: 5677
[ Wed Apr 25 16:31:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:06 2018 ] Training epoch: 5678
[ Wed Apr 25 16:31:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:31:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:31:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:31:10 2018 ] Training epoch: 5679
[ Wed Apr 25 16:31:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:14 2018 ] Training epoch: 5680
[ Wed Apr 25 16:31:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:31:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:31:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:18 2018 ] Eval epoch: 5680
[ Wed Apr 25 16:31:21 2018 ] 	Mean test loss of 1 batches: 0.22158779203891754.
[ Wed Apr 25 16:31:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:31:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:31:21 2018 ] Training epoch: 5681
[ Wed Apr 25 16:31:25 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:31:25 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:31:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:25 2018 ] Training epoch: 5682
[ Wed Apr 25 16:31:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:29 2018 ] Training epoch: 5683
[ Wed Apr 25 16:31:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:33 2018 ] Training epoch: 5684
[ Wed Apr 25 16:31:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:37 2018 ] Training epoch: 5685
[ Wed Apr 25 16:31:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:41 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:31:41 2018 ] Eval epoch: 5685
[ Wed Apr 25 16:31:44 2018 ] 	Mean test loss of 1 batches: 0.22440090775489807.
[ Wed Apr 25 16:31:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:31:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:31:44 2018 ] Training epoch: 5686
[ Wed Apr 25 16:31:48 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:31:48 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:31:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:48 2018 ] Training epoch: 5687
[ Wed Apr 25 16:31:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:52 2018 ] Training epoch: 5688
[ Wed Apr 25 16:31:56 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:31:56 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:31:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:31:56 2018 ] Training epoch: 5689
[ Wed Apr 25 16:32:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:32:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:32:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:00 2018 ] Training epoch: 5690
[ Wed Apr 25 16:32:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:32:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:32:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:04 2018 ] Eval epoch: 5690
[ Wed Apr 25 16:32:07 2018 ] 	Mean test loss of 1 batches: 0.23425185680389404.
[ Wed Apr 25 16:32:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:32:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:32:07 2018 ] Training epoch: 5691
[ Wed Apr 25 16:32:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:32:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:32:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:11 2018 ] Training epoch: 5692
[ Wed Apr 25 16:32:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:32:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:32:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:15 2018 ] Training epoch: 5693
[ Wed Apr 25 16:32:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:32:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:32:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:19 2018 ] Training epoch: 5694
[ Wed Apr 25 16:32:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:32:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:32:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:23 2018 ] Training epoch: 5695
[ Wed Apr 25 16:32:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:32:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:32:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:27 2018 ] Eval epoch: 5695
[ Wed Apr 25 16:32:30 2018 ] 	Mean test loss of 1 batches: 0.2295609563589096.
[ Wed Apr 25 16:32:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:32:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:32:30 2018 ] Training epoch: 5696
[ Wed Apr 25 16:32:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:32:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:32:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:34 2018 ] Training epoch: 5697
[ Wed Apr 25 16:32:38 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:32:38 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:32:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:38 2018 ] Training epoch: 5698
[ Wed Apr 25 16:32:42 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:32:42 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:32:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:42 2018 ] Training epoch: 5699
[ Wed Apr 25 16:32:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:32:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:32:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:46 2018 ] Training epoch: 5700
[ Wed Apr 25 16:32:50 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:32:50 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:32:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:50 2018 ] Eval epoch: 5700
[ Wed Apr 25 16:32:53 2018 ] 	Mean test loss of 1 batches: 0.23081636428833008.
[ Wed Apr 25 16:32:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:32:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:32:53 2018 ] Training epoch: 5701
[ Wed Apr 25 16:32:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:32:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:32:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:32:57 2018 ] Training epoch: 5702
[ Wed Apr 25 16:33:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:01 2018 ] Training epoch: 5703
[ Wed Apr 25 16:33:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:33:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:33:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:05 2018 ] Training epoch: 5704
[ Wed Apr 25 16:33:09 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:09 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:09 2018 ] Training epoch: 5705
[ Wed Apr 25 16:33:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:33:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:33:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:13 2018 ] Eval epoch: 5705
[ Wed Apr 25 16:33:16 2018 ] 	Mean test loss of 1 batches: 0.21920616924762726.
[ Wed Apr 25 16:33:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:33:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:33:16 2018 ] Training epoch: 5706
[ Wed Apr 25 16:33:20 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:33:20 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:33:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:20 2018 ] Training epoch: 5707
[ Wed Apr 25 16:33:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:24 2018 ] Training epoch: 5708
[ Wed Apr 25 16:33:28 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:28 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:28 2018 ] Training epoch: 5709
[ Wed Apr 25 16:33:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:33:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:33:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:32 2018 ] Training epoch: 5710
[ Wed Apr 25 16:33:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:36 2018 ] Eval epoch: 5710
[ Wed Apr 25 16:33:39 2018 ] 	Mean test loss of 1 batches: 0.2232770323753357.
[ Wed Apr 25 16:33:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:33:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:33:39 2018 ] Training epoch: 5711
[ Wed Apr 25 16:33:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:43 2018 ] Training epoch: 5712
[ Wed Apr 25 16:33:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:33:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:33:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:47 2018 ] Training epoch: 5713
[ Wed Apr 25 16:33:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:33:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:33:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:51 2018 ] Training epoch: 5714
[ Wed Apr 25 16:33:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:33:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:33:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:55 2018 ] Training epoch: 5715
[ Wed Apr 25 16:33:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:33:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:33:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:33:59 2018 ] Eval epoch: 5715
[ Wed Apr 25 16:34:02 2018 ] 	Mean test loss of 1 batches: 0.22204364836215973.
[ Wed Apr 25 16:34:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:34:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:34:02 2018 ] Training epoch: 5716
[ Wed Apr 25 16:34:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:06 2018 ] Training epoch: 5717
[ Wed Apr 25 16:34:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:10 2018 ] Training epoch: 5718
[ Wed Apr 25 16:34:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:14 2018 ] Training epoch: 5719
[ Wed Apr 25 16:34:18 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:34:18 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:34:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:18 2018 ] Training epoch: 5720
[ Wed Apr 25 16:34:22 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:34:22 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:34:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:22 2018 ] Eval epoch: 5720
[ Wed Apr 25 16:34:25 2018 ] 	Mean test loss of 1 batches: 0.2167794406414032.
[ Wed Apr 25 16:34:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:34:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:34:25 2018 ] Training epoch: 5721
[ Wed Apr 25 16:34:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:29 2018 ] Training epoch: 5722
[ Wed Apr 25 16:34:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:33 2018 ] Training epoch: 5723
[ Wed Apr 25 16:34:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:34:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:34:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:37 2018 ] Training epoch: 5724
[ Wed Apr 25 16:34:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:42 2018 ] Training epoch: 5725
[ Wed Apr 25 16:34:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:34:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:34:46 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:34:46 2018 ] Eval epoch: 5725
[ Wed Apr 25 16:34:48 2018 ] 	Mean test loss of 1 batches: 0.2207610011100769.
[ Wed Apr 25 16:34:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:34:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:34:48 2018 ] Training epoch: 5726
[ Wed Apr 25 16:34:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:53 2018 ] Training epoch: 5727
[ Wed Apr 25 16:34:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:34:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:34:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:34:56 2018 ] Training epoch: 5728
[ Wed Apr 25 16:35:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:35:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:35:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:01 2018 ] Training epoch: 5729
[ Wed Apr 25 16:35:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:05 2018 ] Training epoch: 5730
[ Wed Apr 25 16:35:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:09 2018 ] Eval epoch: 5730
[ Wed Apr 25 16:35:11 2018 ] 	Mean test loss of 1 batches: 0.22433225810527802.
[ Wed Apr 25 16:35:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:35:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:35:11 2018 ] Training epoch: 5731
[ Wed Apr 25 16:35:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:15 2018 ] Training epoch: 5732
[ Wed Apr 25 16:35:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:20 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:35:20 2018 ] Training epoch: 5733
[ Wed Apr 25 16:35:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:35:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:35:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:24 2018 ] Training epoch: 5734
[ Wed Apr 25 16:35:28 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:35:28 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:35:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:28 2018 ] Training epoch: 5735
[ Wed Apr 25 16:35:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:32 2018 ] Eval epoch: 5735
[ Wed Apr 25 16:35:36 2018 ] 	Mean test loss of 1 batches: 0.2241332232952118.
[ Wed Apr 25 16:35:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:35:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:35:36 2018 ] Training epoch: 5736
[ Wed Apr 25 16:35:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:35:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:35:40 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:35:40 2018 ] Training epoch: 5737
[ Wed Apr 25 16:35:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:35:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:35:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:44 2018 ] Training epoch: 5738
[ Wed Apr 25 16:35:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:48 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:35:48 2018 ] Training epoch: 5739
[ Wed Apr 25 16:35:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:35:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:35:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:52 2018 ] Training epoch: 5740
[ Wed Apr 25 16:35:56 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:35:56 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:35:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:35:56 2018 ] Eval epoch: 5740
[ Wed Apr 25 16:35:59 2018 ] 	Mean test loss of 1 batches: 0.22299200296401978.
[ Wed Apr 25 16:35:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:35:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:35:59 2018 ] Training epoch: 5741
[ Wed Apr 25 16:36:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:03 2018 ] Training epoch: 5742
[ Wed Apr 25 16:36:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:36:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:36:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:07 2018 ] Training epoch: 5743
[ Wed Apr 25 16:36:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:11 2018 ] Training epoch: 5744
[ Wed Apr 25 16:36:15 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:15 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:15 2018 ] Training epoch: 5745
[ Wed Apr 25 16:36:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:19 2018 ] Eval epoch: 5745
[ Wed Apr 25 16:36:22 2018 ] 	Mean test loss of 1 batches: 0.2306879311800003.
[ Wed Apr 25 16:36:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:36:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:36:22 2018 ] Training epoch: 5746
[ Wed Apr 25 16:36:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:36:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:36:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:26 2018 ] Training epoch: 5747
[ Wed Apr 25 16:36:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:30 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:30 2018 ] Training epoch: 5748
[ Wed Apr 25 16:36:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:34 2018 ] Training epoch: 5749
[ Wed Apr 25 16:36:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:36:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:36:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:38 2018 ] Training epoch: 5750
[ Wed Apr 25 16:36:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:42 2018 ] Eval epoch: 5750
[ Wed Apr 25 16:36:45 2018 ] 	Mean test loss of 1 batches: 0.22488510608673096.
[ Wed Apr 25 16:36:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:36:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:36:45 2018 ] Training epoch: 5751
[ Wed Apr 25 16:36:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:49 2018 ] Training epoch: 5752
[ Wed Apr 25 16:36:53 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:53 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:53 2018 ] Training epoch: 5753
[ Wed Apr 25 16:36:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:36:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:36:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:36:57 2018 ] Training epoch: 5754
[ Wed Apr 25 16:37:01 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:37:01 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:37:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:01 2018 ] Training epoch: 5755
[ Wed Apr 25 16:37:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:37:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:37:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:05 2018 ] Eval epoch: 5755
[ Wed Apr 25 16:37:08 2018 ] 	Mean test loss of 1 batches: 0.2247183918952942.
[ Wed Apr 25 16:37:08 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:37:08 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:37:08 2018 ] Training epoch: 5756
[ Wed Apr 25 16:37:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:37:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:37:13 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:37:13 2018 ] Training epoch: 5757
[ Wed Apr 25 16:37:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:17 2018 ] Training epoch: 5758
[ Wed Apr 25 16:37:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:21 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:37:21 2018 ] Training epoch: 5759
[ Wed Apr 25 16:37:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:25 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:37:25 2018 ] Training epoch: 5760
[ Wed Apr 25 16:37:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:29 2018 ] Eval epoch: 5760
[ Wed Apr 25 16:37:32 2018 ] 	Mean test loss of 1 batches: 0.2247718870639801.
[ Wed Apr 25 16:37:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:37:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:37:32 2018 ] Training epoch: 5761
[ Wed Apr 25 16:37:36 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:37:36 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:37:36 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:37:36 2018 ] Training epoch: 5762
[ Wed Apr 25 16:37:40 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:37:40 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:37:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:40 2018 ] Training epoch: 5763
[ Wed Apr 25 16:37:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:37:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:37:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:44 2018 ] Training epoch: 5764
[ Wed Apr 25 16:37:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:37:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:37:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:48 2018 ] Training epoch: 5765
[ Wed Apr 25 16:37:52 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:52 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:37:52 2018 ] Eval epoch: 5765
[ Wed Apr 25 16:37:55 2018 ] 	Mean test loss of 1 batches: 0.2268533706665039.
[ Wed Apr 25 16:37:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:37:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:37:55 2018 ] Training epoch: 5766
[ Wed Apr 25 16:37:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:37:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:37:59 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:37:59 2018 ] Training epoch: 5767
[ Wed Apr 25 16:38:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:38:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:38:04 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:38:04 2018 ] Training epoch: 5768
[ Wed Apr 25 16:38:08 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:38:08 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:38:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:08 2018 ] Training epoch: 5769
[ Wed Apr 25 16:38:12 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:38:12 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:38:12 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:12 2018 ] Training epoch: 5770
[ Wed Apr 25 16:38:16 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:38:16 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:38:16 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:38:16 2018 ] Eval epoch: 5770
[ Wed Apr 25 16:38:19 2018 ] 	Mean test loss of 1 batches: 0.22143732011318207.
[ Wed Apr 25 16:38:19 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:38:19 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:38:19 2018 ] Training epoch: 5771
[ Wed Apr 25 16:38:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:23 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:38:23 2018 ] Training epoch: 5772
[ Wed Apr 25 16:38:27 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:27 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:27 2018 ] Training epoch: 5773
[ Wed Apr 25 16:38:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:32 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:38:32 2018 ] Training epoch: 5774
[ Wed Apr 25 16:38:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:36 2018 ] Training epoch: 5775
[ Wed Apr 25 16:38:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:38:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:38:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:40 2018 ] Eval epoch: 5775
[ Wed Apr 25 16:38:43 2018 ] 	Mean test loss of 1 batches: 0.2176089882850647.
[ Wed Apr 25 16:38:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:38:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:38:43 2018 ] Training epoch: 5776
[ Wed Apr 25 16:38:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:38:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:38:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:47 2018 ] Training epoch: 5777
[ Wed Apr 25 16:38:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:51 2018 ] Training epoch: 5778
[ Wed Apr 25 16:38:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:38:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:38:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:38:55 2018 ] Training epoch: 5779
[ Wed Apr 25 16:38:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:38:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:38:59 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:38:59 2018 ] Training epoch: 5780
[ Wed Apr 25 16:39:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:39:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:39:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:03 2018 ] Eval epoch: 5780
[ Wed Apr 25 16:39:06 2018 ] 	Mean test loss of 1 batches: 0.22180432081222534.
[ Wed Apr 25 16:39:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:39:06 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:39:06 2018 ] Training epoch: 5781
[ Wed Apr 25 16:39:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:10 2018 ] Training epoch: 5782
[ Wed Apr 25 16:39:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:14 2018 ] Training epoch: 5783
[ Wed Apr 25 16:39:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:18 2018 ] Training epoch: 5784
[ Wed Apr 25 16:39:22 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:22 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:22 2018 ] Training epoch: 5785
[ Wed Apr 25 16:39:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:39:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:39:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:26 2018 ] Eval epoch: 5785
[ Wed Apr 25 16:39:29 2018 ] 	Mean test loss of 1 batches: 0.2146870344877243.
[ Wed Apr 25 16:39:29 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:39:29 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:39:29 2018 ] Training epoch: 5786
[ Wed Apr 25 16:39:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:39:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:39:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:33 2018 ] Training epoch: 5787
[ Wed Apr 25 16:39:37 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:39:37 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:39:37 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:39:37 2018 ] Training epoch: 5788
[ Wed Apr 25 16:39:41 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:39:41 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:39:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:41 2018 ] Training epoch: 5789
[ Wed Apr 25 16:39:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:39:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:39:46 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:39:46 2018 ] Training epoch: 5790
[ Wed Apr 25 16:39:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:50 2018 ] Eval epoch: 5790
[ Wed Apr 25 16:39:53 2018 ] 	Mean test loss of 1 batches: 0.2243162840604782.
[ Wed Apr 25 16:39:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:39:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:39:53 2018 ] Training epoch: 5791
[ Wed Apr 25 16:39:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:39:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:39:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:39:57 2018 ] Training epoch: 5792
[ Wed Apr 25 16:40:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:40:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:40:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:01 2018 ] Training epoch: 5793
[ Wed Apr 25 16:40:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:40:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:40:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:05 2018 ] Training epoch: 5794
[ Wed Apr 25 16:40:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:09 2018 ] Training epoch: 5795
[ Wed Apr 25 16:40:13 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:40:13 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:40:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:13 2018 ] Eval epoch: 5795
[ Wed Apr 25 16:40:16 2018 ] 	Mean test loss of 1 batches: 0.22389604151248932.
[ Wed Apr 25 16:40:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:40:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:40:16 2018 ] Training epoch: 5796
[ Wed Apr 25 16:40:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:20 2018 ] Training epoch: 5797
[ Wed Apr 25 16:40:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:24 2018 ] Training epoch: 5798
[ Wed Apr 25 16:40:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:28 2018 ] Training epoch: 5799
[ Wed Apr 25 16:40:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:32 2018 ] Training epoch: 5800
[ Wed Apr 25 16:40:36 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:36 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:36 2018 ] Eval epoch: 5800
[ Wed Apr 25 16:40:39 2018 ] 	Mean test loss of 1 batches: 0.22523276507854462.
[ Wed Apr 25 16:40:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:40:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:40:39 2018 ] Training epoch: 5801
[ Wed Apr 25 16:40:43 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:40:43 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:40:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:43 2018 ] Training epoch: 5802
[ Wed Apr 25 16:40:47 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:47 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:47 2018 ] Training epoch: 5803
[ Wed Apr 25 16:40:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:40:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:40:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:51 2018 ] Training epoch: 5804
[ Wed Apr 25 16:40:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:40:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:40:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:55 2018 ] Training epoch: 5805
[ Wed Apr 25 16:40:59 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:40:59 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:40:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:40:59 2018 ] Eval epoch: 5805
[ Wed Apr 25 16:41:02 2018 ] 	Mean test loss of 1 batches: 0.2374374121427536.
[ Wed Apr 25 16:41:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:41:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:41:02 2018 ] Training epoch: 5806
[ Wed Apr 25 16:41:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:41:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:41:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:06 2018 ] Training epoch: 5807
[ Wed Apr 25 16:41:10 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:41:10 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:41:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:10 2018 ] Training epoch: 5808
[ Wed Apr 25 16:41:14 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:41:14 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:41:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:14 2018 ] Training epoch: 5809
[ Wed Apr 25 16:41:18 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:41:18 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:41:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:18 2018 ] Training epoch: 5810
[ Wed Apr 25 16:41:22 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:41:22 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:41:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:22 2018 ] Eval epoch: 5810
[ Wed Apr 25 16:41:25 2018 ] 	Mean test loss of 1 batches: 0.23543022572994232.
[ Wed Apr 25 16:41:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:41:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:41:25 2018 ] Training epoch: 5811
[ Wed Apr 25 16:41:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:41:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:41:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:29 2018 ] Training epoch: 5812
[ Wed Apr 25 16:41:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:41:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:41:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:33 2018 ] Training epoch: 5813
[ Wed Apr 25 16:41:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:41:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:41:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:37 2018 ] Training epoch: 5814
[ Wed Apr 25 16:41:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:41:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:41:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:41 2018 ] Training epoch: 5815
[ Wed Apr 25 16:41:45 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:41:45 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:41:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:45 2018 ] Eval epoch: 5815
[ Wed Apr 25 16:41:48 2018 ] 	Mean test loss of 1 batches: 0.23536473512649536.
[ Wed Apr 25 16:41:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:41:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:41:48 2018 ] Training epoch: 5816
[ Wed Apr 25 16:41:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:41:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:41:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:52 2018 ] Training epoch: 5817
[ Wed Apr 25 16:41:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:41:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:41:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:41:56 2018 ] Training epoch: 5818
[ Wed Apr 25 16:42:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:42:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:42:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:00 2018 ] Training epoch: 5819
[ Wed Apr 25 16:42:04 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:04 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:04 2018 ] Training epoch: 5820
[ Wed Apr 25 16:42:08 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:42:08 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:42:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:08 2018 ] Eval epoch: 5820
[ Wed Apr 25 16:42:11 2018 ] 	Mean test loss of 1 batches: 0.2403704822063446.
[ Wed Apr 25 16:42:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:42:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:42:11 2018 ] Training epoch: 5821
[ Wed Apr 25 16:42:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:42:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:42:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:15 2018 ] Training epoch: 5822
[ Wed Apr 25 16:42:20 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 16:42:20 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 16:42:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:20 2018 ] Training epoch: 5823
[ Wed Apr 25 16:42:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:24 2018 ] Training epoch: 5824
[ Wed Apr 25 16:42:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:42:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:42:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:28 2018 ] Training epoch: 5825
[ Wed Apr 25 16:42:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:42:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:42:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:32 2018 ] Eval epoch: 5825
[ Wed Apr 25 16:42:34 2018 ] 	Mean test loss of 1 batches: 0.21862050890922546.
[ Wed Apr 25 16:42:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:42:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:42:34 2018 ] Training epoch: 5826
[ Wed Apr 25 16:42:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:38 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:38 2018 ] Training epoch: 5827
[ Wed Apr 25 16:42:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:42:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:42:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:43 2018 ] Training epoch: 5828
[ Wed Apr 25 16:42:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:47 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:42:47 2018 ] Training epoch: 5829
[ Wed Apr 25 16:42:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:51 2018 ] Training epoch: 5830
[ Wed Apr 25 16:42:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:42:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:42:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:42:55 2018 ] Eval epoch: 5830
[ Wed Apr 25 16:42:58 2018 ] 	Mean test loss of 1 batches: 0.21683810651302338.
[ Wed Apr 25 16:42:58 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:42:58 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:42:58 2018 ] Training epoch: 5831
[ Wed Apr 25 16:43:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:02 2018 ] Training epoch: 5832
[ Wed Apr 25 16:43:06 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:43:06 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:43:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:06 2018 ] Training epoch: 5833
[ Wed Apr 25 16:43:10 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:43:10 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:43:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:10 2018 ] Training epoch: 5834
[ Wed Apr 25 16:43:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:14 2018 ] Training epoch: 5835
[ Wed Apr 25 16:43:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:43:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:43:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:18 2018 ] Eval epoch: 5835
[ Wed Apr 25 16:43:21 2018 ] 	Mean test loss of 1 batches: 0.21320368349552155.
[ Wed Apr 25 16:43:21 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:43:21 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:43:21 2018 ] Training epoch: 5836
[ Wed Apr 25 16:43:25 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:43:25 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:43:25 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:43:25 2018 ] Training epoch: 5837
[ Wed Apr 25 16:43:29 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:29 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:29 2018 ] Training epoch: 5838
[ Wed Apr 25 16:43:33 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:43:33 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:43:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:33 2018 ] Training epoch: 5839
[ Wed Apr 25 16:43:37 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:37 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:37 2018 ] Training epoch: 5840
[ Wed Apr 25 16:43:41 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:41 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:41 2018 ] Eval epoch: 5840
[ Wed Apr 25 16:43:44 2018 ] 	Mean test loss of 1 batches: 0.20817480981349945.
[ Wed Apr 25 16:43:44 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:43:44 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:43:44 2018 ] Training epoch: 5841
[ Wed Apr 25 16:43:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:43:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:43:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:48 2018 ] Training epoch: 5842
[ Wed Apr 25 16:43:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:43:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:43:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:52 2018 ] Training epoch: 5843
[ Wed Apr 25 16:43:56 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:43:56 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:43:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:43:56 2018 ] Training epoch: 5844
[ Wed Apr 25 16:44:00 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:44:00 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:44:00 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:44:00 2018 ] Training epoch: 5845
[ Wed Apr 25 16:44:04 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:04 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:04 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:04 2018 ] Eval epoch: 5845
[ Wed Apr 25 16:44:07 2018 ] 	Mean test loss of 1 batches: 0.21071071922779083.
[ Wed Apr 25 16:44:07 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:44:07 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:44:07 2018 ] Training epoch: 5846
[ Wed Apr 25 16:44:11 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:44:11 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:44:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:11 2018 ] Training epoch: 5847
[ Wed Apr 25 16:44:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:44:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:44:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:15 2018 ] Training epoch: 5848
[ Wed Apr 25 16:44:19 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:19 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:19 2018 ] Training epoch: 5849
[ Wed Apr 25 16:44:23 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:23 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:23 2018 ] Training epoch: 5850
[ Wed Apr 25 16:44:27 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:44:27 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:44:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:27 2018 ] Eval epoch: 5850
[ Wed Apr 25 16:44:30 2018 ] 	Mean test loss of 1 batches: 0.21997115015983582.
[ Wed Apr 25 16:44:30 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:44:30 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:44:30 2018 ] Training epoch: 5851
[ Wed Apr 25 16:44:34 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:34 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:34 2018 ] Training epoch: 5852
[ Wed Apr 25 16:44:38 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:38 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:38 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:44:38 2018 ] Training epoch: 5853
[ Wed Apr 25 16:44:42 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:44:42 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:44:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:42 2018 ] Training epoch: 5854
[ Wed Apr 25 16:44:46 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:44:46 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:44:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:46 2018 ] Training epoch: 5855
[ Wed Apr 25 16:44:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:44:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:44:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:50 2018 ] Eval epoch: 5855
[ Wed Apr 25 16:44:53 2018 ] 	Mean test loss of 1 batches: 0.22483839094638824.
[ Wed Apr 25 16:44:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:44:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:44:53 2018 ] Training epoch: 5856
[ Wed Apr 25 16:44:57 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:44:57 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:44:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:44:57 2018 ] Training epoch: 5857
[ Wed Apr 25 16:45:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:45:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:45:01 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:45:01 2018 ] Training epoch: 5858
[ Wed Apr 25 16:45:05 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:45:05 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:45:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:05 2018 ] Training epoch: 5859
[ Wed Apr 25 16:45:10 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:45:10 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:45:10 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:45:10 2018 ] Training epoch: 5860
[ Wed Apr 25 16:45:14 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:45:14 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:45:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:14 2018 ] Eval epoch: 5860
[ Wed Apr 25 16:45:17 2018 ] 	Mean test loss of 1 batches: 0.22426742315292358.
[ Wed Apr 25 16:45:17 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:45:17 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:45:17 2018 ] Training epoch: 5861
[ Wed Apr 25 16:45:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:20 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:45:20 2018 ] Training epoch: 5862
[ Wed Apr 25 16:45:24 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:45:24 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:45:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:24 2018 ] Training epoch: 5863
[ Wed Apr 25 16:45:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:28 2018 ] Training epoch: 5864
[ Wed Apr 25 16:45:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:33 2018 ] 	Time consumption: [Data]77%, [Network]22%
[ Wed Apr 25 16:45:33 2018 ] Training epoch: 5865
[ Wed Apr 25 16:45:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:37 2018 ] Eval epoch: 5865
[ Wed Apr 25 16:45:40 2018 ] 	Mean test loss of 1 batches: 0.22769244015216827.
[ Wed Apr 25 16:45:40 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:45:40 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:45:40 2018 ] Training epoch: 5866
[ Wed Apr 25 16:45:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:45:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:45:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:44 2018 ] Training epoch: 5867
[ Wed Apr 25 16:45:48 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:48 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:48 2018 ] Training epoch: 5868
[ Wed Apr 25 16:45:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:45:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:45:52 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:45:52 2018 ] Training epoch: 5869
[ Wed Apr 25 16:45:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:45:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:45:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:45:56 2018 ] Training epoch: 5870
[ Wed Apr 25 16:46:00 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:00 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:01 2018 ] Eval epoch: 5870
[ Wed Apr 25 16:46:03 2018 ] 	Mean test loss of 1 batches: 0.23131050169467926.
[ Wed Apr 25 16:46:03 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:46:03 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:46:03 2018 ] Training epoch: 5871
[ Wed Apr 25 16:46:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:46:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:46:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:07 2018 ] Training epoch: 5872
[ Wed Apr 25 16:46:11 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:46:11 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:46:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:11 2018 ] Training epoch: 5873
[ Wed Apr 25 16:46:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:46:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:46:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:15 2018 ] Training epoch: 5874
[ Wed Apr 25 16:46:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:20 2018 ] Training epoch: 5875
[ Wed Apr 25 16:46:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:24 2018 ] Eval epoch: 5875
[ Wed Apr 25 16:46:26 2018 ] 	Mean test loss of 1 batches: 0.24254542589187622.
[ Wed Apr 25 16:46:26 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:46:26 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:46:26 2018 ] Training epoch: 5876
[ Wed Apr 25 16:46:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:31 2018 ] Training epoch: 5877
[ Wed Apr 25 16:46:35 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:46:35 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:46:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:35 2018 ] Training epoch: 5878
[ Wed Apr 25 16:46:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:46:39 2018 ] Training epoch: 5879
[ Wed Apr 25 16:46:43 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:43 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:43 2018 ] Training epoch: 5880
[ Wed Apr 25 16:46:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:46:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:46:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:47 2018 ] Eval epoch: 5880
[ Wed Apr 25 16:46:50 2018 ] 	Mean test loss of 1 batches: 0.23450717329978943.
[ Wed Apr 25 16:46:50 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:46:50 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:46:50 2018 ] Training epoch: 5881
[ Wed Apr 25 16:46:54 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:46:54 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:46:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:54 2018 ] Training epoch: 5882
[ Wed Apr 25 16:46:58 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:46:58 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:46:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:46:58 2018 ] Training epoch: 5883
[ Wed Apr 25 16:47:02 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:02 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:47:02 2018 ] Training epoch: 5884
[ Wed Apr 25 16:47:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:47:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:47:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:06 2018 ] Training epoch: 5885
[ Wed Apr 25 16:47:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:47:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:47:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:10 2018 ] Eval epoch: 5885
[ Wed Apr 25 16:47:13 2018 ] 	Mean test loss of 1 batches: 0.2317029982805252.
[ Wed Apr 25 16:47:13 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:47:13 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:47:13 2018 ] Training epoch: 5886
[ Wed Apr 25 16:47:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:47:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:47:17 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:47:17 2018 ] Training epoch: 5887
[ Wed Apr 25 16:47:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:21 2018 ] Training epoch: 5888
[ Wed Apr 25 16:47:25 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:47:25 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:47:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:25 2018 ] Training epoch: 5889
[ Wed Apr 25 16:47:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:29 2018 ] Training epoch: 5890
[ Wed Apr 25 16:47:33 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:33 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:33 2018 ] Eval epoch: 5890
[ Wed Apr 25 16:47:36 2018 ] 	Mean test loss of 1 batches: 0.22816139459609985.
[ Wed Apr 25 16:47:36 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:47:36 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:47:36 2018 ] Training epoch: 5891
[ Wed Apr 25 16:47:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:40 2018 ] Training epoch: 5892
[ Wed Apr 25 16:47:44 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:47:44 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:47:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:44 2018 ] Training epoch: 5893
[ Wed Apr 25 16:47:48 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:47:48 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:47:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:48 2018 ] Training epoch: 5894
[ Wed Apr 25 16:47:52 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:47:52 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:47:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:52 2018 ] Training epoch: 5895
[ Wed Apr 25 16:47:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:47:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:47:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:47:56 2018 ] Eval epoch: 5895
[ Wed Apr 25 16:47:59 2018 ] 	Mean test loss of 1 batches: 0.22504691779613495.
[ Wed Apr 25 16:47:59 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:47:59 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:47:59 2018 ] Training epoch: 5896
[ Wed Apr 25 16:48:03 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:48:03 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:48:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:03 2018 ] Training epoch: 5897
[ Wed Apr 25 16:48:07 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:48:07 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:48:07 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:07 2018 ] Training epoch: 5898
[ Wed Apr 25 16:48:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:48:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:48:11 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:11 2018 ] Training epoch: 5899
[ Wed Apr 25 16:48:15 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:48:15 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:48:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:15 2018 ] Training epoch: 5900
[ Wed Apr 25 16:48:19 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:48:19 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:48:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:19 2018 ] Eval epoch: 5900
[ Wed Apr 25 16:48:22 2018 ] 	Mean test loss of 1 batches: 0.22863543033599854.
[ Wed Apr 25 16:48:22 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:48:22 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:48:22 2018 ] Training epoch: 5901
[ Wed Apr 25 16:48:26 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:48:26 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:48:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:26 2018 ] Training epoch: 5902
[ Wed Apr 25 16:48:30 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:48:30 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:48:30 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:48:30 2018 ] Training epoch: 5903
[ Wed Apr 25 16:48:34 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:48:34 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:48:34 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:34 2018 ] Training epoch: 5904
[ Wed Apr 25 16:48:39 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:48:39 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:48:39 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:39 2018 ] Training epoch: 5905
[ Wed Apr 25 16:48:43 2018 ] 	Batch(0/1) done. Loss: 0.0006  lr:0.000010
[ Wed Apr 25 16:48:43 2018 ] 	Mean training loss: 0.0006.
[ Wed Apr 25 16:48:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:43 2018 ] Eval epoch: 5905
[ Wed Apr 25 16:48:45 2018 ] 	Mean test loss of 1 batches: 0.21646544337272644.
[ Wed Apr 25 16:48:45 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:48:45 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:48:45 2018 ] Training epoch: 5906
[ Wed Apr 25 16:48:49 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:48:49 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:48:49 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:49 2018 ] Training epoch: 5907
[ Wed Apr 25 16:48:53 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:48:53 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:48:53 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:53 2018 ] Training epoch: 5908
[ Wed Apr 25 16:48:57 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:48:57 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:48:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:48:57 2018 ] Training epoch: 5909
[ Wed Apr 25 16:49:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:02 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:49:02 2018 ] Training epoch: 5910
[ Wed Apr 25 16:49:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:49:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:49:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:06 2018 ] Eval epoch: 5910
[ Wed Apr 25 16:49:09 2018 ] 	Mean test loss of 1 batches: 0.22407501935958862.
[ Wed Apr 25 16:49:09 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:49:09 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:49:09 2018 ] Training epoch: 5911
[ Wed Apr 25 16:49:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:13 2018 ] Training epoch: 5912
[ Wed Apr 25 16:49:17 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:49:17 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:49:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:17 2018 ] Training epoch: 5913
[ Wed Apr 25 16:49:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:49:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:49:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:21 2018 ] Training epoch: 5914
[ Wed Apr 25 16:49:25 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:25 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:25 2018 ] Training epoch: 5915
[ Wed Apr 25 16:49:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:49:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:49:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:29 2018 ] Eval epoch: 5915
[ Wed Apr 25 16:49:32 2018 ] 	Mean test loss of 1 batches: 0.21579907834529877.
[ Wed Apr 25 16:49:32 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:49:32 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:49:32 2018 ] Training epoch: 5916
[ Wed Apr 25 16:49:36 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:49:36 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:49:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:36 2018 ] Training epoch: 5917
[ Wed Apr 25 16:49:40 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:40 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:40 2018 ] Training epoch: 5918
[ Wed Apr 25 16:49:44 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:44 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:44 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:44 2018 ] Training epoch: 5919
[ Wed Apr 25 16:49:48 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:48 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:48 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:48 2018 ] Training epoch: 5920
[ Wed Apr 25 16:49:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:49:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:49:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:52 2018 ] Eval epoch: 5920
[ Wed Apr 25 16:49:55 2018 ] 	Mean test loss of 1 batches: 0.21058174967765808.
[ Wed Apr 25 16:49:55 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:49:55 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:49:55 2018 ] Training epoch: 5921
[ Wed Apr 25 16:49:59 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:49:59 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:49:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:49:59 2018 ] Training epoch: 5922
[ Wed Apr 25 16:50:03 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:03 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:03 2018 ] Training epoch: 5923
[ Wed Apr 25 16:50:07 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:07 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:07 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:50:07 2018 ] Training epoch: 5924
[ Wed Apr 25 16:50:11 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:50:11 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:50:11 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:50:11 2018 ] Training epoch: 5925
[ Wed Apr 25 16:50:15 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:50:15 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:50:15 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:15 2018 ] Eval epoch: 5925
[ Wed Apr 25 16:50:18 2018 ] 	Mean test loss of 1 batches: 0.21716783940792084.
[ Wed Apr 25 16:50:18 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:50:18 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:50:18 2018 ] Training epoch: 5926
[ Wed Apr 25 16:50:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:22 2018 ] Training epoch: 5927
[ Wed Apr 25 16:50:26 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:26 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:26 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:26 2018 ] Training epoch: 5928
[ Wed Apr 25 16:50:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:50:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:50:31 2018 ] 	Time consumption: [Data]76%, [Network]23%
[ Wed Apr 25 16:50:31 2018 ] Training epoch: 5929
[ Wed Apr 25 16:50:35 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:50:35 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:50:35 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:35 2018 ] Training epoch: 5930
[ Wed Apr 25 16:50:39 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:50:39 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:50:39 2018 ] 	Time consumption: [Data]79%, [Network]21%
[ Wed Apr 25 16:50:39 2018 ] Eval epoch: 5930
[ Wed Apr 25 16:50:42 2018 ] 	Mean test loss of 1 batches: 0.2170557677745819.
[ Wed Apr 25 16:50:42 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:50:42 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:50:42 2018 ] Training epoch: 5931
[ Wed Apr 25 16:50:46 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:46 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:46 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:46 2018 ] Training epoch: 5932
[ Wed Apr 25 16:50:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:50:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:50:50 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:50 2018 ] Training epoch: 5933
[ Wed Apr 25 16:50:54 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:50:54 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:50:54 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:54 2018 ] Training epoch: 5934
[ Wed Apr 25 16:50:58 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:50:58 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:50:58 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:50:58 2018 ] Training epoch: 5935
[ Wed Apr 25 16:51:02 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:51:02 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:51:02 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:02 2018 ] Eval epoch: 5935
[ Wed Apr 25 16:51:05 2018 ] 	Mean test loss of 1 batches: 0.2207515686750412.
[ Wed Apr 25 16:51:05 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:51:05 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:51:05 2018 ] Training epoch: 5936
[ Wed Apr 25 16:51:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:09 2018 ] Training epoch: 5937
[ Wed Apr 25 16:51:13 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:51:13 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:51:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:13 2018 ] Training epoch: 5938
[ Wed Apr 25 16:51:17 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:51:17 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:51:17 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:17 2018 ] Training epoch: 5939
[ Wed Apr 25 16:51:21 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:21 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:21 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:21 2018 ] Training epoch: 5940
[ Wed Apr 25 16:51:25 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:51:25 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:51:25 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:25 2018 ] Eval epoch: 5940
[ Wed Apr 25 16:51:28 2018 ] 	Mean test loss of 1 batches: 0.21377632021903992.
[ Wed Apr 25 16:51:28 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:51:28 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:51:28 2018 ] Training epoch: 5941
[ Wed Apr 25 16:51:33 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:51:33 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:51:33 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:51:33 2018 ] Training epoch: 5942
[ Wed Apr 25 16:51:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:37 2018 ] Training epoch: 5943
[ Wed Apr 25 16:51:41 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:41 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:41 2018 ] Training epoch: 5944
[ Wed Apr 25 16:51:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:51:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:51:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:45 2018 ] Training epoch: 5945
[ Wed Apr 25 16:51:50 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:50 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:50 2018 ] 	Time consumption: [Data]80%, [Network]20%
[ Wed Apr 25 16:51:50 2018 ] Eval epoch: 5945
[ Wed Apr 25 16:51:53 2018 ] 	Mean test loss of 1 batches: 0.22032879292964935.
[ Wed Apr 25 16:51:53 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:51:53 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:51:53 2018 ] Training epoch: 5946
[ Wed Apr 25 16:51:57 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:51:57 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:51:57 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:51:57 2018 ] Training epoch: 5947
[ Wed Apr 25 16:52:01 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:01 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:01 2018 ] Training epoch: 5948
[ Wed Apr 25 16:52:05 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:05 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:05 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:05 2018 ] Training epoch: 5949
[ Wed Apr 25 16:52:09 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:09 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:09 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:09 2018 ] Training epoch: 5950
[ Wed Apr 25 16:52:13 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:13 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:13 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:13 2018 ] Eval epoch: 5950
[ Wed Apr 25 16:52:16 2018 ] 	Mean test loss of 1 batches: 0.218734472990036.
[ Wed Apr 25 16:52:16 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:52:16 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:52:16 2018 ] Training epoch: 5951
[ Wed Apr 25 16:52:20 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:20 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:20 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:20 2018 ] Training epoch: 5952
[ Wed Apr 25 16:52:24 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:24 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:24 2018 ] Training epoch: 5953
[ Wed Apr 25 16:52:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:28 2018 ] Training epoch: 5954
[ Wed Apr 25 16:52:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:32 2018 ] Training epoch: 5955
[ Wed Apr 25 16:52:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:52:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:52:36 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:36 2018 ] Eval epoch: 5955
[ Wed Apr 25 16:52:39 2018 ] 	Mean test loss of 1 batches: 0.22013923525810242.
[ Wed Apr 25 16:52:39 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:52:39 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:52:39 2018 ] Training epoch: 5956
[ Wed Apr 25 16:52:43 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:52:43 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:52:43 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:43 2018 ] Training epoch: 5957
[ Wed Apr 25 16:52:47 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:52:47 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:52:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:47 2018 ] Training epoch: 5958
[ Wed Apr 25 16:52:51 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:52:51 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:52:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:51 2018 ] Training epoch: 5959
[ Wed Apr 25 16:52:55 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:52:55 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:52:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:55 2018 ] Training epoch: 5960
[ Wed Apr 25 16:52:59 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:52:59 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:52:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:52:59 2018 ] Eval epoch: 5960
[ Wed Apr 25 16:53:02 2018 ] 	Mean test loss of 1 batches: 0.21945346891880035.
[ Wed Apr 25 16:53:02 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:53:02 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:53:02 2018 ] Training epoch: 5961
[ Wed Apr 25 16:53:06 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:53:06 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:53:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:06 2018 ] Training epoch: 5962
[ Wed Apr 25 16:53:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:53:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:53:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:10 2018 ] Training epoch: 5963
[ Wed Apr 25 16:53:14 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:53:14 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:53:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:14 2018 ] Training epoch: 5964
[ Wed Apr 25 16:53:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:53:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:53:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:18 2018 ] Training epoch: 5965
[ Wed Apr 25 16:53:22 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:53:22 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:53:22 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:22 2018 ] Eval epoch: 5965
[ Wed Apr 25 16:53:25 2018 ] 	Mean test loss of 1 batches: 0.21562232077121735.
[ Wed Apr 25 16:53:25 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:53:25 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:53:25 2018 ] Training epoch: 5966
[ Wed Apr 25 16:53:29 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:53:29 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:53:29 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:29 2018 ] Training epoch: 5967
[ Wed Apr 25 16:53:33 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:53:33 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:53:33 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:33 2018 ] Training epoch: 5968
[ Wed Apr 25 16:53:37 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:53:37 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:53:37 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:37 2018 ] Training epoch: 5969
[ Wed Apr 25 16:53:41 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:53:41 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:53:41 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:41 2018 ] Training epoch: 5970
[ Wed Apr 25 16:53:45 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:53:45 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:53:45 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:45 2018 ] Eval epoch: 5970
[ Wed Apr 25 16:53:48 2018 ] 	Mean test loss of 1 batches: 0.22563470900058746.
[ Wed Apr 25 16:53:48 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:53:48 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:53:48 2018 ] Training epoch: 5971
[ Wed Apr 25 16:53:52 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:53:52 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:53:52 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:52 2018 ] Training epoch: 5972
[ Wed Apr 25 16:53:56 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:53:56 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:53:56 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:53:56 2018 ] Training epoch: 5973
[ Wed Apr 25 16:54:00 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:54:00 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:54:00 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:00 2018 ] Training epoch: 5974
[ Wed Apr 25 16:54:04 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:54:04 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:54:04 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:54:04 2018 ] Training epoch: 5975
[ Wed Apr 25 16:54:08 2018 ] 	Batch(0/1) done. Loss: 0.0005  lr:0.000010
[ Wed Apr 25 16:54:08 2018 ] 	Mean training loss: 0.0005.
[ Wed Apr 25 16:54:08 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:08 2018 ] Eval epoch: 5975
[ Wed Apr 25 16:54:11 2018 ] 	Mean test loss of 1 batches: 0.2144174426794052.
[ Wed Apr 25 16:54:11 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:54:11 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:54:11 2018 ] Training epoch: 5976
[ Wed Apr 25 16:54:15 2018 ] 	Batch(0/1) done. Loss: 0.0004  lr:0.000010
[ Wed Apr 25 16:54:15 2018 ] 	Mean training loss: 0.0004.
[ Wed Apr 25 16:54:15 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:54:15 2018 ] Training epoch: 5977
[ Wed Apr 25 16:54:19 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:19 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:19 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:19 2018 ] Training epoch: 5978
[ Wed Apr 25 16:54:23 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:23 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:23 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:23 2018 ] Training epoch: 5979
[ Wed Apr 25 16:54:27 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:27 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:27 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:27 2018 ] Training epoch: 5980
[ Wed Apr 25 16:54:31 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:54:31 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:54:31 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:31 2018 ] Eval epoch: 5980
[ Wed Apr 25 16:54:34 2018 ] 	Mean test loss of 1 batches: 0.22285640239715576.
[ Wed Apr 25 16:54:34 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:54:34 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:54:34 2018 ] Training epoch: 5981
[ Wed Apr 25 16:54:38 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:38 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:39 2018 ] 	Time consumption: [Data]78%, [Network]22%
[ Wed Apr 25 16:54:39 2018 ] Training epoch: 5982
[ Wed Apr 25 16:54:42 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:54:42 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:54:42 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:42 2018 ] Training epoch: 5983
[ Wed Apr 25 16:54:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:47 2018 ] Training epoch: 5984
[ Wed Apr 25 16:54:51 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:54:51 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:54:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:54:51 2018 ] Training epoch: 5985
[ Wed Apr 25 16:54:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:54:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:54:55 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:54:55 2018 ] Eval epoch: 5985
[ Wed Apr 25 16:54:57 2018 ] 	Mean test loss of 1 batches: 0.21861401200294495.
[ Wed Apr 25 16:54:57 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:54:57 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:54:57 2018 ] Training epoch: 5986
[ Wed Apr 25 16:55:01 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:01 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:01 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:01 2018 ] Training epoch: 5987
[ Wed Apr 25 16:55:06 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:06 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:06 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:06 2018 ] Training epoch: 5988
[ Wed Apr 25 16:55:10 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:10 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:10 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:10 2018 ] Training epoch: 5989
[ Wed Apr 25 16:55:14 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:14 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:14 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:14 2018 ] Training epoch: 5990
[ Wed Apr 25 16:55:18 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:55:18 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:55:18 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:18 2018 ] Eval epoch: 5990
[ Wed Apr 25 16:55:20 2018 ] 	Mean test loss of 1 batches: 0.21469813585281372.
[ Wed Apr 25 16:55:20 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:55:20 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:55:20 2018 ] Training epoch: 5991
[ Wed Apr 25 16:55:24 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:55:24 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:55:24 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:24 2018 ] Training epoch: 5992
[ Wed Apr 25 16:55:28 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:55:28 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:55:28 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:28 2018 ] Training epoch: 5993
[ Wed Apr 25 16:55:32 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:55:32 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:55:32 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:32 2018 ] Training epoch: 5994
[ Wed Apr 25 16:55:36 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:36 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:36 2018 ] 	Time consumption: [Data]76%, [Network]24%
[ Wed Apr 25 16:55:36 2018 ] Training epoch: 5995
[ Wed Apr 25 16:55:40 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:55:40 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:55:40 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:40 2018 ] Eval epoch: 5995
[ Wed Apr 25 16:55:43 2018 ] 	Mean test loss of 1 batches: 0.22129689157009125.
[ Wed Apr 25 16:55:43 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:55:43 2018 ] 	Top5: 100.00%
[ Wed Apr 25 16:55:43 2018 ] Training epoch: 5996
[ Wed Apr 25 16:55:47 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:47 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:47 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:47 2018 ] Training epoch: 5997
[ Wed Apr 25 16:55:51 2018 ] 	Batch(0/1) done. Loss: 0.0009  lr:0.000010
[ Wed Apr 25 16:55:51 2018 ] 	Mean training loss: 0.0009.
[ Wed Apr 25 16:55:51 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:51 2018 ] Training epoch: 5998
[ Wed Apr 25 16:55:55 2018 ] 	Batch(0/1) done. Loss: 0.0001  lr:0.000010
[ Wed Apr 25 16:55:55 2018 ] 	Mean training loss: 0.0001.
[ Wed Apr 25 16:55:55 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:55 2018 ] Training epoch: 5999
[ Wed Apr 25 16:55:59 2018 ] 	Batch(0/1) done. Loss: 0.0002  lr:0.000010
[ Wed Apr 25 16:55:59 2018 ] 	Mean training loss: 0.0002.
[ Wed Apr 25 16:55:59 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:55:59 2018 ] Training epoch: 6000
[ Wed Apr 25 16:56:03 2018 ] 	Batch(0/1) done. Loss: 0.0003  lr:0.000010
[ Wed Apr 25 16:56:03 2018 ] 	Mean training loss: 0.0003.
[ Wed Apr 25 16:56:03 2018 ] 	Time consumption: [Data]77%, [Network]23%
[ Wed Apr 25 16:56:03 2018 ] Eval epoch: 6000
[ Wed Apr 25 16:56:06 2018 ] 	Mean test loss of 1 batches: 0.2195865660905838.
[ Wed Apr 25 16:56:06 2018 ] 	Top1: 92.59%
[ Wed Apr 25 16:56:06 2018 ] 	Top5: 100.00%
